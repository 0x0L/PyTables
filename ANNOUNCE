Announcing PyTables 0.4
-----------------------

What's new
-----------

- First beta release (programming API is stable)
- numarray objects (NumArray, CharArray and RecArray) supported
- Performance has been improved by a factor of 10 (see "How Fast Is It?")
- It consumes far less memory than previous version
- Support for reading generic HDF5 files added (!)
- Some bugs and memory leaks existing in 0.2 solved
- Updated documentation
- Added more unit tests (more than 200 now!)

What it is
----------

In short, PyTables provides a powerful and Pythonic interface to
process table and array data.

Its goal is to enable the end user to manipulate easily scientific
data tables and Numerical and numarray Python objects in a persistent
hierarchical structure. The foundation of the underlying hierarchical
data organization is the excellent HDF5 library
(http://hdf.ncsa.uiuc.edu/HDF5).

A table is defined as a collection of records whose values are stored
in fixed-length fields. All records have the same structure and all
values in each field have the same data type.  The terms
"fixed-length" and strict "data types" seems to be quite a strange
requirement for an interpreted language like Python, but they serve a
useful function if the goal is to save very large quantities of data
(such as is generated by many scientific applications, for example) in
an efficient manner that reduces demand on CPU time and I/O resources.

Quite a bit effort has been invested to make browsing the hierarchical
data structure a pleasant experience. PyTables implements just two
(orthogonal) easy-to-use methods for browsing.

What is HDF5?
-------------

For those people who know nothing about HDF5, it is is a general
purpose library and file format for storing scientific data made at
NCSA. HDF5 can store two primary objects: datasets and groups. A
dataset is essentially a multidimensional array of data elements, and
a group is a structure for organizing objects in an HDF5 file. Using
these two basic constructs, one can create and store almost any kind of
scientific data structure, such as images, arrays of vectors, and
structured and unstructured grids. You can also mix and match them in
HDF5 files according to your needs.

How fast is it?
---------------

PyTables can write table records between 20 and 30 times faster than
cPickle and between 3 and 10 times faster than struct (it is a module
present in the Standard Library); and retrieves information around 100
times faster than cPickle and between 8 and 10 times faster than
struct.

When compared with SQLite, one of the fastest (free) relational
databases available, PyTables achieves between a 60% and 80% the speed
of SQLite during selects of dataset sizes that fit in the
O.S. filesystem memory cache, but when those sizes does not fit on the
cache (i.e. when dealing whith large amounts of data), PyTables beats
SQLite by a factor of 2 or even more (depending on the kind of record
selected), and its performance in this case is only limited by the I/O
speed of the disk subsystem.

Go to http://pytables.sf.net/bench.html for a somewhat more detailed
description of this small (and synthetic) benchmark.

Platforms
---------

I'm using Linux as the main development platform, but PyTables should
be easy to compile/install on other UNIX machines. This package has
also passed all the tests on a UltraSparc platform with Solaris 7. It
also compiles and passes all the tests on a SGI Origin2000 with MIPS
R12000 processors and running IRIX 6.5.

If you are using Windows and you get the library to work, please let
me know.

An example?
-----------

At the bottom of this message there is some code (less that 100 lines
and only less than half being real code) that shows basic capabilities
of PyTables.

Web site
--------

Go to the PyTables web site for more details:

http://pytables.sf.net/

Final note
----------

This is the second alpha release, probably last alpha. There is still
if you want to suggest some API or useful capability addition or. Let
me know of any bugs, suggestions, gripes, kudos, etc. you may have.

-- Francesc Alted
falted@openlc.org


*-*-*-**-*-*-**-*-*-**-*-*- Small code example  *-*-*-**-*-*-**-*-*-**-*-*-*
"""Small but quite comprehensive example showing the use of PyTables.

The program creates an output file, 'tutorial1.h5'.  You can view it
with any HDF5 generic utility.

"""


import sys
from Numeric import *
from tables import *


	#'-**-**-**-**-**-**- user record definition  -**-**-**-**-**-**-**-'

# Define a user record to characterize some kind of particles
class Particle(IsDescription):
    name      = Col('CharType', 16)  # 16-character String
    idnumber  = Col("UInt64", 1)     # Unsigned long long 
    ADCcount  = Col("UInt16", 1)     # Unsigned short integer
    TDCcount  = Col("UInt8", 1)      # unsigned byte
    grid_i    = Col("Int32", 1)      # integer
    grid_j    = Col("Int32", 1)      # integer
    pressure  = Col("Float32", 1)    # float  (single-precision)
    energy    = Col("Float64", 1)    # double (double-precision)

print
print	'-**-**-**-**-**-**- file creation  -**-**-**-**-**-**-**-'

# The name of our HDF5 filename
filename = "tutorial1.h5"
    
print "Creating file:", filename

# Open a file in "w"rite mode
h5file = openFile(filename, mode = "w", title = "Test file")

print
print	'-**-**-**-**-**-**- group an table creation  -**-**-**-**-**-**-**-'

# Create a new group under "/" (root)
group = h5file.createGroup("/", 'detector', 'Detector information')
print "Group '/detector' created"

# Create one table on it
table = h5file.createTable(group, 'readout', Particle, "Readout example")
print "Table '/detector/readout' created"

# Get a shortcut to the record object in table
particle = table.row

# Fill the table with 10 particles
for i in xrange(10):
    particle['name']  = 'Particle: %6d' % (i)
    particle['TDCcount'] = i % 256    
    particle['ADCcount'] = (i * 256) % (1 << 16)
    particle['grid_i'] = i 
    particle['grid_j'] = 10 - i
    particle['pressure'] = float(i*i)
    particle['energy'] = float(particle['pressure'] ** 4)
    particle['idnumber'] = i * (2 ** 34)
    # Insert a new particle record
    particle.append()

# Flush the buffers for table
table.flush()

print
print	'-**-**-**-**-**-**- table data reading & selection  -**-**-**-**-**-'

# Read actual data from table. We are interested in collecting pressure values
# on entries where TDCcount field is greater than 3 and pressure less than 50
pressure = [ x['pressure'] for x in table.iterrows()
             if x['TDCcount'] > 3 and x['pressure'] < 50 ]
print "Last record read:"
print x
print "Field pressure elements satisfying the cuts ==>", pressure

# Read also the names with the same cuts
names = [ x['name'] for x in table.iterrows()
          if x['TDCcount'] > 3 and x['pressure'] < 50 ]

print
print	'-**-**-**-**-**-**- array object creation  -**-**-**-**-**-**-**-'

print "Creating a new group called '/columns' to hold new arrays"
gcolumns = h5file.createGroup(h5file.root, "columns", "Pressure and Name")

print "Creating a Numeric array called 'pressure' under '/columns' group"
h5file.createArray(gcolumns, 'pressure', array(pressure), 
                   "Pressure column selection")

print "Creating another Numeric array called 'name' under '/columns' group"
h5file.createArray('/columns', 'name', names, "Name column selection")

# Close the file
h5file.close()
print "File '"+filename+"' created"

