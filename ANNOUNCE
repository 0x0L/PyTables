Announcing PyTables 0.4.5
-------------------------

This is the second public beta release. On this release you will find
a 20% of improvement over the last public release, some bugs has been
fixed and support for a couple of compression (LZO and UCL) libraries
has been added. And... a Windows version is finally available!.


What's new
-----------

- Second beta release (programming API is stable).

- PyTables has been tested against newest numarray 0.5 and it works
  just fine. It even works well with Python 2.3b1.

- As a consequence of some twiking the write/read performance has been
  improved by a 20% overall (numarray 0.5 performance improvements
  also helped here). Now, the reading speed is reaching its
  theoretical maximum (at least when using Python).

- Support for two new compression libraries: LZO and UCL
  (http://www.oberhumer.com/opensource/). These libraries are made by
  Markus F.X.J. Oberhumer, and they stand for allowing *very* fast
  decompression. Now, if your data is compressible, you can obtain
  better reading speed than if not using compression at all!. The
  improvement is still more noticeable if your are dealing with
  extremely large (and compressible) data sets.

- A couple of memory leaks has been isolated and fixed (it was very
  hard, but finally I succeeded!).

- A bug with column ordering of tables that happens in some special
  situations has been fixed (thanks to Stan Heckman for reporting this
  and suggesting the patch).

- The compression was enabled by default in version 0.4, despite of
  what was stated in the documentation. Now, this has been corrected
  and compression is *disabled* by default.

- When reading a Table object, and the user wants to fetch column
  elements which are unidimensional arrays, a copy is delivered
  automatically to him, so there is no need to make a call to .copy()
  method of the numarray arrays anymore. It think this is more
  comfortable for the user.

- File class has now an 'isopen' attribute in order to check if a file
  is open or not.

- Updated documentation, specially for giving advice about the use of
  the new compression libraries. See "Compression issues" subsection,
  (also on the web:
  http://pytables.sourceforge.net/html-doc/usersguide-html.html)

- Added more unit tests (218 now!)

- And last, but not least, a Windows version is available!. Thanks to
  Alan McIntyre for its porting!. There is even a binary ready for
  click and install.


What it is
----------

In short, PyTables provides a powerful and very Pythonic interface to
process table and array data.

Its goal is to enable the end user to manipulate easily scientific
data tables and Numerical and numarray Python objects in a persistent
hierarchical structure. The foundation of the underlying hierarchical
data organization is the excellent HDF5 library
(http://hdf.ncsa.uiuc.edu/HDF5).

A table is defined as a collection of records whose values are stored
in fixed-length fields. All records have the same structure and all
values in each field have the same data type.  The terms
"fixed-length" and strict "data types" seems to be quite a strange
requirement for an interpreted language like Python, but they serve a
useful function if the goal is to save very large quantities of data
(such as is generated by many scientific applications, for example) in
an efficient manner that reduces demand on CPU time and I/O resources.

Quite a bit effort has been invested to make browsing the hierarchical
data structure a pleasant experience. PyTables implements just two
(orthogonal) easy-to-use methods for browsing.

What is HDF5?
-------------

For those people who know nothing about HDF5, it is is a general
purpose library and file format for storing scientific data made at
NCSA. HDF5 can store two primary objects: datasets and groups. A
dataset is essentially a multidimensional array of data elements, and
a group is a structure for organizing objects in an HDF5 file. Using
these two basic constructs, one can create and store almost any kind of
scientific data structure, such as images, arrays of vectors, and
structured and unstructured grids. You can also mix and match them in
HDF5 files according to your needs.

How fast is it?
---------------

PyTables can write table records between 20 and 30 times faster than
cPickle and between 3 and 10 times faster than struct (it is a module
present in the Standard Library); and retrieves information around 100
times faster than cPickle and between 8 and 10 times faster than
struct.

When compared with SQLite (http://www.sqlite.org/), one of the fastest
(free) relational databases available, PyTables achieves between a 70%
and 90% the speed of SQLite during selects of dataset sizes that fit
in the O.S. filesystem memory cache. However, when those sizes does
not fit in the cache (i.e. when dealing with large amounts of data),
PyTables beats SQLite by a factor of 2 or even more (depending on the
kind of record selected), and its performance in this case is only
limited by the I/O speed of the disk subsystem. Besides, if data is
compressible, the advantage is even better.

Go to http://pytables.sourceforge.net/doc/PyCon.html#section4 for a
detailed description on the conducted benchmarks.

Platforms
---------

I'm using Linux as the main development platform, but PyTables should
be easy to compile/install on other UNIX machines. This package has
also passed all the tests on a UltraSparc platform with Solaris 7 and
Solaris 8. It also compiles and passes all the tests on a SGI
Origin2000 with MIPS R12000 processors and running IRIX 6.5.

With Windows, I've only tested (all the tests passes) PyTables with
XP, but it should work just fine with other flavors.

An example?
-----------

At the bottom of this message there is some code that shows basic
capabilities of PyTables. You may also look at
http://pytables.sourceforge.net/tut/tutorial1-1.html and 
http://pytables.sourceforge.net/tut/tutorial1-2.html
for online code.

Web site
--------

Go to the PyTables web site for more details:

http://pytables.sf.net/

Share your experience
---------------------

Let me know of any bugs, suggestions, gripes, kudos, etc. you may
have.

Have fun!

-- Francesc Alted
falted@openlc.org


*-*-*-**-*-*-**-*-*-**-*-*- Small code example  *-*-*-**-*-*-**-*-*-**-*-*-*
from tables import *

class Particle(IsDescription):
    identity = Col("CharType", 22, " ", pos = 0)  # character String
    idnumber = Col("Int16", 1, pos = 1)  # short integer
    speed = Col("Float32", 1, pos = 1)  # single-precision

# Open a file in "w"rite mode
fileh = openFile("objecttree.h5", mode = "w")
# Get the HDF5 root group
root = fileh.root

# Create the groups:
group1 = fileh.createGroup(root, "group1")
group2 = fileh.createGroup(root, "group2")

# Now, create a table in "group0" group
array1 = fileh.createArray(root, "array1", ["string", "array"], "String array")
# Create 2 new tables in group1
table1 = fileh.createTable(group1, "table1", Particle)
table2 = fileh.createTable("/group2", "table2", Particle)
# Create the last table in group2
array2 = fileh.createArray("/group1", "array2", [1,2,3,4])

# Now, fill the tables:
for table in (table1, table2):
    # Get the record object associated with the table:
    row = table.row
    # Fill the table with 10 records
    for i in xrange(10):
        # First, assign the values to the Particle record
        row['identity']  = 'This is particle: %2d' % (i)
        row['idnumber'] = i
        row['speed']  = i * 2.
        # This injects the Record values
        row.append()

    # Flush the table buffers
    table.flush()

# Select actual data from table.
# on entries where TDCcount field is greater than 3 and pressure less than 50
out = [ x['identity'] for x in table.iterrows()
        if x['idnumber'] > 3 and 4 < x['speed'] < 10 ]

print out

# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
