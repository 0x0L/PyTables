<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE book PUBLIC "-//Torsten Bronger//DTD tbook 1.5//EN"
                      "/usr/local/share/xml/tbook/tbook.dtd">
<book>
  <frontmatter>
    <title><visual markup="tt">PyTables</visual> User's Guide</title>
    <author>Francesc Alted</author>

    <subtitle><visual markup="sf">A hierarchical database for
      Python</visual><newline/> Release 0.7</subtitle>

    <date>2003, July, 31th</date>
    <year>2002, 2003</year>
<!--     <city>Castelló de la Plana, Spain</city> -->
    <typeset>Francesc Alted</typeset>
  </frontmatter>

  <!--  This is only for article
  <abstract>

  <p><visual markup="tt">PyTables</visual> is a Python package whose
    goal is to allow dealing easily, but in a powerful way, with
    scientific data tables and Numerical Python objects organized in a
    hierarchical structure. Such a tables are defined as a collection
    of records whose values are stored in fixed-length fields. As a
    foundation for the underlying hierarchical data organization the
    excellent HDF5 library (http://hdf.ncsa.uiuc.edu/HDF5) has been
    chosen.
  </p>

  <p><visual markup="tt">PyTables</visual> is intended to be
    easy-to-use, and tries to be a high-performance interface to
    HDF5. To achieve this, the newest improvements introduced in
    Python 2.2 (like generators or slots and metaclasses in new-brand
    classes) has been used. Pyrex creation extension tool has been
    chosen to access the HDF5 library.
  </p>

  </abstract> -->

  <mainmatter>

<!--    <chapter kind='preface'> -->
<!--       <heading></heading> -->

    <chapter>
      <heading>Introduction</heading>

      <aphorism>La sabiduría no vale la pena si no es posible servirse
	de ella para inventar una nueva manera de preparar los
	garbanzos.<caption>Un sabio catalán<newline/> in "Cien años de
	soledad"<newline/> Gabriel García Márquez</caption>
      </aphorism>

      <p>The goal of <verb>PyTables</verb> is to enable the end user
	to manipulate easily scientific data <visual
	markup="bf">tables</visual> and array objects objects in a
	hierarchical structure. The foundation of the underlying
	hierarchical data organization is the excellent
	<verb>HDF5</verb> library (see <cite
	refid="HDFWhatIs"></cite>).<!--  Right now, <verb>PyTables</verb> -->
<!-- 	provides limited support for importing generic HDF5 files -->
<!-- 	(i.e., those which were created with other tools than -->
<!-- 	<verb>PyTables</verb>), but I hope to add the more interesting -->
<!-- 	ones as time goes on. Still, I think <verb>PyTables</verb> can -->
<!-- 	read a wide range of such files. -->
      </p>
      <p>
	It is important to remark that this package is not intended to
	serve as a complete wrapper for the entire HDF5 API, but to
	provide a flexible, <em>very Pythonic</em> tool to deal with
	(arbitrary) large amounts of data (typically bigger than
	available memory) in tables and arrays organized in a
	hierarchical, persistent disk storage.
      </p>

      <p>A table is defined as a collection of records whose values
	are stored in <em>fixed-length</em> fields. All records have
	the same structure and all values in each field have the same
	<em>data type</em>. The terms <em>fixed-length</em> and
	strict <em>data types</em> seems to be quite a strange
	requirement for an interpreted language like Python, but they
	serve a useful function if the goal is to save very large
	quantities of data (such as is generated by many scientific
	applications, for example) in an efficient manner that reduces
	demand on CPU time and I/O.
      </p>

      <p>In order to emulate records (that will be mapped to C structs
	in HDF5) in Python <verb>PyTables</verb> implements a special
	<em>metaclass</em> object in order to easily define all its
	fields and other properties.  <verb>PyTables</verb> also
	provides a powerful interface to mine data in table. Records
	in tables are also known, in the <verb>HDF5</verb> naming
	scheme, as <em>compound</em> data types.
      </p>

      <p>For example, you can define arbitrary tables in Python
	simply by declaring a class with the name field and types
	information, like in:
      </p>

<verbatim>
class Particle(IsDescription):
    name      = StringCol(16)   # 16-character String
    idnumber  = Int64Col()      # Signed 64-bit integer
    ADCcount  = UInt16Col()     # Unsigned short integer
    TDCcount  = UInt8Col()      # unsigned byte
    grid_i    = Int32Col()      # integer
    grid_j    = IntCol()        # integer (equivalent to Int32Col)
    pressure  = Float32Col(shape=(2,3)) # 2-D float array (single-precision)
    energy    = FloatCol(shape=(2,3,4)) # 3-D float array (double-precision) 
</verbatim>

      <p>then, you have to pass this class to the table constructor,
	fill its rows with your values, and save (arbitrary large)
	collections of them in a file for persistent storage. After
	that, this data can be retrieved and post-processed quite
	easily with <visual markup="tt">PyTables</visual> or even with
	another <verb>HDF5</verb> application (in C, Fortran, Java or
	whatever language that provides an interface to HDF5).
      </p>

      <p>Next section describes the most interesting capabilities of
	<verb>PyTables</verb>.
      </p>

      <section>
	<heading>Main Features</heading>
	<p>
	  <verb>PyTables</verb> take advantage of the powerful object
	  orientation and introspection capabilities offered by Python
	  to bring the next features to the user:
	</p>

	<itemize>
	  <item><em>Support of table entities:</em> Allows working
	    with a large number of records, i.e. that don't fit in
	    memory.
	  </item>
	  <item><em>Appendable tables:</em> It supports adding records
	    to already created tables. This can be done without
	    copying the dataset or redefining its structure, even
	    between different Python sessions.
	  </item>
	  <item><em>Multidimensional table cells:</em> You can declare
	    a column to be formed by general array cells, in addition
	    to only scalars, as the majority of relational databases
	    do.
	  </item>
	  <item><em>Support of arrays:</em> <verb>Numeric</verb> (see
	    <cite refid="Numeric"></cite>) or <verb>numarray</verb>
	    (see <cite refid="Numarray"></cite>) arrays are a very
	    useful complement of tables to keep homogeneous table
	    slices (like selections of table columns).
	  </item>
	  <item><em>Supports a hierarchical data model:</em> That way,
	    you can structure very clearly all your
	    data. <verb>PyTables</verb> builds up an <em>object
	    tree</em> in memory that replicates the underlying file
	    data structure. Access to the file objects is achieved by
	    walking throughout this object tree, and manipulating it.
	  </item>
	  <item><em>Support of files bigger than 2 GB:</em> The
	    underlying HDF5 library already can do that (if your
	    platform supports the C long long integer, or, on Windows,
	    __int64), and <verb>PyTables</verb> automatically inherits
	    this capability.
	  </item>
	  <item><em>Can read generic HDF5 files:</em>
	    <verb>PyTables</verb> can access to objects in generic
	    HDF5 files provided they contain any combination of
	    groups, compound type datasets (that will be mapped to
	    <verb>Table</verb> objects) or homogeneous datasets (that
	    will be mapped to <verb>Array</verb> objects). However, as
	    these kind of data is the most common to be saved HDF5
	    format, <verb>PyTables</verb> can probably most of the
	    HDF5 files out there.
	  </item>
	  <item><em>Data compression:</em> It supports data
	    compression (through the use of the <visual
	    markup="tt"><visual markup="bf">Zlib</visual></visual>,
	    <visual markup="tt"><visual
	    markup="bf">LZO</visual></visual> and <visual
	    markup="tt"><visual markup="bf">UCL</visual></visual>
	    libraries) out of the box. This become important when you
	    have repetitive data patterns and don't want to loose your
	    time searching for an optimized way to save them (i.e. it
	    saves you data organization analysis time).
	  </item>
	  <item><em>High performance I/O:</em> On modern systems, and
	    for large amounts of data, tables and array objects can be
	    read and written at a speed only limited by the
	    performance of the underlying I/O subsystem. Moreover, if
	    your data is compressible, even faster than that!.
	  </item>
	  <item><em>Architecture-independent:</em> <visual
	    markup="tt">PyTables</visual> has been carefully coded (as
	    HDF5 itself) with little-endian/big-endian byte orderings
	    issues in mind . So, in principle, you can write a file in
	    a big-endian machine (like a Sparc or MIPS) and read it in
	    other little-endian (like Intel or Alpha) without
	    problems.
	  </item>

	</itemize>

      </section>

      <section id="ObjectTreeSection">
	<heading>The Object Tree</heading>

	<p>The hierarchical model of the underlying HDF5 library
	  allows <verb>PyTables</verb> to manage tables and arrays in
	  a tree-like structure. In order to achieve this, an
	  <em>object tree</em> entity is <em>dynamically</em> created
	  imitating the HDF5 structure on disk. That way, the access
	  to the HDF5 objects is made by walking throughout this
	  object tree, and, by looking at their <em>metadata</em>
	  nodes, you can get a nice picture of what kind data is kept
	  there.
	</p>

	<p>The different nodes in the object tree are instances of
	  <verb>PyTables</verb> classes. There are several types of
	  those classes, but the most important ones are the
	  <verb>Group</verb> and the
	  <verb>Leaf</verb>. <verb>Group</verb> instances (that we
	  will be calling <em>groups</em> from now on) are a grouping
	  structure containing instances of zero or more groups or
	  leaves, together with supplementary metadata.
	  <verb>Leaf</verb> instances (that will be called
	  <em>leaves</em>) are containers for actual data and cannot
	  contain further groups or leaves. The <verb>Table</verb> and
	  <verb>Array</verb> classes are descendants of
	  <verb>Leaf</verb>, and inherits all its properties.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files, respectively, in a Unix
	  filesystem. As with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. In <verb>PyTables</verb> this full
	  path can be specified either as string (like in
	  <verb>'/subgroup2/table3'</verb>) or as a complete object
	  path written in a certain way known as <em>natural name</em>
	  schema (like in <verb>file.root.subgroup2.table3</verb>).
	</p>

	<p>The support for <em>natural naming</em> is a key aspect of
	  <verb>PyTables</verb> and means that the names of instance
	  variables of the node objects are the same as the names of
	  the element's children<footnote>I have got this simple but
	  powerful idea from the excellent <visual
	  markup="tt">Objectify</visual> module by David Mertz (see
	  <cite refid="Objectify"></cite>)</footnote>. This is very
	  <em>Pythonic</em> and comfortable in many cases, as you can
	  check in the tutorial <ref
	  refid="readingAndSelectingUsage">section</ref>.
	</p>
	<p>You should also note that not all the data present on file
	  is loaded in the object tree, but only the <em>metadata</em>
	  (i.e. special data that describes the structure of the
	  actual data). The actual data is not read until you ask for
	  it (by calling a method on a particular node). By making use
	  of the object tree (the metadata) you can get information on
	  the objects on disk such as table names, title, name
	  columns, data types in columns, the number of rows, or, in
	  the case of arrays, the shape, the typecode, and so on. You
	  can also traverse the tree in order to search for something
	  and when you find the data you are interested in you can
	  read it and process it. In some sense, you can think of
	  <verb>PyTables</verb> as a tool that provide the same
	  introspection capabilities of Python objects, but applied to
	  the persistent storage of large amounts of data.
	</p>
	<p>To better understand the dynamic nature of this object tree
	  entity, let's start by a first example and try to realize
	  what kind of object tree the next script (you can find it in
	  <verb>examples/objecttree.py</verb>) would create:
	</p>

	<verbatim>
from tables import *

class Particle(IsDescription):
    identity = StringCol(length=22, dflt=" ", pos = 0)  # character String
    idnumber = Int16Col(1, pos = 1)  # short integer
    speed    = Float32Col(1, pos = 1)  # single-precision

# Open a file in "w"rite mode
fileh = openFile("objecttree.h5", mode = "w")
# Get the HDF5 root group
root = fileh.root

# Create the groups:
group1 = fileh.createGroup(root, "group1")
group2 = fileh.createGroup(root, "group2")

# Now, create a table in "group0" group
array1 = fileh.createArray(root, "array1", ["string", "array"], "String array")
# Create 2 new tables in group1
table1 = fileh.createTable(group1, "table1", Particle)
table2 = fileh.createTable("/group2", "table2", Particle)
# Create the last table in group2
array2 = fileh.createArray("/group1", "array2", [1,2,3,4])

# Now, fill the tables:
for table in (table1, table2):
    # Get the record object associated with the table:
    row = table.row
    # Fill the table with 10 records
    for i in xrange(10):
        # First, assign the values to the Particle record
        row['identity']  = 'This is particle: %2d' % (i)
        row['idnumber'] = i
        row['speed']  = i * 2.
        # This injects the Record values
        row.append()

    # Flush the table buffers
    table.flush()

# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
	</verbatim>

	<p>This small program creates a simple HDF5 file, called
	  <verb>objecttree.h5</verb>, with the structure that appears
	  in <ref refid="objecttree-h5">figure</ref>. During creation
	  time, metadata in the object tree is updated in memory while
	  the actual data is being saved on disk and when you close
	  the file the object tree becomes unavailable. But, when you
	  will open again this file the object tree with will be
	  re-constructed in memory from the metadata existent on disk,
	  so that you can work with it exactly in the same way than
	  during the original creation process.
	</p>

	<figure id="objecttree-h5">
	  <graphics file="objecttree-h5" scale="0.5" kind="bitmap">
	  </graphics>
	  <caption>An HDF5 example with 2 subgroups, 2 tables and 1
	    array.</caption>
	</figure>

	<p>In <ref refid="objecttree">figure</ref> you can see an
	  example of the object tree created by reading the above
	  <verb>objecttree.h5</verb> file (in fact, such an object is
	  always created when reading any supported generic HDF5
	  file). If you are going to become a <visual
	  markup="tt">PyTables</visual> user, take your time to
	  understand it<footnote>Bear in mind, however, that this
	  diagram is <visual markup="bf">not</visual> a standard UML
	  class diagram; it is rather meant to show the connections
	  between the <verb>PyTables</verb> objects and some of its
	  most important attributes and methods.</footnote>. That will
	  also make you more proactive by avoiding programming
	  mistakes.
	</p>

	<figure id="objecttree">
	  <graphics file="objecttree" scale="0.35" kind="vector">
	  
	  <!-- If you want to convert the eps to jpeg use command:
pstoimg -scale 0.75 -aaliastext -type png -crop a -interlace objecttree.eps
	  and then, convert again to jpg with:
	  convert objecttree.png objecttree.jpg
	  Use this tag to include the jpeg file:
	  <graphics file="objecttree" scale="0.5" kind="bitmap">
	  -->
	  </graphics>
	  <caption>An object tree example in <visual
	      markup="tt">PyTables</visual>.
	  </caption>
	</figure>

      </section>

    </chapter>

    <chapter>
      <heading>Installation</heading>

<!--       <aphorism>El meu país es tan petit <newline/> que quan el sol -->
<!-- 	se'n va a dormir <newline/> no està mai prou segur d'haver-lo -->
<!-- 	vist <caption>Lluís Llach in the song "Petit País"</caption> -->
<!--       </aphorism> -->

      <aphorism>T'adones, company,<newline/>
	no volen arguments,<newline/>
	usen la força,<newline/>
	t'adones, amic.<newline/>
	T'adones, company,<newline/>
	que hem de sortir al carrer<newline/>
	junts, molts, com més millor,<newline/>
	si no volem perdre-ho tot,<newline/>
	t'adones, amic.<newline/>
	<caption>Raimon in the song "T'adones, amic"</caption>
      </aphorism>


<!--       <aphorism>Make things as simple as possible, but not any -->
<!-- 	simpler.  <caption>Albert Einstein</caption> </aphorism> -->

      <p>The Python <verb>Distutils</verb> are used to build and
	install <verb>PyTables</verb>, so it is fairly simple to get
	things ready to go. Also, a binary distribution is available
	for Windows (see <ref
	refid="binaryInstallationDescr">section</ref>).
      </p>

      <section id="sourceInstallationDescr">
	<heading>Installation from sources</heading>

	<p>
	  These instructions are both for Unix/Linux and Windows
	  systems. If you are using Windows, it is assumed that you
	  are using a recent version of <verb>MS Visual C++</verb> (>=
	  6.0) compiler. A <verb>GCC</verb> compiler is assumed for
	  Unix, but other compilers should work as well.
	</p>

	<p>Extensions in <visual markup="tt">PyTables</visual> has been
	  made using Pyrex (see <cite refid="Pyrex"></cite>) and C
	  language. You can rebuild everything from scratch if you got
	  Pyrex installed, but this is not necessary, as the Pyrex
	  compiled source is included in the distribution. In order to
	  do that, merely replace <visual markup="tt">setup.py</visual>
	  script in these instructions by <visual
	    markup="tt">setup-pyrex.py</visual>.
	</p>

	<p>To compile <verb>PyTables</verb> you will need a recent
	  version of <verb>HDF5</verb> (C flavor) library and
	  <verb>numarray</verb> (see <cite refid="Numarray"></cite>)
	  package. Although you won't need <verb>Numerical Python</verb>
	  (see <cite refid="Numeric"></cite>) in order to compile
	  PyTables, it is supported; you only will need a reasonably
	  recent version of it (>= 21.x). PyTables has been successfully
	  tested with Numeric 21.3, 22.0 and 23.0. If you have
	  <verb>Numeric</verb> installed, the test driver module will
	  detect it and will run the tests for <verb>Numeric</verb>
	  automatically.
	</p>

	<enumerate>

	  <item>
	    <p>First, make sure that you have <verb>HDF5 1.6.x</verb>
	      and <verb>numarray 0.6</verb> or higher installed (I'm
	      using <verb>HDF5 1.6.0</verb> and <verb>numarray
	      0.6</verb> currently). If don't, you can find them at
	      <newline/>
	      <verb>http://hdf.ncsa.uiuc.edu/HDF5</verb> and
	      <verb>http://www.pfdubois.com/numpy</verb>. Compile/install
	      them.
	    </p>
	    <p>Optionally, consider to install the excellent LZO and
	      UCL compression libraries (see <cite
	      refid="lzouclRef"></cite> and section <ref
	      refid="compressionIssues"></ref>).
	    </p>
	    <description>
	      <term>Windows</term>
	      <item>
		<p>If you are using Windows, and don't want to
		  compile the libraries by hand, there are available
		  binary packages for them. You can fetch the HDF5 and
		  numarray binaries from their homes.
		</p>

		<p>Besides, you can (should) fetch the LZO and UCL
		  binaries from:
		  <verb>http://gnuwin32.sourceforge.net/</verb>. Normally,
		  you will only need to fetch and install the
		  <verb>&lt;package>-&lt;version>-bin.zip</verb> file,
		  although in some cases the headers are in
		  <verb>&lt;package>-&lt;version>-lib.zip</verb> file.
		</p>
		<p>Note that you need to copy manually the
		  <verb>hdf5dll.dll</verb> (and <verb>lzo.dll</verb>
		  or <verb>ucl.dll</verb> if you want them) to a
		  directory in the <verb>PATH</verb>, so that they can
		  be find by PyTables extensions.</p>
	      </item>

	      <term>Unix</term>
	      <item>

		<p><verb>setup.py</verb> will detect
		  <verb>HDF5</verb>, <verb>LZO</verb> or
		  <verb>UCL</verb> libraries and include files under
		  <verb>/usr</verb> or <verb>/usr/local</verb>; this
		  will catch installations from RPMs, DEBs and most
		  hand installations under Unix. If
		  <verb>setup.py</verb> can't find your
		  <verb>libhdf5</verb> (or any other library you may
		  wish) or if you have several versions installed and
		  want to select one of them, then you can give it a
		  hint either in the environment (using the
		  <verb>HDF5_DIR</verb> environment variable or
		  <verb>LZO_DIR</verb> and <verb>UCL_DIR</verb> for
		  the optional libraries) or on the command line by
		  specifying the directory containing the include and
		  lib directory. For example:
		</p>

		<verbatim>
		  --hdf5=/stuff/hdf5-1.6.0
		  --ucl=/stuff/ucl-1.0.1
		</verbatim>

		<p>If your <verb>HDF5</verb> library was built as
		  shared library, and if this shared library is not in
		  the runtime load path, then you can specify the
		  additional linker flags needed to find the shared
		  library on the command line as well. For example:
		</p>
		<verbatim>
		  --lflags="-Xlinker -rpath -Xlinker /stuff/hdf5-1.6.0/lib"
		</verbatim>
		<p>or perhaps just
		</p>
		<verbatim>
		  --lflags="-R /stuff/hdf5-1.6.0/lib"
		</verbatim>

		<p>Check your compiler and linker documentation for correct
		  syntax.
		</p>

		<p>It is also possible to specify linking against different
		  libraries with the <verb>--libs</verb> switch:
		</p>
		<verbatim>
		  --libs="-lhdf5-1.6.5"
		  --libs="-lhdf5-1.6.5 -lnsl"
		</verbatim>
	      </item>
	      <term>Windows</term>
	      <item>

		<p><verb>setup.py</verb> will need that you inform it
		  about where the library <em>stubs</em>
		  (<verb>.lib</verb>) are installed as well as the
		  <em>header</em> files (<verb>.h</verb>). To tell
		  setup.py<verb></verb> where the stubs and headers
		  are, set the next environment variables:
		</p>

		<description>
		  <term>HDF5_DIR</term><item>Points to the HDF5 main
		    directory (where the include/ and dll/ directories
		    hangs). <em>Mandatory</em>.</item>
		    
		  <term>LZO_DIR</term> <item>Points to the LZO main
		    directory (where the include/ and lib/ directories
		    hangs). <em>Optional</em>.</item>

		  <term>UCL_DIR</term> <item>Points to the UCL main
		    directory (where the include/ and lib/ directories
		    hangs). <em>Optional</em>.</item>

		</description> 

		<p>For example:
		</p>
		<verbatim>
		  set HDF5_DIR=c:\stuff\5-160-winVS\c\release
		  set LZO_DIR=c:\stuff\lzo-1.07
		  set UCL_DIR=c:\stuff\ucl-1.01
		</verbatim>

		<p>Or you can pass this info to <verb>setup.py</verb>
		  within the command line by specifying the directory
		  containing the include and lib directory. For
		  example:
		</p>

		<verbatim>
		  --hdf5=c:\stuff\5-160-winVS\c\release --lzo=c:\stuff\lzo-1.07
		  --ucl=c:\stuff\ucl-1.01
		</verbatim>	
	      </item>

	    </description>

	  </item>

	  <item>
 	    <p>From the main <verb>PyTables</verb> distribution
	      directory run this command, (plus any extra flags needed
	      as discussed above):
	    </p>
	    <verbatim>
	      python setup.py build_ext --inplace
	    </verbatim>
	    <p>depending on the compiler flags used when compiling your
	      Python executable, there may appear lots of warnings. Don't
	      worry, almost all of them are caused by variables declared
	      but never used. That's normal in Pyrex extensions.
	    </p>
	  </item>
	  <item>
	    <p>To run the test suite change into the test directory
	      and run this command:
	    </p>
	    <description>
	      <term>Unix</term> <item>In the shell <verb>sh</verb> and
	      its variants:
		<verbatim>
		  PYTHONPATH=..  
		  export PYTHONPATH
		  python test_all.py
		</verbatim>
	      </item>
	      <term>Windows</term>
	      <item>Open a DOS terminal and write:
		<verbatim>
		  set PYTHONPATH=..  
		  python test_all.py
		</verbatim>
	      </item>
	    </description>

	    <p>If you would like to see some verbose output from the
	      tests simply add the flag <verb>-v</verb> and/or the word
	      <verb>verbose</verb> to the command line. You can also
	      run just the tests in a particular test module. For
	      example:
	    </p>
	    <verbatim>
	      python test_types.py -v
	    </verbatim>

	    <p>If there is some test that do not pass, please, run the
	      failing test module with all verbosity enabled (flags
	      <verb>-v verbose</verb>), and send back the output to
	      developers.
	    </p>

	    <p> If you run into problems because Python can't load the
	      HDF5, or any other shared library:
	    </p>
	    <description>
	      <term>Unix</term>
	      <item>
		Try to set the LD_LIBRARY_PATH environment variable to
		point to the directory where the libraries are.
	      </item>
	      <term>Windows</term> <item>Put the DLL libraries
		(<verb>hdf5dll.dll</verb> and, optionally,
		<verb>lzo.dll</verb> and <verb>ucl.dll</verb>) on a
		directory listed on your <verb>PATH</verb> environment
		variable.  The <verb>setup.py</verb> should already
		warned you about that.
	      </item>
	    </description>
	  </item>
	  <item>
	    <p>To install the entire <visual
		markup="tt">PyTables</visual> Python package, change back
	      to the root distribution directory and run this command as
	      the root user (remember to add any extra flags needed):
	    </p>
	    <verbatim>
	      python setup.py install
	    </verbatim>

	  </item>
	</enumerate>

	<p>That's it!. Now, proceed with the next chapter to see how to
	  use <verb>PyTables</verb>.
	</p>

      </section>

      <section id="binaryInstallationDescr">
	<heading>Binary installation (Windows)</heading>

	<p>This section is only intended for Windows platforms. If you
	  have Unix, or want to compile PyTables for Windows, jump to
	  the <ref refid="sourceInstallationDescr">section</ref>.
	</p>
	<p>First, make sure that you have HDF5 1.6.x or higher and
	  numarray 0.6 or higher installed (I'm using HDF5 1.6.0
	  and numarray 0.6 currently). If don't, you can find them at
	  <verb>http://hdf.ncsa.uiuc.edu/HDF5</verb> and
	  <verb>http://sourceforge.net/projects/numpy/</verb>. Download
	  the binary packages and install them. For the HDF5 it should
	  be enough by manually copying the <verb>hdf5dll.dll</verb>
	  file to a directory in your <verb>PATH</verb> environment
	  variable.
	</p>
	<p>Download the
	  <verb>tables-&lt;version>.win32-py&lt;version>.exe</verb>
	  file and execute it. You are done!.
	</p>
	<p>You can (<em>you should</em>) test your installation by
	  unpacking the source tarball. Go to the <verb>test/</verb>
	  directory, add the directory "<verb>..</verb>" to the
	  <verb>PYTHONPATH</verb>environment variable, e.g.:
	</p>

	<verbatim>
	  set PYTHONPATH=..
	</verbatim>

	<p>and execute the <verb>test_all.py</verb> script. If all the
	  tests passes (maybe with a couple of warnings, related with
	  the possibly missing LZO and UCL libs, but that's ok for the
	  binary version) you already have a working, well tested,
	  copy of PyTables installed!. If don't, please, execute the
	  <verb>test_all.py -v</verb> and return the output to me.
	</p>
	<p>If you want support for LZO and UCL libraries (see <ref
	  refid="compressionIssues">section</ref> for hints about what
	  they are useful for), fetch
	  <verb>tables-&lt;version>-LU.win32-py&lt;version>.exe</verb>
	  instead, and remember to install the LZO and UCL DLL
	  libraries (see next section).
	</p>

	<p>That's it!. Now, proceed with the next chapter to see how to
	  use <verb>PyTables</verb>.
	</p>

      </section>


    </chapter>

    <chapter id="usage">
      <heading>Some tutorials</heading>

      <aphorism>Tout le malheur des hommes vient d'une seule chose,
	qui est de ne savoir pas demeurer en repos, dans une chambre.
	<caption>Blaise Pascal</caption>
      </aphorism>

      <p>This chapter begins with a series of simple, yet
	comprehensive sections written in a tutorial style that will
	let you understand the main features that
	<verb>PyTables</verb> provide. If during the trip you want
	more information on some specific instance variable, global
	function or method, look at the doc strings or go to the
	library reference in <ref
	refid="libraryReference">chapter</ref>. However, if you are
	reading this in PDF or HTML formats, there should be an
	hyperlink to its reference near each newly introduced
	entity.
      </p>

      <p>Please, note that throughout this document the terms
	<em>column</em> and <em>field</em> will be used
	interchangeably with the same meaning, and the same goes for
	the terms <em>row</em> and <em>record</em>.
      </p>

      <section>
	<heading>Getting started</heading>

	<p>In this section, we will see how to define our own records
	  from Python and save collections of them (i.e. a <visual
	  markup="bf">table</visual>) on a file. Then, we will select
	  some data in the table using Python cuts, creating
	  <verb>numarray</verb> arrays to keep this selection as
	  separate objects in the tree.
	</p>
	<p>
	  In <em>examples/tutorial1-1.py</em> you will find the
	  working version of all the code in this
	  section. Nonetheless, this tutorial series has been written
	  to allow you reproduce it in a Python interactive
	  console. You are encouraged to take advantage of that by
	  doing parallel testing and inspecting the created objects
	  (variables, docs, children objects, etc.) during the
	  voyage!.
	</p>

	<subsection>
	  <heading>Importing <visual markup="tt">tables</visual>
	    objects</heading>
	  
	  <p>Before doing anything you need to import the
	    public objects in the <verb>tables</verb> package. You
	    normally do that by issuing:
	  </p>
	  <verbatim>
>>> import tables
>>>
	  </verbatim>
	  <p>This is the recommended way to import <verb>tables</verb>
	    if you don't want to pollute too much your
	    namespace. However, <verb>PyTables</verb> has a very
	    reduced set of first-level primitives, so you may consider
	    to use this alternative:
	  </p>
	  <verbatim>
>>> from tables import *
>>>
	  </verbatim>
	  <p>that will export in your caller application namespace the
	    next objects: <verb>openFile</verb>, <verb>isHDF5</verb>,
	    <verb>isPyTablesFile</verb> and
	    <verb>IsDescription</verb>. These are a rather small number
	    of objects, and for convenience, we will use this last way
	    to access them.
	  </p>
	  <p>If you are going to deal with <verb>numarray</verb> or
	    <verb>Numeric</verb> arrays (and normally, you will) you
	    also need to import some objects from it. You can do that
	    in the normal way. So, to access to <verb>PyTables</verb>
	    functionality normally you should start you programs with:
	  </p>
	  <verbatim>
>>> import tables        # but in this tutorial we use "from tables import *"
>>> from numarray import *  # or "from Numeric import *"
>>>
	  </verbatim>
	</subsection>

	<subsection>
	  <heading>Declaring a Column Descriptor</heading>

	  <p>Now, imagine that we have a particle detector and we want
	    to create a table object in order to save data that comes
	    from it. You need first to define that table, how many
	    columns it have, which kind of object is each element on
	    the columns, and so on.
	  </p>
	  <p>Our detector has a TDC (Time to Digital Converter)
	    counter with a dynamic range of 8 bits and an ADC
	    (Analogic to Digital Converter) with a range of 16
	    bits. For these values, we will define 2 fields in our
	    record object called <verb>TDCcount</verb> and
	    <verb>ADCcount</verb>. We also want to save the grid
	    position in which the particle has been detected and we
	    will add two new fields called <verb>grid_i</verb> and
	    <verb>grid_j</verb>. Our instrumentation also can obtain
	    the pressure and energy of this particle that we want to
	    add in the same way. The resolution of pressure-gauge
	    allows us to use simple-precision float which will be
	    enough to save <verb>pressure</verb> information, while
	    <verb>energy</verb> would need a double-precision
	    float. Finally, to track this particle we want to assign
	    it a name to inform about the kind of the particle and a
	    number identifier unique for each particle. So we will add
	    a couple of fields: <verb>name</verb> will be the a string
	    of up-to 16 characters and because we want to deal with a
	    really huge number of particles, <verb>idnumber</verb>
	    will be an integer of 64 bits.
	  </p>
	  <p>With all of that, we can declare a new
	    <verb>Particle</verb> class that will keep all this info:
	  </p>

	  <verbatim>
>>> class Particle(IsDescription):
...     name      = StringCol(16)   # 16-character String
...     idnumber  = Int64Col()      # Signed 64-bit integer
...     ADCcount  = UInt16Col()     # Unsigned short integer
...     TDCcount  = UInt8Col()      # unsigned byte
...     grid_i    = Int32Col()      # integer
...     grid_j    = IntCol()        # integer (equivalent to Int32Col)
...     pressure  = Float32Col()    # float  (single-precision)
...     energy    = FloatCol()      # double (double-precision)
...
>>>
	  </verbatim>
	  <p>This definition class is quite
	    auto-explanatory. Basically, you have to declare a class
	    variable for each field you need, and as its value we
	    assign a subclass instance of the <verb>Col</verb> class,
	    that describes the kind of column (the data type, the
	    length, the shape, ...). See <ref
	    refid="ColClassDescr">section</ref> for a complete
	    description of these subclasses. See also <ref
	    refid="datatypesSupported">appendix</ref> for a list of
	    data types supported in <verb>Col</verb> constructors.
	  </p>
	  <p>From now on, we can use <verb>Particle</verb> instances
	    as a descriptor for our detector data table. We will see
	    how to pass this object to the <verb>Table</verb>
	    constructor. But first, we must create a file where all
	    the actual data pushed into <verb>Table</verb> will be
	    saved.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating a <visual markup="tt">PyTables</visual> file from scratch</heading>

	  <p>To create a <verb>PyTables</verb> file use the
	    first-level <verb>openFile</verb> (see <ref
	    refid="openFileDescr"></ref>) function:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial1.h5", mode = "w", title = "Test file")
	  </verbatim>
	  <p>This <verb>openFile</verb> (<ref
	    refid="openFileDescr">see</ref>) is one of the objects
	    imported by the "<verb>from tables import *</verb>", do
	    you remember?. Here, we are telling that we want to create
	    a new file called "<verb>tutorial1.h5</verb>" in
	    "<verb>w</verb>"rite mode and with an descriptive title
	    string ("<verb>Test file</verb>"). This function tries to
	    open the file, and if successful, returns a
	    <verb>File</verb> (<ref refid="FileClassDescr">see</ref>)
	    instance which hosts the root of the object tree on its
	    <verb>root</verb> attribute.
	  </p>
	</subsection>

	<subsection>
	  <heading>Creating a new group</heading>

	  <p>Now, to better organize our data, we will create a group
	    hanging from the root called <em>detector</em>. We will
	    use this group to save our particle data there.
	  </p>
	  <verbatim>
>>> group = h5file.createGroup("/", 'detector', 'Detector information')
>>>
	  </verbatim>

	  <p>Here, we have taken the <verb>File</verb> instance
	    <verb>h5file</verb> and invoked its
	    <verb>createGroup</verb> method (<ref
	    refid="createGroupDescr">see</ref>), telling that we want
	    to create a new group called <em>detector</em> hanging
	    from "<em>/</em>", which is other way to refer to the
	    <verb>h5file.root</verb> object we mentioned before. This
	    will create a new <verb>Group</verb> (see<ref
	    refid="GroupClassDescr"></ref>) instance that will be
	    assigned to the <verb>group</verb> variable.
	  </p>

	</subsection>
	<subsection>
	  <heading>Creating a new table</heading>

	  <p>Let's now create the <verb>Table</verb> (see <ref
	    refid="TableClassDescr"></ref>) object hanging from the new
	    created group. We do that by calling the
	    <verb>createTable</verb> (see <ref
	    refid="createTableDescr"></ref>) method from the
	    <verb>h5file</verb> object:
	  </p>
	  <verbatim>
>>> table = h5file.createTable(group, 'readout', Particle, "Readout example")
>>>
	  </verbatim>

	  <p>Look at how we asked to create the <verb>Table</verb>
	    instance hanging from <verb>group</verb>, with name
	    "<em>readout</em>". We have passed <verb>Particle</verb>,
	    the class that we have declared before, as the
	    <em>description</em> parameter and finally we have used
	    "<em>Readout example</em>" as a <verb>Table</verb>
	    title. With all this information, a new <verb>Table</verb>
	    instance is created and assigned to <em>table</em>
	    variable.
	  </p>

	  <p>If you are getting curious how the object tree looks like
	    at this moment, simply print the name of the
	    <verb>File</verb> instance, <em>h5file</em>, and look at
	    their output:
	  </p>

	  <verbatim>
>>> print h5file
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:00:13 2003'
/ (Group) 'Test file'
/detector (Group) 'Detector information'
/detector/readout (Table(0,)) 'Readout example'

>>>
	  </verbatim>

	  <p>As you can see, a dump of the object tree has been shown
	    and it's very easy to visualize the <verb>Group</verb> and
	    <verb>Table</verb> objects we have just created. If you
	    want more information, just type the name of the
	    <verb>File</verb> instance:
	  </p>

	  <verbatim>
>>> h5file
>>> h5file
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:00:13 2003'
/ (Group) 'Test file'
/detector (Group) 'Detector information'
/detector/readout (Table(0,)) 'Readout example'

>>> h5file
File(filename='tutorial1.h5', title='Test file', mode='w', trMap={}, rootUEP='/')
/ (Group) 'Test file'
/detector (Group) 'Detector information'
/detector/readout (Table(0,)) 'Readout example'
  description := {
    "ADCcount": Col('UInt16', shape=1, itemsize=2, dflt=0),
    "TDCcount": Col('UInt8', shape=1, itemsize= 1, dflt=0),
    "energy": Col('Float64', shape=1, itemsize=8, dflt=0.0),
    "grid_i": Col('Int32', shape=1, itemsize=4, dflt=0),
    "grid_j": Col('Int32', shape=1, itemsize=4, dflt=0),
    "idnumber": Col('Int64', shape=1, itemsize=8, dflt=0),
    "name": Col('CharType', shape=1, itemsize=16, dflt=None),
    "pressure": Col('Float32', shape=1, itemsize=4, dflt=0.0) }
  byteorder := little

>>>
	  </verbatim>

	  <p>where more detailed info is printed on each object on the
	    tree. Pay attention on how <verb>Particle</verb>, our
	    table descriptor class, is printed as part of the
	    <em>readout</em> table description information. In
	    general, you can obtain lot of information on the objects
	    and its children by just printing them. That introspection
	    capability is very meaningful, so I recommend you to use it
	    extensively.
	  </p>

	  <p>Now, time to fill this table with some values. But first,
	    we are going to get a pointer to the <verb>Row</verb>
	    instance of this <verb>table</verb> instance:
	  </p>
	  <verbatim>
>>> particle = table.row
>>>
	  </verbatim>

	  <p>The <verb>row</verb> attribute of <verb>table</verb>
	    points to the <verb>Row</verb> (see <ref
	    refid="RowClassDescr"></ref>) instance that will be used
	    to input data rows into the table. We achieve this by just
	    assigning it the values for each row as if it was a
	    dictionary (although it is actually an <em>extension
	    class</em>) and using the column names as keys.
	  </p>

	  <p>Look at how the filling process works like:
	  </p>

	  <verbatim>
>>> particle = table.row
>>> for i in xrange(10):
...     particle['name']  = 'Particle: %6d' % (i)
...     particle['TDCcount'] = i % 256
...     particle['ADCcount'] = (i * 256) % (1 &lt;&lt; 16)
...     particle['grid_i'] = i
...     particle['grid_j'] = 10 - i
...     particle['pressure'] = float(i*i)
...     particle['energy'] = float(particle['pressure'] ** 4)
...     particle['idnumber'] = i * (2 ** 34)
...     particle.append()
...
>>>
	  </verbatim>
	  
	  <p>This code should be easy to understand. The lines inside
	    the loop just assign values to the different columns in
	    the <verb>particle</verb> Row instance (<ref
	    refid="RowClassDescr">see</ref>) and then a call to its
	    <verb>append()</verb> method is made to put this
	    information in the <verb>table</verb> I/O buffer.
	  </p>

	  <p>After we have pushed all our data, we should flush the
	    I/O buffer for the table if we want to consolidate all
	    this data on disk. We can achieve that by calling the
	    <verb>table.flush()</verb> method.
	  </p>
	  <verbatim>
>>> table.flush()
>>>
	  </verbatim>

	</subsection>

	<subsection id="readingAndSelectingUsage">
	  <heading>Reading (and selecting) data in table</heading>

	  <p>Ok. We have now our data on disk but to this data be
	    useful we need to access it and select some values we are
	    interested in and located at some specific columns. That's
	    is easy to do:
	  </p>
	  <verbatim>
>>> table = h5file.root.detector.readout
>>> pressure = [ x['pressure'] for x in table.iterrows()
...              if x['TDCcount']>3 and 20&lt;=x['pressure']&lt;50 ]
>>> pressure
[25.0, 36.0, 49.0]
>>>
	  </verbatim>

	  <p>The first line is only to declare a convenient shortcut
	    to the <em>readout</em> table which is a bit deeper on the
	    object tree. As you can see, we have used the <visual
	    markup="bf">natural naming</visual> schema to access
	    it. We could also have used the
	    <verb>h5file.getNode()</verb> method instead, and we
	    will certainly do that later on.
	  </p>

	  <p>You will recognize the last two lines to be a Python list
	    comprehension. It loops over rows in <em>table</em> as
	    they are provided by <verb>table.iterrows()</verb>
	    iterator (see <ref refid="iterrowsDescr"></ref>) that
	    returns values until data in table is exhausted. These
	    rows are filtered using the expression <verb>x['TDCcount']
	    > 3 and x['pressure'] &lt; 50</verb>, and the
	    <verb>pressure</verb> field for satisfying records is
	    selected to form the final list that is assigned to
	    <verb>pressure</verb> variable.
	  </p>

	  <p>We could indeed have used a normal <verb>for</verb> loop
	    to do that, but I find comprehension syntax to be more
	    compact and elegant.
	  </p>

	  <p>Let's select the names for the same set of cuts:
	  </p>

	  <verbatim>
>>> names=[ x['name'] for x in table if x['TDCcount']>3 and 20&lt;=x['pressure']&lt;50 ]
>>> names
['Particle:      5', 'Particle:      6', 'Particle:      7']
>>>
	  </verbatim>

	  <p>Note how we have omitted the iterrows() call in the list
	    comprehension. This is because and __iter__() special
	    function is implemented in the Table class, so that it
	    implements the iterator protocol over all the rows in the
	    table. In fact, iterrows() internally calls this special
	    __iter__() method. This way to access all the rows in a
	    table turns out to be very convenient, specially for
	    interactive use.
	  </p>

	  <p>Ok. that's enough for selections. Next section will show
	    you how to save these selections on file.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating new array objects</heading>

	  <p>In order to separate the selected data from the detector
	    data, we will create a new group, called
	    <verb>columns</verb> hanging from the root group:
	  </p>

	  <verbatim>
>>> gcolumns = h5file.createGroup(h5file.root, "columns", "Pressure and Name")
>>>
	  </verbatim>

	  <p>Note that this time we have specified the first parameter
	    in a <em>natural naming</em> fashion
	    (<verb>h5file.root</verb>) instead of using an absolute
	    path string ("/").
	  </p>

	  <p>Now, create one <verb>Array</verb> object:
	  </p>

	  <verbatim>
>>> h5file.createArray(gcolumns, 'pressure', array(pressure),
...                     "Pressure column selection")
/columns/pressure (Array(3,)) 'Pressure column selection'
  type = Float64
  itemsize = 8
  flavor = 'NumArray'
  byteorder = 'little'
>>>
	  </verbatim>

	  <p>We already know the first two parameters of the
	    <verb>createArray</verb> (see <ref
	    refid="createArrayDescr"></ref>) methods (these are the
	    same as the firsts in <verb>createTable</verb>): they are
	    the parent group <em>where</em> <verb>Array</verb> will be
	    created and the <verb>Array</verb> instance
	    <em>name</em>. You can figure out that the fourth
	    parameter is the <em>title</em>. And in the third position
	    we have the <em>object</em> we want to save on disk. In
	    this case, it is a <verb>Numeric</verb> array that is
	    built from the selection lists we created before.
	  </p>

	  <p>Now, we are going to save the other selection. In this
	    case it's a list of strings, and we want to save this
	    object as is, with no further conversion. Look at how this
	    can be done:
	  </p>

	  <verbatim>
>>> h5file.createArray(gcolumns, 'name', names, "Name column selection")
/columns/name Array(4,) 'Name column selection'
  type = 'CharType'
  itemsize = 16
  flavor = 'List'
  byteorder = 'little'
>>>
	  </verbatim>

	  <p>You see, <verb>createArray()</verb> accepts
	    <em>names</em> (which is a regular Python list) as
	    <em>object</em> parameter. Actually, it accepts a variety
	    of other regular objects (see <ref
	    refid="createArrayDescr"></ref>). We will check that we can
	    retrieve exactly the same object from disk later on.
	  </p>
	  <p>Note that in this examples, <verb>createArray</verb>
	    method returns an <verb>Array</verb> instance that is not
	    assigned to any variable. Don't worry, this was
	    intentional because I wanted to show you the kind of
	    object we have created by showing its
	    representation. Indeed, the <verb>Array</verb> objects has
	    been attached to the object tree and saved on disk, as you
	    can see if you print the complete object tree:
	  </p>
	  <verbatim>
>>> print h5file
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:00:13 2003'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout (Table(10,)) 'Readout example'

>>>	  
	  </verbatim>
	</subsection>

	<subsection>
	  <heading>Closing the file and looking at its content</heading>

	  <p>To finish this first tutorial, we use the
	    <verb>close</verb> method of the h5file <verb>File</verb>
	    instance to close the file before exiting Python:
	  </p>
	  <verbatim>
>>> h5file.close()
>>> ^D
	  </verbatim>

	  <p>With all that, you have created your first
	    <verb>PyTables</verb> file with a table and two
	    arrays. That was easy, admit it. Now, you can have a look
	    at it with some generic HDF5 tool, like
	    <verb>h5dump</verb> or <verb>h5ls</verb>. Here is the
	    result of passing to <verb>h5ls</verb> the
	    <verb>tutorial1.h5</verb> file:
	  </p>
	  <verbatim>
$ h5ls -rd tutorial1.h5
/columns                 Group
/columns/name            Dataset {3}
    Data:
        (0) "Particle:      5", "Particle:      6", "Particle:      7"
/columns/pressure        Dataset {3}
    Data:
        (0) 25, 36, 49
/detector                Group
/detector/readout        Dataset {10/Inf}
    Data:
        (0) {0, 0, 0, 0, 10, 0, "Particle:      0", 0},
        (1) {256, 1, 1, 1, 9, 17179869184, "Particle:      1", 1},
        (2) {512, 2, 256, 2, 8, 34359738368, "Particle:      2", 4},
        (3) {768, 3, 6561, 3, 7, 51539607552, "Particle:      3", 9},
        (4) {1024, 4, 65536, 4, 6, 68719476736, "Particle:      4", 16},
        (5) {1280, 5, 390625, 5, 5, 85899345920, "Particle:      5", 25},
        (6) {1536, 6, 1679616, 6, 4, 103079215104, "Particle:      6", 36},
        (7) {1792, 7, 5764801, 7, 3, 120259084288, "Particle:      7", 49},
        (8) {2048, 8, 16777216, 8, 2, 137438953472, "Particle:      8", 64},
        (9) {2304, 9, 43046721, 9, 1, 154618822656, "Particle:      9", 81}
	  </verbatim>

	  <p>or, using the "dumpFile.py" <verb>PyTables</verb> utility
	    (located in <verb>examples/</verb> directory):
	  </p>

	  <verbatim>
$ python dumpFile.py tutorial1.h5
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:40:51 2003'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout (Table(10,)) 'Readout example'

	  </verbatim>

	  <p>You can pass the <verb>-v</verb> or <verb>-d</verb>
	    options to <verb>dumpFile.py</verb> if you want more
	    verbosity. Try them out!.
	  </p>
	</subsection>
      </section>

      <section>
	<heading>Browsing the <visual markup="it">object tree</visual>
	  and more</heading>

	<p>In this section, we will learn how to browse the tree while
	  retrieving meta-information about the actual data, and will
	  finish by appending some rows to the existing table to show
	  how table objects can be enlarged.
	</p>
	<p>
	  In <em>examples/tutorial1-2.py</em> you will find the
	  working version of all the code in this section. As before,
	  you are encouraged to use a python shell and inspect the
	  object tree during the voyage.
	</p>

	<subsection>
	  <heading>Traversing the object tree</heading>

	  <p>First of all, let's open the file we have recently
	    created in last tutorial section, as we will take it as a
	    basis for this section:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial1.h5", "a")
	  </verbatim>

	  <p>This time, we have opened the file in "a"ppend mode. We
	    are using this mode because we want to add more
	    information to the file.
	  </p>
	  <p><verb>PyTables</verb>, following the Python tradition,
	    offers powerful introspection capabilities, i.e. you can
	    easily ask information about any component of the object
	    tree as well as traverse the tree searching for something.
	  </p>
	  <p>To start with, you can get a first glance image of the
	    object tree, by simply printing the existing
	    <verb>File</verb> instance:
	  </p>

	  <verbatim>
>>> print h5file
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:40:51 2003'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout (Table(10,)) 'Readout example'

>>>
	  </verbatim>

	  <p>That's right, it seems that all our objects are
	    there. Now, let's make use of the File iterator to see how
	    to list all the nodes in the object tree:
	  </p>

	  <verbatim>
>>> for node in h5file:
...   print node
...
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/detector (Group) 'Detector information'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector/readout (Table(10,)) 'Readout example'
>>>
	  </verbatim>
	  
	  <p>We can use the <verb>walkGroups</verb> method (see <ref
	    refid="walkGroupsDescr"></ref>) of <verb>File</verb> class
	    to list only the <em>groups</em> on tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...   print group
...
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/detector (Group) 'Detector information'
>>>
	  </verbatim>

	  <p>Note that <verb>walkGroups()</verb> actually returns an
	    <em>iterator</em>, not a list of objects. Combining this
	    iterator with the <verb>listNodes()</verb> method, we can
	    do very powerful things. Let's see an example listing all
	    the arrays in the tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...     for array in h5file.listNodes(group, classname = 'Array'):
...         print array
...
/columns/name Array(4,) 'Name column selection'
/columns/pressure Array(4,) 'Pressure column selection'
	  </verbatim>

	  <p><verb>listNodes()</verb> (see <ref
	    refid="listNodesDescr"></ref>) returns a list containing
	    all the nodes hanging from a specific <verb>Group</verb>,
	    and if <em>classname</em> keyword is specified, the method
	    will filter all instances which are not descendants of
	    it. We have specified it to solely return
	    <verb>Array</verb> instances.
	  </p>

	  <p>We can combine both calls by using the
	      <verb>__call__(where, classname)</verb> special method
	      of <verb>File</verb> (<ref
	      refid="__callFileDescr">see</ref>), i.e.:
	  </p>

	  <verbatim>
>>> for array in h5file("/", "Array"):
...   print array
...
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
>>>
	  </verbatim>

	  <p>which is a nice shortcut for doing interactive work.</p>

	  <p>As a final example, we will list all the
	    <verb>Leaf</verb>, i.e. <verb>Table</verb> and
	    <verb>Array</verb> instances (see <ref
	    refid="LeafClassDescr"></ref> for detailed information on
	    <verb>Leaf</verb> class), in <verb>/detector</verb>
	    group. Check that only one instance of <verb>Table</verb>
	    class (i.e. <verb>readout</verb>) will be selected in this
	    group (as it should be):
	  </p>

	  <verbatim>
>>> for leaf in h5file.root.detector('Leaf'):
...   print leaf
...
/detector/readout (Table(10,)) 'Readout example'
>>> 
	  </verbatim>

	  <p>where we have used a call to the
	    <verb>Group.__call__(classname, recursive)</verb> special
	    method (<ref refid="__callGroupDescr"></ref>), combined
	    with a <em>natural naming</em> path specification.</p>

	  <p>Of course you can do more sophisticated node selections
	    using these powerful methods, but first, we need to
	    learn a bit about some important instance variables of
	    <verb>PyTables</verb> objects.
	  </p>

	</subsection>

	<subsection>
	  <heading>Setting and getting user attributes</heading>

	  <p>PyTables provides an easy and concise way to complement
	    the meaning of your node objects on the tree by using the
	    <verb>AttributeSet</verb> class (see <ref
	    refid="AttributeSetClassDescr">section</ref>). You can
	    access to this object through the standard attribute
	    <verb>attrs</verb> in <verb>Leaf</verb> nodes and
	    <verb>_v_attrs</verb> in <verb>Group</verb> nodes.
	  </p>

	  <p>For example, let's imagine that we want to save the date
	    indicating when the data in <verb>/detector/readout</verb>
	    table has been acquired, as well as the temperature during
	    the gathering process. That is easy:
	  </p>

	  <verbatim>
>>> table = h5file.root.detector.readout
>>> table.attrs.gath_date = "Wed, 06/12/2003 18:33"
>>> table.attrs.temperature = 18.4
>>> table.attrs.temp_scale = "Celsius"
>>>
	  </verbatim>

	  <p>Now, set a somewhat more complex attribute in the
	    <verb>/detector</verb> group:
	  </p>

	  <verbatim>
>>> detector = h5file.root.detector
>>> detector._v_attrs.stuff = [5, (2.3, 4.5), "Integer and tuple"]
>>>
	  </verbatim>

	  <p>Note how the AttributeSet instance is accessed with
	    <verb>_v_attrs</verb> because detector is a
	    <verb>Group</verb> node. In general, you can save any
	    standard Python data structure as an attribute node, but
	    see <ref refid="AttributeSetClassDescr">section</ref> for
	    a more detailed explanation of how this are serialized on
	    disk.
	  </p>

	  <p>Now, getting the attributes is equally easy:
	  </p>

	  <verbatim>
>>> table.attrs.gath_date
'Wed, 06/12/2003 18:33'
>>> table.attrs.temperature
18.399999999999999
>>> table.attrs.temp_scale
'Celsius'
>>> detector._v_attrs.stuff
[5, (2.2999999999999998, 4.5), 'Integer and tuple']
>>>
	  </verbatim>

	  <p>You can probably guess how to delete attributes:
	  </p>

	  <verbatim>
>>> del table.attrs.gath_date
	  </verbatim>

	  <p>If you want to have a look at the current attribute set
	  of <verb>/detector/table</verb>, you can print its
	  representation (try also hitting the <verb>TAB</verb> key
	  twice if you are on a Python console):
	  </p>

	  <verbatim>
>>> table.attrs
/detector/readout (AttributeSet), 14 attributes:
   [CLASS := 'TABLE',
    FIELD_0_NAME := 'ADCcount',
    FIELD_1_NAME := 'TDCcount',
    FIELD_2_NAME := 'energy',
    FIELD_3_NAME := 'grid_i',
    FIELD_4_NAME := 'grid_j',
    FIELD_5_NAME := 'idnumber',
    FIELD_6_NAME := 'name',
    FIELD_7_NAME := 'pressure',
    NROWS := 10,
    TITLE := 'Readout example',
    VERSION := '2.0',
    tempScale := 'Celsius',
    temperature := 18.399999999999999]
>>>
	  </verbatim>

	  <p>You can get a list only the user or system attributes
	    with the <verb>_v_list()</verb> method.
	  </p>

	  <verbatim>
>>> print table.attrs._f_list("user")
['temp_scale', 'temperature']
>>> print table.attrs._f_list("sys")
['CLASS', 'FIELD_0_NAME', 'FIELD_1_NAME', 'FIELD_2_NAME', 'FIELD_3_NAME',
 'FIELD_4_NAME', 'FIELD_5_NAME', 'FIELD_6_NAME', 'FIELD_7_NAME', 'NROWS',
 'TITLE', 'VERSION']
>>>
	  </verbatim>

	  <p>And rename attributes:
	  </p>

	  <verbatim>
>>> table.attrs._f_rename("temp_scale","tempScale")
>>> print table.attrs._f_list()
['tempScale', 'temperature']
>>>
	  </verbatim>

	  <p>However, you can't set, delete or rename read-only
	    attributes:
	  </p>

	  <verbatim>
>>> table.attrs._f_rename("VERSION", "version")
Traceback (most recent call last):
  File "&gt;stdin>", line 1, in ?
  File "/home/falted/PyTables/pytables-0.7/tables/AttributeSet.py", line 249, in _f_rename
    raise RuntimeError, \
RuntimeError: Read-only attribute ('VERSION') cannot be renamed
>>>
	  </verbatim>

	  <p>After your session, you can check that the
	  <verb>/detector/readout</verb> attributes in disk looks like:
	  </p>

	  <verbatim>
$ h5ls -vr tutorial1.h5/detector/readout
Opened "tutorial1.h5" with sec2 driver.
/detector/readout        Dataset {10/Inf}
    Attribute: CLASS     scalar
        Type:      6-byte null-terminated ASCII string
        Data:  "TABLE"
    Attribute: VERSION   scalar
        Type:      4-byte null-terminated ASCII string
        Data:  "2.0"
    Attribute: TITLE     scalar
        Type:      16-byte null-terminated ASCII string
        Data:  "Readout example"
    Attribute: FIELD_0_NAME scalar
        Type:      9-byte null-terminated ASCII string
        Data:  "ADCcount"
    Attribute: FIELD_1_NAME scalar
        Type:      9-byte null-terminated ASCII string
        Data:  "TDCcount"
    Attribute: FIELD_2_NAME scalar
        Type:      7-byte null-terminated ASCII string
        Data:  "energy"
    Attribute: FIELD_3_NAME scalar
        Type:      7-byte null-terminated ASCII string
        Data:  "grid_i"
    Attribute: FIELD_4_NAME scalar
        Type:      7-byte null-terminated ASCII string
        Data:  "grid_j"
    Attribute: FIELD_5_NAME scalar
        Type:      9-byte null-terminated ASCII string
        Data:  "idnumber"
    Attribute: FIELD_6_NAME scalar
        Type:      5-byte null-terminated ASCII string
        Data:  "name"
    Attribute: FIELD_7_NAME scalar
        Type:      9-byte null-terminated ASCII string
        Data:  "pressure"
    Attribute: tempScale scalar
        Type:      8-byte null-terminated ASCII string
        Data:  "Celsius"
    Attribute: temperature {1}
        Type:      native double
        Data:  18.4
    Attribute: NROWS     {1}
        Type:      native int
        Data:  10
    Location:  0:1:0:1952
    Links:     1
    Modified:  2003-07-24 13:59:19 CEST
    Chunks:    {2048} 96256 bytes
    Storage:   470 logical bytes, 96256 allocated bytes, 0.49% utilization
    Type:      struct {
                   "ADCcount"         +0    native unsigned short
                   "TDCcount"         +2    native unsigned char
                   "energy"           +3    native double
                   "grid_i"           +11   native int
                   "grid_j"           +15   native int
                   "idnumber"         +19   native long long
                   "name"             +27   16-byte null-terminated ASCII string
                   "pressure"         +43   native float
               } 47 bytes
 

	  </verbatim>


	  <p>As you can see, the use of attributes can be a good
	    mechanism to add persistent (meta) information to your
	    actual data. Be sure to use them extensively.
	  </p>

	</subsection>

	<subsection>
	  <heading>Getting object metadata</heading>

	  <p>Each object in <verb>PyTables</verb> has
	    <em>metadata</em> information about the actual data on the
	    file. Normally this <em>metainformation</em> is accessible
	    through the node instance variables. Let's have a look at
	    some examples:
	  </p>

	  <verbatim>
>>> print "Object:", table
Object: /detector/readout Table(10,) 'Readout example'
>>> print "Table name:", table.name
Table name: readout
>>> print "Table title:", table.title
Table title: Readout example
>>> print "Number of rows in table:", table.nrows
Number of rows in table: 10
>>> print "Table variable names with their type and shape:"
Table variable names with their type and shape:
>>> for name in table.colnames:
...   print name, ':= %s, %s' % (table.coltypes[name], table.colshapes[name])
...
ADCcount := UInt16, 1
TDCcount := UInt8, 1
energy := Float64, 1
grid_i := Int32, 1
grid_j := Int32, 1
idnumber := Int64, 1
name := CharType, 1
pressure := Float32, 1
>>>
	  </verbatim>

	  <p>
	    Here, the <verb>name</verb>, <verb>title</verb>,
	    <verb>nrows</verb>, <verb>colnames</verb>,
	    <verb>coltypes</verb> and <verb>colshapes</verb>
	    attributes (see <ref
	    refid="FileInstanceVariablesDescr"></ref> for a complete
	    attribute list) of <verb>Table</verb> object give us quite
	    a lot of information about actual table data.
	  </p>

	  <p>In general, you can get up-to-the-minute information
	    about the public objects in PyTables in a interactive way
	    by printing its internal doc strings:
	  </p>

	  <verbatim>
>>> print table.__doc__
Represent a table in the object tree.

    It provides methods to create new tables or open existing ones, as
    well as to write/read data to/from table objects over the
    file. A method is also provided to iterate over the rows without
    loading the entire table or column in memory.

    Data can be written or read both as Row() instances or as numarray
    (NumArray or RecArray) objects.
    
    Methods:
    
      Common to all leaves:
        close()
        flush()
        getAttr(attrname)
        rename(newname)
        remove()
        setAttr(attrname, attrvalue)
        
      Specific of Table:
        iterrows()
        read([start] [, stop] [, step] [, field [, flavor]])
        removeRows(start, stop)

    Instance variables:
    
      Common to all leaves:
        name -- the leaf node name
        hdf5name -- the HDF5 leaf node name
        title -- the leaf title
        shape -- the leaf shape
        byteorder -- the byteorder of the leaf
        
      Specific of Table:
        description -- the metaobject describing this table
        row -- a reference to the Row object associated with this table
        nrows -- the number of rows in this table
        rowsize -- the size, in bytes, of each row
        colnames -- the field names for the table (list)
        coltypes -- the type class for the table fields (dictionary)
        colshapes -- the shapes for the table fields (dictionary)

>>>
	  </verbatim>

	  <p>This is very handy if you don't have this manual at
	    hand. Try yourself with other objects docs, like for example:
	  </p>

	  <verbatim>
>>> help(table.__class__)
>>> help(table.removeRows)
	  </verbatim>

	  <p>Now, print some metadata in <em>/columns/pressure</em>
	    <verb>Array</verb> object:
	  </p>

	  <verbatim>
>>> pressureObject = h5file.getNode("/columns", "pressure")
>>> print "Info on the object:", repr(pressureObject)
Info on the object: /columns/pressure (Array(3,)) 'Pressure column selection'
  type = Float64
  itemsize = 8
  flavor = 'NumArray'
  byteorder = 'little'
>>> print "  shape: ==>", pressureObject.shape
  shape: ==> (3,)
>>> print "  title: ==>", pressureObject.title
  title: ==> Pressure column selection
>>> print "  type: ==>", pressureObject.type
  type: ==> Float64
>>>
	  </verbatim>

	  <p>Observe how we have used the <verb>getNode()</verb>
	    method of <verb>File</verb> class to access a node in the
	    tree, instead of the natural naming method. Both are
	    useful, and depending on the context you will prefer to
	    use one or another. <verb>getNode()</verb> has the
	    advantage that it can get a node from the pathname string
	    (like in this example), and, besides, you can force a
	    filter so that the node in that location has to be a
	    <em>classname</em> instance. However, I consider natural
	    naming to be more elegant and quicker to specify,
	    specially if you are using the name completion capability
	    present in interactive console. I suggest to give a try at
	    this powerful combination of natural naming and completion
	    capabilities present on most Python consoles. You will see
	    how pleasant can be browsing the object tree (well, as
	    long as this activity can be qualified in that way).
	  </p>
	  <p>If you look at the <verb>type</verb> attribute of the
	    <verb>pressureObject</verb>, you can certify that this is
	    a "<visual markup="bf">Float64</visual>" array, and that
	    by looking at their <verb>shape</verb> attribute, it can
	    deduced that the array on disk is unidimensional and has 4
	    elements. See <ref
	    refid="ArrayClassInstanceVariables"></ref> or the internal
	    string docs for the complete <verb>Array</verb> attribute
	    list.
	  </p>
	</subsection>

	<subsection>
	  <heading>Reading actual data from <visual
	  markup="tt">Array</visual> objects</heading>

	  <p>Once you have found the desired <verb>Array</verb> and
	    decided that you want to retrieve the actual data array
	    from it, you should use the <verb>read()</verb> method of
	    the <verb>Array</verb> object:</p>

	  <verbatim>
>>> pressureArray = pressureObject.read()
>>> pressureArray
array([ 25.,  36.,  49.])
>>> print "pressureArray is an object of type:", type(pressureArray)
pressureArray is an object of type: &lt;class 'numarray.numarraycore.NumArray'>
>>> nameArray = h5file.root.columns.name.read()
>>> nameArray
['Particle:      5', 'Particle:      6', 'Particle:      7']
>>> print "nameArray is an object of type:", type(nameArray)
nameArray is an object of type: &lt;type 'list'>
>>>
>>> print "Data on arrays nameArray and pressureArray:"
Data on arrays nameArray and pressureArray:
>>> for i in range(pressureObject.shape[0]):
...   print nameArray[i], "-->", pressureArray[i]
...
Particle:      5 --> 25.0
Particle:      6 --> 36.0
Particle:      7 --> 49.0
>>> pressureObject.name
'pressure'
>>> 
	  </verbatim>

	  <p>You can verify as the <verb>read()</verb> method (see
	    <ref refid="readArrayDescr">section</ref>) returns an authentic
	    <verb>numarray</verb> object for the
	    <verb>pressureObject</verb> instance by looking at the
	    output of the <verb>type()</verb> call, while for the
	    <verb>nameObject</verb> instance <verb>read()</verb>
	    returns a native Python list (of strings). This is because
	    the type of the object saved is kept as an HDF5 attribute
	    (named <verb>FLAVOR</verb>) for these objects on
	    disk. This attribute is then read as part of the
	    <verb>Array</verb> metainformation and accessible through
	    the <verb>Array.attrs.FLAVOR</verb> variable, enabling the
	    read array to be converted into the original object. This
	    provides a means to save a large variety of objects as
	    arrays with the guarantee that you will be able to recover
	    them in its original form afterwards. See <ref
	    refid="createArrayDescr">section</ref> for a complete list
	    of supported objects for <verb>Array</verb>.
	  </p>

	</subsection>

	<subsection>
	  <heading>Appending data to an existing table</heading>

	  <p>Now, let's have a look at how we can add records to an
	    existing on-disk table. Let's use our well-known
	    <em>readout</em> <verb>Table</verb> instance and let's
	    append some new values to it:
	  </p>

	  <verbatim>
>>> table = h5file.root.detector.readout
>>> particle = table.row
>>> for i in xrange(10, 15):
...     particle['name']  = 'Particle: %6d' % (i)
...     particle['TDCcount'] = i % 256
...     particle['ADCcount'] = (i * 256) % (1 &lt;&lt; 16)
...     particle['grid_i'] = i
...     particle['grid_j'] = 10 - i
...     particle['pressure'] = float(i*i)
...     particle['energy'] = float(particle['pressure'] ** 4)
...     particle['idnumber'] = i * (2 ** 34)
...     particle.append()
...
>>> table.flush()
>>>
	  </verbatim>

	  <p>That works exactly in the same way than filling a new
	    table. <verb>PyTables</verb> knows that this table is on
	    disk, and when you add new records, they are appended to
	    the end of the table<footnote>Note that you can append not
	    only scalar values to tables, but also fully
	    multidimensional array objects.</footnote>.
	  </p>
	  <p>
	    If you look carefully at the code you will see that we
	    have used the <verb>table.row</verb> attribute so as to
	    access a table row and fill it up with the new values.
	    Each time that its <verb>append()</verb> method is called,
	    the actual row is committed to the output buffer and the
	    row pointer is incremented to point to the next table
	    record. When the buffer is full, the data is saved on
	    disk, and the buffer is reused again for the next cycle.
	  </p>

	  <p><visual markup="bf">Caveat emptor</visual>!: Do not
	    forget to always call the .flush() method after a writing
	    operation; else your tables will not be fully
	    updated!.</p>

	  <p>Let's have a look at some columns of the resulting table:
	  </p>

	  <verbatim>
>>> for r in table.iterrows():
...     print "%-16s | %11.1f | %11.4g | %6d | %6d | %8d |" % \
...        (r['name'], r['pressure'], r['energy'], r['grid_i'], r['grid_j'],
...         r['TDCcount'])
...
...
Particle:      0 |         0.0 |           0 |      0 |     10 |        0 |
Particle:      1 |         1.0 |           1 |      1 |      9 |        1 |
Particle:      2 |         4.0 |         256 |      2 |      8 |        2 |
Particle:      3 |         9.0 |        6561 |      3 |      7 |        3 |
Particle:      4 |        16.0 |   6.554e+04 |      4 |      6 |        4 |
Particle:      5 |        25.0 |   3.906e+05 |      5 |      5 |        5 |
Particle:      6 |        36.0 |    1.68e+06 |      6 |      4 |        6 |
Particle:      7 |        49.0 |   5.765e+06 |      7 |      3 |        7 |
Particle:      8 |        64.0 |   1.678e+07 |      8 |      2 |        8 |
Particle:      9 |        81.0 |   4.305e+07 |      9 |      1 |        9 |
Particle:     10 |       100.0 |       1e+08 |     10 |      0 |       10 |
Particle:     11 |       121.0 |   2.144e+08 |     11 |     -1 |       11 |
Particle:     12 |       144.0 |     4.3e+08 |     12 |     -2 |       12 |
Particle:     13 |       169.0 |   8.157e+08 |     13 |     -3 |       13 |
Particle:     14 |       196.0 |   1.476e+09 |     14 |     -4 |       14 |
	  </verbatim>

	</subsection>
	<subsection>
	  <heading>And finally... how to remove rows from a table</heading>

	  <p>Let's starting finishing this tutorial by deleting some
	    rows from the table we have. Suppose that we want to
	    delete the rows from 5th to 9th (inclusive). That's very
	    easy to do:
	  </p>

	  <verbatim>
>>> table.removeRows(5,10)
5
>>>
	  </verbatim>

	  <p><verb>removeRows(start, stop)</verb> (<ref
	      refid="removeRowsDescr">see</ref>) deletes the rows in
	      the range (start, stop). It returns the number of rows
	      effectively removed.
	  </p>

	  <p>We have reached the end of this first tutorial. But, ei!,
	    do not forget to close the file after you finish all the
	    work:
	  </p>

	  <verbatim>
>>> h5file.close()
>>> ^D
$ 
	  </verbatim>

	  <p>In <ref refid="tutorial1-tableview">figure</ref> you can
	    see a graphical view of the <verb>PyTables</verb> file,
	    with the datasets we have just created. And in <ref
	    refid="tutorial1-general">figure</ref> you can see the
	    general properties of the table
	    <verb>/detector/readout</verb>.
	  </p>

	  <figure id="tutorial1-tableview">
	    <graphics file="tutorial1-tableview" scale="0.5" kind="bitmap">
	    </graphics>
	    <caption>The final version of data file for tutorial 1,
	    with a view of the data objects.
	    </caption>
	  </figure>

	  <figure id="tutorial1-general">
	    <graphics file="tutorial1-general" scale="0.5" kind="bitmap">
	    </graphics>
	    <caption>General properties of the <visual
	    markup="tt">/detector/readout</visual> table.
	    </caption>
	  </figure>

	</subsection>

      </section>

      <section id="secondExample">
	<heading>Multidimensional table cells and automatic
	  sanity checks</heading>

	<p>Now, time for a more real life example (i.e. with errors in
	  code). Here, we will create a couple of groups hanging
	  directly from <verb>root</verb> called
	  <verb>Particles</verb> and <verb>Events</verb>. Then, we
	  will put 3 tables in each group; in <verb>Particles</verb>
	  we will put tables based on <verb>Particle</verb> descriptor
	  and in <verb>Events</verb>, tables based <verb>Event</verb>
	  descriptor.
	</p>
	<p>
	  After that, we will feed the tables with a number of
	  records. Finally, we will read the recently created table
	  <verb>/Events/TEvent3</verb> and select some values from it
	  using a comprehension list.
	</p>
	<p>Look at the next script (you can find it in
	  <verb>examples/tutorial2.py</verb>). It seems to do all of
	  that, but a couple of small bugs will be shown up. Note that
	  this <verb>Particle</verb> class is not directly related
	  with the one defined in last example; this one is simpler
	  (but notice the <em>multidimensional</em> columns called
	  <verb>pressure</verb> and <verb>temperature</verb>!). And we
	  will introduce a new manner to describe a <verb>Table</verb>
	  as a dictionary, as you can see in the <verb>Event</verb>
	  description. See section <ref
	  refid="createTableDescr"></ref> about the different kinds of
	  descriptor objects that can be passed to the
	  <verb>createTable()</verb> method.
	</p>

	<verbatim>
from numarray import *
from tables import *

# Describe a particle record
class Particle(IsDescription):
    name        = StringCol(length=16) # 16-character String
    lati        = IntCol()             # integer
    longi       = IntCol()             # integer
    pressure    = Float32Col(shape=(2,3)) # array of floats (single-precision)
    temperature = FloatCol(shape=(2,3))   # array of doubles (double-precision)

# Another way to describe the columns of a table
Event = {
    "name"    : Col('CharType', 16),    # 16-character String
    "TDCcount": Col("UInt8", 1),        # unsigned byte
    "ADCcount": Col("UInt16", 1),       # Unsigned short integer
    "xcoord"  : Col("Float32", 1),      # integer
    "ycoord"  : Col("Float32", 1),      # integer
    }

# Open a file in "w"rite mode
fileh = openFile("tutorial2.h5", mode = "w")
# Get the HDF5 root group
root = fileh.root
# Create the groups:
for groupname in ("Particles", "Events"):
    group = fileh.createGroup(root, groupname)
# Now, create and fill the tables in Particles group
gparticles = root.Particles
# Create 3 new tables
for tablename in ("TParticle1", "TParticle2", "TParticle3"):
    # Create a table
    table = fileh.createTable("/Particles", tablename, Particle,
                           "Particles: "+tablename)
    # Get the record object associated with the table:
    particle = table.row
    # Fill the table with 257 particles
    for i in xrange(257):
        # First, assign the values to the Particle record
        particle['name'] = 'Particle: %6d' % (i)
        particle['lati'] = i 
        particle['longi'] = 10 - i
        ########### Detectable errors start here. Play with them!
        particle['pressure'] = array(i*arange(2*3), shape=(2,4))  # Incorrect
        #particle['pressure'] = array(i*arange(2*3), shape=(2,3))  # Correct
        ########### End of errors
        particle['temperature'] = (i**2)     # Broadcasting
        # This injects the Record values
        particle.append()      
    # Flush the table buffers
    table.flush()

# Now, go for Events:
for tablename in ("TEvent1", "TEvent2", "TEvent3"):
    # Create a table in Events group
    table = fileh.createTable(root.Events, tablename, Event,
                           "Events: "+tablename)
    # Get the record object associated with the table:
    event = table.row
    # Fill the table with 257 events
    for i in xrange(257):
        # First, assign the values to the Event record
        event['name']  = 'Event: %6d' % (i)
        event['TDCcount'] = i % (1&lt;&lt;8)   # Correct range
        ########### Detectable errors start here. Play with them!
        #event['xcoord'] = float(i**2)   # Correct spelling
        event['xcoor'] = float(i**2)     # Wrong spelling
        event['ADCcount'] = i * 2        # Correct type
        #event['ADCcount'] = "s"          # Wrong type
        ########### End of errors
        event['ycoord'] = float(i)**4
        # This injects the Record values
        event.append()

    # Flush the buffers
    table.flush()

# Read the records from table "/Events/TEvent3" and select some
table = root.Events.TEvent3
e = [ p['TDCcount'] for p in table
      if p['ADCcount'] &lt; 20 and 4 &lt;= p['TDCcount'] &lt; 15 ]
print "Last record ==>", p
print "Selected values ==>", e
print "Total selected records ==> ", len(e)
# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
	</verbatim>

	<subsection>
	  <heading>Shape checking</heading>

	  <p>If you have read the code carefully it looks pretty good,
	    but it won't work. When you run this example, you will get
	    the next error:</p>

	<verbatim>
$ python tutorial2.py
Traceback (most recent call last):
  File "tutorial2.py", line 53, in ?
    particle['pressure'] = array(i*arange(2*3), shape=(2,4))  # Incorrect
  File "/usr/local/lib/python2.2/site-packages/numarray/numarraycore.py", line 281, in array
    a.setshape(shape)
  File "/usr/local/lib/python2.2/site-packages/numarray/generic.py", line 530, in setshape
    raise ValueError("New shape is not consistent with the old shape")
ValueError: New shape is not consistent with the old shape
	</verbatim>

	  <p>which is saying that you are trying to assign an array of
	    incompatible shape to a table cell. If you look at the
	    source, we were trying to assign an array of shape
	    <verb>(2,4)</verb> to a pressure<verb></verb> element,
	    which was defined to have a shape of
	    <verb>(2,3)</verb>.
	  </p>
	  <p>In general, this kind of operations are forbidden, with
	    a honorable exception: when you tries to assign an
	    <em>scalar</em> value to a column cell that is
	    multidimensional, all the cell elements are populated with
	    the value of this scalar. This happens in the next line:
	  </p>

	  <verbatim>
        particle['temperature'] = (i**2)    # Broadcasting
	  </verbatim>

	  <p>So, the value <verb>i**2</verb> is assigned to all the
	    elements of the <verb>temperature</verb> table cell. This
	    capability is provided by the <verb>numarray</verb>
	    package and is known as <em>broadcasting</em>.
	  </p>

	</subsection>

	<subsection>
	  <heading>Field name checking</heading>

	  <p>After fixing the previous error, and re-running again the
	  program, we will get another one:
	  </p>
	  <verbatim>
$ python tutorial2.py
Traceback (most recent call last):
  File "tutorial2.py", line 74, in ?
    event['xcoor'] = float(i**2)     # Wrong spelling
  File "/home/falted/PyTables/pytables-0.7/src/hdf5Extension.pyx",
 line 1812, in hdf5Extension.Row.__setitem__
    raise AttributeError, "Error setting \"%s\" attr.\n %s" % \
AttributeError: Error setting "xcoor" attr.
 Error was: "exceptions.KeyError: xcoor"
	  </verbatim>

	  <p>This error is telling us that we tried to assign a value to
	    a non-existent field in the <em>event</em> table
	    object. By looking carefully at the <verb>Event</verb>
	    class attributes, we see that we misspelled the
	    <verb>xcoord</verb> field (we wrote <verb>xcoor</verb>
	    instead). This is very unusual in Python because if you
	    try to assign a value to a non-existent instance variable,
	    a new one is created with that name. Such a feature is not
	    satisfactory when we are dealing with an object that has
	    fixed list of field names. So, a check is made inside
	    PyTables so that if you try to assign a value to a
	    non-existing field a <verb>KeyError</verb> is raised.
	  </p>

	</subsection>

	<subsection>
	  <heading>Data type checking</heading>

	  <p>Finally, in order to test the type checking, we will change
	    the next line:
	  </p>
	  <verbatim>
	    event.ADCcount = i * 2        # Correct type
	  </verbatim>

	  <p>to read:</p>

	  <verbatim>
	    event.ADCcount = "s"          # Wrong type
	  </verbatim>

	  <p>After this modification, the next exception will be
	    raised when the script is executed:
	  </p>

	  <verbatim>
$ python tutorial2.py
Traceback (most recent call last):
  File "tutorial2.py", line 76, in ?
    event['ADCcount'] = "s"          # Wrong type
  File "/home/falted/PyTables/pytables-0.7/src/hdf5Extension.pyx", line 1812, in hdf5Extension.Row.__setitem__
    raise AttributeError, "Error setting \"%s\" attr.\n %s" % \
AttributeError: Error setting "ADCcount" attr.
 Error was: "exceptions.TypeError: NA_setFromPythonScalar: bad value type."
	  </verbatim>

	  <p>that states the kind of error (<verb>TypeError</verb>).
	  </p>

	  <p>You can admire the structure we have created with this
	    (corrected) script in <ref refid="tutorial2">figure</ref>.
	    In particular, pay attention to the multidimensional
	    column cells in table <verb>/Particles/TParticle2</verb>.
	  </p>

	  <figure id="tutorial2">
	    <graphics file="tutorial2-tableview" scale="0.5" kind="bitmap">
	    </graphics>
	    <caption>Table hierarchy for second example.</caption>
	  </figure>

	  <p>Feel free to visit the rest of examples in directory
	    <verb>examples</verb>, and try to understand them. I've
	    tried to make several use cases to give you an idea of the
	    <visual markup="tt">PyTables</visual> capabilities and its
	    way of dealing with HDF5 objects.
	  </p>

	</subsection>
      </section>
    </chapter>

    <chapter id="optimizationTips">
      <heading>Optimization tips</heading>

      <aphorism>"Tenho pensamentos que, se pudesse revelá-los e
	fazê-los viver, acrescentariam nova luminosidade às estrelas,
	nova beleza ao mundo e maior amor ao coração dos homens."
	<caption>Fernando Pessoa, in "O Eu Profundo"</caption>
      </aphorism>

      <p>On this chapter, you will get deeper knowledge of
	<verb>PyTables</verb> internals. <verb>PyTables</verb> has
	several places where the user can improve the performance of
	his application. If you are planning to deal with really large
	data, you should read carefully this section in order to learn
	how to get an important boost for your code. But if your
	dataset is small or medium size (say, up to 1 MB), you should
	not worry about that as the default parameters in
	<verb>PyTables</verb> are already tuned to handle that
	perfectly.
      </p>

      <section>
	<heading>Taking advantage of Psyco</heading>

	<p>Psyco (see <cite refid="psycoRef"></cite>)is a kind of
	  specialized compiler for Python that typically accelerates
	  Python applications with no change in source code. You can
	  think of Psyco as a kind of just-in-time (JIT) compiler, a
	  little bit like Java's, that emit machine code on the fly
	  instead of interpreting your Python program step by
	  step. The result is that your unmodified Python programs run
	  faster.
	</p>

	<p>Psyco is very easy to install and use, so in most scenarios
	  it is worth to have it a try. However, it only runs on Intel
	  386 architectures, so if you are using other architectures,
	  you are out of luck (at least until Psyco will support
	  yours).
	</p>

	<p>As an example, imagine that you have a small script that
	  reads and selects data over a series of datasets, like this:
	</p>

	<verbatim>
def readFile(filename):
    "Select data from all the tables in filename"

    fileh = openFile(filename, mode = "r")
    result = []
    for table in fileh("/", 'Table'):
        result = [ p['var3'] for p in table if p['var2'] &lt;= 20 ]

    fileh.close()
    return e

if __name__=="__main__":
    print readFile("myfile.h5")
	</verbatim>

	<p>In order to accelerate this piece of code, you can rewrite
	  your main program to look like:
	</p>

	<verbatim>
if __name__=="__main__":
    import pysco
    psyco.bind(readFile)
    print readFile("myfile.h5")
	</verbatim>

	<p>That's all!. From now on, each time that you execute your
	  python script, Psyco will deploy its sophisticated
	  algorithms so as to accelerate your calculations.
	</p>

	<p>You can see in the graphs <ref
	  refid="psycoWriteComparison"></ref> and <ref
	  refid="psycoReadComparison"></ref> how much I/O speed
	  improvement you can get by using Psyco. By looking at this
	  figures you can get an idea if these improvements are of
	  your interest or not. In general, if you are not going to
	  use compression you will take advantage of Psyco if your
	  tables are medium sized (1e+3 &lt; nrows &lt; 1e+6), and
	  this advantage will disappear progressively when the number
	  of rows grows well over one million. However if you use
	  compression, you will probably see improvements even beyond
	  this limit (see <ref
	  refid="compressionIssues">section</ref>). As always, there
	  is no substitute for experimentation with your own dataset.
	</p>

	<figure id="psycoWriteComparison">
	  <graphics file="write-medium-psyco-nopsyco-comparison" scale="0.75" kind="vector">
	  </graphics>
	  <caption>Writing tables with/without Psyco.
	  </caption>
	</figure>

	<figure id="psycoReadComparison">
	  <graphics file="read-medium-psyco-nopsyco-comparison" scale="0.75" kind="vector">
	  </graphics>
	  <caption>Reading tables with/without Psyco.
	  </caption>
	</figure>

      </section>

      <section id="compressionIssues">
	<heading>Compression issues</heading>

	<p>One of the beauties of <verb>PyTables</verb> is that it
	  supports compression on tables (but not on arrays!, that may
	  come later), although it is disabled by default. Compression
	  of big amounts of data might be a bit controversial feature,
	  because compression has a legend of being a very big CPU
	  time resources consumer. However, if you are willing to
	  check if compression can help not only reducing your dataset
	  file size but <visual markup="bf">also</visual> improving
	  your I/O efficiency, keep reading.
	</p>

	<p>There is an usual scenario where users need to save
	  duplicated data in some record fields, while the others
	  have varying values. In a relational database approach
	  such a redundant data can normally be moved to other
	  tables and a relationship between the rows on the separate
	  tables can be created. But that takes analysis and
	  implementation time, and made the underlying libraries
	  more complex and slower.
	</p>

	<p><verb>PyTables</verb> transparent compression allows the
	  user to not worry about finding which is their optimum data
	  tables strategy, but rather use less, not directly related,
	  tables with a larger number of columns while still not
	  cluttering the database too much with duplicated data
	  (compression is responsible to avoid that). As a side
	  effect, data selections can be made more easily because you
	  have more fields available in a single table, and they can
	  be referred in the same loop. This process may normally end
	  in a simpler, yet powerful manner to process your data
	  (although you should still be careful about what kind of
	  scenarios compression use is convenient or not).
	</p>

	<p>The compression library used by default is the <visual
	    markup="bf">Zlib</visual> (see <cite
	    refid="zlibRef"></cite>), and as HDF5 <em>requires</em>
	  it, you can safely use it and expect that your HDF5 files
	  can be read on any other platform that has HDF5 libraries
	  installed. Zlib provides good compression ratio, although
	  somewhat slow, and reasonably fast decompression. Because
	  of that, it is a good candidate to be used for compress
	  you data.
	</p>

	<p>However, in many situations (i.e. write <em>once</em>, read
	  <em>multiple</em>), it is critical to have <em>very
	  good</em> decompression speed (at expense of whether less
	  compression or more CPU wasted on compression, as we will
	  see soon). This is why support for two additional
	  compressors has been added to PyTables: LZO and UCL (see
	  <cite refid="lzouclRef"></cite>). Following his author (and
	  checked by the author of this manual), LZO offers pretty
	  fast compression (although small compression ratio) and
	  extremely fast decompression while UCL achieve an excellent
	  compression ratio (at the price of spending much more CPU
	  time) while allowing very fast decompression (and <em>very
	  close</em> to the LZO one). In fact, LZO and UCL are so fast
	  when decompressing that, in general (that depends on your
	  data, of course), writing and reading a compressed table is
	  actually faster (and sometimes <visual markup="bf">much
	  faster</visual>) than if it is uncompressed. This fact is
	  very important, specially if you have to deal with very
	  large amounts of data.
	</p>

	<p>Be aware that the LZO and UCL support in PyTables is not
	  standard on HDF5, so if you are going to use your PyTables
	  files in other contexts different from PyTables you will
	  not be able to read them.
	</p>

	<p>In order to give you a raw idea of what ratios would be
	  achieved, and what resources would be consumed, look at the
	  <ref refid="comprTblComparison">table</ref>. This table has
	  been obtained from synthetic data and with a somewhat
	  outdated PyTables version (0.5), so take this just as a
	  guide because your mileage will probably vary. Have also a
	  look at the graphs <ref
	  refid="lzozlibuclWriteComparison"></ref> and <ref
	  refid="lzozlibuclReadComparison"></ref> (these graphs has
	  been obtained with tables with different row sizes and
	  PyTables version than the previous example, so, do not try
	  to directly compare the figures). They show how evolves the
	  speed of writing/reading rows as the size (the row number)
	  of tables grows. Even though in these graphs the size of one
	  single row is 56 bytes, you can most probably extrapolate
	  this figures to other row sizes. If you are curious how well
	  can perform compression together with Psyco, look at the
	  graphs <ref refid="psycolzozlibuclWriteComparison"></ref>
	  and <ref refid="psycolzozlibuclReadComparison"></ref>. As
	  you can see, the results are pretty interesting.
	</p>

	<table id="comprTblComparison">
	  <!-- 	    <tabular preamble="lrrrrr"> -->
	  <tabular preamble="lccccc">
	    <tabhead>
	      <srow>Compr. Lib | File size (MB) | Time writing (s) |
		Time reading (s) | Speed writing (Krow/s) | 
		Speed reading (Krow/s) </srow>
	    </tabhead>
	    <tabbody>
	      <srow>NO COMPR     | 244.0 | 24.4 | 16.0  | 18.0 |  27.8</srow>
	      <srow>Zlib (lvl 1) |   8.5 | 17.0 |  3.11 | 26.5 | 144.4</srow>
	      <srow>Zlib (lvl 6) |   7.1 | 20.1 |  3.10 | 22.4 | 144.9</srow>
	      <srow>Zlib (lvl 9) |   7.2 | 42.5 |  3.10 | 10.6 | 145.1</srow>
	      <srow>LZO (lvl 1)  |   9.7 | 14.6 |  1.95 | 30.6 | 230.5</srow>
	      <srow>UCL (lvl 1)  |   6.9 | 38.3 |  2.58 | 11.7 | 185.4</srow>
	    </tabbody>
	  </tabular>
	  <caption>Comparison between different compression
	    libraries. The tests has been conducted on a Pentium 4 at 2
	    GHz and a hard disk at 4200 RPM.</caption>
	</table>

	<figure id="lzozlibuclWriteComparison">
	  <graphics file="write-medium-lzo-zlib-ucl-comparison" scale="0.75" kind="vector">
	  
	  </graphics>
	  <caption>Writing tables with several compressors.
	  </caption>
	</figure>

	<figure id="lzozlibuclReadComparison">
	  <graphics file="read-medium-lzo-zlib-ucl-comparison" scale="0.75" kind="vector">
	  
	  </graphics>
	  <caption>Reading tables with several compressors.
	  </caption>
	</figure>

	<figure id="psycolzozlibuclWriteComparison">
	  <graphics file="write-medium-psyco-lzo-zlib-ucl-comparison" scale="0.75" kind="vector">
	  
	  </graphics>
	  <caption>Writing tables with several compressors and Psyco.
	  </caption>
	</figure>

	<figure id="psycolzozlibuclReadComparison">
	  <graphics file="read-medium-psyco-lzo-zlib-ucl-comparison" scale="0.75" kind="vector">
	  
	  </graphics>
	  <caption>Reading tables with several compressors and Psyco.
	  </caption>
	</figure>

	<p>
	  By looking at graphs, you can expect that, generally
	  speaking, LZO would be the fastest both compressing and
	  uncompressing, but the one that achieves the worse
	  compression ratio (although that may be just ok for many
	  situations). UCL is the slowest when compressing, but is
	  faster than Zlib when decompressing, and, besides, it
	  achieves very good compression ratios (generally better than
	  Zlib). Zlib represents a balance between them: it's somewhat
	  slow compressing, the slowest during decompressing, but it
	  normally achieves fairly good compression ratios.
	</p>

	<p>So, if your ultimate goal is reading as fast as possible,
	  choose LZO. If you want to reduce as much as possible your
	  data, while retaining good read speed, choose UCL. If you
	  don't mind too much about the above parameters and/or
	  portability is important for you, Zlib is your best bet.
	</p>

	<p>The compression level that I recommend to use for all
	  compression libraries is 1. This is the lowest level of
	  compression, but if you take the approach suggested above,
	  normally the redundant data is to be found in the same
	  row, so the redundant data locality is very high and such
	  a small level of compression should be enough to achieve a
	  good compression ratio on your data tables, saving CPU
	  cycles for doing other things. Nonetheless, in some
	  situations you may want to check how compression level
	  affects your application.
	</p>

	<p> You can select the compression library and level by
	  setting the <verb>complib</verb> and <verb>compress</verb>
	  keywords in the <verb>createTable</verb> method (see <ref
	    refid="createTableDescr"></ref>). A compression level of 0
	  will completely disable compression (the default), 1 is
	  the less CPU time demanding level, while 9 is the maximum
	  level and most CPU intensive. Finally, have in mind that
	  LZO is not accepting a compression level right now, so,
	  when using LZO, 0 means that compression is not active,
	  and any other value means that LZO is active.
	</p>

      </section>

      <section id="expectedRowsOptim">
	<heading>Informing <visual markup="tt">PyTables</visual>
	  about expected number of rows in tables</heading>

	<p>The underlying HDF5 library that is used by
	  <verb>PyTables</verb> takes the data in bunches of a
	  certain length, so-called <em>chunks</em>, to write them
	  on disk as a whole, i.e. the HDF5 library treats chunks as
	  atomic objects and disk I/O is always made in terms of
	  complete chunks. This allows data filters to be defined by
	  the application to perform tasks such as compression,
	  encryption, checksumming, etc. on entire chunks.
	</p>

	<p>An in-memory B-tree is used to map chunk structures on
	  disk. The more chunks that are allocated for a dataset the
	  larger the B-tree. Large B-trees take memory and causes
	  file storage overhead as well as more disk I/O and higher
	  contention for the meta data cache. Consequently, it's
	  important to balance between memory and I/O overhead
	  (small B-trees) and time to access to data (big B-trees).
	</p>

	<p><verb>PyTables</verb> can determine an optimum chunk size
	  to make B-trees adequate to your dataset size if you help
	  it by providing an estimation of the number of rows for a
	  table. This must be made in table creation time by passing
	  this value in the <verb>expectedrows</verb> keyword of
	  <verb>createTable</verb> method (see <ref
	    refid="createTableDescr"></ref>).
	</p>

	<p>When your dataset size is bigger than 1 MB (take this
	  figure only as a reference, not strictly), by providing
	  this guess of the number of rows, you will be optimizing
	  the access to your table data. When the dataset size is
	  larger than, say 100MB, you are <visual
	    markup="bf">strongly</visual> suggested to provide such a
	  guess; failing to do that may cause your application doing
	  very slow I/O operations and demanding huge amounts
	  of memory. You have been warned!.
	</p>

      </section>

      <section>
	<heading>Selecting an User Entry Point (UEP) in your
	  tree</heading>

	<p>If you have a <visual markup="bf">huge</visual> tree in
	  your data file with many nodes on it, creating the object
	  tree would take long time. Many times, however, you are
	  interested only in access to a part of the complete tree, so
	  you won't strictly need PyTables to build the entire object
	  tree in-memory, but only the <em>interesting</em> part.
	</p>

	<p>This is were the <verb>rootUEP</verb> parameter of
	  <verb>openFile()</verb> function (see <ref
	  refid="openFileDescr"></ref>) can be helpful. Imagine that
	  you have a file called <verb>"test.h5"</verb> with the tree
	  that you can see in figure <ref refid="rootUEPfig1"></ref>,
	  and you are interested only in the section marked in red.
	  You can avoid the build of all the object tree by saying to
	  <verb>openFile</verb> that your root will be the
	  <verb>/Group2/Group3</verb> group. That is:
	</p>
	<verbatim>
	  fileh = openFile("test.h5", rootUEP="/Group2/Group3")
	</verbatim>

	<p>As a result, the actual object tree built will be like the
	  one that can be seen in <ref
	  refid="rootUEPfig2">figure</ref>.
	</p>

	<p>Of course this has been a simple example and it and the use
	  of the <verb>rootUEP</verb> parameter was not very
	  necessary. But when you have <em>thousands</em> of nodes on
	  a tree, you will certainly appreciate the
	  <verb>rootUEP</verb> parameter.
	</p>

	<figure id="rootUEPfig1">
	  <graphics file="rootUEP1" scale="0.6" kind="vector">
	  </graphics>
	  <caption>Complete tree in file <visual
	    markup="tt">test.h5</visual>, and subtree of interest for
	    the user.
	  </caption>
	</figure>

	<figure id="rootUEPfig2">
	  <graphics file="rootUEP2" scale="0.75" kind="vector">
	  </graphics>
	  <caption>Resulting object tree derived from the use of the
	    <visual markup="tt">rootUEP</visual> parameter.
	  </caption>
	</figure>
	
      </section>

    </chapter>

    <chapter id="libraryReference">
      <heading>Library Reference</heading>
      
      <aphorism>... durch planmässiges Tattonieren.  <caption>Johann
	Karl Friedrich Gauss <newline/>[asked how he came upon his
	theorems]</caption>
      </aphorism>

      <p><verb>PyTables</verb> implements several classes to represent
	the different nodes in the object tree. They are named
	<verb>File</verb>, <verb>Group</verb>, <verb>Leaf</verb>,
	<verb>Table</verb> and <verb>Array</verb>. Another one is
	responsible to build record objects from a subclass user
	declaration, and performs field and type checks; its name is
	<verb>IsDescription</verb>. An important function, called
	<verb>openFile</verb> is responsible to create, open or append
	to files. In addition, a few utility functions are defined to
	guess if an user supplied file is a <verb>PyTables</verb> or
	<verb>HDF5</verb> file. These are called
	<verb>isPyTablesFile</verb> and <verb>isHDF5</verb>. Finally,
	several first-level variables are also available to the user
	that informs about <verb>PyTables</verb> version, file format
	version or underlying libraries (as for example
	<verb>HDF5</verb>) version number.
      </p>

      <p>Let's start discussing the first-level variables and
	functions available to the user, then the methods in the
	classes defined in <verb>PyTables</verb>.
      </p>

      <section>
	<heading><visual markup="tt">tables</visual> variables and
	  functions</heading>

	<subsection>
	  <heading>Global variables</heading>

	  <description>

	    <term>__version__</term> <item>The <verb>PyTables</verb>
	    version number.</item>

	    <term>HDF5Version</term>
	    <item>The underlying HDF5 library version number.</item>

	    <term>ExtVersion</term> <item>The Pyrex extension types
	      version. This might be useful when reporting
	      bugs.</item>

	  </description>
	  
	</subsection>

	<subsection id="GlobalFunctDescr">
	  <heading>Global functions</heading>

	  <description id="openFileDescr">
	    <term>openFile(filename, mode='r', title='', trMap={},
	      rootUEP="/")
	    </term>
	    <item>Open a <verb>PyTables</verb> file and returns a File
	    object.
	    
	      <description>

		<term>filename</term> <item>The name of the file
		  (supports environment variable expansion). It is
		  suggested that it should have any of
		  <verb>".h5"</verb>, <verb>".hdf"</verb> or
		  <verb>".hdf5"</verb> extensions, although this is
		  not mandatory.
		</item>

		<term>mode</term> <item>The mode to open the file. It
		  can be one of the following:

		  <description>

		    <term>'r'</term> <item>read-only; no data can be
		      modified.</item>

		    <term>'w'</term> <item>write; a new file is created
		      (an existing file with the same name is
		      deleted).</item>

		    <term>'a'</term> <item>append; an existing file is
		      opened for reading and writing, and if the file does
		      not exist it is created.</item>

		    <term>'r+'</term> <item>is similar to 'a', but the
		      file must already exist.</item>

		  </description>
		</item>

		<term>title</term> <item>If filename is new, this will
		  set a title for the root group in this file. If
		  filename is not new, the title will be read from
		  disk, and this will not have any effect.
		</item>

		<term>trMap</term> <item>A dictionary to map names in
		  the object tree Python namespace into different HDF5
		  names in file namespace. The keys are the Python
		  names, while the values are the HDF5 names. This is
		  useful when you need to name HDF5 nodes with invalid
		  or reserved words in Python.
		</item>

		<term>rootUEP</term> <item>The root User Entry
		  Point. This is a group in the HDF5 hierarchy which
		  will be taken as the starting point to create the
		  object tree. The group has to be named after its
		  HDF5 name and can be a path. If it does not exist, a
		  <verb>RuntimeError</verb> is issued. Use this if you
		  do not want to build the <visual
		  markup="bf">entire</visual> object tree, but rather
		  only a <visual markup="bf">subtree</visual>.
		</item>
	      </description>

	    </item>

	    <term>isHDF5(filename)</term> <item>Determines whether
	      filename is in the HDF5 format or not. When successful,
	      returns a positive value, for TRUE, or 0 (zero), for
	      FALSE. Otherwise returns a negative value.  To this
	      function to work, it needs a closed file.
	    </item>

	    <term>isPyTablesFile(filename)</term> <item>Determines
	      whether a file is in the <verb>PyTables</verb> format.
	      When successful, returns the format version string, for
	      TRUE, or 0 (zero), for FALSE. Otherwise returns a
	      negative value.  To this function to work, it needs a
	      closed file.
	    </item>

	  </description>
	</subsection>
      </section>

      <section id="IsDescriptionClassDescr">
	<heading>The <visual markup="tt">IsDescription</visual> class</heading>

	<p>This class is in fact a so-called <em>metaclass</em>
	  object. There is nothing special on this fact, except that
	  their subclasses attributes are transformed during its
	  instantiation phase, and new methods for instances are
	  defined based on the values of the class attributes.
	</p>
	<p>It is designed to be used as an easy, yet meaningful way to
	  describe the properties of <verb>Table</verb> objects
	  through the use of classes that inherit properties from
	  it. In order to define such an special class, you have to
	  declare it as descendant of <em>IsDescription</em>, with
	  many attributes as columns you want in your table. The name
	  of these attributes will become the name of the columns,
	  while its values are the properties of the columns that are
	  obtained through the use of the <verb>Col</verb> class
	  constructor. See the <ref
	  refid="ColClassDescr">section</ref> for instructions on how
	  define the properties of the table columns.
	</p>
	<p>Then, you can pass an instance of this object to the
	  <verb>Table</verb> constructor, where all the information it
	  contains will be used to define the table structure. See
	  the <ref refid="secondExample">section</ref> for an example
	  on how that works.
	</p>

      </section>

      <section id="ColClassDescr">
	<heading>The <visual markup="tt">Col</visual> class and its descendants</heading>

	<p>
	  The <verb>Col</verb> class is used as a mean to declare the
	  different properties of a column of a table. In addition, a
	  series of descendant classes are offered in order to make
	  these column descriptions easier to the user. In general, it
	  is recommended to use these descendants classes, as they are
	  meaningful when found in the middle of the code.
	</p>
	<p>The only public method accessible in these classes is the
	  constructor itself.
	</p>

	<description>

	  <term>Col(dtype="Float64", shape=1, dflt=None, pos=None)
	  </term>
	  <item>Define properties for a <verb>Table</verb> column.

	    <description>

	      <term>dtype</term> <item>The data type for the
		column. See the <ref
		refid="datatypesSupported">appendix</ref> for a
		relation of data types supported in a <visual
		markup="tt">IsDescription</visual> class
		declaration. The type description is accepted both in
		string format and as numarray data type.</item>

	      <term>shape</term> <item>An integer or a tuple, that
		specifies the number of <em>dtype</em> items for each
		element (or shape, for multidimensional elements) of
		this column. For <verb>CharType</verb> columns, the
		first dimension is used as the length of the character
		strings. For this kind of objects, the use of
		<verb>StringCol</verb> subclass is recommended.</item>

	      <term>dflt</term> <item>The default value for elements
		of this column. If the user does not supply a value
		for an element while filling a table, this default
		value will be written to disk. If the user supplies an
		scalar value for a multidimensional column, this value
		is automatically <em>broadcasted</em> to all the
		elements in the column cell. If <em>dflt</em> is not
		supplied, a appropriate zero value (or <em>null</em>
		string) will be chosen by default.</item>

	      <term>pos</term> <item>By default, columns are disposed in
		memory following an alphanumerical order of the column
		names. In some situations, however, it is convenient to
		impose a user defined ordering. <em>pos</em> parameter
		allows the user to force the wanted disposition.</item>

	    </description>
	  </item>

	  <term>StringCol(length=None, dflt=None, shape=1, pos=None)
	  </term>
	  <item>Define a column to be of <verb>CharType</verb>
	    type. The <verb>length</verb> parameter sets the length of
	    the strings. The meaning of the other parameters are like
	    in the <verb>Col</verb> class.
	  </item>
	  <term>IntCol(dflt=0, shape=1, itemsize=4, sign=1, pos=None)
	  </term>
	  <item>Define a column to be of <verb>IntXXType</verb> type,
	    depending on the value of <verb>itemsize</verb>. The
	    <verb>itemsize</verb> parameter sets the number of bytes
	    of the integers in the column and the default is 4
	    bytes. <verb>sign</verb> determines if the integers are
	    signed or not. The meaning of the other parameters are
	    like in the <verb>Col</verb> class.

	    <p>This class has several descendants:
	    </p>

	    <description>
	      <term>Int8Col(dflt=0, shape=1, pos=None)</term>
	      <item>Define a column as an <verb>Int8</verb> type.</item>

	      <term>UInt8Col(dflt=0, shape=1, pos=None)</term>
	      <item>Define a column as an <verb>UInt8</verb>
	      type.</item>

	      <term>Int16Col(dflt=0, shape=1, pos=None)</term>
	      <item>Define a column as an <verb>Int16</verb> type.</item>

	      <term>UInt16Col(dflt=0, shape=1, pos=None)</term>
	      <item>Define a column as an <verb>UInt16</verb>
	      type.</item>

	      <term>Int32Col(dflt=0, shape=1, pos=None)</term>
	      <item>Define a column as an <verb>Int32</verb> type.</item>

	      <term>UInt32Col(dflt=0, shape=1, pos=None)</term>
	      <item>Define a column as an <verb>UInt32</verb>
	      type.</item>

	      <term>Int64Col(dflt=0, shape=1, pos=None)</term>
	      <item>Define a column as an <verb>Int64</verb> type.</item>

	      <term>UInt64Col(dflt=0, shape=1, pos=None)</term>
	      <item>Define a column as an <verb>UInt64</verb>
	      type.</item>

	    </description>

	  </item>

	  <term>FloatCol(dflt=0, shape=1, itemsize=8, pos=None)
	  </term>
	  <item>Define a column to be of <verb>FloatXXType</verb>
	    type, depending on the value of <verb>itemsize</verb>. The
	    <verb>itemsize</verb> parameter sets the number of bytes
	    of the floats in the column and the default is 8 bytes
	    (double precision). The meaning of the other parameters
	    are like in the <verb>Col</verb> class.

	    <p>This class has two descendants:
	    </p>

	    <description>
	      <term>Float32Col(dflt=0.0, shape=1, pos=None)</term>
	      <item>Define a column as a <verb>Float32</verb>
	      type.</item>

	      <term>Float64Col(dflt=0.0, shape=1, pos=None)</term>
	      <item>Define a column as a <verb>Float64</verb>
	      type.</item>

	    </description>
	  </item>
	</description>

      </section>

      <section id="FileClassDescr">
	<heading>The <visual markup="tt">File</visual> class</heading>

	<p>This class is returned when a <verb>PyTables</verb> file is
	  opened with the <verb>openFile()</verb> function. It has
	  methods to create, open, flush and close
	  <verb>PyTables</verb> files. Also, <verb>File</verb> class
	  offer methods to traverse the object tree, as well as to
	  create, rename and delete nodes. One of its attributes
	  (<verb>rootUEP</verb>) represents the <em>user entry
	  point</em> to the object tree attached to the file.
	</p>

	<p>Next, we will discuss the attributes and methods for File
	  class<footnote>On the following, the term <verb>Leaf</verb>
	  will whether refer to a <verb>Table</verb> or
	  <verb>Array</verb> node object.</footnote>.
	</p>

	<subsection id="FileInstanceVariablesDescr">
	  <heading><visual markup="tt">File</visual> instance
	    variables</heading>
	  <description>

	    <term>filename</term> <item>Filename opened.</item>

	    <term>isopen</term> <item>It takes the value 1 if the
	      underlying file is open. 0 otherwise.</item>

	    <term>mode</term> <item>Mode in which the filename was
	      opened.</item>

	    <term>title</term> <item>The title of the root group in
	      file.</item>

	    <term>rootUEP</term> <item>The UEP (User Entry Point)
	      group in file (see <ref
	      refid="openFileDescr"></ref>).</item>

	    <term>trMap</term> <item>This is a dictionary that maps
	      node names between python and HDF5 domain names. Its
	      initial values are set from the <em>trMap</em> parameter
	      passed to the <verb>openFile()</verb> function. You can
	      change its contents <em>after</em> a file is opened and
	      the new map will take effect over any new object added
	      to the tree.</item>

	    <term>objects</term> <item>Dictionary with all objects
	      (groups or leaves) on tree.</item>

	    <term>groups</term> <item>Dictionary with all object
	      groups on tree.</item>

	    <term>leaves</term> <item>Dictionary with all object
	      leaves on tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">File</visual> methods</heading>

	  <subsubsection id="createGroupDescr">
	    <heading>createGroup(where, name, title='')</heading>

	    <p>Create a new Group instance with name <em>name</em> in
	      <em>where</em> location.
	    </p>

	    <description>
	      <term>where</term> <item>The parent group where the new
		group will hang. <em>where</em> parameter can be a path
		string (for example
		<verb>"/Particles/TParticle1"</verb>), or another Group
		instance. </item>

	      <term>name</term>
	      <item>The name of the new group.</item>
	      
	      <term>title</term> <item>A description for this
		group.</item>

	    </description>

	  </subsubsection>

	  <subsubsection>
	    <heading id="createTableDescr">createTable(where, name,
	      description, title='', compress=0, complib = 'zlib',
	      expectedrows=10000)</heading>

	    <p>Create a new <verb>Table</verb> instance with name
	      <em>name</em> in <em>where</em> location.
	    </p>

	    <description>
	      <term>where</term> <item>The parent group where the
		new table will hang. <em>where</em> parameter can be
		a path string (for example
		<verb>"/Particles/TParticle1"</verb>), or Group
		instance. </item>

	      <term>name</term>
	      <item>The name of the new table.</item>

	      <term>description</term> <item>An instance of a
		user-defined class (derived from the
		<verb>IsDescription</verb> class) where table fields
		are defined. However, in certain situations, it is
		more handy to allow this description to be supplied
		as a dictionary (for example, when you do not know
		beforehand which structure will have your table). In
		such a cases, you can pass the description as a
		dictionary as well. See <ref
		  refid="secondExample">section</ref> for an example
		of use. Finally, a <verb>RecArray</verb> object from
		the <verb>numarray</verb> package is also accepted,
		and all the information about columns and other
		metadata is used as a basis to create the
		<verb>Table</verb> object. Moreover, if the
		<verb>RecArray</verb> has actual data this is also
		injected on the newly created <verb>Table</verb>
		object.
	      </item>

	      <term>title</term> <item>A description for this object.
	      </item>

	      <term>compress</term> <item>Specifies a compress level
		for data. The allowed range is 0-9. A value of 0
		disables compression. The default is that
		compression is disabled, that balances between
		compression effort and CPU consumption.
	      </item>
	      <term>complib</term> <item> Specifies the compression
		library to be used. Right now, <verb>"zlib"</verb>
		(default), <verb>"lzo"</verb> and <verb>"ucl"</verb>
		values are supported. See <ref
		refid="compressionIssues">section</ref> for some advice
		on which library is better suited to your needs.
	      </item>
	      <term>expectedrows</term> <item>An user estimate of the
		number of records that will be on table. If not
		provided, the default value is appropriate for tables
		until 1 MB in size (more or less, depending on the
		record size). If you plan to save bigger tables you
		should provide a guess; this will optimize the HDF5
		B-Tree creation and management process time and memory
		used. See <ref refid="expectedRowsOptim">section</ref>
		for a detailed justification of that issue.
	      </item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="createArrayDescr">createArray(where, name,
	      object, title='')</heading>

	    <p>Create a new <verb>Array</verb> instance with name
	      <em>name</em> in <em>where</em> location.
	    </p>
	    <description>

		<term>where</term> <item>The parent group where the
		  new array will hang. <em>where</em> parameter can be
		  a path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or
		  <verb>Group</verb> instance. 
		</item>

		<term>name</term> <item>The name of the new
		  array.
		</item>

		<term>object</term> <item>The regular array to be
		  saved. Currently accepted values are: lists, tuples,
		  scalars (int and float), strings and
		  (multidimensional) <verb>Numeric</verb> and
		  <verb>NumArray</verb> arrays (including
		  <verb>CharArrays</verb> string arrays). However,
		  these objects must be regular (i.e. they cannot be
		  like, for example, <verb>[[1,2],2]</verb>). Also,
		  objects that has some of its dimension equal to zero
		  are not supported (this will be solved when
		  unlimited arrays will be implemented).
		</item>

		<term>title</term> <item>A description for this
		  object.
		</item>

	      </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="getNodeDescr">getNode(where, name='',
	      classname='')</heading>

	    <p>Returns the object node <em>name</em> under
	      <em>where</em> location.
	    </p>

	      <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>name</term> <item>The object name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

		<term>classname</term> <item>If supplied, returns only
		  an instance of this class name. Allowed names in
		  <em>classname</em> are: <verb>'Group'</verb>,
		  <verb>'Leaf'</verb>, <verb>'Table'</verb> and
		  <verb>'Array'</verb>. Note that these values are
		  strings.
		</item>

	      </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="getAttrNodeDescr">getAttrNode(where,
	      attrname, name='' )</heading>

	    <p>Returns the attribute <em>attrname</em> under
	      <em>where.name</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>attrname</term> <item>The name of the attribute
		  to get.
		</item>

		<term>name</term> <item>The node name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="setAttrNodeDescr">setAttrNode(where,
	      attrname, attrvalue, name='')</heading>

	    <p>Sets the attribute <em>attrname</em> with value
	      <em>attrvalue</em> under <em>where.name</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>attrname</term> <item>The name of the attribute
		  to set on disk.
		</item>

		<term>attrvalue</term> <item>The value of the
		  attribute to set. Only strings attributes are
		  supported natively right now. However, you can
		  always use <verb>(c)Pickle</verb> so as to serialize
		  any object you want save therein.
		</item>

		<term>name</term> <item>The node name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="listNodesDescr">listNodes(where,
	      classname='')</heading>

	    <p>Returns a list with all the object nodes (Group or
	      Leaf) hanging from <em>where</em>. The list is
	      alphanumerically sorted by node name.
	    </p>
	    <description>

		<term>where</term> <item>The parent group. Can be a
		  path string or <verb>Group</verb> instance.
		</item>

		<term>classname</term> <item>If a <em>classname</em>
		  parameter is supplied, the iterator will return only
		  instances of this class (or subclasses of it). The
		  only supported classes in <em>classname</em> are
		  <verb>'Group'</verb>, <verb>'Leaf'</verb>,
		  <verb>'Table'</verb> and <verb>'Array'</verb>. Note
		  that these values are strings.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="removeNodeDescr">removeNode(where, name = "",
	      recursive=0)</heading>

	    <p>Removes the object node
	      <em>name</em> under <em>where</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance.  If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>LookupError</verb> error is
		  raised.</item>

		<term>name</term> <item>The name of the node to be
		  removed. If not provided, the <em>where</em> node is
		  changed.</item>

		<term>recursive</term> <item>If not supplied, the
		  object will be removed only if it has no
		  children. If supplied with a true value, the object
		  and all its descendants will be completely
		  removed.</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="renameNodeDescr">renameNode(where, newname,
	      name)</heading>

	    <p>Rename the object node <em>name</em> under
	      <em>where</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance.  If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>LookupError</verb> error is
		  raised.</item>

		<term>newname</term> <item>Is the new name to be
		  assigned to the node.</item>

		<term>name</term> <item>The name of the node to be
		  changed. If not provided, the <em>where</em> node is
		  changed.</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="walkGroupsDescr">walkGroups(where='/')</heading>

	    <p><em>Iterator</em> that returns the list of Groups (not
	      Leaves) hanging from <em>where</em>. If <em>where</em>
	      is not supplied, the root object is taken as origin. The
	      returned Group list is in a top-bottom order, and
	      alphanumerically sorted when they are at the same level.
	    </p>
	    <description>

		<term>where</term> <item>The origin group. Can be a
		  path string or <verb>Group</verb> instance.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading>flush()</heading>

	    <p>Flush all the leaves in the object tree.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading>close()</heading>

	    <p>Flush all the leaves in object tree and close the file.
	    </p>
	  </subsubsection>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">File</visual> special
	      methods</heading>

	  <p>Following are described the methods that automatically
	    trigger actions when a <verb>File</verb> instance is
	    accessed in a special way (e.g.,
	    <verb>fileh("/detector")</verb> will cause a call to
	    <verb>group.__call__("/detector")</verb>).
	  </p>

	  <subsubsection>
	    <heading id="__callFileDescr">__call__(where="/",
	      classname="")</heading>

	    <p>Recursively iterate over the children in the
	      <verb>File</verb> instance. It takes two parameters:</p>

	    <description>

	      <term>where</term> <item>If supplied, the iteration
	      starts from this group.</item>

	      <term>classname</term> <item><em>(String)</em> If
	      supplied, only instances of this class are
	      returned.</item>

	    </description>

	    <p>Example of use:</p>

	    <verbatim>
	      # Recursively print all the nodes hanging from '/detector'
	      print "Nodes hanging from group '/detector':"
	      for node in h5file("/detector"):
	          print node
	    </verbatim>

	  </subsubsection>

	  <subsubsection>
	    <heading id="__iterFileDescr">__iter__()</heading>

	    <p>Iterate over the children on the <verb>File</verb>
	      instance. However, this does not accept parameters. This
	      iterator <em>is recursive</em>.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      # Recursively list all the nodes in the object tree
	      print "All nodes in the object tree:"
	      for node in h5file:
	          print node
	    </verbatim>

	  </subsubsection>

	</subsection>

      </section>

      <section id="GroupClassDescr">
	<heading>The <visual markup="tt">Group</visual> class</heading>

	<p>Instances of this class are a grouping structure containing
	  instances of zero or more groups or leaves, together with
	  supporting metadata.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files, respectively, in a Unix
	  filesystem. As with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. This full path can be specified either
	  as string (like in <verb>'/group1/group2'</verb>) or as a
	  complete object path written in the Pythonic fashion known
	  as <em>natural name</em> schema (like in
	  <verb>file.root.group1.group2</verb>) and discussed in the
	  <ref refid='ObjectTreeSection'>section</ref>.
	</p>

	<p>A collateral effect of the <em>natural naming</em> schema
	  is that you must be aware when assigning a new attribute
	  variable to a Group object to not collide with existing
	  children node names. For this reason and to not pollute the
	  children namespace, it is explicitly forbidden to assign
	  "normal" attributes to Group instances, and the only ones
	  allowed must start with some reserved prefixes, like
	  "<verb>_f_</verb>" (for methods) or "<verb>_v_</verb>" (for
	  instance variables) prefixes. Any attempt to assign a new
	  attribute that does not starts with these prefixes, will
	  raise a <verb>NameError</verb> exception.
	</p>

	<p>Other effect is that you cannot use reserved Python names
	  or other non-allowed python names (like for example "$a" or
	  "44") as node names. You can, however, make use of a
	  translation map dictionary in the
	  <verb>File.openfile()</verb> method (see section <ref
	  refid="openFileDescr"></ref>) so as to use non valid Python
	  names as node names in the file.
	</p>

	<subsection>

	  <heading><visual markup="tt">Group</visual> instance
	    variables</heading>
	  <description>

	    <term>_v_title</term>
	    <item>A description for this group.</item>

	    <term>_v_name</term>
	    <item>The name of this group.</item>

	    <term>_v_hdf5name</term> <item>The name of this group in
	      HDF5 file namespace.</item>

	    <term>_v_pathname</term>
	    <item>A string representation of the group location
	      in tree.</item>

	    <term>_v_parent</term>
	    <item>The parent Group instance.</item>

	    <term>_v_rootgroup</term>
	    <item>Pointer to the root group object.</item>

	    <term>_v_file</term>
	    <item>Pointer to the associated File object.</item>

	    <term>_v_childs</term> <item>Dictionary with all nodes
	      (groups or leaves) hanging from this instance.</item>

	    <term>_v_groups</term> <item>Dictionary with all node
	      groups hanging from this instance.</item>

	    <term>_v_leaves</term> <item>Dictionary with all node
	      leaves hanging from this instance.</item>

	    <term>_v_attrs</term> <item>The associated
	    <verb>AttributeSet</verb> instance (see <ref
	    refid="AttributeSetClassDescr"></ref>).</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> methods</heading>

	  <p>This class define the <verb>__setattr__</verb>,
	    <verb>__getattr__</verb> and <verb>__delattr__</verb> and
	    they work as normally intended. So, you can access, assign
	    or delete childs to a group by just using the next
	    constructs:

	    <verbatim>
	      # Add a Table child instance under group with name "tablename"
	      group.tablename = Table(recordDict, "Record instance")
	      table = group.tablename     # Get the table child instance
	      del group.tablename         # Delete the table child instance
	    </verbatim>             

	  </p>

	  <p><visual markup="bf">Caveat: </visual>The following
	    methods are documented for completeness, and they can be
	    used without any problem. However, you should use the
	    high-level counterpart methods in the <verb>File</verb>
	    class, because these are most used in documentation and
	    examples, and are a bit more powerful than ones those
	    exposed here.
	  </p>

	  <description>

	    <term>_f_join(name)</term>
	    <item>Helper method to correctly concatenate a name child object
	      with the pathname of this group.</item>

	    <term>_f_rename(newname)</term>
	    <item>Change the name of this group to <em>newname</em>.</item>

	    <term>_f_remove(recursive=0)</term> <item>Remove this
	      object. If <em>recursive</em> is true, force the removal
	      even if this group has children.</item>

	    <term>_f_getAttr(attrname)</term> <item>Gets the HDF5
	      attribute <em>attrname</em> of this group.</item>

	    <term>_f_setAttr(attrname, attrvalue)</term> <item>Sets
	      the attribute <em>attrname</em> of this group to the
	      value <em>attrvalue</em>. Only string values are
	      allowed.</item>

	    <term>_f_listNodes(classname='')</term> <item>Returns a
	      <em>list</em> with all the object nodes hanging from
	      this instance. The list is alphanumerically sorted by
	      node name. If a <em>classname</em> parameter is
	      supplied, it will only return instances of this class
	      (or subclasses of it). The supported classes in
	      <em>classname</em> are <verb>'Group'</verb>,
	      <verb>'Leaf'</verb>, <verb>'Table'</verb> and
	      <verb>'Array'</verb>.</item>

	    <term>_f_walkGroups()</term> <item>Iterator that returns
	      the list of Groups (not Leaves) hanging from
	      <em>self</em>. The returned Group list is in a
	      top-bottom order, and alphanumerically sorted when they
	      are at the same level. </item>

	    <term>_f_close()</term> <item>Close this group, making it
	      and its children unaccessible in the object tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> special
	      methods</heading>

	  <p>Following are described the methods that automatically
	    trigger actions when a <verb>Group</verb> instance is
	    accessed in a special way (e.g.,
	    <verb>group("Table")</verb> will cause a call to
	    <verb>group.__call__("Table")</verb>).
	  </p>

	  <subsubsection>
	    <heading id="__callGroupDescr">__call__(classname="",
	      recursive=0)</heading>

	    <p>Iterate over the childs in the <verb>Group</verb>
	      instance. It takes two parameters:</p>

	    <description>

	      <term>classname</term> <item><em>(String)</em> If
	      supplied, only instances of this class are
	      returned.</item>

	      <term>recursive</term> <item><em>(Integer)</em> If
	      false, only childs hanging immediately after the group
	      are returned. If true, a recursion over all the groups
	      hanging from it is performed. </item>

	    </description>

	    <p>Example of use:</p>

	    <verbatim>
	      # Recursively print all the arrays hanging from '/'
	      print "Arrays the object tree '/':"
	      for array in h5file.root(classname="Array", recursive=1):
	          print array
	    </verbatim>

	  </subsubsection>

	  <subsubsection>
	    <heading id="__iterGroupDescr">__iter__()</heading>

	    <p>Iterate over the childs on the group instance. However,
	      this does not accept parameters. This iterator is not
	      recursive.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      # Non-recursively list all the nodes hanging from '/detector'
	      print "Nodes in '/detector' group:"
	      for node in h5file.root.detector:
	          print node
	    </verbatim>

	  </subsubsection>

	</subsection>

      </section>

      <section id="LeafClassDescr">
	<heading>The <visual markup="tt">Leaf</visual> class</heading>

	<p>This is a helper class useful to place common functionality
	  of all Leaf objects. It is also useful for classifying
	  purposes. A Leaf object is an end-node, that is, a node that
	  can hang directly from a group object, but that is not a
	  group itself. Right now this set is composed by
	  <verb>Table</verb> and <verb>Array</verb> objects. In fact,
	  <verb>Table</verb> and <verb>Array</verb> classes inherit
	  functionality from this class using the <em>mix-in</em>
	  technique.
	</p>

	<p>The public variables and methods that <verb>Table</verb>
	  and <verb>Array</verb> inherits from <verb>Leaf</verb> are
	  listed below.</p>

	<subsection>
	  <heading><visual markup="tt">Leaf</visual> instance
	    variables</heading>
	  <description>

	    <term>name</term> <item>The Leaf node name in Python
	      namespace.</item>
	    
	    <term>hdf5name</term> <item>The Leaf node name in HDF5
	      namespace.</item>
	    
	    <term>title</term> <item>The Leaf title.</item>

	    <term>shape</term> <item>The shape of the associated data
	      in the Leaf.</item>

	    <term>byteorder</term> <item>The byteorder of
	      the associated data of the Leaf.</item>

	    <term>attrs</term> <item>The associated
	    <verb>AttributeSet</verb> instance (see <ref
	    refid="AttributeSetClassDescr"></ref>).</item>

	  </description>
	</subsection>

	<subsection>
	  <heading><visual markup="tt">Leaf</visual> methods</heading>
	  <description>

	    <term>rename(newname)</term>
	    <item>Change the name of this leaf to <em>newname</em>.</item>

	    <term>remove()</term> <item>Remove this
	      leaf.</item>

	    <term>getAttr(attrname)</term> <item>Gets the HDF5
	      attribute <em>attrname</em> of this leaf.</item>

	    <term>setAttr(attrname, attrvalue)</term> <item>Sets
	      the attribute <em>attrname</em> of this leaf to the
	      value <em>attrvalue</em>. Only string values are
	      allowed.</item>

	    <term>flush()</term> <item>Flush the leaf buffers.</item>

	    <term>close()</term> <item>Flush the leaf buffers and
	      close the HDF5 dataset.</item>

	  </description>
	</subsection>

      </section>

      <section id="TableClassDescr">
	<heading>The <visual markup="tt">Table</visual> class</heading>

	<p>Instances of this class represents table objects in the
	  object tree. It provides methods to create new tables or
	  open existing ones, as well as methods to read/write data
	  and metadata from/to table objects in the file.
	</p>
	<p>Data can be read from or written to tables by accessing to
	  an special object that hangs from <verb>Table</verb>. This
	  object is an instance of the <verb>Row</verb> class (see
	  <ref refid="RowClassDescr"></ref>). See the tutorial
	  sections <ref refid="usage">chapter</ref> on how to use the
	  <verb>Row</verb> interface.
	</p>
	<p>Please note that this object inherits all the public
	  attributes and methods that <verb>Leaf</verb> has.
	</p>

	<subsection>
	  <heading><visual markup="tt">Table</visual> instance
	    variables</heading>
	  <description>

	    <term>description</term> <item>The metaobject describing
	      this table</item>

	    <term>row</term> <item>The <verb>Row</verb> instance for
	      this table (see <ref
	      refid="RowClassDescr"></ref>).</item>

	    <term>nrows</term>
	    <item>The number of rows in this table.</item>

	    <term>colnames</term>
	    <item>The field names for the table (list).</item>

	    <term>coltypes</term>
	    <item>The data types for the table fields (dictionary).</item>

	    <term>colshapes</term>
	    <item>The shapes for the table fields (dictionary).</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Table</visual> methods</heading>

	  <subsubsection>
	    <heading id="iterrowsDescr">iterrows(start=None,
	      stop=None, step=None)</heading>


	    <p>Returns an iterator yielding Row instances built from
	      rows in table. If a range is supplied (i.e. some of the
	      <em>start</em>, <em>stop</em> or <em>step</em>
	      parameters are passed), only the appropriate rows are
	      returned. Else, all the rows are returned.
	    </p>
	    <description>
		<term>start</term> <item>Sets the starting row to
		  return data. It accepts negative values meaning that
		  the count starts from the end.</item>

		<term>stop</term> <item>Sets the last row to be
		  returned to stop - 1, i.e. the end point is omitted
		  (in the Python <verb>range</verb> tradition). It
		  accepts, likewise start, negative values. A special
		  value of 0 means the last row.
		</item>

		<term>step</term> <item>When step is given, it
		  specifies the increment. Negative values are not
		  allowed right now.</item>

	      </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="readDescr">read(self, start=None, stop=None,
	      step=None, field=None, flavor=None)</heading>

	    <p>Returns the actual data in <verb>Table</verb>. If
	      <em>field</em> is not supplied, it returns the data as a
	      <verb>RecArray</verb> object table.
	    </p>
	    <description>

		<term>start</term> <item>Sets the starting row to
		  return data. It accepts negative values meaning that
		  the count starts from the end.</item>

		<term>stop</term> <item>Sets the last row to be
		  returned to stop - 1, i.e. the end point is omitted
		  (in the Python <verb>range</verb> tradition). It
		  accepts, likewise start, negative values. A special
		  value of 0 means the last row.
		</item>

		<term>step</term> <item>When step is given, it
		  specifies the increment. Negative values are not
		  allowed right now.</item>

		<term>field</term> <item>If specified, only the column
		  <em>field</em> is returned as a
		  <verb>NumArray</verb> object. If this is not
		  supplied, all the fields are selected and a
		  <verb>RecArray</verb> is returned.</item>

		<term>flavor</term> <item>When a field in table is
		  selected, passing a <em>flavor</em> parameter make
		  an additional conversion to happen in the default
		  <verb>NumArray</verb> object. <em>flavor</em> must
		  have any of the next values: <verb>Numeric</verb>,
		  <verb>Tuple</verb> or <verb>List</verb>. </item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="removeRowsDescr">removeRows(start=None,
	      stop=None)</heading>

	    <p>Removes a range of rows in the table.  If only
	      <em>start</em> is supplied, this row is to be
	      deleted. If a range is supplied, i.e. both the
	      <em>start</em> and <em>stop</em> parameters are passed,
	      all the rows in the range are removed<footnote>However,
	      for <verb>removeRows()</verb> to work, you need that the
	      rows <visual markup="bf">after</visual> the
	      <verb>stop</verb> parameter will fit in-memory so as to
	      method to work. This limitation will be hopefully
	      removed in a future version.</footnote>. A <em>step</em>
	      parameter is not supported yet.
	    </p>
	    <description>
		<term>start</term> <item>Sets the starting row to
		  be removed. It accepts negative values meaning that
		  the count starts from the end.</item>

		<term>stop</term> <item>Sets the last row to be
		  removed to <em>stop</em> - 1, i.e. the end point is
		  omitted (in the Python <verb>range</verb>
		  tradition). It accepts, likewise start, negative
		  values. A special value of 0 means the last row.
		</item>

	      </description>
	  </subsubsection>

	</subsection>
	<subsection>
	  <heading><visual markup="tt">Table</visual> special
	      methods</heading>

	  <p>Following are described the methods that automatically
	    trigger actions when a <verb>Table</verb> instance is
	    accessed in a special way (e.g.,
	    <verb>table["var2"]</verb> will cause a call to
	    <verb>table.__getitem__("var2")</verb>).
	  </p>

	  <subsubsection>
	    <heading id="__callTableDescr">__call__(start=None,
	    stop=None, step=None)</heading>

	    <p>It returns the same iterator than
	      <verb>Table.iterrows(start, stop, step)</verb>. It is,
	      therefore, a shorter way to call it.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      result = [ row['var2'] for row in table(step=4)
                          	      if row['var1'] &lt;= 20 ]
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      result = [ row['var2'] for row in table.iterrows(step=4) 
                          	      if row['var1'] &lt;= 20 ]
	    </verbatim>

	  </subsubsection>
	  <subsubsection>
	    <heading id="__iterTableDescr">__iter__()</heading>

	    <p>It returns the same iterator than
	      <verb>Table.iterrows(0,0,1)</verb>. However, this does not
	      accept parameters.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      result = [ row['var2'] for row in table 
                                      if row['var1'] &lt;= 20 ]
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      result = [ row['var2'] for row in table.iterrows() 
                          	      if row['var1'] &lt;= 20 ]
	    </verbatim>

	  </subsubsection>

	  <subsubsection>
	    <heading id="__getitemTableDescr">__getitem__(key)</heading>

	    <p>It takes different actions depending on the
	      type of the <verb>key</verb> parameter:</p>

	    <description>
	      <term><visual markup="tt">key</visual> is an
		<verb>Integer</verb></term> <item>The corresponding
		table row is returned as a
		<verb>RecArray.Record</verb> object.</item>

	      <term><visual markup="tt">key</visual> is a
		<verb>Slice</verb></term><item>The row slice
		determined by <verb>key</verb> is returned as a
		<verb>RecArray</verb> object.</item>

	      <term><visual markup="tt">key</visual> is a
		<verb>String</verb></term> <item>The <verb>key</verb>
		is interpreted as a <em>column</em> name of the table,
		and, if it exists, it is read and returned as a
		<verb>NumArray</verb> or <verb>CharArray</verb> object
		(whatever is appropriate).</item>
	    </description>

	    <p>Example of use:</p>

	    <verbatim>
	      record = table[4]
	      recarray = table[4:1000:2]
	      narray = table["var2"]
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      record = table.read(start=4)[0]
	      recarray = table.read(start=4, stop=1000, step=2)
	      narray = table.read(field="var2")
	    </verbatim>

	  </subsubsection>
	</subsection>
      </section>

      <section id="RowClassDescr">
	<heading>The <visual markup="tt">Row</visual> class</heading>

	<p>This class is used to fetch and set values on the table
	  fields. It works very much like a dictionary, where the keys
	  are the field names of the associated table and the values
	  are the values of those fields in a specific row.
	</p>
	<p>This object turns out to actually be an extension type, so
	  you won't be able to access their documentation
	  interactively. Neither you won't be able to access it's
	  internal attributes (they are not directly accessible from
	  Python), although that <em>accessors</em> (i.e. methods that
	  return an internal attribute) has been defined for the most
	  important variables.
	</p>

	<subsection>
	  <heading><visual markup="tt">Row</visual>
	    methods</heading>

	  <description>

	    <term id="appendRowDescr">append()</term> <item>Once you
	    have filled the proper fields for the current row, calling
	    this method actually commit this data to the disk
	    (actually data is written to the output buffer).</item>

	    <term>nrow()</term> <item>Accessor that returns the current
	      row in the table. It is useful to know which row is being
	      dealt with in the middle of a loop.</item>
	  </description>
	</subsection>
      </section>

      <section id="ArrayClassDescr">
	<heading>The <visual markup="tt">Array</visual>
	class</heading>

	<p>Represents an array on file. It provides methods to create
	  new arrays or open existing ones, as well as methods to
	  write/read data and metadata to/from array objects in the
	  file.
	</p>

	<p><visual markup="bf">Caveat:</visual> All
	  <verb>Numeric</verb> and <verb>numarray</verb> data types
	  are supported except those that corresponds to complex data
	  types<footnote>However, these might be included in the
	  future</footnote>. See <verb>numarray</verb> manual (<cite
	  refid="Numarray"></cite>) to know more about the supported
	  data types, or see <ref
	  refid="datatypesSupported">appendix</ref>.
	</p>

	<p>Please note that this object inherits all the public
	  attributes and methods from <verb>Leaf</verb>.
	</p>

	<subsection id="ArrayClassInstanceVariables">
	  <heading><visual markup="tt">Array</visual> instance
	    variables</heading>
	  <description>

	    <term>type</term> <item>The type class of the represented
	      array.</item>

	    <term>flavor</term> <item>The string object representation
	      for this array. It can be any of <em>"NumArray"</em>,
	      <em>"CharArray"</em>, <em>"Numeric"</em>,
	      <em>"List"</em>, <em>"Tuple"</em>, <em>"String"</em>,
	      <em>"Int"</em> or <em>"Float"</em> values.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Array</visual>
	    methods</heading>

	  <p>Note that, as this object has not internal I/O buffers,
	    there is no point in calling flush() method inherited from
	    <verb>Leaf</verb>.
	  </p>

	  <description>

	    <term id="readArrayDescr">read()</term> <item>Read the
	      array from disk and return it as a <verb>NumArray</verb>
	      (default) object, or if possible, with the original
	      <em>flavor</em> that it was saved. The supported flavors
	      are: <verb>NumArray</verb>, <verb>CharArray</verb>,
	      <verb>Numeric</verb>, <verb>List</verb>,
	      <verb>Tuple</verb>, <verb>String</verb>,
	      <verb>Int</verb> or <verb>Float</verb>. Note that as
	      long as this method is not called, the actual array data
	      is resident on disk, not in memory.</item>

	  </description>
	</subsection>
      </section>

      <section id="AttributeSetClassDescr">
	<heading>The <visual markup="tt">AttributeSet</visual>
	class</heading>

	<p>Represents the set of attributes of a node (Leaf or
	  Group). It provides methods to create new attributes, open,
	  rename or delete existing ones.
	</p>

	<p>Like in <verb>Group</verb> instances,
           <verb>AttributeSet</verb> instances use a special feature
           called <em>natural naming</em>, i.e. you can access the
           attributes on disk like if they were <em>normal</em>
           <verb>AttributeSet</verb> attributes. This offers the user
           a very convenient way to access (but also set and delete)
           node attributes by simply specifying them like a
           <em>normal</em> attribute class.
        </p>

	<p><visual markup="bf">Caveat:</visual> All Python data types
	  are supported. The scalar ones (i.e. String, Int and Float)
	  are mapped directly to the HDF5 counterparts, so you can
	  correctly visualize them with any HDF5 tool. However, the
	  rest of the data types and more general objects are
	  serialized using <verb>cPickle</verb>, so you will be able
	  to correctly retrieve them only from a Python-aware HDF5
	  library. Hopefully, the list of supported native attributes
	  will be extended to multidimensional arrays sometime in the
	  future.
	</p>

	<subsection id="AttributeSetClassInstanceVariables">
	  <heading><visual markup="tt">AttributeSet</visual> instance
	    variables</heading>
	  <description>

	    <term>_v_node</term> <item>The parent node instance.</item>

	    <term>_v_attrnames</term> <item>List with all attribute
	      names.</item>

	    <term>_v_attrnamessys</term> <item>List with system attribute
	      names.</item>

	    <term>_v_attrnamesuser</term> <item>List with user attribute
	      names.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">AttributeSet</visual>
	    methods</heading>

	  <p>Note that this class define the <verb>__setattr__</verb>,
	    <verb>__getattr__</verb> and <verb>__delattr__</verb> and
	    they work as normally intended. So, you can access, assign
	    or delete attributes on disk by just using the next
	    constructs:

	    <verbatim>
	      leaf.attrs.myattr = "string attr"  # Set the attribute myattr
	      attrib = leaf.attrs.myattr  # Get the attribute myattr
	      del leaf.attrs.myattr       # Delete the attribute myattr
	    </verbatim>             

	  </p>

	  <description>
	    <term id="listAttrDescr">_f_list(attrset = "user")
	    </term><item>Return the list of attributes of the parent
	      node.

		<description>
		  <term>attrset</term> <item>Selects the attribute set
		    to be returned. An <verb>"user"</verb> value
		    returns only the user attributes. This is the
		    default. <verb>"sys"</verb> returns only the
		    system (some of which are read-only)
		    attributes. <verb>"readonly"</verb> returns the
		    system read-only attributes. <verb>"all"</verb>
		    returns both the system and user
		    attributes.</item>
		</description>
	      </item>

	    <term id="renameAttrDescr">_f_rename(oldattrname,
	      newattrname)</term><item>Rename an attribute.</item>
	  </description>

	</subsection>

      </section>
    </chapter>

    <appendix>
      <chapter id="datatypesSupported">
	<heading>Supported data types in tables</heading>

	<p><verb>IsDescription</verb> subclasses supports a limited
	  set of data types to define the table fields. Such a set is
	  roughly the same than the types supported by the <visual
	  markup="tt">numarray</visual> package (see <cite
	  refid="Numarray"></cite>) in Python, with the exception of
	  the complex datatypes that are not supported yet.
	</p>
	<p>These data types in table columns can be set through the
	  use of the <verb>Col</verb> class and its descendants (<ref
	  refid="ColClassDescr">see</ref>). You may find useful the
	  <ref refid="datatypesSupported">table</ref> as a quick
	  reference to the complete set of supported data types in
	  PyTables.
	</p>

	<table id="datatypesSupportedTable">
	  <tabular preamble="lllcl">
	  <tabhead>
	    <srow>Type Code | Description | C Type | Size (in bytes) |
	      Python Counterpart</srow>
	  </tabhead>
	  <tabbody>
	    <srow>Int8 | 8-bit integer | signed char | 1 | Integer </srow>
	    <srow>UInt8 | 8-bit unsigned integer | unsigned char | 1 | Integer </srow>
	    <srow>Int16 | 16-bit integer | short | 2 | Integer </srow>
	    <srow>UInt16 | 16-bit unsigned integer | unsigned short | 2 | Integer </srow>
	    <srow>Int32 | integer | int | 4  | Integer </srow>
	    <srow>UInt32 | unsigned integer | unsigned int | 4 | Long </srow>
	    <srow>Int64 | 64-bit integer | long long | 8 | Long </srow>
	    <srow>UInt64 | unsigned 64-bit integer | unsigned long long | 8 | Long </srow>
	    <srow>Float32 | single-precision float | float | 4 | Float </srow>
	    <srow>Float64 | double-precision float | double | 8 | Float </srow>
	    <srow>CharType | arbitrary length string | char[] | * | String </srow>
	  </tabbody>
	</tabular>
	  <caption>Data types supported by subclasses of <visual
	      markup="tt">IsDescription</visual> definitions.</caption>
	</table>

      </chapter>
    </appendix>
  </mainmatter>

</book>

<!-- Keep this comment at the end of the file
Local variables:
mode: xml
sgml-omittag:nil
sgml-shorttag:nil
sgml-namecase-general:nil
sgml-general-insert-case:lower
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:2
sgml-indent-data:t
sgml-parent-document:nil
sgml-exposed-tags:nil
sgml-local-catalogs:nil
sgml-local-ecat-files:nil
End:
-->

