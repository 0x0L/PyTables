<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE book PUBLIC "-//Torsten Bronger//DTD tbook 1.3//EN"
                      "/usr/local/share/xml/tbook/tbook.dtd">
<book>
  <frontmatter>
    <title><visual markup="tt">PyTables</visual> User's Guide</title>
    <author>Francesc Alted</author>
    <date>November, 13th</date>
    <year>2002</year>
    <legalnotice>


<!--	   Copyright (c) 2002 Francesc Alted -->

      <p>Permission is hereby granted, free of charge, to any person
	obtaining a copy of this software and associated documentation
	files (the "Software"), to deal in the Software without
	restriction, including without limitation the rights to use,
	copy, modify, merge, publish, distribute, sublicense, and/or
	sell copies of the Software, and to permit persons to whom the
	Software is furnished to do so, subject to the following
	conditions:
      </p>
      <p>The above copyright notice and this permission notice shall
	be included in all copies or substantial portions of the
	Software.
      </p>
      <p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
	KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
	WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR
	PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
	COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
	LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
	OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
	SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
	<newline vspace="1cm"/>
      </p>

<!-- NCSA license -->

      <p><visual markup="bf">Copyright Notice and Statement for NCSA
	  HDF5 (Hierarchical Data Format 5) Software Library and
	  Utilities</visual>
      </p>

      <p>NCSA HDF5 (Hierarchical Data Format 5) Software Library and
	Utilities Copyright 1998, 1999, 2000, 2001, 2002 by the Board
	of Trustees of the University of Illinois <newline/>
	<visual markup="bf">All rights reserved.</visual>
      </p>
      <p>Contributors: National Center for Supercomputing Applications
	(NCSA) at the University of Illinois at Urbana-Champaign
	(UIUC), Lawrence Livermore National Laboratory (LLNL), Sandia
	National Laboratories (SNL), Los Alamos National Laboratory
	(LANL), Jean-loup Gailly and Mark Adler (gzip library).
      </p>
      <p>Redistribution and use in source and binary forms, with or
	without modification, are permitted for any purpose (including
	commercial purposes) provided that the following conditions
	are met:
      </p>

      <enumerate>
	<item>
	  Redistributions of source code must retain the above
	  copyright notice, this list of conditions, and the
	  following disclaimer.
	</item>
	<item>
	  Redistributions in binary form must reproduce the above
	  copyright notice, this list of conditions, and the
	  following disclaimer in the documentation and/or materials
	  provided with the distribution.
	</item>
	<item>In addition, redistributions of modified forms of the
	  source or binary code must carry prominent notices stating
	  that the original code was changed and the date of the
	  change.
	</item>
	<item>All publications or advertising materials mentioning
	  features or use of this software are asked, but not
	  required, to acknowledge that it was developed by the
	  National Center for Supercomputing Applications at the
	  University of Illinois at Urbana-Champaign and to credit
	  the contributors.
	</item>
	<item>Neither the name of the University nor the names of
	  the Contributors may be used to endorse or promote
	  products derived from this software without specific prior
	  written permission from the University or the
	  Contributors, as appropriate for the name(s) to be
	  used.
	</item>

	<item>THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY AND THE
	  CONTRIBUTORS "AS IS" WITH NO WARRANTY OF ANY KIND, EITHER
	  EXPRESSED OR IMPLIED.  In no event shall the University or
	  the Contributors be liable for any damages suffered by the
	  users arising out of the use of this software, even if
	  advised of the possibility of such damage.
	</item>

      </enumerate>

      <p>Portions of HDF5 were developed with support from the
	University of California, Lawrence Livermore National
	Laboratory (UC LLNL). The following statement applies to those
	portions of the product and must be retained in any
	redistribution of source code, binaries, documentation, and/or
	accompanying materials:
      </p>
      <p>This work was partially produced at the University of
	California, Lawrence Livermore National Laboratory (UC LLNL)
	under contract no. W-7405-ENG-48 (Contract 48) between the
	U.S. Department of Energy (DOE) and The Regents of the
	University of California (University) for the operation of UC
	LLNL.
      </p>

<!-- This paragraph does not fit well. Skip it!
      <p><visual markup="bf">DISCLAIMER:</visual> This work was
	prepared as an account of work sponsored by an agency of the
	United States Government. Neither the United States Government
	nor the University of California nor any of their employees,
	makes any warranty, express or implied, or assumes any
	liability or responsibility for the accuracy, completeness, or
	usefulness of any information, apparatus, product, or process
	disclosed, or represents that its use would not infringe
	privately- owned rights. Reference herein to any specific
	commercial products, process, or service by trade name,
	trademark, manufacturer, or otherwise, does not necessarily
	constitute or imply its endorsement, recommendation, or
	favoring by the United States Government or the University of
	California. The views and opinions of authors expressed herein
	do not necessarily state or reflect those of the United States
	Government or the University of California, and shall not be
	used for advertising or product endorsement purposes.
      </p>
-->
    </legalnotice>
  </frontmatter>

  <!--  This is only for article
  <abstract>

  <p><visual markup="tt">PyTables</visual> is a Python package whose
    goal is to allow dealing easily, but in a powerful way, with
    scientific data tables and Numerical Python objects organized in a
    hierarchical structure. Such a tables are defined as a collection
    of records whose values are stored in fixed-length fields. As a
    foundation for the underlying hierarchical data organization the
    excellent HDF5 library (http://hdf.ncsa.uiuc.edu/HDF5) has been
    chosen.
  </p>

  <p><visual markup="tt">PyTables</visual> is intended to be
    easy-to-use, and tries to be a high-performance interface to
    HDF5. To achieve this, the newest improvements introduced in
    Python 2.2 (like generators or slots and metaclasses in new-brand
    classes) has been used. Pyrex creation extension tool has been
    chosen to access the HDF5 library.
  </p>

  </abstract> -->

  <mainmatter>

<!--    <chapter kind='preface'>
      <heading></heading>

      <aphorism>La sabiduría no vale la pena si no es posible servirse
	de ella para inventar una nueva manera de preparar los
	garbanzos.<caption>Un sabio catalán<newline/> in "Cien años de
	soledad"<newline/> Gabriel García
	Márquez</caption>
      </aphorism>

    </chapter>
-->
    <chapter>
      <heading>Introduction</heading>

      <aphorism>La sabiduría no vale la pena si no es posible servirse
	de ella para inventar una nueva manera de preparar los
	garbanzos.<caption>Un sabio catalán<newline/> in "Cien años de
	soledad"<newline/> Gabriel García
	Márquez</caption>
      </aphorism>

      <p>The goal of <verb>PyTables</verb> is to enable the end user
	to manipulate easily scientific data <visual
	markup="bf">tables</visual> and <em>Numerical Python</em>
	objects in a hierarchical structure. The foundation of the
	underlying hierarchical data organization is the excellent
	<verb>HDF5</verb> library
	(<verb>http://hdf.ncsa.uiuc.edu/HDF5</verb>). Right now,
	<verb>PyTables</verb> provides limited support of all the HDF5
	functions, but I hope to add the more interesting ones (for
	<verb>PyTables</verb> needs) in the near future. Nonetheless,
	this package is not intended to serve as a complete wrapper
	for the entire HDF5 API.
      </p>

      <p>A table is defined as a collection of records whose values
	are stored in <em>fixed-length</em> fields. All records have
	the same structure and all values in each field have the same
	<em>data type</em>. The terms <em>fixed-length</em> and
	strict <em>data types</em> seems to be quite a strange
	requirement for an interpreted language like Python, but they
	serve a useful function if the goal is to save very large
	quantities of data (such as is generated by many scientific
	applications, for example) in an efficient manner that reduces
	demand on CPU time and I/O.
      </p>

      <p>In order to emulate records (that will be mapped to C structs
	in HDF5) in Python <verb>PyTables</verb> implements a special
	<em>metaclass</em> object with the capability to detect errors
	in field assignments as well as type and range
	overflows. <verb>PyTables</verb> also provides a powerful
	interface to process table data. Records in tables are also
	known, in the <verb>HDF5</verb> naming scheme, as
	<em>compound</em> data types.
      </p>

      <p>For example, you can define arbitrary records in Python
	simply by declaring a class with the name field and types
	information, like in:
      </p>

<verbatim>
class Particle(IsRecord):
    name        = '16s'  # 16-character String
    idnumber    = 'Q'    # unsigned long long (i.e. 64-bit integer)
    TDCcount    = 'B'    # unsigned byte
    ADCcount    = 'H'    # unsigned short integer
    grid_i      = 'i'    # integer
    grid_j      = 'i'    # integer
    pressure    = 'f'    # float  (single-precision)
    energy      = 'd'    # double (double-precision)

</verbatim>

      <p>then, you will normally instantiate that class, fill the
	instance with your values, and save (arbitrary large)
	collections of them in a file for persistent storage. After
	that, this data can be retrieved and post-processed quite
	easily with <visual markup="tt">PyTables</visual> or even with
	another <verb>HDF5</verb> application.
      </p>

      <p>Next section describes the most interesting capabilities of
	<verb>PyTables</verb>.</p>

      <section>
	<heading>Features</heading> <p><visual
	markup="tt">PyTables</visual> has the next capabilities:</p>

	<itemize>
	  <item><em>Support of table entities:</em> Allows working
	    with a large number of records, i.e. that don't fit in
	    memory.
	  </item>
	  <item><em>Support of <visual markup="tt">Numerical
		Python</visual> arrays:</em> <verb>Numeric</verb>
		arrays are a very useful complement of tables to keep
		homogeneous table slices (like selections of table
		columns).
	  </item>
	  <item><em>Supports a hierarchical data model:</em> That way,
	    you can structure very clearly all your
	    data. <verb>PyTables</verb> builds up an <em>object
	    tree</em> in memory that replicates the underlying file
	    data structure. Access to the file objects is achieved by
	    walking throughout this object tree, and manipulating it.
	  </item>
	  <item><em>Incremental I/O:</em> It supports adding records
	    to already created tables. So you won't need to book large
	    amounts of memory to fill the entire table and then save
	    it to disk but you can do that incrementally, even between
	    different Python sessions.
	  </item>
	  <item><em>Automatically check for correct field name, data
	    type and data range:</em> That reduces programmer mistakes
	    and if <visual markup="tt">PyTables</visual> does not
	    report an error, you can be more confident that your data
	    is probably ok.
	  </item>
	  <item><em>Support of files bigger than 2 GB:</em> The
	    underlying HDF5 library already can do that (if your
	    platform supports the C long long integer, or, on Windows,
	    __int64), and <verb>PyTables</verb> automatically inherits
	    this capability.
	  </item>
	  <item><em>Data compression:</em> It supports data
	    compression (through the use of the <visual
	    markup="tt"><visual markup="bf">zlib</visual></visual>
	    library) out of the box. This become important when you
	    have repetitive data patterns and don't want to loose your
	    time searching for an optimized way to save them (i.e. it
	    saves you data organization analysis time). This feature
	    is also inherited from HDF5.
	  </item>
	  <item><em>Big-Endian/Low-Endian safety:</em> <visual
	    markup="tt">PyTables</visual> has been carefully coded (as
	    HDF5 itself) with little-endian/big-endian byte orderings
	    issues in mind . So, in principle, you can write a file in
	    a big-endian machine and read it in other little-endian
	    without problems<footnote>Well, I didn't actually test
	    that in real world, but if you do, please, tell
	    me.</footnote>.</item>
	</itemize>

	<p>Finally, it should noted that <visual
	  markup="tt">PyTables</visual> is not intended to merely be a
	  high level wrapper of selected HDF5 functionality (for this,
	  have a look at HL-HDF5, the Swedish Meteorological and
	  Hydrological Institute effort to provide another python
	  interface to HDF5; see <ref refid="HL-HDF">reference</ref>),
	  but to provide a flexible, <em>very Pythonic</em> tool to
	  deal with (very) large amounts of data (i.e., typically
	  bigger than available memory) in tables (heterogeneous data
	  types) and arrays (homogeneous data types) organized in a
	  hierarchical, persistent disk storage. <verb>PyTables</verb>
	  take advantage of the powerful object orientation and
	  introspection capabilities offered by Python to bring all
	  this power to the user in a friendly manner.
	</p>
      </section>

      <section id="NaturalTreeSection">
	<heading>The Object Tree</heading>

	<p>The hierarchical model of the underlying HDF5 library
	  allows <verb>PyTables</verb> to manage tables and arrays in
	  a tree-like structure. In order to achieve this, an
	  <em>object tree</em> entity is <em>dynamically</em> created
	  by <verb>PyTables</verb> imitating the HDF5 structure on
	  disk. That way, the access to the HDF5 objects is made by
	  walking throughout the <visual markup="tt">PyTables</visual>
	  object tree, and, by looking at their <em>metadata</em>
	  nodes, you can get a nice picture of what kind data is kept
	  there.
	</p>

	<p>The different nodes in the object tree are instances of
	  <verb>PyTables</verb> classes. There are several types of
	  those classes, but the most important ones are the
	  <verb>Group</verb> and the
	  <verb>Leaf</verb>. <verb>Group</verb> instances (that we
	  will be calling <em>groups</em> from now on) are a grouping
	  structure containing instances of zero or more groups or
	  leaves, together with supporting metadata. <verb>Leaf</verb>
	  instances (that will be called <em>leaves</em>) are
	  containers for actual data and cannot contain any other
	  instances<footnote>Except <verb>Attribute</verb> instances
	  in the short future</footnote>. The <verb>Table</verb> and
	  <verb>Array</verb> classes are descendants of
	  <verb>Leaf</verb>, and inherits all its properties. See <ref
	  refid="LeafClassDescr">section</ref> for a more detailed
	  <verb>Leaf</verb> class description.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files, respectively, in a Unix
	  filesystem. As with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. This full path can be specified either
	  as string (like in <verb>'/subgroup2/table3'</verb>) or as a
	  complete object path written in the Pythonic fashion known
	  as <em>natural name</em> schema (like in
	  <verb>file.root.subgroup2.table3</verb>).
	</p>

	<p>The support for <em>natural naming</em> is a key aspect of
	  <verb>PyTables</verb> and means that the names of instance
	  variables of the node objects are the same as the names of
	  the element's children<footnote>I've taken this simple but
	  powerful idea from the excellent <visual
	  markup="tt">Objectify</visual> module by David Mertz (see
	  references <ref refid="Objectify"></ref> and <ref
	  refid="GnosisUtils"></ref>)</footnote>. This is very
	  <em>Pythonic</em> and comfortable in many cases, as you can
	  check in the tutorial <ref
	  refid="readingAndSelectingUsage">section</ref>.
	</p>
	<p>You should also note that not all the data present on file
	  is loaded in <visual markup="tt">PyTables</visual> tree, but
	  only the <em>metadata</em> (i.e. special data that describes
	  the structure of the actual data). The actual data is not
	  read until you ask for it (by calling a method in a
	  particular node). By making use of the object tree (the
	  metadata) you can get information on the objects on disk
	  such as table names, title, name fields, data types in
	  fields, number of records, or, in the case of arrays,
	  shapes, typecode, and so on. You can also traverse the tree
	  in order to search for something and when you find the data
	  you are interested in you can read it and process it. In
	  some sense, you can think of <verb>PyTables</verb> as a tool
	  that provide the same introspection capabilities of Python
	  objects, but applied to the persistent storage of large
	  amounts of data.
	</p>
	<p>To better understand the dynamic nature of this object tree
	  entity, imagine that we have made a script (in fact, this
	  script actually exists and you can find it in
	  <verb>examples/objecttree.py</verb>; check it out!) that
	  creates a simple <verb>PyTables</verb> file, with the
	  structure that appears in <ref
	  refid="objecttree-h5">figure</ref> (we have used the
	  <verb>hdfview</verb> utility to obtain this image). During
	  creation time, metadata in the object tree is updated in
	  memory while the actual data is being saved on disk and when
	  you close the file the object tree becomes unavailable. If
	  you re-open again this file (in read only mode, for
	  example), the object tree with will be re-constructed in
	  memory from the metadata existent on disk, and you can work
	  with it exactly in the same way than during the original
	  creation process.
	</p>

	<figure id="objecttree-h5">
	  <graphics file="objecttree-h5" scale="0.6" kind="bitmap">
	  </graphics>
	  <caption>An HDF5 example with 2 subgroups and 3 tables.</caption>
	</figure>

	<p>In <ref refid="objecttree">figure</ref> you can see an
	  example of the object tree created by reading a
	  <verb>PyTables</verb> file. If you are going to be a <visual
	  markup="tt">PyTables</visual> user, take your time to
	  understand it<footnote>Bear in mind, however, that this
	  diagram is <visual markup="bf">not</visual> a standard UML
	  class diagram; I've used an UML tool to draw it, that's
	  all)</footnote>. That will also make you more proactive by
	  avoiding programming mistakes.
	</p>

	<figure id="objecttree">
	  <!-- Now, this works! -->
	  <graphics file="objecttree" scale="0.4" kind="vector">
	  
	  <!-- If you want to convert the eps to jpeg use command:
pstoimg -scale 0.75 -aaliastext -type png -crop a -interlace objecttree.eps
	  and then, convert again to jpg with:
	  convert objecttree.png objecttree.jpg
	  Use this tag to include the jpeg file:
	  <graphics file="objecttree" scale="0.5" kind="bitmap">
	  -->
	  </graphics>
	  <caption>An object tree example in <visual
	      markup="tt">PyTables</visual>.
	  </caption>
	</figure>

      </section>

    </chapter>

    <chapter>
      <heading>Installation</heading>

      <p>This are instructions for Unix/Linux system. If you are using
	Windows, and you get the library to work, please tell me about.
      </p>

      <p>Extensions in <visual markup="tt">PyTables</visual> has been
	made using Pyrex (see <ref refid="Pyrex">reference</ref>) and
	C language. You can rebuild everything from scratch if you got
	Pyrex installed, but this is not necessary, as the Pyrex
	compiled source is included in the distribution. In order to
	do that, merely replace <visual markup="tt">setup.py</visual>
	script in these instructions by <visual
	markup="tt">setup-pyrex.py</visual>.
      </p>

      <p>The Python Distutils are used to build and install
	<verb>PyTables</verb>, so it is fairly simple to get things
	ready to go.
      </p>

      <enumerate>

	<item>
	  <p>First, make sure that you have <verb>HDF5 1.4.x</verb>
	    and <verb>Numerical Python</verb> installed (I'm using
	    <verb>HDF5 1.4.4</verb> and <verb>Numeric 22.0</verb>
	    currently). If don't, you can find them at
	    <verb>http://hdf.ncsa.uiuc.edu/HDF5</verb> and
	    <verb>http://www.pfdubois.com/numpy</verb>. Compile/install
	    them.
	  </p>
	  
	  <p><verb>setup.py</verb> will detect <verb>HDF5</verb>
	    libraries and include files under <verb>/usr</verb> or
	    <verb>/usr/local</verb>; this will catch installations
	    from RPMs, DEBs and most hand installations under Unix. If
	    <verb>setup.py</verb> can't find your <verb>libhdf5</verb>
	    or if you have several versions installed and want to
	    select one of them, then you can give it a hint either in
	    the environment (using the <verb>HDF5_DIR</verb>
	    environment variable) or on the command line by specifying
	    the directory containing the include and lib directory.
	    For example:
	  </p>
	  <verbatim>
	    --hdf5=/stuff/hdf5-1.4.4
	  </verbatim>

	  <p>If your <verb>HDF5</verb> library was built as shared
	    library, and if this shared library is not in the runtime
	    load path, then you can specify the additional linker
	    flags needed to find the shared library on the command
	    line as well. For example:
	  </p>
	  <verbatim>
	    --lflags="-Xlinker -rpath -Xlinker /stuff/hdf5-1.4.4/lib"
	  </verbatim>
	  <p>or perhaps just
	  </p>
	  <verbatim>
	    --lflags="-R /stuff/hdf5-1.4.4/lib"
	  </verbatim>

	  <p>Check your compiler and linker documentation for correct
	    syntax.
	  </p>

	  <p>It is also possible to specify linking against different
	    libraries with the <verb>--libs</verb> switch:
	  </p>
	  <verbatim>
	    --libs="-lhdf5-1.4.6"
	    --libs="-lhdf5-1.4.6 -lnsl"
	  </verbatim>
	</item>
	<item>
	  <p>From the main <verb>PyTables</verb> distribution
	    directory run this command, (plus any extra flags needed
	    as discussed above):
	  </p>
	  <verbatim>
	    python setup.py build_ext --inplace
	  </verbatim>
	  <p>depending on the compiler flags used when compiling your
	    Python executable, there may appear lots of warnings. Don't
	    worry, almost all of them are caused by variables declared
	    but never used. That's normal in Pyrex extensions.
	  </p>
	</item>
	<item>
	  <p>To run the test suite change into the test directory and run this
	    command, (assuming your shell is <verb>sh</verb> or compatible):
	  </p>
	  <verbatim>
	    PYTHONPATH=..
	    export PYTHONPATH
	    python test_all.py
	  </verbatim>
	  <p>If you would like to see some verbose output from the
	    tests simply add the flag <verb>-v</verb> and/or the word
	    <verb>verbose</verb> to the command line. You can also
	    run just the tests in a particular test module. For
	    example:
	  </p>
	  <verbatim>
	    python test_types.py -v
	  </verbatim>
	  <p>If you run into problems because Python can't load hdf5
	    shared libraries, try to set the
	    <verb>LD_LIBRARY_PATH</verb> environment variable to point
	    to the directory where the libraries are.
	  </p>
	</item>
	<item>
	  <p>To install the entire <visual
	    markup="tt">PyTables</visual> Python package, change back
	    to the root distribution directory and run this command as
	    the root user (remember to add any extra flags needed):
	  </p>
	  python setup.py install
	</item>
      </enumerate>

      <p>That's it!. Now, proceed with the next section to see how to
	use <verb>PyTables</verb>.
      </p>

    </chapter>

    <chapter id="usage">
      <heading>Usage</heading>

      <p>This chapter starts with a series of simple, yet
	comprehensive sections written in a tutorial style that will
	let you understand the main features that
	<verb>PyTables</verb> provide. If during the trip you want
	more information on some specific instance variable, global
	function or method, go to the library reference in <ref
	refid="libraryReference">chapter</ref>. You can get deeper
	knowledge of <verb>PyTables</verb> internals by reading the
	last section (<ref refid="optimizationTips"></ref>) in this
	chapter.
      </p>

      <section>
	<heading>Getting started</heading>

	<p>In this section, we will see how to define our own records
	  from Python and save collections of them (i.e. a <visual
	  markup="bf">table</visual>) on a file. Then, we will select
	  some data in the table using Python cuts, creating Numerical
	  arrays to keep this selection as separate objects in the
	  tree.
	</p>
	<p>
	  In <em>examples/tutorial1-1.py</em> you will find the
	  working version of all the code in this section. However,
	  this tutorial series has been written to allow you reproduce
	  it in a Python interactive console. You are encouraged to
	  take advantage of that by doing parallel testing and
	  inspecting the created objects during the voyage!.
	</p>

	<subsection>
	  <heading>Importing <visual markup="tt">tables</visual>
	    objects</heading>
	  
	  <p>Before to do anything you need to import the
	    public objects in the <verb>tables</verb> package. You
	    normally do that by issuing:
	  </p>
	  <verbatim>
>>> import tables
>>>
	  </verbatim>
	  <p>That is the recommended way to import <verb>tables</verb>
	    if you don't want to pollute too much your
	    namespace. However, <verb>PyTables</verb> has a very
	    reduced set of first-level primitives, so you may consider
	    to use this alternative:
	  </p>
	  <verbatim>
>>> from tables import *
>>>
	  </verbatim>
	  <p>which will export in your caller application namespace the
	    next objects: <verb>openFile</verb>, <verb>isHDF5</verb>,
	    <verb>isPyTablesFile</verb> and
	    <verb>IsRecord</verb>. These are a rather small number of
	    objects, and for commodity we will use this last way to
	    access them.
	  </p>
	  <p>If you are going to deal with <verb>Numeric</verb> arrays
	    (and normally, you will) you also need to import some
	    objects from it. You can do that in the normal way. So, to
	    access to <verb>PyTables</verb> functionality normally you
	    should start you programs with:
	  </p>
	  <verbatim>
>>> from tables import *
>>> from Numeric import *
>>>
	  </verbatim>

	</subsection>

	<subsection>
	  <heading>Declaring a Record</heading>

	  <p>Now, imagine that we have a particle detector and we want
	    to declare a record object in order to save data that
	    comes from it.
	  </p>
	  <p>Our detector has a TDC (Time to Digital Converter)
	    counter with a dynamic range of 8 bits and an ADC
	    (Analogic to Digital Converter) with a range of 16
	    bits. For these values, we will define 2 fields in our
	    record object called <verb>TDCcount</verb> and
	    <verb>ADCcount</verb>. We also want to save the grid
	    position in which the particle has been detected and we
	    will add two new fields called <verb>grid_i</verb> and
	    <verb>grid_j</verb>. Our instrumentation also can obtain
	    the pressure and energy of this particle that we want to
	    add in the same way. The resolution of pressure-gauge
	    allows us to use simple-precision float which will be
	    enough to save <verb>pressure</verb> information, while
	    <verb>energy</verb> would need a double-precision
	    float. Finally, to track this particle we want to assign
	    it a name to inform about the kind of the particle and a
	    number identifier unique for each particle. So we will add
	    a couple of fields: <verb>name</verb> will be the a string
	    of up-to 16 characters and because we want to deal with a
	    really huge number of particles, <verb>idnumber</verb>
	    will be an integer of 64-bits.
	  </p>
	  <p>With all of that, we can declare a new
	    <verb>Particle</verb> class that will keep all this info:
	  </p>

	  <verbatim>
>>> class Particle(IsRecord):
...     name        = '16s'  # 16-character String
...     idnumber    = 'Q'    # unsigned long long (i.e. 64-bit integer)
...     TDCcount    = 'B'    # unsigned byte
...     ADCcount    = 'H'    # unsigned short integer
...     grid_i      = 'i'    # integer
...     grid_j      = 'i'    # integer
...     pressure    = 'f'    # float  (single-precision)
...     energy      = 'd'    # double (double-precision)
... 
>>> 
	  </verbatim>
	  <p>This definition class is quite
	    auto-explanatory. Basically, you have to declare a class
	    variable for each field you need, and as its value you put
	    the typecode for this data field. See <ref
	    refid="datatypesSupported">appendix</ref> for a list of
	    typecodes supported in record classes
	    (<verb>IsRecord</verb> descendants).
	  </p>
	  <p>From now on, we can use <verb>Particle</verb> instances
	    as a container for our detector data and, as you will see
	    shortly, we will benefit of some magic properties
	    associated with these instances derived from the fact that
	    they are descendants from the class
	    <verb>IsRecord</verb><footnote><verb>IsRecord</verb> is
	    actually a <em>metaclass</em> in object slang, but we
	    don't need to explain nothing more about it in this
	    context. Check the sources if you are interested on how
	    that works.</footnote>.
	  </p>

	  <p>In order to do something useful with this record, we need
	    to attach it to a <verb>Table</verb> object. But first, we
	    must create a file where all the actual data pushed into
	    <verb>Table</verb> will be saved.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating a <visual markup="tt">PyTables</visual> file from scratch</heading>

	  <p>To create a <verb>PyTables</verb> file use the
	    first-level <verb>openFile</verb> (see <ref
	    refid="openFileDescr"></ref>) function:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial1.h5", mode = "w", title = "Test file")
	  </verbatim>
	  <p>This <verb>openFile</verb> is one of the objects imported
	    by the "<verb>from tables import *</verb>", do you
	    remember?. Here, we are telling that we want to create a
	    new file called "<verb>tutorial1.h5</verb>" in
	    "<verb>w</verb>"rite mode and with an informative title
	    string ("<verb>Test file</verb>"). This function tries to
	    open this file, and if successful, returns a
	    <verb>File</verb> (see <ref refid="FileClassDescr"></ref>)
	    instance which hosts the root of the object tree on its
	    <verb>root</verb> attribute.
	  </p>
	</subsection>

	<subsection>
	  <heading>Creating a new group</heading>

	  <p>Now, to better organize our data, we will create a group
	    hanging from the root called <em>detector</em>. We will
	    use this group to save our particle data there.
	  </p>
	  <verbatim>
group = h5file.createGroup("/", 'detector', 'Detector information')
	  </verbatim>

	  <p>Here, we have take the <verb>File</verb> instance
	    <verb>h5file</verb> and invoked its
	    <verb>createGroup</verb> method (see <ref
	    refid="createGroupDescr"></ref>), telling that we want to
	    create a new group called <em>detector</em> hanging from
	    "<em>/</em>", which is other way to refer to the
	    <verb>h5file.root</verb> object we mentioned before. This
	    will create a new <verb>Group</verb> (see <ref
	    refid="GroupClassDescr"></ref>) instance that will be
	    assigned to the <verb>group</verb> variable.
	  </p>

	</subsection>
	<subsection>
	  <heading>Creating a new table</heading>

	  <p>Let's now create the <verb>Table</verb> (see <ref
	    refid="TableClassDescr"></ref>) object hanging from the new
	    created group. We do that by calling the
	    <verb>createTable</verb> (see <ref
	    refid="createTableDescr"></ref>) method from the
	    <verb>h5file</verb> object:
	  </p>
	  <verbatim>
>>> table = h5file.createTable(group, 'readout', Particle(), "Readout example")
	  </verbatim>

	  <p>You can see how we asked to create the <verb>Table</verb>
	    instance hanging from <verb>group</verb>, with name
	    <em>'readout'</em>. As the record object we have passed an
	    instance of Particle, the class that we have declared
	    before, and finally we attach it a "<em>Readout
	    example</em>" title. With all this information, a new
	    <verb>Table</verb> instance is created and assigned to
	    <verb>table</verb> variable.
	  </p>

	  <p>Now, time to fill this table with some values. But first,
	    we want to get a pointer to the record object in this
	    <verb>table</verb> instance:
	  </p>
	  <verbatim>
>>> particle = table.record
	  </verbatim>

	  <p>The <verb>record</verb> attribute of <verb>table</verb>
	    points to the <verb>Particle</verb> instance used to
	    create the table, and we assign it to the
	    <verb>particle</verb> variable that will be used as a
	    shortcut. This step is not really necessary, but helps to
	    code legibility (and allows me to introduce the
	    <verb>record</verb> attribute).
	  </p>

	  <p>We can proceed right now to the filling process:
	  </p>

	  <verbatim>
>>> for i in xrange(10):
...     # First, assign the values to the Particle record
...     particle.name  = 'Particle: %6d' % (i)
...     particle.TDCcount = i % 256    
...     particle.ADCcount = (i * 256) % (1 &lt;&lt; 16)
...     particle.grid_i = i 
...     particle.grid_j = 10 - i
...     particle.pressure = float(i*i)
...     particle.energy = float(particle.pressure ** 4)
...     particle.idnumber = i * (2 ** 34)  # This exceeds long integer range
...     # Insert a new particle record
...     table.appendAsRecord(particle)      
...
>>> 
	  </verbatim>
	  
	  <p>This code is quite easy to understand. The lines inside
	    the loop just assigned values to the <verb>particle</verb>
	    record object and then a call to the
	    <verb>appendAsRecord</verb> (see <ref
	    refid="appendAsRecordDescr"></ref>) method of
	    <verb>table</verb> instance is made to put this
	    information in the <verb>table</verb> I/O buffer.
	  </p>

	  <p>After we have filled all our data, we should flush the
	    I/O buffer for the table if we want to consolidate all
	    this data on disk. We do that by calling the
	    <verb>table</verb> <verb>flush</verb> method.
	  </p>
	  <verbatim>
>>> table.flush()
	  </verbatim>

	</subsection>

	<subsection>
	  <heading>Reading (and selecting) data in table</heading>

	  <p>Ok. We have now our data on disk but to this data be
	    useful we need to access it and select some values we are
	    interested in and located at some specific columns. That's
	    is easy to do:
	  </p>
	  <verbatim>
>>> table = h5file.root.detector.readout
>>> pressure = [ x.pressure for x in table.readAsRecords()
...                  if x.TDCcount > 3 and x.pressure &lt; 50 ]
	  </verbatim>

	  <p>The first line is only to declare a convenient shortcut
	    to the <em>readout</em> table which is a bit deeper on the
	    object tree. As you can see, we have used the <visual
	    markup="bf">natural naming</visual> schema to access
	    it. We could also have used the
	    <verb>h5file.getNode</verb> method instead, and we
	    certainly do that later on.
	  </p>

	  <p>The last two lines are a Python comprehensive list. It
	    loops on records returned by
	    <verb>table.readAsRecords()</verb> (see <ref
	    refid="readAsRecordsDescr"></ref>) iterator that returns
	    values until table data is exhausted. This records are
	    filtered using the <em>cut</em> expression
	    <verb>x.TDCcount > 3 and x.pressure &lt; 50</verb>, and
	    the <verb>pressure</verb> field for satisfying records is
	    selected to form the final list that is assigned to
	    <verb>pressure</verb> variable.
	  </p>

	  <p>We could have used a normal <verb>for</verb> loop to do
	    that, but I find comprehension syntax more compact and
	    elegant (and faster to execute!).
	  </p>

	  <p>Let's select the names for the same set of particles:
	  </p>

	  <verbatim>
>>> names = [ x.name for x in table.readAsRecords()
...               if x.TDCcount > 3 and x.pressure &lt; 50 ]
	  </verbatim>

	  <p>Ok. that's enough for selections. Next section will show
	    you how save these selections on file.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating new array objects</heading>

	  <p>In order to separate the selected data from the detector
	    data, we will create a new group, called
	    <verb>columns</verb> hanging from the root group:
	  </p>

	  <verbatim>
>>> gcolumns = h5file.createGroup(h5file.root, "columns", "Pressure and Name")
	  </verbatim>

	  <p>Note that this time we have specified the first parameter
	    in a natural naming fashion (<verb>h5file.root</verb>)
	    instead of using an absolute path string ("/").
	  </p>

	  <p>Now, create the <verb>Array</verb> objects on file:
	  </p>

	  <verbatim>
>>> h5file.createArray(gcolumns, 'pressure', array(pressure),
...                    "Pressure column selection")
&lt;tables.Array.Array object at 0x8217cac>
>>> h5file.createArray('/columns', 'name', array(names), 
...                    "Name column selection")
&lt;tables.Array.Array object at 0x814c3dc>
	  </verbatim>

	  <p>We already know the first two parameters of the
	    <verb>createArray</verb> (see <ref
	    refid="createArrayDescr"></ref>) methods (these are the
	    same as the firsts in <verb>createTable</verb>): they are
	    the parent group <em>where</em> <verb>Array</verb> will be
	    created and the <verb>Array</verb> instance
	    <em>name</em>. You can figure out that the fourth
	    parameter is the <em>title</em>. And in the third position
	    we have the <verb>Numeric</verb> object we want to save on
	    disk. They are built from the selection lists we created
	    before, and their typecodes are automatically selected by
	    the <verb>array()</verb> constructor to store the list of
	    values. In this case they are double-precision arrays, as
	    we will see in short.
	  </p>

	  <p>Note that <verb>createArray</verb> method returns an
	    <verb>Array</verb> instance that is not assigned to any
	    variable. Don't worry, this was intentional. The
	    <verb>Array</verb> object has been attached to the object
	    tree and saved in disk. Keep reading, in short I will show
	    you how to retrieve it.
	  </p>

	</subsection>

	<subsection>
	  <heading>Closing the file and looking at its content</heading>

	  <p>To finish this small tutorial, we use the
	    <verb>close</verb> method of the h5file <verb>File</verb>
	    instance to close the file:
	  </p>
	  <verbatim>
>>> h5file.close()
	  </verbatim>

	  <p>With all that, you have created your first
	    <verb>PyTables</verb> file with a table inside it. That
	    was easy, admit it. Now, you can have a look at it with
	    some generic HDF5 tool, like h5dump or h5ls. Here is the
	    result of passing to h5ls the <verb>tutorial1.h5</verb>
	    file:
	  </p>
	  <verbatim>
$ h5ls -rd tutorial1.h5 
/tutorial1.h5/columns    Group
/tutorial1.h5/columns/name Dataset {1}
    Data:
        (0) ["P","a","r","t","i","c","l","e",":"," "," "," "," "," "," ","4",
        (0)  "P","a","r","t","i","c","l","e",":"," "," "," "," "," "," ","5",
        (0)  "P","a","r","t","i","c","l","e",":"," "," "," "," "," "," ","6",
        (0)  "P","a","r","t","i","c","l","e",":"," "," "," "," "," "," ","7"]
/tutorial1.h5/columns/pressure Dataset {1}
    Data:
        (0) [16,25,36,49]
/tutorial1.h5/detector   Group
/tutorial1.h5/detector/readout Dataset {10/Inf}
    Data:
        (0) {0, 0, 0, 0, 10, 0, "Particle:      0", 0},
        (1) {256, 1, 1, 1, 9, 17179869184, "Particle:      1", 1},
        (2) {512, 2, 256, 2, 8, 34359738368, "Particle:      2", 4},
        (3) {768, 3, 6561, 3, 7, 51539607552, "Particle:      3", 9},
        (4) {1024, 4, 65536, 4, 6, 68719476736, "Particle:      4", 16},
        (5) {1280, 5, 390625, 5, 5, 85899345920, "Particle:      5", 25},
        (6) {1536, 6, 1679616, 6, 4, 103079215104, "Particle:      6", 36},
        (7) {1792, 7, 5764801, 7, 3, 120259084288, "Particle:      7", 49},
        (8) {2048, 8, 16777216, 8, 2, 137438953472, "Particle:      8", 64},
        (9) {2304, 9, 43046721, 9, 1, 154618822656, "Particle:      9", 81}

	  </verbatim>

	  <p>or, using the "dumpFile.py" <verb>PyTables</verb> utility
	    (located in <verb>examples/</verb> directory):
	  </p>

	  <verbatim>
Filename: tutorial1.h5
All objects:
Filename: tutorial1.h5 \\ Title: "Test file" \\ Format version: 1.0
/ (Group) "Test file"
/columns (Group) "Pressure and Name"
/columns/name Array(4, 16) "Name column selection"
/columns/pressure Array(4,) "Pressure column selection"
/detector (Group) "Detector information"
/detector/readout Table(8, 10) "Readout example"

	  </verbatim>

	  <p>You can pass the <verb>-v</verb> option to
	    <verb>dumpFile.py</verb> if you want more verbosity.
	  </p>
	</subsection>
      </section>

      <section>
	<heading>Browsing the <visual markup="it">object tree</visual>
	  and beyond</heading>

	<p>In this section, we will learn how to browse the tree while
	  retrieving metainformation about the actual data, and will
	  finish by appending some rows to the existing table to show
	  how table objects can be enlarged.
	</p>
	<p>
	  In <em>examples/tutorial1-2.py</em> you will find the
	  working version of all the code in this section. As before,
	  you are encouraged to use a python shell and inspect the
	  object tree during the voyage.
	</p>

	<subsection>
	  <heading>Traversing the object tree</heading>

	  <p>First of all, let's open the file we have recently
	    created in last tutorial section, as we will take it as a
	    basis for this section:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial1.h5", "a")
	  </verbatim>

	  <p>This time, we have opened the file in "a"ppend mode. We
	    are using this mode because we want to add more
	    information to the file.
	  </p>
	  <p><verb>PyTables</verb>, following the Python tradition,
	    offers powerful instropection capabilities, i.e. you can
	    easily ask information about any component of the object
	    tree as well as traverse the tree searching for something.
	  </p>
	  <p>To start with, you can get a first glance image of the
	    object tree, by simply printing the existing
	    <verb>File</verb> instance:
	  </p>

	  <verbatim>
>>> print h5file
Filename: tutorial1.h5 \\ Title: "Test file" \\ Format version: 1.0
/ (Group) "Test file"
/columns (Group) "Pressure and Name"
/columns/name Array(4, 16) "Name column selection"
/columns/pressure Array(4,) "Pressure column selection"
/detector (Group) "Detector information"
/detector/readout Table(8, 10) "Readout example"

>>>
	  </verbatim>

	  <p>That's right, it seems that all our objects are there. We
	    can use the <verb>walkGroups</verb> method (see <ref
	    refid="walkGroupsDescr"></ref>) of <verb>File</verb> class
	    to list all the groups on tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...     print group
... 
/ (Group) "Test file"
/columns (Group) "Pressure and Name"
/detector (Group) "Detector information"
	  </verbatim>

	  <p>Note that <verb>walkGroups</verb> actually returns an
	    iterator, not a list of objects. And combining it with the
	    <verb>listNodes</verb> method, we can do very powerful
	    things. Let's see an example listing all the arrays in the
	    tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...     for array in h5file.listNodes(group, classname = 'Array'):
...         print array
... 
/columns/name Array(4, 16) "Name column selection"
/columns/pressure Array(4,) "Pressure column selection"
	  </verbatim>

	  <p><verb>listNodes</verb> (see <ref
	    refid="listNodesDescr"></ref>) lists all the nodes hanging
	    from a <verb>group</verb>, and if <em>classname</em>
	    keyword is specified, the method will filter all instances
	    which are not descendants of it. We have specified it so
	    as to return only the <verb>Array</verb> instances.
	  </p>
	  <p>
	    <visual markup="bf">Caveat emptor</visual>:
	    <verb>listNodes</verb> (conversely to
	    <verb>walkGroups</verb>) returns an actual list, not an
	    iterator!.
	  </p>

	  <p>As a final example, we will list all the
	    <verb>Leaf</verb> (i.e. <verb>Table</verb> and
	    <verb>Array</verb> instances, see <ref
	    refid="LeafClassDescr"></ref> for detailed information on
	    <verb>leaf</verb> class) objects in <em>/detector</em>
	    group. Check that only one instance of <verb>Table</verb>
	    class will be selected in this group (as it should be):
	  </p>

	  <verbatim>
>>> for table in h5file.listNodes("/detector", 'Leaf'):
...     print table
... 
/detector/readout Table(8, 10) "Readout example"
>>> 
	  </verbatim>

	  <p>Of course you can do more sophisticated node selections
	    using this two powerful functions, but first, we need to
	    learn a bit about important instance variable of
	    <verb>PyTables</verb> objects.
	  </p>

	</subsection>

	<subsection>
	  <heading>Getting object metadata</heading>

	  <p>Each object in <verb>PyTables</verb> has metadata about
	    the actual data on the file. Normally this metainformation
	    is accessible through the node instance variables. Let's
	    see some examples:
	  </p>

	  <verbatim>
>>># Get a pointer to '/detector/readout' data
... table = h5file.root.detector.readout
>>> # Get metadata from table
... print "Object:", table
Object: /detector/readout Table(8, 10) "Readout example"
>>> print "Table name:", table.name
Table name: readout
>>> print "Table title:", table.title
Table title: Readout example
>>> print "Number of rows in table: %d" % (table.nrows)
Number of rows in table: 10
>>> print "Table variable names (sorted alphanumerically) with their type:"
Table variable names (sorted alphanumerically) with their type:
>>> for i in range(len(table.varnames)):
...     print "  ", table.varnames[i], ':=', table.vartypes[i]
... 
   ADCcount := H
   TDCcount := B
   energy := d
   grid_i := i
   grid_j := i
   idnumber := Q
   name := 16s
   pressure := f

	  </verbatim>

	  <p>
	    Here, the <verb>name</verb>, <verb>title</verb>,
	    <verb>nrows</verb>, <verb>varnames</verb> and
	    <verb>vartypes</verb> attributes (see <ref
	    refid="FileInstanceVariablesDescr"></ref> for a complete
	    attribute list) of <verb>Table</verb> object give us quite
	    a lot of information about actual table data.
	  </p>
	  <p>Observe how we have used the <verb>getNode</verb> method
	    of <verb>File</verb> class to access a node in the tree,
	    as well as the natural naming method. Both are useful, and
	    depending on the context you will prefer to use one or
	    another. <verb>getNode</verb> has the advantage that can
	    get a node from the pathname string (like in this
	    example), and you can force that the node in that location
	    has to be a <em>classname</em> instance. However, natural
	    naming is more elegant and quicker to specify (specially
	    if you are using the name completion capability present in
	    interactive console).
	  </p>

	  <p>Now, print some metadata in <em>/columns/pressure</em>
	    Array object:
	  </p>

	  <verbatim>
>>> # Get the object in "/columns pressure"
... pressureObject = h5file.getNode("/columns", "pressure")
>>> 
>>> # Get some metadata on this object
... print "Info on the object:", pressureObject
Info on the object: /columns/pressure Array(4,) "Pressure column selection"
>>> print "  shape: ==>", pressureObject.shape
  shape: ==> (4,)
>>> print "  title: ==>", pressureObject.title
  title: ==> Pressure column selection
>>> print "  typecode ==>", pressureObject.typecode
  typecode ==> d
	  </verbatim>

	  <p>If you look at the <verb>typecode</verb> attribute of the
	    <verb>pressureObject</verb>, you can certify that this is
	    a "d"ouble <verb>Numeric</verb> array, and that by looking
	    at their <verb>shape</verb> attribute the array on disk is
	    unidimensional and has 4 elements. See <ref
	    refid="ArrayClassInstanceVariables"></ref> for the
	    complete <verb>Array</verb> attribute list
	  </p>
	</subsection>

	<subsection>
	  <heading>Reading actual data from <visual
	  markup="tt">Array</visual> objects</heading>

	  <p>Once you have found the desired <verb>Array</verb> and
	    decided that you want to retrieve the actual
	    <verb>Numeric</verb> array from it, you should use the
	    <verb>read</verb> method of the <verb>Array</verb>
	    object:</p>

	  <verbatim>
>>> # Read the 'pressure' actual data
... pressureArray = pressureObject.read()
>>> 
>>> # Read the 'name' Array actual data
... nameArray = h5file.root.columns.name.read()
>>> 
>>> # Check the kind of object we have created (they should be Numeric arrays)
... print "pressureArray is object of type:", type(pressureArray)
pressureArray is object of type: &lt;type 'array'>
>>> print "nameArray is object of type:", type(nameArray)
nameArray is object of type: &lt;type 'array'>
>>> # Print the data for both arrays
... print "Data on arrays nameArray and pressureArray:"
Data on arrays nameArray and pressureArray:
>>> for i in range(pressureObject.shape[0]):
...     print "".join(nameArray[i]), "-->", pressureArray[i]
... 
Particle:      4 --> 16.0
Particle:      5 --> 25.0
Particle:      6 --> 36.0
Particle:      7 --> 49.0
>>> 

	  </verbatim>

	  <p>You can verify that <verb>read</verb> method (see <ref
	    refid="readArrayDescr"></ref>) returns an authentic
	    <verb>Numeric</verb> array looking at the output of the
	    <verb>type()</verb> call. Check also that
	    <verb>nameArray</verb> is actually a 2-dimensional Numeric
	    array. This is because Numeric does not support arrays of
	    strings, and these are represented as arrays of characters
	    plus one dimension (that of the string dimension). This is
	    why we have used the standard <verb>join</verb> method to
	    glue the characters on this extra dimension and get the
	    original arrays.
	  </p>

	</subsection>

	<subsection>
	  <heading>Appending data to an existing table</heading>

	  <p>To finish this section, let's have a look at how
	    we can add records to an existing on-disk table. Let's use
	    our well-known <em>readout</em> <verb>Table</verb>
	    instance and let's append some new values to it:
	  </p>

	  <verbatim>
>>> # Create a shortcut to table object
... table = h5file.root.detector.readout
>>> 
>>> # Get the object record from table
... particle = table.record
>>> 
>>> # Append 5 new particles to table (yes, tables can be enlarged!)
... for i in xrange(10, 15):
...     particle.name  = 'Particle: %6d' % (i)
...     particle.TDCcount = i % 256
...     particle.ADCcount = (i * 256) % (1 &lt;&lt; 16)
...     particle.grid_i = i
...     particle.grid_j = 10 - i
...     particle.pressure = float(i*i)
...     particle.energy = float(particle.pressure ** 4)
...     particle.idnumber = i * (2 ** 34)  # This exceeds long integer range
...     table.appendAsRecord(particle)
... 
>>> # Flush this table
... table.flush()
	  </verbatim>

	  <p>That works exactly in the same way than filling a new
	    table. <verb>PyTables</verb> knows that this table is on
	    disk, and when you add new records, they are appended to
	    the end of the table<footnote>Note that you can only
	    append values to tables, not array objects. However, I
	    plan to support unlimited dimension arrays in short
	    term. Keep tuned.</footnote>.
	  </p>
	  <p>
	    If you look carefully at the code you will see that we
	    have used the <verb>table.record</verb> attribute to
	    access to a <verb>Particle</verb> instance and that way we
	    could use it to fill new values. However, it should be
	    stressed that it is not necessary to have the original
	    class definition (<verb>Particle</verb>) in our code to
	    re-create it (in fact, we don't even declared it in our
	    current python session!): it will be created only from
	    metadata existing on file, and it behaves exactly as an
	    original <verb>Particle</verb> instance!.
	  </p>
	  <p>This is part of the magic that allow the use of
	    <em>metaclasses</em> in <verb>PyTables</verb>, and that
	    will easy the creation of portable applications that can
	    read any <verb>PyTables</verb> file <visual
	    markup="bf">regardless</visual> of having access to the
	    original Python record class definition.
	  </p>

	  <p>Let's have a look at some columns of the resulting table:
	  </p>

	  <verbatim>
>>> for x in table.readAsRecords():
...     print "%-16s | %11.1f | %11.4g | %6d | %6d | %8d |" % \
...        (x.name, x.pressure, x.energy, x.grid_i, x.grid_j,
...         x.TDCcount)
... 
Particle:      0 |         0.0 |           0 |      0 |     10 |        0 |
Particle:      1 |         1.0 |           1 |      1 |      9 |        1 |
Particle:      2 |         4.0 |         256 |      2 |      8 |        2 |
Particle:      3 |         9.0 |        6561 |      3 |      7 |        3 |
Particle:      4 |        16.0 |   6.554e+04 |      4 |      6 |        4 |
Particle:      5 |        25.0 |   3.906e+05 |      5 |      5 |        5 |
Particle:      6 |        36.0 |    1.68e+06 |      6 |      4 |        6 |
Particle:      7 |        49.0 |   5.765e+06 |      7 |      3 |        7 |
Particle:      8 |        64.0 |   1.678e+07 |      8 |      2 |        8 |
Particle:      9 |        81.0 |   4.305e+07 |      9 |      1 |        9 |
Particle:     10 |       100.0 |       1e+08 |     10 |      0 |       10 |
Particle:     11 |       121.0 |   2.144e+08 |     11 |     -1 |       11 |
Particle:     12 |       144.0 |     4.3e+08 |     12 |     -2 |       12 |
Particle:     13 |       169.0 |   8.157e+08 |     13 |     -3 |       13 |
Particle:     14 |       196.0 |   1.476e+09 |     14 |     -4 |       14 |
>>> print

>>> print "Total numbers of entries after appending new rows:", table.nrows
Total numbers of entries after appending new rows: 15

	  </verbatim>

	  <p>In <ref refid="tutorial-h5">figure</ref> you can see a
	    view of the <verb>PyTables</verb> file we have created.
	  </p>

	  <figure id="tutorial-h5">
	    <graphics file="tutorial-h5" scale="0.6" kind="bitmap">
	    </graphics>
	    <caption>The data file after appending some rows.
	    </caption>
	  </figure>


	  <p>We are near the end of this first tutorial. Ei!, do not
	    forget to close the file after you finish all the work:
	  </p>

	  <verbatim>
>>> h5file.close()
>>> ^D
$ 

	  </verbatim>

	</subsection>

      </section>

      <section id="secondExample">
	<heading>Checking tables</heading>

	<p>Now, time for a more real life example (i.e. with errors in
	  code). Here, we will create a couple of directories (groups,
	  in HDF5 jargon) hanging directly from <verb>root</verb>
	  called <verb>Particles</verb> and <verb>Events</verb>. Then,
	  we will put 3 tables in each group; in
	  <verb>Particles</verb> we will put instances of
	  <verb>Particle</verb> records and in <verb>Events</verb>,
	  instances of <verb>Event</verb>.
	</p>
	<p>
	  After that, we will feed the tables with 257 (you will see
	  soon why I choose such an <em>esoteric</em> number) entries
	  each. Finally, we will read the recently created table
	  <verb>/Events/TEvent3</verb> and select some values from it
	  using a comprehension list.
	</p>
	<p>Look at the next script. It seems to do all of that, but a
	  couple of small bugs will be shown up. Note that this
	  <verb>Particle</verb> class is not directly related with the
	  one defined in last example; this is simpler.
	</p>

	<verbatim>
from tables import *

class Particle(IsRecord):
    name        = '16s'  # 16-character String
    lati        = 'i'    # integer
    longi       = 'i'    # integer
    pressure    = 'f'    # float  (single-precision)
    temperature = 'd'    # double (double-precision)

class Event(IsRecord):
    name        = '16s'  # 16-character String
    TDCcount    = 'B'    # unsigned char
    ADCcount    = 'H'    # unsigned short
    xcoord      = 'f'    # float  (single-precision)
    ycoord      = 'f'    # float  (single-precision)

# Open a file in "w"rite mode
fileh = openFile("tutorial2.h5", mode = "w")
# Get the HDF5 root group
root = fileh.root

# Create the groups:
for groupname in ("Particles", "Events"):
    group = fileh.createGroup(root, groupname)

# Now, create and fill the tables in Particles group
gparticles = root.Particles
# Create 3 new tables
for tablename in ("TParticle1", "TParticle2", "TParticle3"):
    # Create a table
    table = fileh.createTable("/Particles", tablename, Particle(),
                           "Particles: "+tablename)
    # Get the record object associated with the table:
    particle = table.record
    # Fill the table with 10 particles
    for i in xrange(257):
        # First, assign the values to the Particle record
        particle.name  = 'Particle: %6d' % (i)
        particle.lati = i 
        particle.longi = 10 - i
        particle.pressure = float(i*i)
        particle.temperature = float(i**2)
        # This injects the Record values
        table.appendAsRecord(particle)      

    # Flush the table buffers
    table.flush()

# Now, go for Events:
for tablename in ("TEvent1", "TEvent2", "TEvent3"):
    # Create a table in Events group
    table = fileh.createTable(root.Events, tablename, Event(),
                           "Events: "+tablename)
    # Get the record object associated with the table:
    event = table.record
    # Fill the table with 257 events
    for i in xrange(257):
        # First, assign the values to the Event record
        event.name  = 'Event: %6d' % (i)
        event.TDCcount = i
        event.ADCcount = i * 2
        event.xcoor = float(i**2)
        event.ycoord = float(i**4)
        # This injects the Record values
        table.appendAsRecord(event)

    # Flush the buffers
    table.flush()

# Read the records from table "/Events/TEvent3" and select some
table = root.Events.TEvent3
e = [ p.TDCcount for p in table.readAsRecords()
      if p.ADCcount &lt; 20 and 4 &lt;= p.TDCcount &lt; 15 ]
print "Last record ==>", p
print "Selected values ==>", e
print "Total selected records ==> ", len(e)

# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
	</verbatim>

	<subsection>
	  <heading>Field name checking</heading>

	<p>If you have read the code carefully it looks pretty good,
	  but it won't work. When you run this example, you will get
	  the next error:
	</p>
	<verbatim>
Traceback (most recent call last):
  File "tutorial2.py", line 68, in ?
    event.xcoor  = float(i**2)
AttributeError: 'Event' object has no attribute 'xcoor'
	</verbatim>
	<p>This error is telling us that we tried to assign a value to
	  a non-existent field in an <verb>Event</verb> object. By
	  looking carefully at the <verb>Event</verb> attributes, we
	  see that we misspelled the <verb>xcoord</verb> field (we
	  wrote <verb>xcoor</verb> instead). This is very unusual in
	  Python because if you try to assign a value to a
	  non-existent instance variable, a new one is created with
	  that name. Such a feature is not satisfactory when we are
	  dealing with an object that has fixed list of variable names
	  (the user record, that is responsible for defining the table
	  columns). So, thanks to the magic that provides the
	  <verb>IsRecord</verb> metaclass, all instance variables
	  (data fields) are declared internally as class
	  <verb>__slots__</verb>. This is why the last error appeared.
	</p>

	</subsection>

	<subsection>
	  <heading>Data range checking</heading>

	<p>After correcting the last attribute error in the source,
	  and running the script again... oooops! we find another
	  problem:
	</p>
	<verbatim>
Traceback (most recent call last):
  File "tutorial2.py", line 69, in ?
    table.appendAsRecord(event)      
  File "/usr/lib/python2.2/site-packages/tables/Table.py", line 210, in appendAsRecord
    self._v_packedtuples.append(recordObject._f_pack2())
  File "/usr/lib/python2.2/site-packages/tables/IsRecord.py", line 121, in _f_pack2
    self._f_raiseValueError()
  File "/usr/lib/python2.2/site-packages/tables/IsRecord.py", line 130, in 
_f_raiseValueError
    raise ValueError, \
ValueError: Error packing record object: 
 [('ADCcount', 'H', 256), ('TDCcount', 'B', 256), ('name', '16s', 'Event:    256'),
 ('xcoord', 'f', 65536.0), ('ycoord', 'f', 4294967296.0)]
 Error was: ubyte format requires 0&lt;=number&lt;=255
	</verbatim>
	<p>This time the exception is telling us that one of the
	  records is having trouble to be converted to the data types
	  stated in the Event class definition. By looking carefully
	  at the record object causing the problem, we see that we are
	  trying to assign a value of 256 to the <verb>TDCcount</verb>
	  field which has a <verb>'B'</verb> (C unsigned char)
	  typecode and the allowed range for it is
	  <verb>0&lt;=TDCcount&lt;=255</verb>. This is a very powerful
	  capability to automatically check for ranges and the message
	  error should be explicit enough to figure out what is
	  happening. In this case you can solve the problem either by
	  promoting the <verb>TDCcount</verb> to <verb>'H'</verb>
	  which is an unsigned 16-bit integer, or, by avoiding the
	  mistake we have probably made in assigning a value greater
	  than 255 to a 'B' typecode.
	</p>
	<p>If we change the line:
	</p>
	<verbatim>
          event.TDCcount = i
	</verbatim>
	<p>by the next one:
	</p>
	<verbatim>
           event.TDCcount = i % (1&lt;&lt;8)
	</verbatim>
	<p>you will see that our problem has disappeared, and that the
	  HDF5 file has been created.
	</p>
	</subsection>

	<subsection>
	  <heading>Data type checking</heading>

	<p>Finally, in order to test the type checking, we will change
	  the next line:
	</p>
	<verbatim>
	  event.ADCcount = i * 2        # Correct type
	</verbatim>

	<p>to read:</p>

	<verbatim>
	  event.ADCcount = "s"          # Wrong type
	</verbatim>

	<p>After this modification, the next exception will be raised
	  when the script is executed:
	</p>

	<verbatim>
Traceback (most recent call last):
  File "tutorial2.py", line 68, in ?
    table.appendAsRecord(event)      
  File "/home/falted/PyTables/pytables-0.2/tables/Table.py", line 279,
in appendAsRecord
    self._v_packedtuples.append(RecordObject._f_pack2())
  File "/home/falted/PyTables/pytables-0.2/tables/IsRecord.py", line
181, in_f_pack2
    self._f_raiseValueError()
  File "/home/falted/PyTables/pytables-0.2/tables/IsRecord.py", line
135, in _f_raiseValueError
    raise ValueError, \
ValueError: Error packing record object: 
 [('ADCcount', 'H', '0'), ('TDCcount', 'B', 0), ('name', '16s',
   'Event:      0'), ('xcoord', 'f', 0.0), ('ycoord', 'f', 0.0)]
 Error was: required argument is not an integer
	</verbatim>

	<p>that states the error.</p>

	<p>You can admire the structure we have created with this
	  (corrected) script in <ref refid="tutorial2">figure</ref>. As
	  before, you will find this example in source file
	  <verb>tutorial2.py</verb> that is located in the directory
	  <verb>examples</verb>.
	</p>

	<figure id="tutorial2">
	  <graphics file="tutorial2-h5" scale="0.6" kind="bitmap">
	  </graphics>
	  <caption>Table hierarchy for second example.</caption>
	</figure>

	<p>Feel free to visit the rest of examples in directory
	  <verb>examples</verb>, and try to understand them. I've
	  tried to make several use cases to give you an idea of the
	  <visual markup="tt">PyTables</visual> capabilities and its
	  way of dealing with HDF5 objects.
	</p>

	</subsection>
      </section>

      <section id='optimizationTips'>
	<heading>Optimization tips</heading>

	<p><verb>PyTables</verb> has several places where the user can
	  improve the performance of his application. If you are
	  planning to deal with really large data, you should read
	  carefully this section so as to learn how to get an
	  important boost for your code. But if your dataset is small
	  or medium size (say, up to 1 MB), you should not worry about
	  that as the default parameters in <verb>PyTables</verb> are
	  already tuned to handle that perfectly.
	</p>

	<subsection>
	  <heading>Compression issues</heading>

	  <p>One of the beauties of <verb>PyTables</verb> is that it
	    comes with compression activated by <visual
	    markup="bf">default</visual> for tables. This might be a
	    bit controversial feature, because compression has a
	    legend of being a very CPU time resources consumer (but if
	    you are completely against compression, you can disable
	    it; keep reading).
	  </p>
	  <p> However, there is an usual scenario where users need to
	    save duplicated data in some record fields, while the
	    others have varying values. In a relational database
	    approach such a redundant data can normally be moved to
	    other tables and a relationship between the rows on the
	    separate tables can be created. But that takes analysis
	    and implementation time, and made the underlying libraries
	    more complex and slower.
	  </p>

	  <p><verb>PyTables</verb> approach is to not support
	    relationships between tables, but to compress duplicated
	    data in tables. That allows the user to not worry about
	    finding their optimum data tables strategy, but rather use
	    less, not directly related, tables with a larger number of
	    columns while still not cluttering the database too much
	    with duplicated data (compression is responsible to avoid
	    that). As a side effect, data selections can be made more
	    easily because you have more fields available in a single
	    table, and they can be referred in the same loop (or
	    comprehension list).
	  </p>

	  <p>The compression library used is the <visual
	    markup="bf">zlib</visual> (see reference <ref
	    refid="zlibRef"></ref>), and the compression level used by
	    default for <verb>Table</verb> objects is 3. This level is
	    less than 6 which is the default level recommend in zlib
	    documentation as a compromise between speed and
	    compression. I've made this decision for two reasons:
	  </p>

	  <itemize>

	    <item>Choosing level 3 is a more conservative (in terms of
	      CPU usage) value. This fact together with the generally
	      available fast CPU today, can make a better balance
	      between CPU usage and I/O performance. It would be even
	      possible in certain situations that reading a compressed
	      table would take less wall-clock time than not using
	      compression at all.
	    </item>

	    <item>Normally (except in some degenerate cases), table
	      columns values are stored very closely in memory
	      (i.e. they have a high degree of locality), so the
	      compression algorithm has to make little effort to
	      discover data duplication (as the majority of this
	      duplication would appear in values of the same
	      column). So a small compression level should offer
	      roughly the same results as a big one.
	    </item>

	  </itemize>

	  <p>Nonetheless, in some situations you may want to check how
	    compression level affects your application. You can
	    control it by setting the <verb>compress</verb> keyword in
	    the <verb>createTable</verb> method (see <ref
	    refid="createTableDescr"></ref>). A value of 0 will
	    completely disable compression, 1 is the less CPU time
	    demanding level, while 9 is the maximum level and most CPU
	    intensive.
	  </p>

	</subsection>

	<subsection id="expectedRowsOptim">
	  <heading>Informing <visual markup="tt">PyTables</visual>
	    about expected number of rows in tables</heading>

	  <p>The underlying HDF5 library that is used by
	    <verb>PyTables</verb> takes the data in bunches of a
	    certain length, so-called <em>chunks</em>, to write them
	    on disk as a whole, i.e. the HDF5 library treats chunks as
	    atomic objects and disk I/O is always made in terms of
	    complete chunks. This allows data filters to be defined by
	    the application to perform tasks such as compression,
	    encryption, checksumming, etc. on entire chunks.
	  </p>

	  <p>An in-memory B-tree is used to map chunk structures on
	    disk. The more chunks that are allocated for a dataset the
	    larger the B-tree. Large B-trees take memory and causes
	    file storage overhead as well as more disk I/O and higher
	    contention for the meta data cache. Consequently, it's
	    important to balance between memory and I/O overhead
	    (small B-trees) and time to access to data (big B-trees).
	  </p>

	  <p><verb>PyTables</verb> can determine an optimum chunk size
	    to make B-trees adequate to your dataset size if you help
	    it by providing an estimation of the number of rows for a
	    table. This must be made in table creation time by passing
	    this value in the <verb>expectedrows</verb> keyword of
	    <verb>createTable</verb> method (see <ref
	    refid="createTableDescr"></ref>).
	  </p>

	  <p>When your dataset size is bigger than 1 MB (take this
	    figure only as a reference, not strictly), by providing
	    this guess of the number of rows, you will be optimizing
	    the access to your table data. When the dataset size is
	    larger than, say 100MB, you are <visual
	    markup="bf">strongly</visual> suggested to provide such a
	    guess; failing to do that may cause your application doing
	    very slow I/O operations and demanding huge amounts
	    of memory. You have been warned!.
	  </p>

	</subsection>

	<subsection id="tuplesOptim">
	  <heading>Optimized ways to fill and read data from
	    tables</heading>

	  <p>The <verb>appendAsRecord</verb> and
	    <verb>readAsRecords</verb> methods in <verb>Table</verb>
	    class are very convenient to use when you are dealing with
	    small to medium size tables. They are safe and intuitive,
	    <visual markup="bf">but</visual> they are slow. When you
	    have to deal with large tables, you can use the alternate
	    methods <verb>appendAsValues</verb>,
	    <verb>appendAsTuple</verb> and
	    <verb>readAsTuples</verb>. Look at sections <ref
	    refid="appendAsValuesDescr"></ref>, <ref
	    refid="appendAsTupleDescr"></ref> and <ref
	    refid="readAsTuplesDescr"></ref> for a detailed reference
	    of these optimized methods.
	  </p>

	  <p>These three new methods are different to the two formers
	    in that they accept or return the values to/from rows in
	    table as Python tuples (or independent values in the case
	    of <verb>appendAsValues</verb>). They are much faster (at
	    least a factor two or even more) than
	    <verb>xxxxAsRecord</verb> counterparts, but they are also
	    unsafer, because it is your responsibility to pass the
	    correct order of parameters to be appended to the table
	    (or guess the correct order of fields in tuple when
	    reading). This field order is however well defined
	    as the result of alphanumerically sorting the names of
	    table fields (or columns).
	  </p>

	  <p>For example, if you have a table with three fields named
	    "<em>TDCcount</em>", "<em>ADCcount</em>" and
	    "<em>energy</em>", you have to feed
	    <verb>appendAsValues</verb> with a series of parameters
	    like in:
	  </p>
	  <verbatim>
table.appendAsValues(ADCcountValue, TDCcountValue, energyValue)
	  </verbatim>

	  <p>For <verb>readAsTuple</verb> method you have to follow
	    the same rule, i.e. you must unpack the values in the
	    returned tuple in alphanumerical order, like in:
	  </p>
	  <verbatim>
(ADCcountValue, TDCcountValue, energyValue) = table.readAsTuple()
	  </verbatim>

	  <p>For a working example that also allows you to do some
	    timings easily, look at the
	    <em>examples/table-bench.py</em> script.
	  </p>

	</subsection>

      </section>

    </chapter>

    <chapter id='libraryReference'>
      <heading>Library Reference</heading>
      
      <p><verb>PyTables</verb> implements several classes to represent
	the different nodes in the object tree. They are named
	<verb>File</verb>, <verb>Group</verb>, <verb>Leaf</verb>,
	<verb>Table</verb> and <verb>Array</verb>. Another one is
	responsible to build record objects from a subclass user
	declaration, and performs field, type and range checks; its
	name is <verb>IsRecord</verb>. An important function, called
	<verb>openFile</verb> is responsible to create, open or append
	to <verb>PyTables</verb> files. In addition, a few utility
	functions are defined to guess if an user supplied file is a
	<verb>PyTables</verb> or HDF5 file. These are called
	<verb>isPyTablesFile</verb> and <verb>isHDF5</verb>. Finally,
	several first-level variables are also available to the user
	that informs about <verb>PyTables</verb> version, file format
	version or underlying libraries (as for example
	<verb>HDF5</verb>) version number.
      </p>

      <p>Let's start discussing the first-level variables and
	functions available to the user, then the methods in the
	classes defined in <verb>PyTables</verb>.
      </p>

      <section>
	<heading><visual markup="tt">tables</visual> variables and
	  functions</heading>

	<subsection>
	  <heading>Global variables</heading>

	  <description>

	    <term>__version__</term> <item>The <verb>PyTables</verb>
	    version number.</item>

	    <term>HDF5Version</term>
	    <item>The underlying HDF5 library version number.</item>

	    <term>ExtVersion</term> <item>The Pyrex extension types
	      version. This might be useful when reporting
	      bugs.</item>

	  </description>
	  
	</subsection>

	<subsection>
	  <heading>Global functions</heading>

	  <description id='openFileDescr'>
	    <term>openFile(filename, mode='r', title='')</term>
	    <item>Open a <verb>PyTables</verb> file and returns a File
	    object.
	    
	      <description>

		<term>filename</term> <item>The name of the file
		  (supports environment variable expansion). It must
		  have any of <verb>".h5"</verb>, <verb>".hdf"</verb>
		  or <verb>".hdf5"</verb> extensions.
		</item>

		<term>mode</term> <item>The mode to open the file. It
		  can be one of the following:

		  <description>

		    <term>'r'</term> <item>read-only; no data can be
		      modified.</item>

		    <term>'w'</term> <item>write; a new file is created
		      (an existing file with the same name is
		      deleted).</item>

		    <term>'a'</term> <item>append; an existing file is
		      opened for reading and writing, and if the file does
		      not exist it is created.</item>

		    <term>'r+'</term> <item>is similar to 'a', but the
		      file must already exist.</item>

		  </description>
		</item>

		<term>title</term> <item>If filename is new, this will
		  set a title for the root group in this file. If
		  filename is not new, the title will be read from
		  disk, and this will not have any effect.
		</item>

	      </description>

	    </item>

	    <term>isHDF5(filename)</term> <item>Determines whether
	      filename is in the HDF5 format. When successful, returns
	      a positive value, for TRUE, or 0 (zero), for
	      FALSE. Otherwise returns a negative value.  To this
	      function to work, it needs a closed file.
	    </item>

	    <term>isPyTablesFile(filename)</term> <item>Determines
	      whether a file is in the <verb>PyTables</verb> format.
	      When successful, returns the format version string, for
	      TRUE, or 0 (zero), for FALSE. Otherwise returns a
	      negative value.  To this function to work, it needs a
	      closed file.
	    </item>

	  </description>
	</subsection>
      </section>

      <section id="IsRecordClassDescr">
	<heading>The <visual markup="tt">IsRecord</visual> class</heading>

	<p>This class is in fact a so-called <em>metaclass</em>
	  object. There is nothing special on this fact, except that
	  their subclasses attributes are transformed during its
	  instantiation phase, and new methods for instances are
	  defined based on the values of the class attributes.
	</p>
	<p>That way, <verb>PyTables</verb> <em>force</em> the
	  resulting instance to only accept assignments on the
	  declared attributes<footnote> In fact, descendants of
	  <verb>IsRecord</verb> class has a few more, internal
	  attributes, but they start with prefixes like <visual
	  markup="tt">"__"</visual>, <visual
	  markup="tt">"_v_"</visual> or <visual
	  markup="tt">"_f_"</visual>, so you should not use attribute
	  names starting with these prefixes</footnote>. If you try to
	  do an assignment to a non-declared attribute, <visual
	  markup="tt">PyTables</visual> will raise an error.</p>

	<p>To define such a special class, you have to declare it as
	  descendent from <em>IsRecord</em>, with many attributes as
	  fields you want in your record. To declare their types, you
	  simply assign to these attributes their
	  <em>typecode</em>. See the <ref
	  refid="datatypesSupported">appendix</ref> for a relation of
	  data types supported in a <visual
	  markup="tt">IsRecord</visual> class declaration.
	</p>
	<p> That's all, from now on, you can instantiate objects from
	  your new class and use them as a very flexible record
	  objects with safe features like automatic name field, data
	  type and range checks (see the <ref
	  refid="secondExample">section</ref> for an example on how it
	  works).
	</p>

      </section>

      <section id="FileClassDescr">
	<heading>The <visual markup="tt">File</visual> class</heading>

	<p>This class is returned when a <verb>PyTables</verb> is
	  opened with the <verb>openFile</verb> function. It has
	  methods to create, open, flush and close
	  <verb>PyTables</verb> files. Also, <verb>File</verb> class
	  offer methods to traverse the object tree, as well as to
	  create new nodes. One of its attributes (<verb>root</verb>)
	  is quite important because represents the entry point to the
	  object tree attached to the file.
	</p>

	<p>Next, we will discuss the attributes and methods for File
	  class<footnote>On the following, the term <verb>Leaf</verb>
	  will refer to a <verb>Table</verb> or <verb>Array</verb>
	  node object.</footnote>.
	</p>

	<subsection id="FileInstanceVariablesDescr">
	  <heading><visual markup="tt">File</visual> instance
	    variables</heading>
	  <description>

	    <term>filename</term> <item>Filename opened.</item>

	    <term>mode</term> <item>Mode in which the filename was
	      opened.</item>

	    <term>title</term> <item>The title of the root group in
	      file.</item>

	    <term>root</term> <item>The root group in file. This is
	      the entry point to the object tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">File</visual> methods</heading>

	  <description>

	    <term id='createGroupDescr'>createGroup(where, name,
	      title='') </term> <item>Create a new Group instance with
	      name <em>name</em> in <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the new
		  group will hang. <em>where</em> parameter can be a
		  path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or another
		  Group instance. </item>

		<term>name</term>
		<item>The name of the new group.</item>

		<term>title</term> <item>A description for this
		group.</item>

	      </description>
	    </item>

	    <term id='createTableDescr'>createTable(where, name,
	      RecordObject, title='', compress=3,
	      expectedrows=10000)</term> <item>Create a new
	      <verb>Table</verb> instance with name <em>name</em> in
	      <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the
		  new table will hang. <em>where</em> parameter can be
		  a path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or Group
		  instance. </item>

		<term>name</term>
		<item>The name of the new table.</item>

		<term>RecordObject</term> <item>An instance of a
		  user-defined class (derived from the
		  <verb>IsRecord</verb> class) where table fields are
		  defined.
		</item>

		<term>title</term> <item>A description for this object.
		</item>

		<term>compress</term> <item>Specifies a compress level
		  for data. The allowed range is 0-9. A value of 0
		  disables compression. The default is compression
		  level 3, that balances between compression effort
		  and CPU consumption.
		</item>

		<term>expectedrows</term> <item>An user estimate of
		  the number of records that will be on table. If not
		  provided, the default value is appropriate for tables
		  until 1 MB in size (more or less, depending on the
		  record size). If you plan to save bigger tables you
		  should provide a guess; this will optimize the HDF5
		  B-Tree creation and management process time and
		  memory used. See <ref
		  refid="expectedRowsOptim">section</ref> for a
		  detailed justification of that issue.
		</item>

	      </description>
	    </item>

	    <term id='createArrayDescr'>createArray(where, name,
	      NumericObject, title='')</term> <item>Create a new
	      <verb>Array</verb> instance with name <em>name</em> in
	      <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the
		  new array will hang. <em>where</em> parameter can be
		  a path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or
		  <verb>Group</verb> instance. 
		</item>

		<term>name</term> <item>The name of the new
		  array.
		</item>

		<term>NumericObject</term> <item>The Numeric array to
		  be saved.
		</item>

		<term>title</term> <item>A description for this
		  object.
		</item>

	      </description>
	    </item>

	    <term id='getNodeDescr'>getNode(where, name='',
	      classname='')</term> <item>Returns the object node
	      <em>name</em> under <em>where</em> location

	      <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>name</term> <item>The object name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

		<term>classname</term> <item>If supplied, returns only
		  an instance of this class name. Allowed names in
		  <em>classname</em> are: <verb>'Group'</verb>,
		  <verb>'Leaf'</verb>, <verb>'Table'</verb> and
		  <verb>'Array'</verb>. Note that these values are
		  strings.
		</item>

	      </description>
	    </item>

	    <term id='listNodesDescr'>listNodes(where,
	      classname='')</term> <item>Returns a list with all the
	      object nodes (Group or Leaf) hanging from
	      <em>where</em>. The list is alphanumerically sorted by
	      node name.

	      <description>

		<term>where</term> <item>The parent group. Can be a
		  path string or <verb>Group</verb> instance.
		</item>

		<term>classname</term> <item>If a <em>classname</em>
		  parameter is supplied, the iterator will return only
		  instances of this class (or subclasses of it). The
		  only supported classes in <em>classname</em> are
		  <verb>'Group'</verb>, <verb>'Leaf'</verb>,
		  <verb>'Table'</verb> and <verb>'Array'</verb>. Note
		  that these values are strings.
		</item>

	      </description>
	    </item>

	    <term id='walkGroupsDescr'>walkGroups(where='/')</term>
	      <item><em>Iterator</em> that recursively obtains groups
	      (not leaves) hanging from <em>where</em>. If
	      <em>where</em> is not supplied, the root object is taken
	      as origin. The groups are returned from in a top to
	      bottom order, and alphanumerically sorted when they are
	      at the same level.

	      <description>

		<term>where</term> <item>The origin group. Can be a
		  path string or <verb>Group</verb> instance.
		</item>

	      </description>
	    </item>

	    <term>flush()</term> <item>Flush all the leaves existing
	      in the object tree.
	    </item>

	    <term>close()</term> <item>Flush all the objects in
	      object tree and close the file.
	    </item>

	  </description>

	</subsection>
      </section>

      <section id="GroupClassDescr">
	<heading>The <visual markup="tt">Group</visual> class</heading>

	<p>Instances of this class are a grouping structure containing
	  instances of zero or more groups or leaves, together with
	  supporting metadata.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files, respectively, in a Unix
	  filesystem. As with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. This full path can be specified either
	  as string (like in <verb>'/group1/group2'</verb>) or as a
	  complete object path written in the Pythonic fashion known
	  as <em>natural name</em> schema (like in
	  <verb>file.root.group1.group2</verb>) and discussed in the
	  <ref refid='NaturalTreeSection'>section</ref>.
	</p>

	<p>A collateral effect of the <em>natural naming</em> schema
	  is that you must be aware when assigning a new attribute to
	  a Group object to not collide with existing children node
	  names. For this reason and to not pollute the children
	  namespace, it is explicitly forbidden to assign "normal"
	  attributes to Group instances, and the only ones allowed
	  must start with "<verb>_c_</verb>" (for class variables),
	  "<verb>_f_</verb>" (for methods) or "<verb>_v_</verb>" (for
	  instance variables) prefixes. Any attempt to assign a new
	  attribute that does not starts with these prefixes, will
	  raise a <verb>NameError</verb> exception.
	</p>

	<subsection>
	  <heading><visual markup="tt">Group</visual> class variables</heading>
	  <description>

	    <term>_c_objects</term> <item>Dictionary with all objects
	      (groups or leaves) on tree.</item>

	    <term>_c_objgroups</term> <item>Dictionary with all object
	      groups on tree.</item>

	    <term>_c_objleaves</term> <item>Dictionary with all object
	      leaves on tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> instance variables</heading>
	  <description>

	    <term>_v_title</term>
	    <item>A description for this group.</item>

	    <term>_v_name</term>
	    <item>The name of this group.</item>

	    <term>_v_pathname</term>
	    <item>A string representation of the group location
	      in tree.</item>

	    <term>_v_parent</term>
	    <item>The parent Group instance.</item>

	    <term>_v_objchilds</term> <item>Dictionary with all nodes
	      (groups or leaves) hanging from this instance.</item>

	    <term>_v_objgroups</term> <item>Dictionary with all node
	      groups hanging from this instance.</item>

	    <term>_v_objleaves</term> <item>Dictionary with all node
	      leaves hanging from this instance.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> methods</heading>

	  <p><visual markup="bf">Caveat: </visual>These methods are
	    documented for completeness, and they can be used without
	    any problem. However, you should use the high-level
	    counterpart methods in the <verb>File</verb> class,
	    because these are most used in documentation and examples,
	    and are a bit more powerful than those exposed here.
	  </p>

	  <description>

	    <term>_f_join(name)</term>
	    <item>Helper method to correctly concatenate a name child object
	      with the pathname of this group.</item>

	    <term>_f_listNodes(classname='')</term> <item>Returns a
	      <em>list</em> with all the object nodes hanging from
	      this instance. The list is alphanumerically sorted by
	      node name. If a <em>classname</em> parameter is
	      supplied, it will only return instances of this class
	      (or subclasses of it). The supported classes in
	      <em>classname</em> are <verb>'Group'</verb>,
	      <verb>'Leaf'</verb>, <verb>'Table'</verb> and
	      <verb>'Array'</verb>.</item>

	    <term>_f_walkGroups()</term> <item><em>Iterator</em> that
	      recursively obtains Groups (not Leaves) hanging from
	      self. The groups are returned from top to bottom, and
	      are alphanumerically sorted when they are at the same
	      level.
	    </item>

	  </description>

	</subsection>
      </section>

      <section id="LeafClassDescr">
	<heading>The <visual markup="tt">Leaf</visual> class</heading>

	<p>This is a helper class useful to place common functionality
	  of all Leaf objects. It is also useful for classifying
	  purposes. A Leaf object is an end-node, that is, a node that
	  can hang directly from a group object, but that is not a
	  group itself. Right now this set is composed by
	  <verb>Table</verb> and <verb>Array</verb> objects. In fact,
	  <verb>Table</verb> and <verb>Array</verb> classes inherit
	  functionality from this class using the <em>mix-in</em>
	  technique.
	</p>
	<p>Normally the user will not need to call any method from
	  here, but it is useful to know that it exists because it can
	  be used as a filter in methods like
	  <verb>File.GetNode()</verb> or
	  <verb>File.listNodes()</verb>, against others.
	</p>
      </section>

      <section id="TableClassDescr">
	<heading>The <visual markup="tt">Table</visual> class</heading>

	<p>Instances of this class represents table objects in the
	  object tree. It provides methods to create new tables or
	  open existing ones, as well as methods to read/write data
	  and metadata from/to table objects in the file.
	</p>
	<p>Data can be read or written both as records or as tuples
	  and <em>different</em> methods are provided to that
	  end. Records are recommended because they are more intuitive
	  and less error prone although they are slow. Using tuples
	  (or value sequences) is faster, but the user must be very
	  careful because when passing the sequence of values, they
	  have to be in the correct order (alphanumerically ordered by
	  field names). If not, unexpected results can appear (most
	  probably <verb>ValueError</verb> exceptions will be
	  raised). See <ref refid="tuplesOptim">section</ref> for
	  usage details.
	</p>

	<subsection>
	  <heading><visual markup="tt">Table</visual> instance
	    variables</heading>
	  <description>

	    <term>name</term>
	    <item>The node name.</item>

	    <term>title</term>
	    <item>The title for this node.</item>

	    <term>record</term>
	    <item>The record object for this table.</item>

	    <term>nrows</term>
	    <item>The number of rows (records) in this table.</item>

	    <term>varnames</term>
	    <item>The field names for the table.</item>

	    <term>vartypes</term>
	    <item>The typecodes for the table fields.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Table</visual>
	    methods</heading>
	  <description>

	    <term
	      id='appendAsRecordDescr'>appendAsRecord(RecordObject)</term>
	      <item>Append the <verb>RecordObject</verb> to the output
	      buffer of the table instance.

	      <description>

		<term>RecordObject</term> <item>An instance of the
		  user-defined record class. It has to be a
		  <verb>IsRecord</verb> descendant instance. If it is
		  not, a <verb>ValueError</verb> exception is
		  raised.</item>

	      </description>

	    </item>

	    <term
	      id='appendAsTupleDescr'>appendAsTuple(tupleValues)</term>
	      <item>Append the <em>tupleValues</em> tuple to the
	      output buffer of the table instance. This method is
	      faster (but also unsafer, because requires user to
	      introduce the values in correct order!) than
	      <verb>appendAsRecord</verb> method.

	      <description>

		<term>tupleValues</term> <item> is a tuple that has
		  values for all the user record fields. The user has
		  to provide them in the order determined by
		  alphanumerically sorting the record name
		  fields.</item>

	      </description>
	    </item>

	    <term
	      id='appendAsValuesDescr'>appendAsValues(*values)</term>
	      <item> Append the <em>values</em> parameters to the
	      table output buffer. This method is faster (and unsafer,
	      because requires user to introduce the values in correct
	      order) than <verb>appendAsRecord</verb> method. It is
	      similar to the <verb>appendAsTuple</verb> method, but
	      accepts separate parameters as values instead of a
	      monolithic tuple.
        
	      <description>
		<term>values</term> <item>Is a series of parameters
		that provides values for all the user record
		fields. The user has to provide them in the order
		determined by alphanumerically sorting the record
		fields.</item>
	      </description>
	    </item>

	    <term id='readAsRecordsDescr'>readAsRecords()</term>
	      <item>Returns an iterator yielding record instances
	      built from rows in table. This method is a
	      <em>generator</em>, i.e. it keeps track on the last
	      record returned so that next time it is invoked it
	      returns the next available record. It is slower than
	      <verb>readAsTuples</verb> but in exchange, it returns
	      full-fledged instance records.</item>

	    <term id='readAsTuplesDescr'>readAsTuples()</term>
	      <item>Returns an iterator yielding tuples built from
	      rows in table. This method is a <em>generator</em>,
	      i.e. it keeps track on the last record returned so that
	      next time it is invoked it returns the next available
	      record. This method is twice as faster than
	      readAsRecords, but it yields the rows as
	      (alphanumerically ordered) tuples, instead of
	      full-fledged instance records.</item>

	    <term>flush()</term> <item>Flush the table buffers.</item>

	    <term>close()</term> <item>Flush the table buffers and
	      close the HDF5 dataset.</item>

	  </description>

	</subsection>

      </section>

      <section id="ArrayClassDescr">
	<heading>The <visual markup="tt">Array</visual> class</heading>

	<p>Represents a <verb>Numeric</verb> array on file. It
	  provides methods to create new arrays or open existing ones,
	  as well as methods to write/read data and metadata to/from
	  array objects in the file.
	</p>
	<p><visual markup="bf">Caveat:</visual> All
	  <verb>Numeric</verb> typecodes are supported except
	  "<verb>F</verb>" and "<verb>D</verb>" which corresponds to
	  complex data types<footnote>However, these might be included
	  in short future</footnote>. See <ref
	  refid="Numerical">reference</ref> to know more about
	  <verb>Numeric</verb> intrinsics, and in particular about
	  supported data types.
	</p>

	<subsection id="ArrayClassInstanceVariables">
	  <heading><visual markup="tt">Array</visual> instance
	    variables</heading>
	  <description>

	    <term>name</term>
	    <item>The node name.</item>

	    <term>title</term>
	    <item>The node title.</item>

	    <term>shape</term> <item>tuple with the array shape (in
	      the Numeric style).</item>

	    <term>typecode</term>
	    <item>The typecode of the represented array.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Array</visual>
	    methods</heading>

	  <p>The methods for this class are very few. Please note that
	    this object has not internal I/O buffers, so there is no
	    need to call flush() method. However, it is included for
	    consistency with <verb>Leaf</verb> nodes.</p>

	  <description>

	    <term id='readArrayDescr'>read()</term> <item>Read the
	      array from disk and return it as a Numeric object. Note
	      that while this method is not called, the actual array
	      data is resident on disk.</item>

	    <term>flush()</term> <item>Flush the internal
	      buffers. Remember: this is a do-nothing method.</item>

	    <term>close()</term> <item>Close the array on file.</item>

	  </description>

	</subsection>

      </section>

    </chapter>

    <appendix>
      <chapter id="datatypesSupported">
	<heading>Supported data types in tables</heading>

	<p><verb>IsRecord</verb> descendants supports a limited set of
	  data types to define the table fields. This is roughly the
	  same that the set supported by the <visual
	  markup="tt">array</visual> module in Python, with some
	  additions that will be briefly discussed shortly. The
	  supported set is listed on <ref
	  refid="datatypesSupported">table</ref>.
	</p>

	<table id="datatypesSupportedTable">
	  <tabular preamble="lllcl">
	  <tabhead>
	    <srow>Type Code | Description | C Type | Size (in bytes) |
	      Python Counterpart</srow>
	  </tabhead>
	  <tabbody>
	    <srow>'c' | 8-bit character | char | 1 | String of length 1 </srow>
	    <srow>'b' | 8-bit integer | signed char | 1 | Integer </srow>
	    <srow>'B' | 8-bit unsigned integer | unsigned char | 1 | Integer </srow>
	    <srow>'h' | 16-bit integer | short | 2 | Integer </srow>
	    <srow>'H' | 16-bit unsigned integer | unsigned short | 2 | Integer </srow>
	    <srow>'i' | integer | int | 4 or 8 | Integer </srow>
	    <srow>'I' | unsigned integer | unsigned int | 4 or 8 | Long </srow>
	    <srow>'l' | long integer | long | 4 or 8 | Integer </srow>
	    <srow>'L' | unsigned long integer | unsigned long | 4 or 8 | Long </srow>
	    <srow>'q' | long long integer | long long | 8 | Long </srow>
	    <srow>'Q' | unsigned long long integer | unsigned long long | 8 | Long </srow>
	    <srow>'f' | single-precision float | float | 4 | Float </srow>
	    <srow>'d' | double-precision float | double | 8 | Float </srow>
	    <srow>'s' | arbitrary length string | char[] | * | String </srow>
	  </tabbody>
	</tabular>
	  <caption>Data types supported by <visual
	      markup="tt">IsRecord</visual> descendants.</caption>
	</table>

	<p>The additions to the array module typecodes are the <visual
	  markup="tt">'q'</visual>, <visual markup="tt">'Q'</visual>
	  and <visual markup="tt">'s'</visual>.  The <visual
	  markup="tt">'q'</visual> and <visual
	  markup="tt">'Q'</visual> conversion codes are available in
	  native mode only if the platform C compiler supports C long
	  long, or, on Windows, __int64. They are always available in
	  standard modes. The <visual markup="tt">'s'</visual>
	  typecode can be preceded by an integer to indicate the
	  maximum length of the string, so <visual
	  markup="tt">'16s'</visual> represents a 16-byte string.</p>

	<p>Also note that when the <visual markup="tt">'I'</visual>
	  and <visual markup="tt">'L'</visual> codetypes are used in
	  records, Python uses internally <visual
	  markup="tt">Long</visual> integers to represent them, that
	  can (or cannot, depending on what you are trying to do) be
	  a source of inefficiency in your code.</p>
      </chapter>
    </appendix>
  </mainmatter>

  <backmatter>
    <references>
      <enumerate>

	<item id="HDF5WhatIs"><em>What is HDF5?.</em> Concise
	  description about HDF5 capabilities and its differences from
	  earlier versions (HDF4). <url
	  name="http://hdf.ncsa.uiuc.edu/whatishdf5.html"/>
	</item>

	<item id="HDF5Intr"><em>Introduction to HDF5.</em>
	  Introduction to the HDF5 data model and programming
	  model. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/doc/H5.intro.html"/>
	</item>

	<item id="HDF5_HL"><em>HDF5: High Level APIs.</em> A set of
	  functions built on top of the basic HDF5 library. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/hdf5_hl/doc/"/>
	</item>

	<item id="HDF5TableExamples"><em>The HDF5 table programming
	  model.</em> Examples on using HDF5 tables with the C
	  API. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/hdf5_hl/doc/RM_hdf5tb_ex.html"/>
	</item>

	<item id="HL-HDF"><em>HL-HDF.</em> A High Level Interface to
	  the HDF5 File Format. <url
	  name="ftp://ftp.ncsa.uiuc.edu/HDF/HDF5/contrib/hl-hdf5/README.html"/>
	</item>

	<item id="zlibRef"><em>zlib.</em>A Massively Spiffy Yet
	  Delicately Unobtrusive Compression Library. 
	  <url name="http://www.gzip.org/zlib/"/>
	</item>

	<item id="Objectify"><em>On the 'Pythonic' treatment of XML
	  documents as objects(II).</em> Article describing XML
	  Objectify, a Python module that allows working with XML
	  documents as Python objects. Some of the ideas presented
	  here are used in <visual markup="tt">PyTables</visual>. <url
	  name="http://www-106.ibm.com/developerworks/xml/library/xml-matters2/index.html"/>
	</item>

	<item id="GnosisUtils"><em>gnosis.xml.objectify.</em> This
	  module is part of the Gnosis utilities, and allows to create
	  a mapping between any XML element to "native" Python
	  objects. <url
	  name="http://gnosis.cx/download/Gnosis_Utils-current.tar.gz"/>
	</item>

	<item id="Pyrex"><em>Pyrex.</em> A Language for Writing Python
	  Extension Modules. <url
	  name="http://www.cosc.canterbury.ac.nz/~greg/python/Pyrex"/>
	</item>

	<item id="NetCDF"><em>NetCDF (network Common Data Form).</em>
	  This is an interface for array-oriented data access and a
	  library that provides an implementation of the
	  interface. <url
	  name="http://www.unidata.ucar.edu/packages/netcdf/"/>
	</item>

	<item id="NetCDFSP"><em>NetCDF module on Scientific
	  Python.</em> ScientificPython is a collection of Python
	  modules that are useful for scientific computing. Its NetCDF
	  module is a powerful interface for NetCDF data format. <url
	  name="http://starship.python.net/~hinsen/ScientificPython/ScientificPythonManual/"/>
	</item>

	<item id="Numerical"><em>Numerical Python.</em> Package to
	  speed-up arithmetic operations on arrays of numbers. <url
	  name="http://www.pfdubois.com/numpy/"/>
	</item>

	<item id="Numarray"><em>Numarray.</em> Reimplementation of
	  Numeric which adds the ability to efficiently manipulate
	  large numeric arrays in ways similar to Matlab and
	  IDL. Among others, Numarray provides the record array
	  extension. <url name="http://stsdas.stsci.edu/numarray/"/>
	</item>

      </enumerate>
    </references>
  </backmatter>
</book>

