<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE book PUBLIC "-//Torsten Bronger//DTD tbook 1.3//EN"
                      "/usr/local/share/xml/tbook/tbook.dtd">
<book>
  <frontmatter>
    <title><visual markup="tt">PyTables</visual> User's Guide</title>
    <author>Francesc Alted</author>
    <date>October, 8th</date>
    <year>2002</year>
  </frontmatter>

  <!-- <abstract>

  <p><visual markup="tt">PyTables</visual> is a Python package whose
    goal is to allow dealing easily, but in a powerful way, with
    scientific data tables and Numeric Python objects organized in a
    hierarchical structure. Such a tables are defined as a collection
    of records whose values are stored in fixed-length fields. As a
    foundation for the underlying hierachical data organization the
    excellent HDF5 library (http://hdf.ncsa.uiuc.edu/HDF5) has been
    choosed.
  </p>

  <p><visual markup="tt">PyTables</visual> is intended to be
    easy-to-use, and tries to be a high-performance interface to
    HDF5. To achieve this, the newest improvements introduced in
    Python 2.2 (like generators or slots and metaclasses in new-brand
    classes) has been used. Pyrex creation extension tool has been
    chosen to access the HDF5 library.
  </p>

  </abstract> -->

  <mainmatter>
    <chapter>
      <heading>Introduction</heading>

      <p>The goal of PyTables is to enable the end user to manipulate
	easily scientific data <visual markup="bf">tables</visual> and
	<em>Numeric Python</em> objects in a hierarchical structure. The
	foundation of the underlying hierachical data organization is
	the excellent <verb>HDF5</verb> library
	(<verb>http://hdf.ncsa.uiuc.edu/HDF5</verb>). Right now,
	PyTables provides limited support of all the HDF5 functions,
	but I hope to add the more interesting ones (for PyTables
	needs) in the near future. Nonetheless, this package is not
	intended to serve as a complete wrapper for the entire HDF5
	API.
      </p>

      <p>A table is defined as a collection of records whose values
	are stored in <em>fixed-length</em> fields. All records have
	the same structure and all values in each field have the same
	<em>data type</em>.  The terms <em>fixed-length</em> and
	strict <em>data types</em> seems to be quite a strange
	requirement for an interpreted language like Python, but they
	serve a useful function if the goal is to save very large
	quantities of data (such as is generated by many scientifc
	applications, for example) in an efficient manner that reduces
	demand on CPU time and I/O.
      </p>

      <p>In order to emulate records (C structs in HDF5) in Python
	PyTables implements a special metaclass object with the
	capability to detect errors in field assignments as well as
	range overflows. PyTables also provides a powerful interface
	to process table data. Records in tables are also known, in
	the <verb>HDF5</verb> naming scheme, as <em>compound</em> data
	types.
      </p>

      <p>For example, you can define arbitrary records in Python
	simply by declaring a class with the name field and types
	information, like in:
      </p>

<verbatim>
class Particle(IsRecord):
    name        = '16s'  # 16-character String
    idnumber    = 'Q'    # unsigned long long (i.e. 64-bit integer)
    TDCcount    = 'B'    # unsigned byte
    ADCcount    = 'H'    # unsigned short integer
    grid_i      = 'i'    # integer
    grid_j      = 'i'    # integer
    pressure    = 'f'    # float  (single-precision)
    energy      = 'd'    # double (double-precision)

</verbatim>

      <p>then, you will normally instantiate it, fill it with your
	values, and save (arbitrary large) collections of them in a
	file for persistent storage. After that, this data can be
	retrieved and post-processed quite easily with <visual
	markup="tt">PyTables</visual> or even with another
	<verb>HDF5</verb> application.
      </p>

      <section>
	<heading>Features</heading> <p><visual
	markup="tt">PyTables</visual> has the next capabilities:</p>

	<itemize>
	  <item><em>Support of table entities:</em> Allows
	    working with large number of records that don't fit in
	    memory.
	  </item>
	  <item><em>Support of <visual markup="tt">Numeric
	    Python</visual> arrays:</em> Numeric arrays are a very
	    useful complement of tables to keep homogeneus table
	    slices (like selections of table columns).
	  </item>
	  <item><em>Supports a hierarchical data model:</em> That way,
	    you can structure very clearly all your data. Pytables
	    builds up an object tree in memory that replicates the
	    underlying file structure and the access to the file
	    objects is made by walking throughout the <visual
	    markup="tt">PyTables</visual> object tree, and
	    manipulating them.
	  </item>
	  <item><em>Incremental I/O:</em> It supports adding records
	    to already created tables. So you won't need to book large
	    amounts of memory to fill the entire table and then save
	    it to disk but you can do that incrementally, even between
	    different Python sessions.
	  </item>
	  <item><em>Allows field name, data type and range
	    checking:</em> So you can be confident that if <visual
	    markup="tt">PyTables</visual> does not report an error,
	    you can be confident that your data is probably ok.
	  </item>
	  <item><em>Support of files bigger than 2 GB:</em> The
	    underlying HDF5 library already can do that (if your
	    platform supports the C long long integer, or, on Windows,
	    __int64), so PyTables automatically inherits get this
	    benefit.
	  </item>
	  <item><em>Data compression:</em> It supports data
	    compression (trough the use of the zlib library) out of
	    the box. This become important when you have repetitive
	    data patterns and don't want to loose your time searching
	    for an optimized way to save them (i.e. it saves you data
	    organization analysis time).
	  </item>
	  <item><em>Big-Endian/Low-Endian safety:</em> <visual
	    markup="tt">PyTables</visual> has been coded (as HDF5 is)
	    to care with little-endian/big-endian byte orderings. So,
	    in principle, you can write a file in a big-endian machine
	    and read it in other little-endian without
	    problems<footnote>Well, I didn't actually test that in
	    real world, but if you do, please, tell
	    me.</footnote>.</item>
	</itemize>

	<p>Finally, it should noted that <visual
	  markup="tt">PyTables</visual> is not intended to be merely a
	  wrapper of HDF5_HL library (don't confuse with HL-HDF5, the
	  Swedish Meteorological and Hydrological Institute effort to
	  provide another high Level interface to HDF5; see <ref
	  refid="HL-HDF">reference</ref>), but to provide a flexible
	  tool to deal with large amounts of data (i.e., typically
	  bigger than available memory) in tables (heterogeneus data
	  types) and arrays (homogeneus data types) organized in a
	  hierarchical, persistent disk storage. PyTables take
	  advantage of the powerful object orientation and
	  introspection capabilities offered by Python to present all
	  this power to the user in a friendly manner.
	</p>
      </section>

      <section>
	<heading>The object tree</heading>

	<p>The hierarchical model of the underlying HDF5 library
	  allows PyTables to manage tables and arrays in a tree-like
	  structure. This is achieved by <em>dynamically</em> creating
	  an object tree imitating the HDF5 structure on disk. That
	  way, the access to the HDF5 objects is made by walking
	  throughout the <visual markup="tt">PyTables</visual> object
	  tree, and manipulating them. A key aspect of PyTables is
	  that for accessing to the different nodes on the object tree
	  a <visual markup="bf">natural naming</visual> schema is
	  used, i.e. the attributes of the objects that represent HDF5
	  elements are the same as the names of the element's
	  children<footnote>I've taken this simple but powerful idea
	  from the excellent <visual markup="tt">Objectify</visual>
	  module by David Mertz (see references <ref
	  refid="Objectify"></ref> and <ref
	  refid="GnosisUtils"></ref>)</footnote>. See the <ref
	  refid="usage">Chapter</ref> for a more detailed explanation.
	</p>
	<p>You should note that not all the data present on file is
	  loaded in <visual markup="tt">PyTables</visual> tree, but
	  only the <em>metadata</em> (i.e. data that actually
	  describes the structure of the real data). The actual access
	  to the real data is provided through the methods of those
	  objects.
	</p>
	<p>To better understand the dynamic nature of this object
	  tree, imagine we have made a script (in fact, this script
	  exists; its name is <verb>objecttree.py</verb> and you can
	  find it in the <verb>examples/</verb> directory) that
	  creates a simple HDF5 file, with the structure that appears
	  in <ref refid="objecttree-h5">figure</ref> (we have used the
	  java program <verb>hdfview</verb> to obtain this
	  image). During creation time, the object tree is updated at
	  the same time that data is saved on file and when you close
	  the file, this object is destroyed. If you re-open again
	  this file (in read only mode, for example), the object tree
	  with will be re-constructed from the metadata existent on
	  file.
	</p>
	<p>
	  It is important to stress that actual data is not read until
	  you ask for it in a particular node, but by making use of
	  the object tree (the metadata) you can get information on
	  the objects on disk, for example, table names, title, name
	  fields, data types in fields, number of records, or, in the
	  case of arrays, shapes, typecode, and so on. You can
	  traverse the tree with the supplied methods, and when you
	  find the data you want you can read and process it. In some
	  sense, you can think of PyTables to provide the
	  introspection capabilities of Python objects, but applied to
	  the persistent storage of large amounts of data.
	</p>

	<figure id="objecttree-h5">
	  <graphics file="objecttree-h5" scale="0.6" kind="bitmap">
	  </graphics>
	  <caption>An HDF5 example with 2 subgroups and 3 tables.</caption>
	</figure>

	<p>In <ref refid="objecttree">figure</ref> you can see an
	  example of the object tree created by reading a PyTables
	  file. If you are going to be a <visual
	  markup="tt">PyTables</visual> user, take your time to
	  understand it<footnote>Bear in mind, however, that this
	  diagram is <visual markup="bf">not</visual> a standard UML
	  class diagram; I've used an UML tool to draw it, that's
	  all)</footnote>. That will also make you more proactive by
	  avoiding programming mistakes.
	</p>

	<figure id="objecttree">
	  <!-- Now, this works! -->
	  <graphics file="objecttree" scale="0.4" kind="vector">
	  
	  <!-- We have a processing error here. We solved this by
	  converting the eps to jpeg with command:
pstoimg -scale 0.75 -aaliastext -type png -crop a -interlace objecttree.eps
	  and then, applying a new conversion to jpg with
	  convert objecttree.png objecttree.jpg
	  -->
	  <!-- <graphics file="objecttree" scale="0.5" kind="bitmap"> -->
	  </graphics>
	  <caption>An object tree example in <visual
	      markup="tt">PyTables</visual>.
	  </caption>
	</figure>
      
	<p>
	</p>

      </section>

    </chapter>

    <chapter>
      <heading>Installation</heading>

      <p>This are instructions for Unix/Linux system. If you are using
	Windows, and you get the library to work, please tell me about.
      </p>

      <p>Extensions in <visual markup="tt">PyTables</visual> has been
	made using Pyrex (see <ref refid="Pyrex">reference</ref>) and
	C. You can rebuild everything from scratch if you got Pyrex
	installed, but this is not necessary, as the Pyrex compiled
	source is included in the distribution. In order to do that,
	merely replace <visual markup="tt">setup.py</visual> script in
	these instructions by <visual
	markup="tt">setup-pyrex.py</visual>.
      </p>

      <p>The Python Distutils are used to build and install PyTables,
	so it is fairly simple to get things ready to go.
      </p>

      <enumerate>

	<item>
	  <p>First, make sure that you have <verb>HDF5 1.4.x</verb>
	    and <verb>Numeric Python</verb> installed (I'm using
	    <verb>HDF5 1.4.4</verb> and <verb>Numeric 22.0</verb>
	    currently). If don't, you can find them at
	    <verb>http://hdf.ncsa.uiuc.edu/HDF5</verb> and
	    <verb>http://www.pfdubois.com/numpy</verb>. Compile/install
	    them.
	  </p>
	  
	  <p><verb>setup.py</verb> will detect <verb>HDF5</verb>
	    libraries and include files under <verb>/usr</verb> or
	    <verb>/usr/local</verb>; this will catch installations
	    from RPMs, DEBs and most hand installations under Unix. If
	    <verb>setup.py</verb> can't find your <verb>libhdf5</verb>
	    or if you have several versions installed and want to
	    select one of them, then you can give it a hint either in
	    the environment (using the <verb>HDF5_DIR</verb>
	    evironment variable) or on the command line by specifying
	    the directory containing the include and lib directory.
	    For example:
	  </p>
	  <verbatim>
	    --hdf5=/stuff/hdf5-1.4.4
	  </verbatim>

	  <p>If your <verb>HDF5</verb> library was built as shared
	    library, and if this shared library is not in the runtime
	    load path, then you can specify the additional linker
	    flags needed to find the shared library on the command
	    line as well. For example:
	  </p>
	  <verbatim>
	    --lflags="-Xlinker -rpath -Xlinker /stuff/hdf5-1.4.4/lib"
	  </verbatim>
	  <p>or perhaps just
	  </p>
	  <verbatim>
	    --lflags="-R /stuff/hdf5-1.4.4/lib"
	  </verbatim>

	  <p>Check your compiler and linker documentation for correct
	    syntax.
	  </p>

	  <p>It is also possible to specify linking against different
	    libraries with the <verb>--libs</verb> switch:
	  </p>
	  <verbatim>
	    --libs="-lhdf5-1.4.6"
	    --libs="-lhdf5-1.4.6 -lnsl"
	  </verbatim>
	</item>
	<item>
	  <p>From the main pytables distribution directory run this
	    command, (plus any extra flags needed as discussed above):
	  </p>
	  <verbatim>
	    python setup.py build_ext --inplace
	  </verbatim>
	  <p>depending on the compiler flags used when compiling your
	    Python executable, there may appear lots of warnings. Don't
	    worry, almost all of them are caused by variables declared
	    but never used. That's normal in Pyrex extensions.
	  </p>
	</item>
	<item>
	  <p>To run the test suite change into the test directory and run this
	    command, (assuming your shell is <verb>sh</verb> or compatible):
	  </p>
	  <verbatim>
	    PYTHONPATH=..
	    export PYTHONPATH
	    python test_all.py
	  </verbatim>
	  <p>If you would like to see some verbose output from the
	    tests simply add the flag <verb>-v</verb> and/or the word
	    <verb>verbose</verb> to the command line. You can also
	    run just the tests in a particular test module. For
	    example:
	  </p>
	  <p>If you would like to see some verbose output from the tests
	    simply add the word <verb>verbose</verb> to the command
	    line. You can also run only the tests in a particular test
	    module by themselves. For example:</p>
	  <verbatim>
	    python test_types.py -v
	  </verbatim>
	</item>
	<item>
	  <p>To install the entire <visual
	    markup="tt">PyTables</visual> Python package, change back
	    to the root distribution directory and run this command as
	    the root user:
	  </p>
	  python setup.py install
	</item>
      </enumerate>

      <p>That's it!. Now, read on the next section to see how to use
	PyTables.
      </p>

    </chapter>

    <chapter id="usage">
      <heading>Usage</heading>

      <section id="firstexample">
	<heading>A first example</heading> 

	<p>Let's start by showing a simple example. For simplicity and
	  direct comparison, I'll choose the same that is exposed in
	  an HDF5_HL example (see <ref
	  refid="HDF5TableExamples">reference</ref>).
	</p>
	<p>So, we want to create a table whose records are particle
	  properties. Each particle (record) has a name, a position
	  (specified by latitude and longitude), pressure and
	  temperature.
	</p>
	<p>We start by define this record in <visual
	  markup="tt">PyTables</visual> by declaring a subclass of
	  <verb>IsRecord</verb>. But first, the necessary imports:
	</p>
	<verbatim>
from tables import File, IsRecord

class Particle(IsRecord):
    name        = '16s'  # 16-character String
    lati        = 'i'    # integer
    longi       = 'i'    # integer
    pressure    = 'f'    # float  (single-precision)
    temperature = 'd'    # double (double-precision)
	</verbatim>
	<p>As you see, we define the Particle class as a subclass of
	  IsRecord (which is actually a <em>metaclass</em>, but this
	  is not important now). The name of each Particle attribute
	  will be the name of the record field and its value will
	  become its data type. '16s' typecode means a 16-character
	  string, 'i' an integer, 'd' a double, and so on. For a
	  complete list of data types supported see <ref
	  refid="datatypesSupported">table</ref>.
	</p>
      <p>Now, we open an HDF5 file in write mode:
      </p>
      <verbatim>
fileh = File(filename = "example1.h5", mode = "w")
      </verbatim>
      <p>and get the object which is the root directory in HDF5 hierarchy:
      </p>
      <verbatim>
group = fileh.getRootGroup()
      </verbatim>
      <p>then, create a new table object
      </p>
      <verbatim>
table = fileh.newTable(group, 'table', Particle(), "Title example")
      </verbatim>
      <p>get the the Particle instance associated with the table
      </p>
      <verbatim>
particle = fileh.getRecordObject(table)
      </verbatim>
      <p>and fill the table with 10 particles
      </p>
      <verbatim>
for i in xrange(10):
    # First, assign the values to the Particle record
    particle.name  = '%16d' % i
    particle.lati = i 
    particle.longi = i
    particle.pressure = float(i)
    particle.temperature = float(i)
    # This injects the Particle values
    fileh.appendRecord(table, particle)
      </verbatim>
      <p>and finally, close the file:
      </p>
      <verbatim>
fileh.close()
      </verbatim>
      <p>That's it!. We can see here the complete example for a better
	inspection, with a few additional comments:
      </p>
      <verbatim>
from tables import File, IsRecord

class Particle(IsRecord):
    name        = '16s'  # 16-character String
    lati        = 'i'    # integer
    longi       = 'i'    # integer
    pressure    = 'f'    # float  (single-precision)
    temperature = 'd'    # double (double-precision)

# Open a file in "w"rite mode
fileh = File(name = "example1.h5", mode = "w")
# Get the HDF5 root group
root = fileh.getRootGroup()
# Create a new table
table = fileh.newTable(root, 'table', Particle(), "Title example")
#print "Table name ==>", table._v_name
# Get the record object associated with the table: all three ways are valid
#particle = table.record
particle = fileh.getRecordObject(table)  # This is really an accessor
#particle = fileh.getRecordObject("/table")
# Fill the table with 10 particles
for i in xrange(10):
    # First, assign the values to the Particle record
    particle.name  = 'Particle: %6d' % (i)
    particle.lati = i 
    particle.longi = 10 - i
    particle.pressure = float(i*i)
    particle.temperature = float(i**2)
    # This injects the Record values. Both ways do that.
    #table.appendRecord(particle)      
    fileh.appendRecord(table, particle)      

# Finally, close the file
fileh.close()
      </verbatim> 

      <p>In <ref refid="example1">figure</ref> you can see the table we
	have created in this example. You will find in the directory
	<verb>examples</verb> the working version of the code
	(source file <verb>example1.py</verb>).
      </p>

      <figure id="example1">
	<graphics file="example1" scale="0.6" kind="bitmap">
	</graphics>
	<caption>A simple table in HDF5.</caption>
      </figure>
      </section>

      <section id="secondExample">
	<heading>A somewhat more complex exercise</heading>

      <p>Now, time for a more sophisticated example. Here, we will
	create a couple of directories (groups, in HDF5 jargon)
	hanging directly from the root directory called
	<verb>Particles</verb> and <verb>Events</verb>. Then, we will
	put 3 tables in each group; in <verb>Particles</verb> we will
	put instances of <verb>Particle</verb> records and in
	<verb>Events</verb>, instances of <verb>Event</verb>. After
	that, we will feed the tables with 257 (you will see soon why
	I choose such an "esoteric" number) entries each. Finally, we
	will read the recently created table
	<verb>/Events/TEvent3</verb> and select some values from it
	using a comprehension list.
      </p>
      <p>Lets go,</p>

      <verbatim>
from tables import File, IsRecord

class Particle(IsRecord):
    name        = '16s'  # 16-character String
    lati        = 'i'    # integer
    longi       = 'i'    # integer
    pressure    = 'f'    # float  (single-precision)
    temperature = 'd'    # double (double-precision)

class Event(IsRecord):
    name        = '16s'  # 16-character String
    TDCcount    = 'B'    # unsigned char
    ADCcount    = 'H'    # unsigned short
    xcoord      = 'f'    # float  (single-precision)
    ycoord      = 'f'    # float  (single-precision)

# Open a file in "w"rite mode
fileh = File(name = "example2.h5", mode = "w")
# Get the HDF5 root group
root = fileh.getRootGroup()

# Create the groups:
for groupname in ("Particles", "Events"):
    group = fileh.newGroup(root, groupname)

# Now, create and fill the tables in Particles group
gparticles = fileh.getNode("/Particles")
# You can achieve the same result with the next notation
# (it can be convenient and more intuitive in some contexts)
#gparticles = root.Particles
# Create 3 new tables
for tablename in ("TParticle1", "TParticle2", "TParticle3"):
    # Create a table
    table = fileh.newTable("/Particles", tablename, Particle(),
                           "Particles: "+tablename)
    # Get the record object associated with the table:
    particle = fileh.getRecordObject(table)
    # Fill the table with 10 particles
    for i in xrange(257):
        # First, assign the values to the Particle record
        particle.name  = 'Particle: %6d' % (i)
        particle.lati = i 
        particle.longi = 10 - i
        particle.pressure = float(i*i)
        particle.temperature = float(i**2)
        # This injects the Record values
        fileh.appendRecord(table, particle)      

    # Flush the table buffers
    fileh.flushTable(table)

# Now, go for Events:
for tablename in ("TEvent1", "TEvent2", "TEvent3"):
    # Create a table. Look carefully at how we reference the Events group!.
    table = fileh.newTable(root.Events, tablename, Event(),
                           "Events: "+tablename)
    # Get the record object associated with the table:
    event = table.record
    # Fill the table with 10 events
    for i in xrange(257):
        # First, assign the values to the Event record
        event.name  = 'Event: %6d' % (i)
        #event.TDCcount = i
        event.ADCcount = i * 2
        event.xcoor = float(i**2)
        event.ycoord = float(i**4)
        # This injects the Record values
        fileh.appendRecord(table, event)      

    # Flush the buffers
    fileh.flushTable(table)

# Read the records from table "/Events/TEvent3" and select some
e = [ p.TDCcount for p in fileh.readRecords("/Events/TEvent3")
      if p.ADCcount &lt; 20 and 4&lt;= p.TDCcount &lt; 15 ]
print "Last record ==>", p
print "Selected values ==>", e
print "Total selected records ==> ", len(e)

# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
      </verbatim>

      <p>Throughout the comments, you can see that <visual markup="tt">PyTables</visual> let's you
      do things in, generally, more than one way. I don't know if
      that's good or not, but I'm afraid it is not. This is in part
      due to the fact that <visual markup="tt">PyTables</visual> is in first stages of development,
      and probably as the API matures, there will be less choices.</p>

      <p>If you have read the code carefully it looks pretty good, but
      it won't work. If you run this example, you will get the next
      error:
      </p>
      <verbatim>
Traceback (most recent call last):
  File "example2.py", line 68, in ?
    event.xcoor  = float(i**2)
AttributeError: 'Event' object has no attribute 'xcoor'
      </verbatim>
      <p>This error is saying us that we tried to assign a value to a
	non-existent field in an <verb>Event</verb> object. By looking
	carefully at the <verb>Event</verb> attributes, we see that we
	misspelled the <verb>xcoord</verb> field (we wrote
	<verb>xcoor</verb> instead). So we correct this in the source,
	and run it again.</p>
      <p>And again, we find another problem:
      </p>
      <verbatim>
Traceback (most recent call last):
  File "example2.py", line 69, in ?
    table.appendRecord(event)      
  File "/usr/lib/python2.2/site-packages/tables/Table.py", line 210, in appendRecord
    self._v_packedtuples.append(recordObject._f_pack2())
  File "/usr/lib/python2.2/site-packages/tables/IsRecord.py", line 121, in _f_pack2
    self._f_raiseValueError()
  File "/usr/lib/python2.2/site-packages/tables/IsRecord.py", line 130, in 
_f_raiseValueError
    raise ValueError, \
ValueError: Error packing record object: 
 [('ADCcount', 'H', 256), ('TDCcount', 'B', 256), ('name', '16s', 'Event:    256'),
 ('xcoord', 'f', 65536.0), ('ycoord', 'f', 4294967296.0)]
 Error was: ubyte format requires 0&lt;=number&lt;=255
      </verbatim>
      <p>This other error is saying that one of the records is having
	trouble to be converted to the data types stated in the Event
	class definition. By looking carefully to the record object
	causing the problem, we see that we are trying to assign a
	value of 256 to the 'TDCcount' field which has a 'B' (C
	unsigned char) typecode and the allowed range for it is
	<verb>0&lt;=TDCcount&lt;=255</verb>. This is a very powerful
	capability to automatically check for ranges: the message
	error is explicit enough to figure out what is happening. In
	this case you can solve the problem by promoting the
	<verb>TDCcount</verb> to 'H' which is a unsigned 16-bit
	integer, or avoid the mistake you probably made in assigning a
	value greater than 255 to a 'B' typecode.
      </p>
      <p>If we change the line:
      </p>
      <verbatim>event.TDCcount = i
      </verbatim>
      <p>by the next one:
      </p>
      <verbatim>event.TDCcount = i % (1&lt;&lt;8)
      </verbatim>
      <p>you will see that our problem has disappeared, and the HDF5
	file has been created. As before, you will find in the
	directory <verb>examples</verb> the working version of the
	code (source file <verb>example2.py</verb>).
      </p>
      <p>Finally, admire the structure we have created in <ref
      refid="example2">figure</ref>.</p>

      <figure id="example2">
	<graphics file="example2" scale="0.6" kind="bitmap">
	</graphics>
	<caption>Tables structured in a hierarchical order.</caption>
      </figure>

      <p>Feel free to visit the rest of examples in directory
        <verb>examples</verb>, and try to understand them. I've tried
        to make the cases as orthogonal as possible to give you an
        idea of the <visual markup="tt">PyTables</visual> capabilities
        and its way of dealing with HDF5 objects.</p>

      </section>
    </chapter>

    <chapter>
      <heading>Library Reference</heading>
      
      <p><verb>PyTables</verb> implements several classes to represent
	the different nodes in the object tree. They are called
	<verb>File</verb>, <verb>Group</verb>, <verb>Leaf</verb>,
	<verb>Table</verb> and <verb>Array</verb>. Another one is
	responsible to build record objects from a subclass user
	declaration, and performs field, type and range checks; it is
	called <verb>IsRecord</verb>. An important function, called
	<verb>openFile</verb> is responsible to create, open or append
	to <verb>PyTables</verb> files. In addition, a few utility
	funtions are defined to guess if an user supplied file is a
	<verb>PyTables</verb> file or not. These are called
	<verb>isPyTablesFile</verb> and <verb>isHDF5</verb>. Finally,
	several variables are also available to the user that informs
	about <verb>PyTables</verb> version, file format version or
	underlying libraries (as for example <verb>HDF5</verb>)
	version number.
      </p>

      <p>Let's start discussing the global variables and functions
	available to the user, then the methods in the classes defined
	in PyTables.
      </p>

      <section>
	<heading><visual markup="tt">tables</visual> Variables and
	  Functions</heading>

	<subsection>
	  <heading>Global Variables</heading>

	  <description>

	    <term>__version__</term>
	    <item>The PyTables version number.</item>

	    <term>HDF5Version</term>
	    <item>The underlying HDF5 library version number.</item>

	    <term>ExtVersion</term>
	    <item>The Pyrex extension types version. This may be
	      useful for reporting bugs.</item>

	</description>

<!--	  <subsubsection>
	    <heading>__version__</heading>

	    <p>The PyTables version number.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading>HDF5Version</heading>
	    
	    <p>The underlying HDF5 library version number.
	    </p>
	  </subsubsection>
-->
	</subsection>



	<subsection>
	  <heading>Global Functions</heading>

	  <description>
	    <term>openFile(filename, mode='r', title='')</term>
	    <item>Open a PyTables file an returns a File object.
	    
	      <description>

		<term>filename:</term>

		<item>The name of the file (supports environment variable
		  expansion). It must have any of <verb>".h5"</verb>,
		  <verb>".hdf"</verb> or <verb>".hdf5"</verb> extensions.
		</item>

		<term>mode:</term>

		<item>The mode to open the file. It can be one of the
		  following:
		  <description>

		    <term>'r':</term> <item>read-only; no data can be
		      modified.</item>

		    <term>'w':</term> <item>write; a new file is created
		      (an existing file with the same name is
		      deleted).</item>

		    <term>'a':</term> <item>append; an existing file is
		      opened for reading and writing, and if the file does
		      not exist it is created.</item>

		    <term>'r+':</term> <item>is similar to 'a', but the
		      file must already exist.</item>

		    <term>title</term> <item>If filename is new, this
		      will set a title for the root group in this
		      file. If filename is not new, the title will be
		      read from disk, and this will not have any
		      effect.</item>

		  </description>
		</item>
	      </description>
	    </item>

	    <term>isHDF5(filename)</term> <item>Determines whether
	      filename is in the HDF5 format. When successful, returns
	      a positive value, for TRUE, or 0 (zero), for
	      FALSE. Otherwise returns a negative value.  To this
	      function to work, it needs a closed file.
	    </item>

	    <term>isPyTablesFile(filename)</term> <item>Determines
	      whether a file is in the PyTables format.  When
	      successful, returns the format version string, for TRUE,
	      or 0 (zero), for FALSE. Otherwise returns a negative
	      value.  To this function to work, it needs a closed
	      file.
	    </item>

	  </description>
	</subsection>
      </section>


      <section id="FileClass">
	<heading>The <em>File</em> class</heading>

	<p>This class is returned when a PyTables is opened with the
	  <verb>openFile</verb> function. It is in charge of create,
	  open, flush and close the PyTables files. Also, File class
	  offer methods to traverse the object tree, as well as to
	  create new nodes. One of its attributes (<verb>root</verb>)
	  represents the entry point to the object tree.
	</p>

	<p>Next, we will discuss the attributes and methods for File
	  class<footnote>On the following, the term <verb>Leaf</verb>
	  will refer to a <verb>Table</verb> instance. Right now, the
	  only supported <verb>Leaf</verb> objects are
	  <verb>Table</verb> and <verb>Array</verb>, but this list may
	  be increased in the future.</footnote>.
	</p>

	<subsection>
	  <heading>File attributes</heading>
	  <description>

	    <term>filename</term> <item>Filename opened.</item>

	    <term>mode</term> <item>Mode in which the filename was
	      opened.</item>

	    <term>title</term> <item>The title of the root group in
	      file.</item>

	    <term>root</term>
	    <item>The root group in file. This is the entry point to
	      the object tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading>File methods</heading>

	  <description>

	    <term>createGroup(where, name, title='') </term>
	    <item>Create a new Group instance with name <em>name</em>
	    in <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the new
		  group will hang. <em>where</em> parameter can be a
		  path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or another
		  Group instance. </item>

		<term>name</term>
		<item>The name of the new group.</item>

		<term>title</term>
		<item>A descrition for this group.</item>

	      </description>
	    </item>

	    <term>createTable(where, name, RecordObject, title='',
	      compress=3, expectedrows=10000)</term> <item>Create
	      a new Table instance with name <em>name</em> in
	      <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the
		  new table will hang. <em>where</em> parameter can be
		  a path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or Group
		  instance. </item>

		<term>name</term>
		<item>The name of the new table.</item>

		<term>RecordObject</term> <item>A IsRecord instance
		  where all the table fields are defined.</item>

		<term>title</term>
		<item>A descrition for this table.</item>

		<term>compress</term> <item>Specifies a compress level
		  for data. The allowed range is 0-9. A value of 0
		  disables compression. The default is compression
		  level 3, that balances between compression effort
		  and CPU consumption.
		</item>

		<term>expectedrows</term> <item>An user estimate about
		  the number of records that will be on table. If not
		  provided, the default value is appropiate for tables
		  until 1 MB in size (more or less, depending on the
		  record size). If you plan to save bigger tables try
		  providing a guess; this will optimize the HDF5
		  B-Tree creation and management process time and
		  memory used.</item>

	      </description>
	    </item>

	    <term>createArray(where, name, NumericObject,
	      title='')</term> <item>Create a new instance Array with
	      name <em>name</em> in <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the
		  new array will hang. <em>where</em> parameter can be
		  a path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or Group
		  instance. </item>

		<term>name</term>
		<item>The name of the new array.</item>

		<term>NumericObject</term> <item>The Numeric array to
		  be saved.</item>

		<term>title</term>
		<item>A description for this table.</item>

	      </description>
	    </item>

	    <term>getNode(where, name='', classname='')</term>
	    <item>Returns the object node <em>name</em> under
	      <em>where</em> location

	      <description>

		<term>where</term> <item>Can be a path string or Group
		  instance. If <em>where</em> doesn't exists or has not a
		  child called <em>name</em>, a ValueError error is raised.
		</item>

		<term>name</term> <item>The object name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.</item>

		<term>classname</term> <item>If supplied, returns only
		  an instance of this class name. Allowed names in
		  <em>classname</em> are: 'Group', 'Leaf', 'Table' and
		  'Array'.</item>

	      </description>
	    </item>

	    <term>listNodes(where, classname='')</term>
	    <item>Returns a list with all the object nodes (Group or
	    Leaf) hanging from <em>where</em>. The list is
	    alphanumerically sorted by node name.

	      <description>

		<term>where</term> <item>The parent group. Can be a
		  path string or Group instance.  </item>

		<term>classname</term> <item>If a <em>classname</em>
		  parameter is supplied, the iterator will return only
		  instances of this class (or subclasses of it). The
		  only supported classes in <em>classname</em> are
		  'Group' and 'Leaf'.</item>

	      </description>
	    </item>

	    <term>walkGroups(where='/')</term> <item>Recursively
	      obtains Groups (not Leaves) hanging from
	      <em>where</em>. If <em>where</em> is not supplied, the
	      root object is taken as origin. The groups are returned
	      from top to bottom, and alphanumerically sorted when in
	      the same level.

	      <description>

		<term>where</term> <item>The origin group. Can be a
		  path string or Group instance.
		</item>

	      </description>
	    </item>

	    <term>flush()</term> <item>Flush all the objects on all
	      the HDF5 objects tree.
	    </item>

	    <term>close()</term> <item>Flush all the objects in HDF5
	      file and close the file.
	    </item>

	  </description>

	</subsection>
      </section>

      <section id="IsRecordClass">
	<heading>The <em>IsRecord</em> class.</heading>

	<p>This class is in fact a so-called <em>metaclass</em>
	  object. There is nothing special on it, except that their
	  subclasses attributes are transformed during its
	  construction phase, and new methods for the are defined
	  based on the values of the attributes. In that way, we can
	  <em>force</em> the resulting instance to only accept
	  assignments on the declared attributes (in fact, it has a
	  few more, but they are hidden with prefixes like <visual
	  markup="tt">"__"</visual>, <visual
	  markup="tt">"_v_"</visual> or <visual
	  markup="tt">"_f_"</visual>, so please, don't use attributes
	  names starting with these prefixes). If you try to do an
	  assignment to a non-declared attribute, <visual markup="tt">PyTables</visual> will raise
	  an error.</p>

	<p>To use such a particular class, you have to declare a
	  descendent class from <em>IsRecord</em>, with many
	  attributes as fields you want in your record. To declare
	  their types, you simply assign to these attributes their
	  <em>typecode</em>. That's all, from now on, you can
	  instantiate objects from you new class and use them as a
	  very flexible record object with safe features like
	  automatic name field, data type and range checks (see the
	  <ref refid="secondExample">section</ref> for an example on
	  how it works).
	</p>
	<p>See the <ref refid="datatypesSupported">appendix</ref> for
	  a relation of data types supported in a <visual
	  markup="tt">IsRecord</visual> class declaration.
	</p>

      </section>
    </chapter>

    <appendix>
      <chapter id="datatypesSupported">
	<heading><visual markup="tt">PyTables</visual> Supported Data Types</heading>
        <p>The supported data types are the same that are supported by
	  the <visual markup="tt">array</visual> module in Python,
	  with some additions, which will be briefly discussed
	  shortly. The typecodes for the supported data types are
	  listed on <ref refid="datatypesSupported">table</ref>.
	</p>

	<table id="datatypesSupportedTable">
	  <tabular preamble="lllcl">
	  <tabhead>
	    <srow>Type Code | Description | C Type | Size (in bytes) |
	      Python Counterpart</srow>
	  </tabhead>
	  <tabbody>
	    <srow>'c' | 8-bit character | char | 1 | String of lenght 1 </srow>
	    <srow>'b' | 8-bit integer | signed char | 1 | Integer </srow>
	    <srow>'B' | 8-bit unsigned integer | unsigned char | 1 | Integer </srow>
	    <srow>'h' | 16-bit integer | short | 2 | Integer </srow>
	    <srow>'H' | 16-bit unsigned integer | unsigned short | 2 | Integer </srow>
	    <srow>'i' | integer | int | 4 or 8 | Integer </srow>
	    <srow>'I' | unsigned integer | unsigned int | 4 or 8 | Long </srow>
	    <srow>'l' | long integer | long | 4 or 8 | Integer </srow>
	    <srow>'L' | unsigned long integer | unsigned long | 4 or 8 | Long </srow>
	    <srow>'q' | long long integer | long long | 8 | Long </srow>
	    <srow>'Q' | unsigned long long integer | unsigned long long | 8 | Long </srow>
	    <srow>'f' | single-precision float | float | 4 | Float </srow>
	    <srow>'d' | double-precision float | double | 8 | Float </srow>
	    <srow>'s' | arbitrary lenght string | char[] | * | String </srow>
	  </tabbody>
	</tabular>
	  <caption>Data types supported by <visual markup="tt">PyTables</visual></caption>
	</table>

	<p>The additions to the array module typecodes are the <visual
	  markup="tt">'q'</visual>, <visual markup="tt">'Q'</visual>
	  and <visual markup="tt">'s'</visual>.  The <visual
	  markup="tt">'q'</visual> and <visual
	  markup="tt">'Q'</visual> conversion codes are available in
	  native mode only if the platform C compiler supports C long
	  long, or, on Windows, __int64. They are always available in
	  standard modes. The <visual markup="tt">'s'</visual>
	  typecode can be preceded by an integer to indicate the
	  maximum length of the string, so <visual
	  markup="tt">'16s'</visual> represents a 16-byte string.</p>

	<p>Also note that when the <visual markup="tt">'I'</visual>
	  and <visual markup="tt">'L'</visual> codetypes are used in
	  records, Python uses internally <visual
	  markup="tt">Long</visual> integers to represent them, that
	  can (or cannot, depending on what you are trying to do) be
	  a source of inefficiency in your code.</p>
      </chapter>
    </appendix>
  </mainmatter>

  <backmatter>
    <references>
      <enumerate>

	<item id="HDF5WhatIs"><em>What is HDF5?.</em> Concise
	  description about HDF5 capabilities and its differences from
	  earlier versions (HDF4). <url
	  name="http://hdf.ncsa.uiuc.edu/whatishdf5.html"/>
	</item>

	<item id="HDF5Intr"><em>Introduction to HDF5.</em>
	  Introduction to the HDF5 data model and programming
	  model. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/doc/H5.intro.html"/>
	</item>

	<item id="HDF5_HL"><em>HDF5: High Level APIs.</em> A set of
	  functions built on top of the basic HDF5 library. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/hdf5_hl/doc/"/>
	</item>

	<item id="HDF5TableExamples"><em>The HDF5 table programming
	  model.</em> Examples on using HDF5 tables with the C
	  API. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/hdf5_hl/doc/RM_hdf5tb_ex.html"/>
	</item>

	<item id="HL-HDF"><em>HL-HDF.</em> A High Level Interface to
	  the HDF5 File Format. <url
	  name="ftp://ftp.ncsa.uiuc.edu/HDF/HDF5/contrib/hl-hdf5/README.html"/>
	</item>

	<item id="Objectify"><em>On the 'Pythonic' treatment of XML
	  documents as objects(II).</em> Article describing XML
	  Objectify, a Python module that allows working with XML
	  documents as Python objects. Some of the ideas presented
	  here are used in <visual markup="tt">PyTables</visual>. <url
	  name="http://www-106.ibm.com/developerworks/xml/library/xml-matters2/index.html"/>
	</item>

	<item id="GnosisUtils"><em>gnosis.xml.objectify.</em> This
	  module is part of the Gnosis utilities, and allows to create
	  a mapping between any XML element to "native" Python
	  objects. <url
	  name="http://gnosis.cx/download/Gnosis_Utils-current.tar.gz"/>
	</item>

	<item id="Pyrex"><em>Pyrex.</em> A Language for Writing Python
	  Extension Modules. <url
	  name="http://www.cosc.canterbury.ac.nz/~greg/python/Pyrex"/>
	</item>

	<item id="NetCDF"><em>NetCDF (network Common Data Form).</em>
	  This is an interface for array-oriented data access and a
	  library that provides an implementation of the
	  interface. <url
	  name="http://www.unidata.ucar.edu/packages/netcdf/"/>
	</item>

	<item id="NetCDFSP"><em>NetCDF module on Scientific
	  Python.</em> ScientificPython is a collection of Python
	  modules that are useful for scientific computing. Its NetCDF
	  module is a powerful interface for NetCDF data format. <url
	  name="http://starship.python.net/~hinsen/ScientificPython/ScientificPythonManual/Scientific_24.html"/>
	</item>

	<item id="Numerical"><em>Numerical Python.</em> Package to
	  speed-up arithmetic operations on arrays of numbers. <url
	  name="http://www.pfdubois.com/numpy/"/>
	</item>

	<item id="Numarray"><em>Numarray.</em> Reimplementation of
	  Numeric which adds the ability to efficiently manipulate
	  large numeric arrays in ways similar to Matlab and
	  IDL. Among others, Numarray provides the record array
	  extension. <url name="http://stsdas.stsci.edu/numarray/"/>
	</item>

      </enumerate>
    </references>
  </backmatter>
</book>

