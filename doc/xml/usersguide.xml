<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE book PUBLIC "-//Torsten Bronger//DTD tbook 1.5//EN"
"/usr/local/share/xml/tbook/tbook.dtd">
<book>
  <frontmatter>
    <title><visual markup="tt">PyTables</visual> User's Guide</title>
    <author>Francesc Alted</author>
    <author>Scott Prater</author>

    <subtitle><visual markup="sf">Hierarchical datasets in
      Python</visual><newline/> Release 0.9(beta) </subtitle>

    <date>2004, August, 12th</date>
    <year>2002, 2003, 2004</year>
<!--     <graphics kind="bitmap" file="logo4-ombra"/> -->
    <graphics kind="bitmap" file="logo3-ombra"/>
<!--     <city>Castelló de la Plana, Spain</city> -->
    <typeset>Francesc Alted and Scott Prater</typeset>

    <legalnotice>

<!--	   Copyright (c) 2002, 2003, 2004 Francesc Alted -->

      <p><visual markup="bf">Copyright Notice and Statement for
	  <verb>PyTables</verb> Software Library and
	  Utilities</visual> <newline vspace="0.25cm"/>
      </p>

      <p>Redistribution and use in source and binary forms, with or
	without modification, are permitted provided that the
	following conditions are met:

	<newline vspace="0.1cm"/>
      </p>

      <p>1. Redistributions of source code must retain the above copyright
	notice, this list of conditions and the following disclaimer.
      </p>
      <p>2. Redistributions in binary form must reproduce the above
	copyright notice, this list of conditions and the following
	disclaimer in the documentation and/or other materials
	provided with the distribution.

	<newline vspace="0.25cm"/>
      </p>

      <p>THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY
	EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
	THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
	PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE
	AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
	SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
	NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
	LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
	HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
	CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
	OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
	EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

	<newline vspace="1cm"/>
      </p>

<!-- NCSA license -->

      <p><visual markup="bf">Copyright Notice and Statement for NCSA
	  Hierarchical Data Format (HDF) Software Library and
	  Utilities</visual>
	<newline vspace="0.1cm"/>
      </p>


      <p>NCSA HDF5 (Hierarchical Data Format 5) Software Library and
	Utilities Copyright 1998, 1999, 2000, 2001, 2002, 2003, 2004 by
	the Board of Trustees of the University of Illinois.  All rights
	reserved.  <newline vspace="0.25cm"/>
      </p>

      <p>See more information about the terms of this license at:
	<newline/> <url
	name="http://hdf.ncsa.uiuc.edu/HDF5/doc/Copyright.html"><verb>http://hdf.ncsa.uiuc.edu/HDF5/doc/Copyright.html</verb></url>
	<newline vspace="1cm"/>
      </p>

      <!-- numarray license -->

      <!-- This is not needed anymore, as PyTables does not include a
      private copy of the numarray.records module -->

<!--       <p><visual markup="bf">Copyright Notice and Statement for AURA -->
<!-- 	  <em>numarray</em> software library</visual> -->
<!-- 	<newline vspace="0.25cm"/> -->
<!--       </p> -->


<!--       <p>Copyright (C) 2001 Association of Universities for Research -->
<!-- 	in Astronomy (AURA) <newline vspace="0.25cm"/> -->
<!--       </p> -->


<!--       <p> -->
<!-- 	THIS SOFTWARE IS PROVIDED BY AURA ``AS IS'' AND ANY EXPRESS OR -->
<!-- 	IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED -->
<!-- 	WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR -->
<!-- 	PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL AURA BE LIABLE FOR -->
<!-- 	ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR -->
<!-- 	CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, -->
<!-- 	PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, -->
<!-- 	DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND -->
<!-- 	ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT -->
<!-- 	LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING -->
<!-- 	IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF -->
<!-- 	THE POSSIBILITY OF SUCH DAMAGE. -->
<!--       </p> -->

    </legalnotice>
  </frontmatter>

  <!--  This is only for the article
  <abstract>

  <p><visual markup="tt">PyTables</visual> is a Python package whose
    goal is to provide a powerful and easy-to-use interface for managing
    scientific data tables and Numerical Python objects organized in a
    hierarchical structure. Such a tables are defined as a collection
    of records whose values are stored in fixed-length fields. The 
    excellent HDF5 library (http://hdf.ncsa.uiuc.edu/HDF5) is the
    foundation for the underlying hierarchical data organization.
  </p>

  <p><visual markup="tt">PyTables</visual> is designed to be
    an easy-to-use as well as high-performance interface to
    HDF5.  The latest improvements introduced in Python 2.2 (such as 
    generators, iterators and metaclasses in new-brand classes) have been 
    used. The HDF5 library is accessed through the Pyrex creation 
    extension tool.
  </p>

  </abstract> -->

  <mainmatter>

<!--    <chapter kind='preface'> -->
<!--       <heading></heading> -->

    <chapter>
      <heading>Introduction</heading>

      <!-- SGP:  I translated this aphorism, but not any of the
      others.  I'd translate all the aphorisms, as it's a little
      pendantic to assume your readers can read French, Spanish,
      Valencian, Catalan, Portuguese, etc. -->

      <aphorism>La sabiduría no vale la pena si no es posible servirse
	de ella para inventar una nueva manera de preparar los
	garbanzos.<newline/>(Wisdom isn't worth anything if you can't
	use it to come up with a new way to cook garbanzos).
	<caption>A wise Catalan<newline/>in "Cien años de
	soledad"<newline/> Gabriel García Márquez</caption>
      </aphorism>

      <p>The goal of <verb>PyTables</verb> is to enable the end user
	to manipulate easily scientific data <visual
	markup="bf">tables</visual> and <visual
	markup="bf">array</visual> objects in a hierarchical
	structure. The foundation of the underlying hierarchical data
	organization is the excellent <verb>HDF5</verb> library (see
	<cite refid="HDFWhatIs"></cite>).<!-- Right now,
	<verb>PyTables</verb> --> <!-- provides limited support for
	importing generic HDF5 files --> <!-- (i.e., those which were
	created with other tools than --> <!-- <verb>PyTables</verb>),
	but I hope to add the more interesting --> <!-- tools as time
	goes on. Still, I think <verb>PyTables</verb> can --> <!--
	read a wide range of such files. -->
      </p>
      <p>
	It should be noted that this package is not intended to
	serve as a complete wrapper for the entire HDF5 API, but only to
	provide a flexible, <em>very Pythonic</em> tool to deal with
	(arbitrarily) large amounts of data (typically bigger than
	available memory) in tables and arrays organized in a
	hierarchical and persistent disk storage structure.
      </p>

      <p>A table is defined as a collection of records whose values
	are stored in <em>fixed-length</em> fields. All records have
	the same structure and all values in each field have the same
	<em>data type</em>. The terms <em>fixed-length</em> and strict
	<em>data types</em> may seem to be a strange requirement for
	an interpreted language like Python, but they serve a useful
	function if the goal is to save very large quantities of data
	(such as is generated by many Internet services applications
	or scientific applications, for example) in an efficient
	manner that reduces demand on CPU time and I/O.
      </p>

      <p>In order to emulate in Python records mapped to HDF5 C
	structs <verb>PyTables</verb> implements a special
	<em>metaclass</em> object so as to easily define all its
	fields and other properties.  <verb>PyTables</verb> also
	provides a powerful interface to mine data in tables. Records
	in tables are also known in the <verb>HDF5</verb> naming
	scheme as <em>compound</em> data types.
      </p>

      <p>For example, you can define arbitrary tables in Python
	simply by declaring a class with name field and types
	information, such as in the following example:
      </p>

<verbatim>
class Particle(IsDescription):
    name      = StringCol(16)   # 16-character String
    idnumber  = Int64Col()      # Signed 64-bit integer
    ADCcount  = UInt16Col()     # Unsigned short integer
    TDCcount  = UInt8Col()      # unsigned byte
    grid_i    = Int32Col()      # integer
    grid_j    = IntCol()        # integer (equivalent to Int32Col)
    pressure  = Float32Col(shape=(2,3)) # 2-D float array (single-precision)
    energy    = FloatCol(shape=(2,3,4)) # 3-D float array (double-precision) 
</verbatim>

      <p>You then pass this class to the table constructor,
	fill its rows with your values, and save (arbitrarily large)
	collections of them to a file for persistent storage. After
	that, the data can be retrieved and post-processed quite
	easily with <visual markup="tt">PyTables</visual> or even with
	another <verb>HDF5</verb> application (in C, Fortran, Java or
	whatever language that provides a library to interface with HDF5).
      </p>

      <!-- FA addition -->
      
      <p>Other important entities in <visual
        markup="tt">PyTables</visual> are the <em>array</em> objects
        that are analogous to tables with the difference that all of
        their components are homogeneous.  They come in different
        flavors, like <em>generic</em> (they provide a quick and fast
        way to deal with for numerical arrays), <em>enlargeable</em>
        (arrays can be extended in any single dimension) and
        <em>variable length</em> (each row in the array can have a
        different number of elements).
      </p>

      <!-- FA end addition -->

      <p>The next section describes the most interesting capabilities of
	<verb>PyTables</verb>.
      </p>

      <section>
	<heading>Main Features</heading>
	<p>
	  <verb>PyTables</verb> takes advantage of the powerful object
	  orientation and introspection capabilities offered by Python
	  to provide these features:
	</p>

	<itemize>
	  <item><em>Support for table entities:</em> Allows the user
	    to work with a large number of records, i.e. more
	    than will fit into memory.
	  </item>
	  <item><em>Appendable tables:</em> Supports adding records
	    to already created tables. This can be done even between
	    different Python sessions without copying the dataset or 
	    redefining its structure.
	  </item>
	  <item><em>Multidimensional table cells:</em> You can declare
	    a column to consist of general array cells as well as
	    scalars, which is the only dimensionality allowed the
	    majority of relational databases.
	  </item>
	  <item><em>Support for numerical arrays:</em>
	    <verb>Numeric</verb> (see <cite refid="Numeric"></cite>)
	    and <verb>numarray</verb> (see <cite
	    refid="Numarray"></cite>) arrays can be used as a useful
	    complement of tables to store homogeneous table slices
	    (such as selections of table columns).
	  </item>
     
          <!-- FA addition -->

          <item><em>Enlargeable arrays:</em> You can add new elements
            to existing arrays on disk in any dimension you want (but
            only one). Besides, you can access to only a slice of your
            datasets by using the powerful extended slicing mechanism,
            without need to load all your complete dataset in-memory.
          </item>
          <item><em>Variable length arrays:</em> The number of
            elements in these arrays can be variable from row to
            row. This provides a lot of flexibility when dealing with
            complex data.
          </item>

          <!-- end FA addition -->

	  <item><em>Supports a hierarchical data model:</em> Allows
	    the user to clearly structure all the data. 
	    <verb>PyTables</verb> builds up an <em>object
	    tree</em> in memory that replicates the underlying file
	    data structure. Access to the file objects is achieved by
	    walking through and manipulating this object tree.
	  </item>
	  <item><em>Support of files bigger than 2 GB:</em>
            <verb>PyTables</verb> automatically inherits
	    this capability from the underlying HDF5 library (assuming 
	    your platform supports the C long long integer, or, on 
	    Windows, __int64).
	  </item>
	  <item><em>Ability to read/modify generic HDF5 files:</em>
	    <verb>PyTables</verb> can access a wide range of objects
	    in generic HDF5 files, like compound type datasets (that
	    can be mapped to <verb>Table</verb> objects), homogeneous
	    datasets (that can be mapped to <verb>Array</verb>
	    objects) or variable length record datasets (that can be
	    mapped to <verb>VLArray</verb> objects).  Besides, if a
	    dataset is not supported, it will be mapped into a special
	    <verb>UnImplemented</verb> class (see <ref
	    refid="UnImplementedClassDescr"></ref>), that will let the
	    user see that the data is there, although it would be
	    unreachable (still, you will be able to access the
	    attributes and some metadata in the dataset).  With that,
	    <verb>PyTables</verb> probably can access and
	    <em>modify</em> most of the HDF5 files out there.
	  </item>
	  <item><em>Data compression:</em> Supports data
	    compression (using the <visual markup="tt">
	    <visual markup="bf">Zlib</visual></visual>,
            <visual markup="tt"><visual markup="bf">LZO</visual></visual> 
            and <visual markup="tt"><visual markup="bf">UCL</visual></visual>
	    compression libraries) out of the box. This is important 
	    when you have repetitive data patterns and don't want to
	    spend time searching for an optimized way to store them 
	    (saving you time spent analyzing your data organization).
	  </item>
	  <item><em>High performance I/O:</em> On modern systems
	    storing large amounts of data, tables and array objects can be
	    read and written at a speed only limited by the
	    performance of the underlying I/O subsystem. Moreover, if
	    your data is compressible, even that limit is surmountable!
	  </item>
	  <item><em>Architecture-independent:</em> <visual
	    markup="tt">PyTables</visual> has been carefully coded (as
	    has HDF5 itself) with little-endian/big-endian byte orderings
	    issues in mind.  In principle you can write a file on
	    a big-endian machine (like a Sparc or MIPS) and read it on
	    other little-endian machine (like an Intel or Alpha) without
	    problems. In addition, it has been tested successfully
	    with 64 bit platforms (Intel-64, MIPS, UltraSparc).
	  </item>

	</itemize>

      </section>

      <section id="ObjectTreeSection">
	<heading>The Object Tree</heading>

	<p>The hierarchical model of the underlying HDF5 library
	  allows <verb>PyTables</verb> to manage tables and arrays in
	  a tree-like structure. In order to achieve this, an
	  <em>object tree</em> entity is <em>dynamically</em> created
	  imitating the HDF5 structure on disk.  The HDF5 objects are
	  read by walking through this object tree.  You can get a
	  good picture of what kind of data is kept in the object by
	  examining the <em>metadata</em> nodes.
	</p>

	<p>The different nodes in the object tree are instances of
	  <verb>PyTables</verb> classes. There are several types of
	  classes, but the most important ones are the
	  <verb>Group</verb> and the <verb>Leaf</verb>
	  classes. <verb>Group</verb> instances (referred to as
	  <em>groups</em> from now on) are a grouping structure
	  containing instances of zero or more groups or leaves,
	  together with supplementary metadata.  <verb>Leaf</verb>
	  instances (referred to as <em>leaves</em>) are containers
	  for actual data and cannot contain further groups or
	  leaves. The <verb>Table</verb>, <verb>Array</verb>,
	  <verb>EArray</verb>, <verb>VLArray</verb> and
	  <verb>UnImplemented</verb> classes are descendents of
	  <verb>Leaf</verb>, and inherit all its properties.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files on a Unix filesystem. As 
	  is the case with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. In <verb>PyTables</verb> this full
	  path can be specified either as string (such as
	  <verb>'/subgroup2/table3'</verb>) or as a complete object
	  path written in a format known as the <em>natural name</em>
	  schema (such as <verb>file.root.subgroup2.table3</verb>).
	</p>

	<p>Support for <em>natural naming</em> is a key aspect of
	  <verb>PyTables</verb>.  It means that the names of instance
	  variables of the node objects are the same as the names of
	  the element's children<footnote>I got this simple but
	  powerful idea from the excellent <visual
	  markup="tt">Objectify</visual> module by David Mertz (see
	  <cite refid="Objectify"></cite>)</footnote>. This is very
          <em>Pythonic</em> and intuitive in many cases. Check the 
	  tutorial <ref refid="readingAndSelectingUsage">section</ref>
	  for usage examples.
	</p>
	<p>You should also be aware that not all the data present in a 
	  file is loaded into the object tree.  Only the <em>metadata</em>
	  (i.e. special data that describes the structure of the
	  actual data) is loaded. The actual data is not read until you 
	  request it (by calling a method on a particular node). Using
	  the object tree (the metadata) you can retrieve information
	  about the objects on disk such as table names, titles, name
	  columns, data types in columns, numbers of rows, or, in
	  the case of arrays, the shapes, typecodes, etc. of the array. 
	  You can also search through the tree for specific kinds of data
	  then read it and process it. In a certain sense, you can think of
	  <verb>PyTables</verb> as a tool that applies the same
	  introspection capabilities of Python objects to large
	  amounts of data in persistent storage.
	</p>
	<p>To better understand the dynamic nature of this object tree
	  entity, let's start with a sample <verb>PyTables</verb>
	  script (you can find it in <verb>examples/objecttree.py</verb>) 
	  to create a HDF5 file:
	</p>

	<!-- IVB: Thus the sample values of the string array
	do not look like keywords. -->
	<verbatim>
from tables import *

class Particle(IsDescription):
    identity = StringCol(length=22, dflt=" ", pos = 0)  # character String
    idnumber = Int16Col(1, pos = 1)  # short integer
    speed    = Float32Col(1, pos = 2)  # single-precision

# Open a file in "w"rite mode
fileh = openFile("objecttree.h5", mode = "w")
# Get the HDF5 root group
root = fileh.root

# Create the groups:
group1 = fileh.createGroup(root, "group1")
group2 = fileh.createGroup(root, "group2")

# Now, create an array in the root group
array1 = fileh.createArray(root, "array1", 
                           ["this is", "a string array"], "String array")
# Create 2 new tables in group1 and group2
table1 = fileh.createTable(group1, "table1", Particle)
table2 = fileh.createTable("/group2", "table2", Particle)
# Create one more Array in group1
array2 = fileh.createArray("/group1", "array2", [1,2,3,4])

# Now, fill the tables:
for table in (table1, table2):
    # Get the record object associated with the table:
    row = table.row
    # Fill the table with 10 records
    for i in xrange(10):
        # First, assign the values to the Particle record
        row['identity']  = 'This is particle: %2d' % (i)
        row['idnumber'] = i
        row['speed']  = i * 2.
        # This injects the Record values
        row.append()

    # Flush the table buffers
    table.flush()

# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
	</verbatim>

	<p>This small program creates a simple HDF5 file called
	  <verb>objecttree.h5</verb> with the structure that appears
	  in <ref refid="objecttree-h5">figure</ref>. When the file is
	  created, the metadata in the object tree is updated in
	  memory while the actual data is saved to disk. When you
	  close the file the object tree is no longer
	  available. However, when you reopen this file the object
	  tree will be reconstructed in memory from the metadata on
	  disk, allowing you to work with it in exactly the same way
	  as when you originally created it.
	</p>

	<figure id="objecttree-h5">
	  <graphics file="objecttree-h5" scale="0.5" kind="bitmap">
	  </graphics>
	  <caption>An HDF5 example with 2 subgroups, 2 tables and 1
	    array.</caption>
	</figure>

	<p>In <ref refid="objecttree">figure</ref> you can see an
	  example of the object tree created when the above
	  <verb>objecttree.h5</verb> file is read (in fact, such an object is
	  always created when reading any supported generic HDF5
	  file).  It's worthwhile to take your time to understand
	  it<footnote>Bear in mind, however, that this
	  diagram is <visual markup="bf">not</visual> a standard UML
	  class diagram; it is rather meant to show the connections
	  between the <verb>PyTables</verb> objects and some of its
	  most important attributes and methods.</footnote>. It will
	  help you to avoid programming mistakes.
	</p>

	<figure id="objecttree">
	  <graphics file="objecttree" scale="0.4" kind="vector">
	  
	  <!-- If you want to convert the eps to jpeg use the command:
pstoimg -scale 0.75 -aaliastext -type png -crop a -interlace objecttree.eps
	  and then, convert the png file again to jpg with:
	  convert objecttree.png objecttree.jpg
	  Use this tag to include the jpeg file:
	  <graphics file="objecttree" scale="0.5" kind="bitmap">
	  -->
	  </graphics>
	  <caption>A <visual markup="tt">PyTables</visual> object tree
	      example.
	  </caption>
	</figure>

      </section>

    </chapter>

    <chapter>
      <heading>Installation</heading>

<!--       <aphorism>El meu país es tan petit <newline/> que quan el sol -->
<!-- 	se'n va a dormir <newline/> no està mai prou segur d'haver-lo -->
<!-- 	vist <caption>Lluís Llach in the song "Petit País"</caption> -->
<!--       </aphorism> -->

<!--       <aphorism>T'adones, company,<newline/> -->
<!-- 	no volen arguments,<newline/> -->
<!-- 	usen la força,<newline/> -->
<!-- 	t'adones, amic.<newline/> -->
<!-- 	T'adones, company,<newline/> -->
<!-- 	que hem de sortir al carrer<newline/> -->
<!-- 	junts, molts, com més millor,<newline/> -->
<!-- 	si no volem perdre-ho tot,<newline/> -->
<!-- 	t'adones, amic.<newline/> -->
<!-- 	<caption>Raimon in the song "T'adones, amic"</caption> -->
<!--       </aphorism> -->


<!--       <aphorism>Make things as simple as possible, but not any -->
<!-- 	simpler.  <caption>Albert Einstein</caption> </aphorism> -->

      <p>The Python <verb>Distutils</verb> are used to build and
	install <verb>PyTables</verb>, so it is fairly simple to get
	the application up and running. If you want to install the
	package from sources go to the next section. But if you are
	running Windows and want to install precompiled binaries jump
	to <ref refid="binaryInstallationDescr">section</ref>). In
	addition, packages are starting to appear in different Linux
	distributions, for instance <url
	name="http://www.rocklinux.org/"><verb>RockLinux</verb></url>,
	<url name="http://www.debian.org/"><verb>Debian</verb></url>,
	<url
	name="http://monkeyrpms.net/fedora/linux/monkeyrpms/1/i386/html/pytables.html"><verb>Fedora</verb></url>
	or <url
	name="http://www.gentoo.org/"><verb>Gentoo</verb></url>.
	There also packages for other Unices like <url
	name="http://www.freshports.org/"><verb>FreeBSD</verb></url>
	or <url
	name="http://www.opendarwin.org/"><verb>MacOSX</verb></url>
      </p>

      <section id="sourceInstallationDescr">
	<heading>Installation from source</heading>

	<p>
	  These instructions are for both Unix/Linux and Windows
	  systems. If you are using Windows, it is assumed that you
	  have a recent version of <verb>MS Visual C++</verb> (>=
	  6.0) compiler installed. A <verb>GCC</verb> compiler is assumed for
	  Unix, but other compilers should work as well.
	</p>

	<p>Extensions in <visual markup="tt">PyTables</visual> have
	  been developed in Pyrex (see <cite refid="Pyrex"></cite>)
	  and C language. You can rebuild everything from scratch if
	  you have Pyrex installed, but this is not necessary, as the
	  Pyrex compiled source is included in the distribution.
	</p>

	<p>To compile <verb>PyTables</verb> you will need a recent
	  version of the <verb>HDF5</verb> (C flavor) library and the
	  <verb>numarray</verb> (see <cite refid="Numarray"></cite>)
	  package. Although you won't need <verb>Numerical Python</verb>
	  (see <cite refid="Numeric"></cite>) in order to compile
	  PyTables, it is supported; you only need a reasonably
	  recent version of it (>= 21.x) if you plan on using its
	  methods in your applications. PyTables has been successfully
	  tested with Numeric 21.3, 22.0 and 23.0. If you already have
	  <verb>Numeric</verb> installed, the test driver module will
	  detect it and will run the tests for <verb>Numeric</verb>
	  automatically.
	</p>

	<!-- SGP:  Put heading "Prerequisites" here . Done! -->
        <subsection id="PrerequisitesSourceDescr">
	  <heading>Prerequisites</heading>

	  <p>First, make sure that you have <verb>HDF5 1.6.2</verb>
	    and <verb>numarray 1.0</verb> or higher installed (I'm
	    using <verb>HDF5 1.6.2</verb> and <verb>numarray
	    1.0</verb> currently). If you don't, you can find them at
	    <url
	    name="http://hdf.ncsa.uiuc.edu/HDF5"><verb>http://hdf.ncsa.uiuc.edu/HDF5</verb></url>
	    and <url
	    name="http://www.pfdubois.com/numpy"><verb>http://www.pfdubois.com/numpy</verb></url>.
	  </p>
	  <p>
	    Compile and install these packages (but see <ref
	      refid="prerequisitesBinInst">section</ref> for
	    instructions on how to install precompiled binaries if
	    you are not willing to compile the prerequisites on
	    Windows systems).
	  </p>
	  <p>For compression (and possibly improved performance), you
	    will need to install the <verb>Zlib</verb> (see <cite
	      refid="zlibRef"></cite>), which is also required by
	    <verb>HDF5</verb> as well. You may also optionally install
	    the excellent <verb>LZO</verb> and <verb>UCL</verb>
	    compression libraries (see <cite refid="lzouclRef"></cite>
	    and section <ref refid="compressionIssues"></ref>).
	  </p>
	  <description>
	    <term>Unix</term>
	    <item>
	      <p><verb>setup.py</verb> will detect <verb>HDF5</verb>,
		<verb>LZO</verb> or <verb>UCL</verb> libraries and
		include files under <verb>/usr</verb> or
		<verb>/usr/local</verb>; this will cover most manual
		installations as well as installations from packages.
		If <verb>setup.py</verb> can't find
		<verb>libhdf5</verb> or <verb>libz</verb> (or
		<verb>liblzo</verb> or <verb>libucl</verb> that you
		may wish to use) or if you have several versions of a
		library installed and want to use a particular one,
		then you can set the path to the resource in the
		environment, setting the values of the
		<verb>HDF5_DIR</verb>, <verb>LZO_DIR</verb> or
		<verb>UCL_DIR</verb> environment variables to the path
		to the particular resource.  You may also specify the
		locations of the resource root directories on the
		<verb>setup.py</verb> command line. For example:
	      </p>

	      <verbatim>
		--hdf5=/stuff/hdf5-1.6.2
		--lzo=/stuff/lzo-1.08
		--ucl=/stuff/ucl-1.02
	      </verbatim>

	      <p>If your <verb>HDF5</verb> library was built as
		a shared library not in the runtime load path, then 
		you can specify the additional linker flags needed to 
		find the shared library on the command line as well. 
		For example:
		<verbatim>
		  --lflags="-Xlinker -rpath -Xlinker /stuff/hdf5-1.6.2/lib"
		</verbatim>
		or perhaps just
		<verbatim>
		  --rpath="/stuff/hdf5-1.6.2/lib"
		</verbatim> 
		
		Check your compiler and linker documentation as well as
		the Python <verb>Distutils</verb> documentation for the
		correct syntax.
	      </p>

	      <p>It is also possible to link with specific libraries by
		setting the <verb>LIBS</verb> environment variable:
		<verbatim>
		  LIBS="hdf5-1.6.5"
		  LIBS="hdf5-1.6.5 nsl"
		</verbatim>
	      </p>
	    </item>

	    <term>Windows</term>
	    <item>
	      <p>Once you have installed the prerequisites,
		<verb>setup.py</verb> needs to know where the
		necessary library <em>stub</em> (<verb>.lib</verb>)
		and <em>header</em> (<verb>.h</verb>) files are
		installed.  Set the following environment variables:
	      </p>

	      <description>
		<term>HDF5_DIR</term><item>Points to the root HDF5 
		  directory (where the include/ and dll/ directories
		  can be found). <em>Mandatory</em>.</item>
		
<!-- 		<term>ZLIB_DIR</term> <item>Points to the root ZLIB -->
<!-- 		  directory (where the include/ and lib/ directories -->
<!-- 		  can be found). <em>Mandatory</em>.</item> -->

		<term>LZO_DIR</term> <item>Points to the root LZO
		  directory (where the include/ and lib/ directories
		  can be found). <em>Optional</em>.</item>

		<term>UCL_DIR</term> <item>Points to the root UCL
		  directory (where the include/ and lib/ directories
		  can be found). <em>Optional</em>.</item>

	      </description> 

	      <p>For example:
		<verbatim>
		  set HDF5_DIR=c:\stuff\5-162-win2k\c\release
		  set UCL_DIR=c:\stuff\ucl-1-02
		  set LZO_DIR=c:\stuff\lzo-1-08
		</verbatim>

		Or, you can pass this information to
		<verb>setup.py</verb> by setting the appropriate
		arguments on the command line. For example:
	      </p>

	      <verbatim>
		--hdf5=c:\stuff\5-162-win2k\c\release
		--lzo=c:\stuff\lzo-1-08
		--ucl=c:\stuff\ucl-1-02
	      </verbatim>	
	    </item>

	  </description>

	</subsection>

        <subsection id="PyTablesSourceInstallationDescr">
	  <heading><visual markup="tt">PyTables</visual> package
	    installation
	  </heading>

          <p>Once you have installed the HDF5 library and numarray
            packages, you can proceed with the <verb>PyTables</verb>
            package itself:
          </p>

	  <enumerate>
	    <item>
	      <p>Run this command from the main <verb>PyTables</verb>
		distribution directory, including any extra command line
		arguments as discussed above:
		<verbatim>
		  python setup.py build_ext --inplace
		</verbatim>
		Depending on the compiler flags used when compiling your
		Python executable, there may appear many warnings. Don't
		worry, almost all of them are caused by variables declared
		but never used. That's normal in Pyrex extensions.
	      </p>
	    </item>
	    <item>
	      <p>To run the test suite, change into the test directory
		and execute this command:
	      </p>
	      <description>
		<term>Unix</term> <item>In the shell <verb>sh</verb> and
		  its variants:
		  <verbatim>
		    PYTHONPATH=..  
		    export PYTHONPATH
		    python test_all.py
		  </verbatim>
		</item>
		<term>Windows</term>
		<item>Open a DOS terminal and type:
		  <verbatim>
		    set PYTHONPATH=..  
		    python test_all.py
		  </verbatim>
		</item>
	      </description>

	      <p>If you would like to see verbose output from the tests
		simply add the flag <verb>-v</verb> and/or the word
		<verb>verbose</verb> to the command line. You can also
		run only the tests in a particular test module. For
		example, to execute just the <verb>types</verb> test:
		<verbatim>
		  python test_types.py -v
		</verbatim>
		If a test fails, please enable verbose output (the
		<verb>-v</verb> flag <visual markup="bf">and</visual>
		<verb>verbose</verb> option), run the failing test
		module again, and, very important, get your
		<verb>PyTables</verb> version information by running
		the command:
		<verbatim>
		  python test_all.py --show-versions-only
		</verbatim>
		and send back the output to developers so that we may
		continue improving <verb>PyTables</verb>.
	      </p>

	      <p> If you run into problems because Python can't load the
		HDF5 library or other shared libraries:
	      </p>
	      <description>
		<term>Unix</term>
		<item>
		  Try setting the LD_LIBRARY_PATH environment variable to
		  point to the directory where the missing libraries can
		  be found.
		</item>
		<term>Windows</term> <item>Put the DLL libraries
		  (<verb>hdf5dll.dll</verb> and, optionally,
		  <verb>lzo.dll</verb> and <verb>ucl.dll</verb>) in a
		  directory listed in your <verb>PATH</verb>
		  environment variable.  The <verb>setup.py</verb>
		  installation program will print out a warning to
		  that effect if the libraries can't be found.
		</item>
	      </description>
	    </item>
	    <item>
		  <!-- SGP: What if they're not root, or if they're on
		  a Windows machine?  Can you set the install prefix
		  on the command line?  Where does PyTables install
		  itself by default?  Amplify this part.  Done! -->

	      <p>To install the entire <visual
		  markup="tt">PyTables</visual> Python package, change
		back to the root distribution directory and run the
		following command (make sure you have sufficient
		permissions to write to the directories where the
		<verb>PyTables</verb> files will be installed):
		
		<verbatim>
		  python setup.py install
		</verbatim>

		Of course, you will need super-user privileges if you
		want to install <verb>PyTables</verb> on a
		system-protected area. You can select, though, a
		different place to install the package using the
		<verb>--prefix</verb> flag:

		<verbatim>
		  python setup.py install --prefix="/home/myuser/mystuff"
		</verbatim>

		Have in mind, however, that if you use the
		<verb>--prefix</verb> flag to install in a non-standard
		place, you should properly setup your
		<verb>PYTHONPATH</verb> environment variable, so that
		the Python interpreter would be able to find your new
		<verb>PyTables</verb> installation.
	      </p>

	      <p>You have more installation options available in
		the distutils package. Issue a:
		<verbatim>
		  python setup.py install --help
		</verbatim>
		for more information on that subject.
	      </p>

	    </item>
	  </enumerate>

	</subsection>

	<!-- IVB: To avoid confusing the Win installation section
	with the next chapter. -->
	<p>That's it! Now you can skip to the next chapter to learn how to use
	  <verb>PyTables</verb>. <!-- <newline vspace="4.0cm"/> -->
	</p>

      </section>

      <section id="binaryInstallationDescr">
	<heading>Binary installation (Windows)</heading>

	<p>This section is intended for installing precompiled
	  binaries on Windows platforms. You may also find it useful
	  for instructions on how to install <em>binary
	  prerequisites</em> even if you want to compile
	  <verb>PyTables</verb> itself on Windows.
	</p>

	<subsection id="prerequisitesBinInst">
	  <heading>Windows prerequisites</heading>

	  <p>First, make sure that you have HDF5 1.6.2 or higher and
	    numarray 1.0 or higher installed (I'm using HDF5 1.6.2 and
	    numarray 1.0 currently). If don't, you can find them at
	    <url
	    name="http://hdf.ncsa.uiuc.edu/HDF5"><verb>http://hdf.ncsa.uiuc.edu/HDF5</verb></url>
	    and <url
	    name="http://sourceforge.net/projects/numpy/"><verb>http://sourceforge.net/projects/numpy/</verb></url>. Download
	    the binary packages (or sources, if you want to compile
	    everything yourself) and install them.
          </p>
          <p>For the HDF5 it should be enough to manually copy the
	    <verb>hdf5dll.dll</verb>, <verb>zlib1.dll</verb> <visual
	    markup="bf">and</visual> <verb>szipdll.dll</verb> files to
	    a directory in your <verb>PATH</verb> environment variable
	    (for example <verb>C:\WINDOWS\SYSTEM</verb>).
	  </p>

	  <p><visual markup="bf">Caveat:</visual> When downloading the
	    binary distribution for HDF5 libraries, select one compiled with
	    MSVC 6.0, such as the package
	    <verb>5-162-win2k.zip</verb>, regardless of whether you are using
	    Win2k or WinXP (it should work fine on both). The file
	    <verb>5-162-winxp-net.zip</verb> was compiled with the
	    MSVC 7.0 (aka "<verb>.NET</verb>") and <visual
	    markup="bf">does not</visual> work well with the PyTables
	    binary (which has been generated with MSVC 6.0). You have
	    been warned!
	  </p>

<!-- 	  <p>Normally, the NCSA team generate binaries that links -->
<!-- 	    against the Zlib binary libraries that can be found at: -->
<!-- 	    <url -->
<!-- 	    name="http://www.gzip.org/zlib/">http://www.gzip.org/zlib/</url>. -->
<!-- 	    Please, use this build if you don't want to run into -->
<!-- 	    problems. -->
<!-- 	  </p> -->

	  <p>To enable compression with optional LZO and UCL libraries
	    (see the <ref refid="compressionIssues">section</ref> for
	    hints about how they may be used to improve performance),
	    fetch and install the <verb>LZO</verb> and
	    <verb>UCL</verb> binaries from:<newline/> <url
	    name="http://gnuwin32.sourceforge.net/">
	    <verb>http://gnuwin32.sourceforge.net/</verb></url>. Normally,
	    you will only need to fetch and install the<newline/>
	    <verb>&lt;package>-&lt;version>-bin.zip</verb> file and
	    copy the <verb>lzo.dll</verb> or <verb>ucl.dll</verb>
	    files in a directory in the <verb>PATH</verb> environment
	    variable, so that they can be found by the <visual
	    markup="tt">PyTables</visual> extensions.
          </p>
          <p><visual markup="bf">Note:</visual> If you are reading
	    this because you have been redirected from the <ref
	    refid="sourceInstallationDescr">section</ref>
	    (<em>Installation from source</em>), some of the headers
	    you will need are in the
	    <verb>&lt;package>-&lt;version>-lib.zip</verb> file.
	  </p>

	  <!-- SGP: I assume that the zlib prerequisite is discussed
	  in the HDF5 installation manual.  In any event, you don't
	  need to mention it here; simply say that a working HDF5
	  library installation is required.  In fact, this whole
	  section is superfluous; you've already covered it in
	  "Prerequisites".  I'd cut straight to the chase and talk
	  about installing the PyTables precompiled Windows binaries.  Done! -->

        </subsection>

        <subsection id="PyTablesBinInstallDescr">
	  <heading><visual markup="tt">PyTables</visual> package
	    installation
	  </heading>

	  <p>Download the
	    <verb>tables-&lt;version>.win32-py&lt;version>.exe</verb>
            <newline/>
	    (<verb>tables-&lt;version>-LU.win32-py&lt;version>.exe</verb>
	    if you want support for LZO and UCL libraries) file and
	    execute it.
	  </p>

	  <p>You can (<em>you should</em>) test your installation by
	    unpacking the source tar-ball, changing to the
	    <verb>test/</verb> subdirectory and executing the
	    <verb>test_all.py</verb> script. If all the tests pass
	    (possibly with a few warnings, related to the potential
	    unavailability of LZO and UCL libs) you already have a
	    working, well-tested copy of <verb>PyTables</verb>
	    installed! If any test fails, please try to locate which
	    test module is failing and execute:
          
	    <verbatim>
	      python test_&lt;module>.py -v verbose
	    </verbatim>
	    
	    and also:

	    <verbatim>
	      python test_all.py --show-versions-only
	    </verbatim>
	    
	    and mail the output to the developers so that the problem
	    can be fixed in future releases.
	  </p>

	</subsection>

	<newline vspace="0.25cm"/>

	<p>That's it! Now, proceed to the next chapter to see how to
	  use <verb>PyTables</verb>.
	</p>

      </section>


    </chapter>

    <chapter id="usage">
      <heading>Tutorials</heading>

<!--       <aphorism>Tout le malheur des hommes vient d'une seule chose, -->
<!-- 	qui est de ne savoir pas demeurer en repos, dans une chambre. -->
<!-- 	<caption>Blaise Pascal</caption> -->
<!--       </aphorism> -->

      <p>This chapter consists of a series of simple yet comprehensive
	tutorials that will enable you to understand
	<verb>PyTables</verb>' main features. If you would like more
	information about some particular instance variable, global
	function, or method, look at the doc strings or go to the
	library reference in <ref
	refid="libraryReference">chapter</ref>. If you are reading
	this in PDF or HTML formats, follow the corresponding
	hyperlink near each newly introduced entity.
      </p>

      <p>Please note that throughout this document the terms
	<em>column</em> and <em>field</em> will be used
	interchangeably, as will the terms <em>row</em> and
	<em>record</em>.
      </p>

      <section>
	<heading>Getting started</heading>

	<p>In this section, we will see how to define our own records
	  in Python and save collections of them (i.e. a <visual
	  markup="bf">table</visual>) into a file. Then we will select
	  some of the data in the table using Python cuts and create
	  <verb>numarray</verb> arrays to store this selection as
	  separate objects in a tree.
	</p>
	<p>
	  In <em>examples/tutorial1-1.py</em> you will find the
	  working version of all the code in this
	  section. Nonetheless, this tutorial series has been written
	  to allow you reproduce it in a Python interactive
	  console. I encourage you to do parallel testing and inspect 
	  the created objects (variables, docs, children objects, 
	  etc.) during the course of the tutorial!
	</p>

	<subsection>
	  <heading>Importing <visual markup="tt">tables</visual>
	    objects</heading>
	  
          <p>Before starting you need to import the
	    public objects in the <verb>tables</verb> package. You
	    normally do that by executing:
	  </p>
	  <verbatim>
>>> import tables
	  </verbatim>
	  <p>This is the recommended way to import <verb>tables</verb>
	    if you don't want to pollute your namespace. However, 
	    <verb>PyTables</verb> has a very reduced set of first-level 
	    primitives, so you may consider using the alternative:
	  </p>
	  <verbatim>
>>> from tables import *
	  </verbatim>
	  <p>which will export in your caller application namespace the
	    following objects: <verb>openFile</verb>, <verb>isHDF5</verb>,
	    <verb>isPyTablesFile</verb> and
	    <verb>IsDescription</verb>. This is a rather reduced set
	    of objects, and for convenience, we will use this
	    technique to access them.
	  </p>
	  <p>If you are going to work with <verb>numarray</verb> or
	    <verb>Numeric</verb> arrays (and normally, you will) you
	    will also need to import objects from them.  So most <verb>PyTables</verb>
	    programs begin with:
	  </p>
	  <verbatim>
>>> import tables        # but in this tutorial we use "from tables import *"
>>> from numarray import *  # or "from Numeric import *"
	  </verbatim>
	</subsection>

	<subsection>
	  <heading>Declaring a Column Descriptor</heading>

	  <p>Now, imagine that we have a particle detector and we want
	    to create a table object in order to save data
	    retrieved from it. You need first to define the table, the
	    number of columns it has, what kind of object is contained
	    in each column, and so on.
	  </p>
	  <p>Our particle detector has a TDC (Time to Digital Converter)
	    counter with a dynamic range of 8 bits and an ADC
	    (Analogical to Digital Converter) with a range of 16
	    bits. For these values, we will define 2 fields in our
	    record object called <verb>TDCcount</verb> and
	    <verb>ADCcount</verb>. We also want to save the grid
	    position in which the particle has been detected, so we
	    will add two new fields called <verb>grid_i</verb> and
	    <verb>grid_j</verb>. Our instrumentation also can obtain
	    the pressure and energy of the particle. The resolution 
	    of the pressure-gauge allows us to use a simple-precision 
	    float to store <verb>pressure</verb> readings, while the 
	    <verb>energy</verb> value will need a double-precision
	    float. Finally, to track the particle we want to assign
	    it a name to identify the kind of the particle it is and a
	    unique numeric identifier. So we will add two more fields: 
	    <verb>name</verb> will be a string of up to 16 characters,
	    and <verb>idnumber</verb> will be an integer of 64 bits
	    (to allow us to store records for extremely large numbers
	    of particles).
	    <!-- SGP:  Whew.  You didn't exactly choose the most
	    intuitive example.  If you want this to be understandable
	    to people outside the physics communitiy, you may want to
	    come up with a different example (say, a database of dirty
	    pictures). -->
	  </p>
	  <p>Having determined our columns and their types, we can now 
	    declare a new <verb>Particle</verb> class that will
	    contain all this information:
	  </p>

	  <verbatim>
>>> class Particle(IsDescription):
...     name      = StringCol(16)   # 16-character String
...     idnumber  = Int64Col()      # Signed 64-bit integer
...     ADCcount  = UInt16Col()     # Unsigned short integer
...     TDCcount  = UInt8Col()      # unsigned byte
...     grid_i    = Int32Col()      # integer
...     grid_j    = IntCol()        # integer (equivalent to Int32Col)
...     pressure  = Float32Col()    # float  (single-precision)
...     energy    = FloatCol()      # double (double-precision)
...
>>>
	  </verbatim>
	  <p>This definition class is self-explanatory.  Basically,
	    you declare a class variable for each field you need.  As
	    its value you assign an instance of the appropriate
	    <verb>Col</verb> subclass, according to the kind of column
	    defined (the data type, the length, the shape, etc).  See
	    the <ref refid="ColClassDescr">section</ref> for a
	    complete description of these subclasses. See also <ref
	    refid="datatypesSupported">appendix</ref> for a list of
	    data types supported by the <verb>Col</verb> constructor.
	  </p>
	  <p>From now on, we can use <verb>Particle</verb> instances
	    as a descriptor for our detector data table. We will see
	    later on how to pass this object to construct the table.
	    But first, we must create a file where all the actual data
	    pushed into our table will be saved.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating a <visual markup="tt">PyTables</visual> file from scratch</heading>

	  <p>Use the first-level <verb>openFile</verb> (see <ref
	    refid="openFileDescr"></ref>) function to create a 
	    <verb>PyTables</verb> file:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial1.h5", mode = "w", title = "Test file")
	  </verbatim>
	  <p><verb>openFile</verb> (<ref
	    refid="openFileDescr">see</ref>) is one of the objects
	    imported by the "<verb>from tables import *</verb>"
	    statement. Here, we are saying that we want to create
	    a new file in the current working directory called 
	    "<verb>tutorial1.h5</verb>" in "<verb>w</verb>"rite mode 
	    and with an descriptive title string ("<verb>Test file</verb>"). 
	    This function attempts to open the file, and if successful, 
	    returns the <verb>File</verb> (<ref refid="FileClassDescr">see</ref>)
	    object instance <verb>h5file</verb>.  The root of the object tree is
	    specified in the instance's <verb>root</verb> attribute.
	  </p>
	</subsection>

	<subsection>
	  <heading>Creating a new group</heading>

	  <p>Now, to better organize our data, we will create a group
	    called <em>detector</em> that branches from the root node. We will
	    save our particle data table in this group.
	  </p>
	  <verbatim>
>>> group = h5file.createGroup("/", 'detector', 'Detector information')
	  </verbatim>

	  <p>Here, we have taken the <verb>File</verb> instance
	    <verb>h5file</verb> and invoked its
	    <verb>createGroup</verb> method (<ref
	    refid="createGroupDescr">see</ref>) to create a new group 
	    called <em>detector</em> branching
	    from "<em>/</em>" (another way to refer to the
	    <verb>h5file.root</verb> object we mentioned above). This
	    will create a new <verb>Group</verb> (see<ref
	    refid="GroupClassDescr"></ref>) object instance that will be
	    assigned to the variable <verb>group</verb>.
	  </p>

	</subsection>
	<subsection>
	  <heading>Creating a new table</heading>

	  <p>Let's now create a <verb>Table</verb> (see <ref
	    refid="TableClassDescr"></ref>) object as a branch off the 
	    newly-created group. We do that by calling the
	    <verb>createTable</verb> (see <ref
	    refid="createTableDescr"></ref>) method of the
	    <verb>h5file</verb> object:
	  </p>
	  <verbatim>
>>> table = h5file.createTable(group, 'readout', Particle, "Readout example")
	  </verbatim>

	  <p>We create the <verb>Table</verb> instance under <verb>group</verb>. 
	    We assign this table the node name "<em>readout</em>".
	    The <verb>Particle</verb> class declared before is the
	    <em>description</em> parameter (to define the columns of
	    the table) and finally we set "<em>Readout example</em>"
	    as the <verb>Table</verb> title. With all this information, 
	    a new <verb>Table</verb> instance is created and assigned to 
	    the variable <em>table</em>.
	  </p>

	  <p>If you are curious about how the object tree looks
	    right now, simply <verb>print</verb> the <verb>File</verb> 
	    instance variable <em>h5file</em>, and examine
	    the output:
	  </p>

	  <verbatim>
>>> print h5file
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:00:13 2003'
/ (Group) 'Test file'
/detector (Group) 'Detector information'
/detector/readout (Table(0,)) 'Readout example'

	  </verbatim>

	  <p>As you can see, a dump of the object tree is displayed.
	    It's easy to see the <verb>Group</verb> and
	    <verb>Table</verb> objects we have just created. If you
	    want more information, just type the variable containing the
	    <verb>File</verb> instance:
	  </p>

	  <verbatim>
>>> h5file
File(filename='tutorial1.h5', title='Test file', mode='w', trMap={}, rootUEP='/')
/ (Group) 'Test file'
/detector (Group) 'Detector information'
/detector/readout (Table(0,)) 'Readout example'
  description := {
    "ADCcount": Col('UInt16', shape=1, itemsize=2, dflt=0),
    "TDCcount": Col('UInt8', shape=1, itemsize= 1, dflt=0),
    "energy": Col('Float64', shape=1, itemsize=8, dflt=0.0),
    "grid_i": Col('Int32', shape=1, itemsize=4, dflt=0),
    "grid_j": Col('Int32', shape=1, itemsize=4, dflt=0),
    "idnumber": Col('Int64', shape=1, itemsize=8, dflt=0),
    "name": Col('CharType', shape=1, itemsize=16, dflt=None),
    "pressure": Col('Float32', shape=1, itemsize=4, dflt=0.0) }
  byteorder := little

	  </verbatim>

	  <p>More detailed information is displayed about each object 
	    in the tree. Note how <verb>Particle</verb>, our
	    table descriptor class, is printed as part of the
	    <em>readout</em> table description information. In
	    general, you can obtain much more information about the objects
	    and their children by just printing them. That introspection
	    capability is very useful, and I recommend that you use it
	    extensively.
	  </p>

	  <p>The time has come to fill this table with some
	    values. First we will get a pointer to the
	    <verb>Row</verb> (see <ref refid="RowClassDescr"></ref>)
	    instance of this <verb>table</verb> instance:
	  </p>
	  <verbatim>
>>> particle = table.row
	  </verbatim>

	  <p>The <verb>row</verb> attribute of <verb>table</verb>
	    points to the <verb>Row</verb> instance that will be used
	    to write data rows into the table. We write data simply by
	    assigning the <verb>Row</verb> instance the values for
	    each row as if it were a dictionary (although it is
	    actually an <em>extension class</em>), using the column
	    names as keys.
	  </p>

	  <p>Below is an example of how to write rows:
	  </p>

	  <verbatim>
>>> for i in xrange(10):
...     particle['name']  = 'Particle: %6d' % (i)
...     particle['TDCcount'] = i % 256
...     particle['ADCcount'] = (i * 256) % (1 &lt;&lt; 16)
...     particle['grid_i'] = i
...     particle['grid_j'] = 10 - i
...     particle['pressure'] = float(i*i)
...     particle['energy'] = float(particle['pressure'] ** 4)
...     particle['idnumber'] = i * (2 ** 34)
...     particle.append()
...
>>>
	  </verbatim>
	  
	  <p>This code should be easy to understand. The lines inside
	    the loop just assign values to the different columns in
	    the Row instance <verb>particle</verb> (<ref
	    refid="RowClassDescr">see</ref>). A call to its
	    <verb>append()</verb> method writes this
	    information to the <verb>table</verb> I/O buffer.
	  </p>

	  <p>After we have processed all our data, we should flush the
	    table's I/O buffer if we want to write all
	    this data to disk. We achieve that by calling the
	    <verb>table.flush()</verb> method.
	  </p>
	  <verbatim>
>>> table.flush()
	  </verbatim>

	</subsection>

	<subsection id="readingAndSelectingUsage">
	  <heading>Reading (and selecting) data in a table</heading>
	  <p>Ok. We have our data on disk, and now we need to access it 
	    and select from specific columns the values we are
	    interested in. See the example below:
	  </p>
	  <verbatim>
>>> table = h5file.root.detector.readout
>>> pressure = [ x['pressure'] for x in table.iterrows()
...              if x['TDCcount']>3 and 20&lt;=x['pressure']&lt;50 ]
>>> pressure
[25.0, 36.0, 49.0]
	  </verbatim>

	  <p>The first line creates a "shortcut"
	    to the <em>readout</em> table deeper on the
	    object tree. As you can see, we use the <visual
	    markup="bf">natural naming</visual> schema to access
	    it. We also could have used the
	    <verb>h5file.getNode()</verb> method, as we will do
	    later on.
	  </p>

	  <p>You will recognize the last two lines as a Python list
	    comprehension. It loops over the rows in <em>table</em> as
	    they are provided by the <verb>table.iterrows()</verb>
	    iterator (see <ref refid="iterrowsTableDescr"></ref>). The
	    iterator returns values until all the data in table is
	    exhausted. These rows are filtered using the expression:
	    <verbatim>
	      x['TDCcount'] > 3 and x['pressure'] &lt;50
	    </verbatim>
	    We select the value of the <verb>pressure</verb> column from
	    filtered records to create the final list and assign it to
	    <verb>pressure</verb> variable.
	  </p>

	  <p>We could have used a normal <verb>for</verb> loop
	    to accomplish the same purpose, but I find comprehension 
	    syntax to be more compact and elegant.
	  </p>

	  <p>Let's select the <verb>name</verb> column for the same set of cuts:
	  </p>

	  <verbatim>
>>> names=[ x['name'] for x in table if x['TDCcount']>3 and 20&lt;=x['pressure']&lt;50 ]
>>> names
['Particle:      5', 'Particle:      6', 'Particle:      7']
	  </verbatim>

	  <p>Note how we have omitted the <verb>iterrows()</verb> call
	    in the list comprehension. The <verb>Table</verb> class 
	    has an implementation of the special method <verb>__iter__()</verb>
	    that iterates over all the rows in the table. In fact, 
	    <verb>iterrows()</verb> internally calls
	    this special <verb>__iter__()</verb> method.  Accessing all 
	    the rows in a table using this method is very
	    convenient, especially when working with the data interactively.
	  </p>

	  <p>That's enough about selections. The next section will show
	    you how to save these select results to a file.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating new array objects</heading>

	  <p>In order to separate the selected data from the mass of
	    detector data, we will create a new group
	    <verb>columns</verb> branching off the root
	    group. Afterwards, under this group, we will create two
	    arrays that will contain the selected data. First, we
	    create the group:
	  </p>

	  <verbatim>
>>> gcolumns = h5file.createGroup(h5file.root, "columns", "Pressure and Name")
	  </verbatim>

	  <p>Note that this time we have specified the first parameter
	    using <em>natural naming</em>
	    (<verb>h5file.root</verb>) instead of with an absolute
	    path string ("/").
	  </p>

	  <p>Now, create the first of the two <verb>Array</verb>
	    objects we've just mentioned:
	  </p>

	  <verbatim>
>>> h5file.createArray(gcolumns, 'pressure', array(pressure),
...                     "Pressure column selection")
/columns/pressure (Array(3,)) 'Pressure column selection'
  type = Float64
  itemsize = 8
  flavor = 'NumArray'
  byteorder = 'little'
	  </verbatim>

	  <p>We already know the first two parameters of the
	    <verb>createArray</verb> (see <ref
	    refid="createArrayDescr"></ref>) methods (these are the
	    same as the first two in <verb>createTable</verb>): they are
	    the parent group <em>where</em> <verb>Array</verb> will be
	    created and the <verb>Array</verb> instance
	    <em>name</em>.  The third parameter is the <em>object</em> 
	    we want to save to disk. In this case, it is a <verb>Numeric</verb> 
	    array that is built from the selection list we created before.
	    The fourth parameter is the <em>title</em>.
	  </p>

	  <p>Now, we will save the second array. It contains the list
	    of strings we selected before: we save this object as-is,
	    with no further conversion.
	  </p>

	  <verbatim>
>>> h5file.createArray(gcolumns, 'name', names, "Name column selection")
/columns/name Array(4,) 'Name column selection'
  type = 'CharType'
  itemsize = 16
  flavor = 'List'
  byteorder = 'little'
	  </verbatim>

	  <p>As you can see, <verb>createArray()</verb> accepts
	    <em>names</em> (which is a regular Python list) as an
	    <em>object</em> parameter. Actually, it accepts a variety
	    of different regular objects (see <ref
	    refid="createArrayDescr"></ref>) as parameters. The
	    <verb>flavor</verb> attribute (see the output above) saves
	    the original kind of object that was saved. Based on this
	    <em>flavor</em>, <verb>PyTables</verb> will be able to
	    retrieve exactly the same object from disk later on.
	  </p>
	  <p>Note that in these examples, the <verb>createArray</verb>
	    method returns an <verb>Array</verb> instance that is not
	    assigned to any variable. Don't worry, this is intentional
	    to show the kind of object we have created by displaying
	    its representation.  The <verb>Array</verb> objects have
	    been attached to the object tree and saved to disk, as you
	    can see if you print the complete object tree:
	  </p>
	  <verbatim>
>>> print h5file
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:00:13 2003'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout (Table(10,)) 'Readout example'

	  </verbatim>
	</subsection>

	<subsection>
	  <heading>Closing the file and looking at its content</heading>

	  <p>To finish this first tutorial, we use the
	    <verb>close</verb> method of the h5file <verb>File</verb>
	    object to close the file before exiting Python:
	  </p>
	  <verbatim>
>>> h5file.close()
>>> ^D
	  </verbatim>

	  <p>You have now created your first
	    <verb>PyTables</verb> file with a table and two
	    arrays. You can examine it with any generic HDF5 tool,
	    such as <verb>h5dump</verb> or <verb>h5ls</verb>. Here 
	    is what the <verb>tutorial1.h5</verb> looks like when read
	    with the <verb>h5ls</verb> program:
	  </p>
	  <verbatim>
$ h5ls -rd tutorial1.h5
/columns                 Group
/columns/name            Dataset {3}
    Data:
        (0) "Particle:      5", "Particle:      6", "Particle:      7"
/columns/pressure        Dataset {3}
    Data:
        (0) 25, 36, 49
/detector                Group
/detector/readout        Dataset {10/Inf}
    Data:
        (0) {0, 0, 0, 0, 10, 0, "Particle:      0", 0},
        (1) {256, 1, 1, 1, 9, 17179869184, "Particle:      1", 1},
        (2) {512, 2, 256, 2, 8, 34359738368, "Particle:      2", 4},
        (3) {768, 3, 6561, 3, 7, 51539607552, "Particle:      3", 9},
        (4) {1024, 4, 65536, 4, 6, 68719476736, "Particle:      4", 16},
        (5) {1280, 5, 390625, 5, 5, 85899345920, "Particle:      5", 25},
        (6) {1536, 6, 1679616, 6, 4, 103079215104, "Particle:      6", 36},
        (7) {1792, 7, 5764801, 7, 3, 120259084288, "Particle:      7", 49},
        (8) {2048, 8, 16777216, 8, 2, 137438953472, "Particle:      8", 64},
        (9) {2304, 9, 43046721, 9, 1, 154618822656, "Particle:      9", 81}
	  </verbatim>

	  <p>Here's the outputs as displayed by the "ptdump" 
	   <verb>PyTables</verb> utility (located in 
	   <verb>utils/</verb> directory):
	  </p>

	  <verbatim>
$ ptdump tutorial1.h5
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:40:51 2003'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout (Table(10,)) 'Readout example'

	  </verbatim>

	  <p>You can pass the <verb>-v</verb> or <verb>-d</verb>
	    options to <verb>ptdump</verb> if you want more
	    verbosity. Try them out!
	  </p>
	</subsection>
      </section>

      <section>
	<heading>Browsing the <visual markup="it">object tree</visual>
		and appending to tables</heading>

	<p>In this section, we will learn how to browse the tree and
	  retrieve meta-information about the actual data, then
	  append some rows to an existing table to show
	  how table objects can be enlarged.
	</p>
	<p>
	  In <em>examples/tutorial1-2.py</em> you will find the
	  working version of all the code in this section. As before,
	  you are encouraged to use a python shell and inspect the
	  object tree during the course of the tutorial.
	</p>

	<subsection>
	  <heading>Traversing the object tree</heading>

	  <p>Let's start by opening the file we created in last tutorial 
	    section. 
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial1.h5", "a")
	  </verbatim>

	  <p>This time, we have opened the file in "a"ppend mode. We
	    use this mode to add more information to the file.
	  </p>
	  <p><verb>PyTables</verb>, following the Python tradition,
	    offers powerful introspection capabilities, i.e. you can
	    easily ask information about any component of the object
	    tree as well as search the tree.
	  </p>
	  <p>To start with, you can get a preliminary overview of the
	    object tree by simply printing the existing
	    <verb>File</verb> instance:
	  </p>

	  <verbatim>
>>> print h5file
Filename: 'tutorial1.h5' Title: 'Test file' Last modif.: 'Sun Jul 27 14:40:51 2003'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout (Table(10,)) 'Readout example'

	  </verbatim>

	  <p>It looks like all of our objects are there. 
	    Now let's make use of the <verb>File</verb> 
	    iterator to see to list all the nodes in the 
	    object tree:
	  </p>

	  <verbatim>
>>> for node in h5file:
...   print node
...
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/detector (Group) 'Detector information'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector/readout (Table(10,)) 'Readout example'
	  </verbatim>
	  
	  <p>We can use the <verb>walkGroups</verb> method (see <ref
	    refid="walkGroupsDescr"></ref>) of the <verb>File</verb> class
	    to list only the <em>groups</em> on tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...   print group
...
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/detector (Group) 'Detector information'
	  </verbatim>

	  <p>Note that <verb>walkGroups()</verb> actually returns an
	    <em>iterator</em>, not a list of objects. Using this
	    iterator with the <verb>listNodes()</verb> method is a
	    powerful combination. Let's see an example listing of all
	    the arrays in the tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...     for array in h5file.listNodes(group, classname = 'Array'):
...         print array
...
/columns/name Array(3,) 'Name column selection'
/columns/pressure Array(3,) 'Pressure column selection'
	  </verbatim>

	  <p><verb>listNodes()</verb> (see <ref
	    refid="listNodesDescr"></ref>) returns a list containing
	    all the nodes hanging off a specific <verb>Group</verb>.
	    If the <em>classname</em> keyword is specified, the method
	    will filter out all instances which are not descendants of
	    the class. We have asked for only <verb>Array</verb> 
	    instances.
	  </p>

	  <p>We can combine both calls by using the
	      <verb>__call__(where, classname)</verb> special method
	      of the <verb>File</verb> object (<ref
	      refid="__callFileDescr">see</ref>). For example:
	  </p>

	  <verbatim>
>>> for array in h5file("/", "Array"):
...   print array
...
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
	  </verbatim>

	  <p>This is a nice shortcut when working interactively.</p>

	  <p>Finally, we will list all the <verb>Leaf</verb>,
	    i.e. <verb>Table</verb> and <verb>Array</verb> instances
	    (see <ref refid="LeafClassDescr"></ref> for detailed
	    information on <verb>Leaf</verb> class), in the
	    <verb>/detector</verb> group. Note that only one instance
	    of the <verb>Table</verb> class
	    (i.e. <verb>readout</verb>) will be selected in this group
	    (as should be the case):
	  </p>

	  <verbatim>
>>> for leaf in h5file.root.detector('Leaf'):
...   print leaf
...
/detector/readout (Table(10,)) 'Readout example'
	  </verbatim>

	  <p>We have used a call to the
	    <verb>Group.__call__(classname, recursive)</verb> special
	    method (<ref refid="__callGroupDescr"></ref>), using
	    the <em>natural naming</em> path specification.</p>

	  <p>Of course you can do more sophisticated node selections
	    using these powerful methods. But first, let's take a look
	    at some important <verb>PyTables</verb> object instance
	    variables.
	  </p>

	</subsection>

	<subsection>
	  <heading>Setting and getting user attributes</heading>

	  <p>PyTables provides an easy and concise way to complement
	    the meaning of your node objects on the tree by using the
	    <verb>AttributeSet</verb> class (see <ref
	    refid="AttributeSetClassDescr">section</ref>). You can
	    access this object through the standard attribute
	    <verb>attrs</verb> in <verb>Leaf</verb> nodes and
	    <verb>_v_attrs</verb> in <verb>Group</verb> nodes.
	  </p>

	  <p>For example, let's imagine that we want to save the date
	    indicating when the data in <verb>/detector/readout</verb>
	    table has been acquired, as well as the temperature during
	    the gathering process:
	  </p>

	  <verbatim>
>>> table = h5file.root.detector.readout
>>> table.attrs.gath_date = "Wed, 06/12/2003 18:33"
>>> table.attrs.temperature = 18.4
>>> table.attrs.temp_scale = "Celsius"
	  </verbatim>

	  <p>Now, let's set a somewhat more complex attribute in the
	    <verb>/detector</verb> group:
	  </p>
          <!-- SGP:  What is this attribute? -->
	  <verbatim>
>>> detector = h5file.root.detector
>>> detector._v_attrs.stuff = [5, (2.3, 4.5), "Integer and tuple"]
	  </verbatim>

	  <p>Note how the AttributeSet instance is accessed with
	    the <verb>_v_attrs</verb> attribute because detector is a
	    <verb>Group</verb> node. In general, you can save any
	    standard Python data structure as an attribute node.
	    See <ref refid="AttributeSetClassDescr">section</ref> for
	    a more detailed explanation of how they are serialized for
	    export to disk.
	  </p>

	  <p>Retrieving the attributes is equally simple:
	  </p>

	  <verbatim>
>>> table.attrs.gath_date
'Wed, 06/12/2003 18:33'
>>> table.attrs.temperature
18.399999999999999
>>> table.attrs.temp_scale
'Celsius'
>>> detector._v_attrs.stuff
[5, (2.2999999999999998, 4.5), 'Integer and tuple']
	  </verbatim>

	  <p>You can probably guess how to delete attributes:
	  </p>

	  <verbatim>
>>> del table.attrs.gath_date
	  </verbatim>

	  <p>If you want to examine the current complete attribute set
	  of <verb>/detector/table</verb>, you can print its
	  representation (try hitting the <verb>TAB</verb> key
	  twice if you are on a Unix Python console with the
	  <verb>rlcompleter</verb> module active):
	  </p>

	  <verbatim>
>>> table.attrs
/detector/readout (AttributeSet), 14 attributes:
   [CLASS := 'TABLE',
    FIELD_0_NAME := 'ADCcount',
    FIELD_1_NAME := 'TDCcount',
    FIELD_2_NAME := 'energy',
    FIELD_3_NAME := 'grid_i',
    FIELD_4_NAME := 'grid_j',
    FIELD_5_NAME := 'idnumber',
    FIELD_6_NAME := 'name',
    FIELD_7_NAME := 'pressure',
    NROWS := 10,
    TITLE := 'Readout example',
    VERSION := '2.0',
    tempScale := 'Celsius',
    temperature := 18.399999999999999]
	  </verbatim>

	  <p>You can get a list of only the user or system attributes
	    with the <verb>_f_list()</verb> method.
	  </p>

	  <verbatim>
>>> print table.attrs._f_list("user")
['temp_scale', 'temperature']
>>> print table.attrs._f_list("sys")
['CLASS', 'FIELD_0_NAME', 'FIELD_1_NAME', 'FIELD_2_NAME', 'FIELD_3_NAME',
 'FIELD_4_NAME', 'FIELD_5_NAME', 'FIELD_6_NAME', 'FIELD_7_NAME', 'NROWS',
 'TITLE', 'VERSION']
	  </verbatim>

	  <p>You can also rename attributes:
	  </p>

	  <verbatim>
>>> table.attrs._f_rename("temp_scale","tempScale")
>>> print table.attrs._f_list()
['tempScale', 'temperature']
	  </verbatim>

	  <p>However, you can't set, delete or rename read-only
	    attributes:
	  </p>

	  <verbatim>
>>> table.attrs._f_rename("VERSION", "version")
Traceback (most recent call last):
  File "&gt;stdin>", line 1, in ?
  File "/home/falted/PyTables/pytables-0.7/tables/AttributeSet.py", 
  line 249, in _f_rename
    raise RuntimeError, \
RuntimeError: Read-only attribute ('VERSION') cannot be renamed
	  </verbatim>

	  <p>If you would terminate your session now, you would be
	  able to use the <verb>h5ls</verb> command to read the
	  <verb>/detector/readout</verb> attributes from the file
	  written to disk:
	  </p>

	  <verbatim>
$ h5ls -vr tutorial1.h5/detector/readout
Opened "tutorial1.h5" with sec2 driver.
/detector/readout        Dataset {10/Inf}
    Attribute: CLASS     scalar
        Type:      6-byte null-terminated ASCII string
        Data:  "TABLE"
    Attribute: VERSION   scalar
        Type:      4-byte null-terminated ASCII string
        Data:  "2.0"
    Attribute: TITLE     scalar
        Type:      16-byte null-terminated ASCII string
        Data:  "Readout example"
    Attribute: FIELD_0_NAME scalar
        Type:      9-byte null-terminated ASCII string
        Data:  "ADCcount"
    Attribute: FIELD_1_NAME scalar
        Type:      9-byte null-terminated ASCII string
        Data:  "TDCcount"
    Attribute: FIELD_2_NAME scalar
        Type:      7-byte null-terminated ASCII string
        Data:  "energy"
    Attribute: FIELD_3_NAME scalar
        Type:      7-byte null-terminated ASCII string
        Data:  "grid_i"
    Attribute: FIELD_4_NAME scalar
        Type:      7-byte null-terminated ASCII string
        Data:  "grid_j"
    Attribute: FIELD_5_NAME scalar
        Type:      9-byte null-terminated ASCII string
        Data:  "idnumber"
    Attribute: FIELD_6_NAME scalar
        Type:      5-byte null-terminated ASCII string
        Data:  "name"
    Attribute: FIELD_7_NAME scalar
        Type:      9-byte null-terminated ASCII string
        Data:  "pressure"
    Attribute: tempScale scalar
        Type:      8-byte null-terminated ASCII string
        Data:  "Celsius"
    Attribute: temperature {1}
        Type:      native double
        Data:  18.4
    Attribute: NROWS     {1}
        Type:      native int
        Data:  10
    Location:  0:1:0:1952
    Links:     1
    Modified:  2003-07-24 13:59:19 CEST
    Chunks:    {2048} 96256 bytes
    Storage:   470 logical bytes, 96256 allocated bytes, 0.49% utilization
    Type:      struct {
                   "ADCcount"         +0    native unsigned short
                   "TDCcount"         +2    native unsigned char
                   "energy"           +3    native double
                   "grid_i"           +11   native int
                   "grid_j"           +15   native int
                   "idnumber"         +19   native long long
                   "name"             +27   16-byte null-terminated ASCII string
                   "pressure"         +43   native float
               } 47 bytes
 

	  </verbatim>


	  <p>Attributes are a useful mechanism to add persistent 
	    (meta) information to your data.
	  </p>

	</subsection>

	<subsection>
	  <heading>Getting object metadata</heading>

	  <p>Each object in <verb>PyTables</verb> has
	    <em>metadata</em> information about the data in the
	    file. Normally this <em>metainformation</em> is accessible
	    through the node instance variables. Let's take a look at
	    some examples:
	  </p>

	  <verbatim>
>>> print "Object:", table
Object: /detector/readout Table(10,) 'Readout example'
>>> print "Table name:", table.name
Table name: readout
>>> print "Table title:", table.title
Table title: Readout example
>>> print "Number of rows in table:", table.nrows
Number of rows in table: 10
>>> print "Table variable names with their type and shape:"
Table variable names with their type and shape:
>>> for name in table.colnames:
...   print name, ':= %s, %s' % (table.coltypes[name], table.colshapes[name])
...
ADCcount := UInt16, 1
TDCcount := UInt8, 1
energy := Float64, 1
grid_i := Int32, 1
grid_j := Int32, 1
idnumber := Int64, 1
name := CharType, 1
pressure := Float32, 1
	  </verbatim>

	  <p>
	    Here, the <verb>name</verb>, <verb>title</verb>,
	    <verb>nrows</verb>, <verb>colnames</verb>,
	    <verb>coltypes</verb> and <verb>colshapes</verb>
	    attributes (see <ref
	    refid="FileInstanceVariablesDescr"></ref> for a complete
	    attribute list) of the <verb>Table</verb> object gives us quite
	    a bit of information about the table data.
	  </p>

	  <p>You can interactively retrieve general information
	    about the public objects in PyTables by printing their 
	    internal doc strings:
	  </p>

	  <verbatim>
>>> print table.__doc__
Represent a table in the object tree.

    It provides methods to create new tables or open existing ones, as
    well as to write/read data to/from table objects over the
    file. A method is also provided to iterate over the rows without
    loading the entire table or column in memory.

    Data can be written or read both as Row instances or as numarray
    (NumArray or RecArray) objects.
    
    Methods:
    
      Common to all leaves:
        close()
        flush()
        getAttr(attrname)
        rename(newname)
        remove()
        setAttr(attrname, attrvalue)
        
      Specific of Table:
        iterrows()
        read([start] [, stop] [, step] [, field [, flavor]])
        removeRows(start, stop)

    Instance variables:
    
      Common to all leaves:
        name -- the leaf node name
        hdf5name -- the HDF5 leaf node name
        title -- the leaf title
        shape -- the leaf shape
        byteorder -- the byteorder of the leaf
        
      Specific of Table:
        description -- the metaobject describing this table
        row -- a reference to the Row object associated with this table
        nrows -- the number of rows in this table
        rowsize -- the size, in bytes, of each row
        colnames -- the field names for the table (list)
        coltypes -- the type class for the table fields (dictionary)
        colshapes -- the shapes for the table fields (dictionary)

	  </verbatim>

	  <p>The <verb>help</verb> function is also a handy way 
	    to see <verb>PyTables</verb> reference documentation 
	    online.  Try it yourself with other object docs:
	  </p>

	  <verbatim>
>>> help(table.__class__)
>>> help(table.removeRows)
	  </verbatim>

	  <p>To examine metadata in the <em>/columns/pressure</em>
	    <verb>Array</verb> object:
	  </p>

	  <verbatim>
>>> pressureObject = h5file.getNode("/columns", "pressure")
>>> print "Info on the object:", repr(pressureObject)
Info on the object: /columns/pressure (Array(3,)) 'Pressure column selection'
  type = Float64
  itemsize = 8
  flavor = 'NumArray'
  byteorder = 'little'
>>> print "  shape: ==>", pressureObject.shape
  shape: ==> (3,)
>>> print "  title: ==>", pressureObject.title
  title: ==> Pressure column selection
>>> print "  type: ==>", pressureObject.type
  type: ==> Float64
	  </verbatim>

	  <p>Observe that we have used the <verb>getNode()</verb>
	    method of the <verb>File</verb> class to access a node in the
	    tree, instead of the natural naming method. Both are
	    useful, and depending on the context you will prefer
	    one or the other. <verb>getNode()</verb> has the
	    advantages that it can get a node from the pathname string
	    (as in this example) and can also act as a
	    filter to show only nodes in a particular location that
	    are instances of class <em>classname</em>. In general, 
	    however, I consider natural naming to be more elegant and
	    easier to use, especially if you are using the name completion 
	    capability present in interactive console. Try
	    this powerful combination of natural naming and completion
	    capabilities present in most Python consoles, and see
	    how pleasant it is to browse the object tree (at
	    least, as pleasant as such an activity can be).
	  </p>
	  <p>If you look at the <verb>type</verb> attribute of the
	    <verb>pressureObject</verb> object, you can verify that it is
	    a "<visual markup="bf">Float64</visual>" array. 
	    By looking at its <verb>shape</verb> attribute, you can
	    deduce that the array on disk is unidimensional and has 3
	    elements. See <ref
	    refid="ArrayClassInstanceVariables"></ref> or the internal
	    string docs for the complete <verb>Array</verb> attribute
	    list.
	  </p>
	</subsection>

	<subsection>
	  <heading>Reading data from <visual
	  markup="tt">Array</visual> objects</heading>

	  <p>Once you have found the desired <verb>Array</verb>,
	    use the <verb>read()</verb> method of the <verb>Array</verb> 
	    object to retrieve its data:</p>

	  <verbatim>
>>> pressureArray = pressureObject.read()
>>> pressureArray
array([ 25.,  36.,  49.])
>>> print "pressureArray is an object of type:", type(pressureArray)
pressureArray is an object of type: &lt;class 'numarray.numarraycore.NumArray'>
>>> nameArray = h5file.root.columns.name.read()
>>> nameArray
['Particle:      5', 'Particle:      6', 'Particle:      7']
>>> print "nameArray is an object of type:", type(nameArray)
nameArray is an object of type: &lt;type 'list'>
>>>
>>> print "Data on arrays nameArray and pressureArray:"
Data on arrays nameArray and pressureArray:
>>> for i in range(pressureObject.shape[0]):
...   print nameArray[i], "-->", pressureArray[i]
...
Particle:      5 --> 25.0
Particle:      6 --> 36.0
Particle:      7 --> 49.0
>>> pressureObject.name
'pressure'
	  </verbatim>

	  <p>You can see that the <verb>read()</verb> method (see
	    <ref refid="readArrayDescr">section</ref>) returns an authentic
	    <verb>numarray</verb> object for the
	    <verb>pressureObject</verb> instance by looking at the
	    output of the <verb>type()</verb> call.  A <verb>read()</verb>
	    of the <verb>nameObject</verb> object instance
	    returns a native Python list (of strings). 
	    The type of the object saved is stored as an HDF5 attribute
	    (named <verb>FLAVOR</verb>) for objects on
	    disk. This attribute is then read as 
	    <verb>Array</verb> metainformation (accessible through
	    in the <verb>Array.attrs.FLAVOR</verb> variable), enabling the
	    read array to be converted into the original object. This
	    provides a means to save a large variety of objects as
	    arrays with the guarantee that you will be able to later recover
	    them in their original form. See <ref
	    refid="createArrayDescr">section</ref> for a complete list
	    of supported objects for the <verb>Array</verb> object class.
	  </p>

	</subsection>

	<subsection>
	  <heading>Appending data to an existing table</heading>

	  <p>Now, let's have a look at how we can add records to an
	    existing table on disk. Let's use our well-known
	    <em>readout</em> <verb>Table</verb> object and
	    append some new values to it:
	  </p>

	  <verbatim>
>>> table = h5file.root.detector.readout
>>> particle = table.row
>>> for i in xrange(10, 15):
...     particle['name']  = 'Particle: %6d' % (i)
...     particle['TDCcount'] = i % 256
...     particle['ADCcount'] = (i * 256) % (1 &lt;&lt; 16)
...     particle['grid_i'] = i
...     particle['grid_j'] = 10 - i
...     particle['pressure'] = float(i*i)
...     particle['energy'] = float(particle['pressure'] ** 4)
...     particle['idnumber'] = i * (2 ** 34)
...     particle.append()
...
>>> table.flush()
	  </verbatim>

	  <p>It's the same method we used to fill a new
	    table. <verb>PyTables</verb> knows that this table is on
	    disk, and when you add new records, they are appended to
	    the end of the table<footnote>Note that you can append not
	    only scalar values to tables, but also fully
	    multidimensional array objects.</footnote>.
	  </p>
	  <p>
	    If you look carefully at the code you will see that we
	    have used the <verb>table.row</verb> attribute to
	    create a table row and fill it with the new values.
	    Each time that its <verb>append()</verb> method is called,
	    the actual row is committed to the output buffer and the
	    row pointer is incremented to point to the next table
	    record. When the buffer is full, the data is saved on
	    disk, and the buffer is reused again for the next cycle.
	  </p>

	  <p><visual markup="bf">Caveat emptor</visual>: Do not
	    forget to always call the <verb>.flush()</verb>
	    method after a write operation, or else your tables 
	    will not be updated!</p>

	  <p>Let's have a look at some rows in the modified table and
	    verify that our new data has been appended:
	  </p>

	  <verbatim>
>>> for r in table.iterrows():
...     print "%-16s | %11.1f | %11.4g | %6d | %6d | %8d |" % \
...        (r['name'], r['pressure'], r['energy'], r['grid_i'], r['grid_j'],
...         r['TDCcount'])
...
...
Particle:      0 |         0.0 |           0 |      0 |     10 |        0 |
Particle:      1 |         1.0 |           1 |      1 |      9 |        1 |
Particle:      2 |         4.0 |         256 |      2 |      8 |        2 |
Particle:      3 |         9.0 |        6561 |      3 |      7 |        3 |
Particle:      4 |        16.0 |   6.554e+04 |      4 |      6 |        4 |
Particle:      5 |        25.0 |   3.906e+05 |      5 |      5 |        5 |
Particle:      6 |        36.0 |    1.68e+06 |      6 |      4 |        6 |
Particle:      7 |        49.0 |   5.765e+06 |      7 |      3 |        7 |
Particle:      8 |        64.0 |   1.678e+07 |      8 |      2 |        8 |
Particle:      9 |        81.0 |   4.305e+07 |      9 |      1 |        9 |
Particle:     10 |       100.0 |       1e+08 |     10 |      0 |       10 |
Particle:     11 |       121.0 |   2.144e+08 |     11 |     -1 |       11 |
Particle:     12 |       144.0 |     4.3e+08 |     12 |     -2 |       12 |
Particle:     13 |       169.0 |   8.157e+08 |     13 |     -3 |       13 |
Particle:     14 |       196.0 |   1.476e+09 |     14 |     -4 |       14 |
	  </verbatim>

	</subsection>
	<subsection>
	  <heading>And finally... how to delete rows from a table</heading>

	  <p>We'll finish this tutorial by deleting some
	    rows from the table we have. Suppose that we want to
	    delete the the 5th to 9th rows (inclusive):
	  </p>

	  <verbatim>
>>> table.removeRows(5,10)
5
	  </verbatim>

	  <p><verb>removeRows(start, stop)</verb> (<ref
	      refid="removeRowsDescr">see</ref>) deletes the rows in
	      the range (start, stop). It returns the number of rows
	      effectively removed.
	  </p>

	  <!-- SGP:  It would be cool if you could delete all the rows
	  returned by a selection. -->
	  <p>We have reached the end of this first tutorial.
	    Don't forget to close the file when you finish:
	  </p>

	  <verbatim>
>>> h5file.close()
>>> ^D
$ 
	  </verbatim>

	  <p>In <ref refid="tutorial1-tableview">figure</ref> you can
	    see a graphical view of the <verb>PyTables</verb> file
	    with the datasets we have just created. In <ref
	    refid="tutorial1-general">figure</ref> are displayed the
	    general properties of the table
	    <verb>/detector/readout</verb>.
	  </p>

	  <figure id="tutorial1-tableview">
	    <graphics file="tutorial1-tableview" scale="0.5" kind="bitmap">
	    </graphics>
	    <caption>The final version of the data file for tutorial 1,
	    with a view of the data objects.
	    </caption>
	  </figure>

	  <figure id="tutorial1-general">
	    <graphics file="tutorial1-general" scale="0.5" kind="bitmap">
	    </graphics>
	    <caption>General properties of the <visual
	    markup="tt">/detector/readout</visual> table.
	    </caption>
	  </figure>

	</subsection>

      </section>

      <section id="secondExample">
	<heading>Multidimensional table cells and automatic
	  sanity checks</heading>

	<p>Now it's time for a more real-life example (i.e. with errors in
	  the code). We will create two groups that branch
	  directly from the <verb>root</verb> node, 
	  <verb>Particles</verb> and <verb>Events</verb>. Then, we
	  will put three tables in each group. In <verb>Particles</verb>
	  we will put tables based on the <verb>Particle</verb> descriptor
	  and in <verb>Events</verb>, the tables based the <verb>Event</verb>
	  descriptor.
	</p>
	<p>
	  Afterwards, we will provision the tables with a number of
	  records. Finally, we will read the newly-created table
	  <verb>/Events/TEvent3</verb> and select some values from it,
	  using a comprehension list.
	</p>
	<p>Look at the next script (you can find it in
	  <verb>examples/tutorial2.py</verb>). It appears to do all of
	  the above, but it contains some small bugs. Note that
	  this <verb>Particle</verb> class is not directly related
	  to the one defined in last tutorial; this class is simpler
	  (note, however, the <em>multidimensional</em> columns called
	  <verb>pressure</verb> and <verb>temperature</verb>). 
	</p>
	<p>We also introduce a new manner to describe a <verb>Table</verb>
	  as a dictionary, as you can see in the <verb>Event</verb>
	  description. See section <ref
	  refid="createTableDescr"></ref> about the different kinds of
	  descriptor objects that can be passed to the
	  <verb>createTable()</verb> method.
	</p>

	<verbatim>
from numarray import *
from tables import *

# Describe a particle record
class Particle(IsDescription):
    name        = StringCol(length=16) # 16-character String
    lati        = IntCol()             # integer
    longi       = IntCol()             # integer
    pressure    = Float32Col(shape=(2,3)) # array of floats (single-precision)
    temperature = FloatCol(shape=(2,3))   # array of doubles (double-precision)

# Another way to describe the columns of a table
Event = {
    "name"    : Col('CharType', 16),    # 16-character String
    "TDCcount": Col("UInt8", 1),        # unsigned byte
    "ADCcount": Col("UInt16", 1),       # Unsigned short integer
    "xcoord"  : Col("Float32", 1),      # integer
    "ycoord"  : Col("Float32", 1),      # integer
    }

# Open a file in "w"rite mode
fileh = openFile("tutorial2.h5", mode = "w")
# Get the HDF5 root group
root = fileh.root
# Create the groups:
for groupname in ("Particles", "Events"):
    group = fileh.createGroup(root, groupname)
# Now, create and fill the tables in the Particles group
gparticles = root.Particles
# Create 3 new tables
for tablename in ("TParticle1", "TParticle2", "TParticle3"):
    # Create a table
    table = fileh.createTable("/Particles", tablename, Particle,
                           "Particles: "+tablename)
    # Get the record object associated with the table:
    particle = table.row
    # Fill the table with data for 257 particles
    for i in xrange(257):
        # First, assign the values to the Particle record
        particle['name'] = 'Particle: %6d' % (i)
        particle['lati'] = i 
        particle['longi'] = 10 - i
        ########### Detectable errors start here. Play with them!
        particle['pressure'] = array(i*arange(2*3), shape=(2,4))  # Incorrect
        #particle['pressure'] = array(i*arange(2*3), shape=(2,3))  # Correct
        ########### End of errors
        particle['temperature'] = (i**2)     # Broadcasting
        # This injects the Record values
        particle.append()      
    # Flush the table buffers
    table.flush()

# Now Events:
for tablename in ("TEvent1", "TEvent2", "TEvent3"):
    # Create a table in the Events group
    table = fileh.createTable(root.Events, tablename, Event,
                           "Events: "+tablename)
    # Get the record object associated with the table:
    event = table.row
    # Fill the table with data on 257 events
    for i in xrange(257):
        # First, assign the values to the Event record
        event['name']  = 'Event: %6d' % (i)
        event['TDCcount'] = i % (1&lt;&lt;8)   # Correct range
        ########### Detectable errors start here. Play with them!
        #event['xcoord'] = float(i**2)   # Correct spelling
        event['xcoor'] = float(i**2)     # Wrong spelling
        event['ADCcount'] = i * 2        # Correct type
        #event['ADCcount'] = "sss"          # Wrong type
        ########### End of errors
        event['ycoord'] = float(i)**4
        # This injects the Record values
        event.append()

    # Flush the buffers
    table.flush()

# Read the records from table "/Events/TEvent3" and select some
table = root.Events.TEvent3
e = [ p['TDCcount'] for p in table
      if p['ADCcount'] &lt; 20 and 4 &lt;= p['TDCcount'] &lt; 15 ]
print "Last record ==>", p
print "Selected values ==>", e
print "Total selected records ==> ", len(e)
# Finally, close the file (this also will flush all the remaining buffers)
fileh.close()
	</verbatim>

	<subsection>
	  <heading>Shape checking</heading>

	  <p>If you look at the code carefully, you'll see that it 
	    won't work. You will get the following error:</p>

	<verbatim>
$ python tutorial2.py
Traceback (most recent call last):
  File "tutorial2.py", line 53, in ?
    particle['pressure'] = array(i*arange(2*3), shape=(2,4))  # Incorrect
  File  "/usr/local/lib/python2.2/site-packages/numarray/numarraycore.py",
 line 281, in array
  a.setshape(shape)
  File "/usr/local/lib/python2.2/site-packages/numarray/generic.py", 
 line 530, in setshape
    raise ValueError("New shape is not consistent with the old shape")
ValueError: New shape is not consistent with the old shape
	</verbatim>

	  <p>This error indicates that you are trying to assign an array
	    with an incompatible shape to a table cell. Looking at the 
	    source, we see that we were trying to assign an array of shape
	    <verb>(2,4)</verb> to a <verb>pressure</verb> element,
	    which was defined with the shape <verb>(2,3)</verb>.
	  </p>
	  <p>In general, these kinds of operations are forbidden, with
	    one valid exception: when you assign a
	    <em>scalar</em> value to a multidimensional column cell,
	    all the cell elements are populated with the value of the 
	    scalar. For example:
	  </p>

	  <verbatim>
        particle['temperature'] = (i**2)    # Broadcasting
	  </verbatim>

	  <p>The value <verb>i**2</verb> is assigned to all the
	    elements of the <verb>temperature</verb> table cell. This
	    capability is provided by the <verb>numarray</verb>
	    package and is known as <em>broadcasting</em>.
	  </p>

	</subsection>

	<subsection>
	  <heading>Field name checking</heading>

	  <p>After fixing the previous error and rerunning the
	  program, we encounter another error:
	  </p>
	  <verbatim>
$ python tutorial2.py
Traceback (most recent call last):
  File "tutorial2.py", line 74, in ?
    event['xcoor'] = float(i**2)     # Wrong spelling
  File "/home/falted/PyTables/pytables-0.8/src/hdf5Extension.pyx",
 line 1812, in hdf5Extension.Row.__setitem__
    raise KeyError, "Error setting \"%s\" field.\n %s" % \
KeyError: Error setting "xcoor" field.
 Error was: "exceptions.KeyError: xcoor"
	  </verbatim>

	  <p>This error indicates that we are attempting to assign a value to
	    a non-existent field in the <em>event</em> table
	    object. By looking carefully at the <verb>Event</verb>
	    class attributes, we see that we misspelled the
	    <verb>xcoord</verb> field (we wrote <verb>xcoor</verb>
	    instead). This is unusual behavior for Python, as normally
	    when you assign a value to a non-existent instance variable,
	    Python creates a new variable with that name. Such a feature 
	    can be dangerous when dealing with an object that 
	    contains a fixed list of field names. PyTables checks
	    that the field exists and raises a <verb>KeyError</verb>
	    if the check fails.
	  </p>

	</subsection>

	<subsection>
	  <heading>Data type checking</heading>

	  <p>Finally, in order to test type checking, we will change
	    the next line:
	  </p>
	  <verbatim>
	    event.ADCcount = i * 2        # Correct type
	  </verbatim>

	  <p>to read:</p>

	  <verbatim>
	    event.ADCcount = "sss"          # Wrong type
	  </verbatim>

	  <p>This modification will cause the following <verb>TypeError</verb>
	    exception to be raised when the script is executed:
	  </p>

	  <verbatim>
$ python tutorial2.py
Traceback (most recent call last):
  File "tutorial2.py", line 76, in ?
    event['ADCcount'] = "sss"          # Wrong type
  File "/home/falted/PyTables/pytables-0.8/src/hdf5Extension.pyx",
 line 1812, in hdf5Extension.Row.__setitem__
    raise KeyError, "Error setting \"%s\" field.\n %s" % \
KeyError: Error setting "ADCcount" field.
 Error was: "exceptions.TypeError: NA_setFromPythonScalar: bad value type."
	  </verbatim>

	  <p>You can see the structure created with this
	    (corrected) script in <ref refid="tutorial2">figure</ref>.
	    In particular, note the multidimensional
	    column cells in table <verb>/Particles/TParticle2</verb>.
	  </p>

	  <figure id="tutorial2">
	    <graphics file="tutorial2-tableview" scale="0.5" kind="bitmap">
	    </graphics>
	    <caption>Table hierarchy for tutorial 2.</caption>
	  </figure>

	  <p>Feel free to examine the rest of examples in directory
	    <verb>examples</verb>, and try to understand them. I've
	    written several practical sample scripts to give you an 
	    idea of the <visual markup="tt">PyTables</visual> 
	    capabilities, its way of dealing with HDF5 objects, 
	    and how it can be used in the real world.
	  </p>

	</subsection>
      </section>
    </chapter>

    <!-- SGP:  Ended here -->
    <chapter id="libraryReference">
      <heading>Library Reference</heading>
      
<!--       <aphorism>"Tenho pensamentos que, se pudesse revelá-los e -->
<!-- 	fazê-los viver, acrescentariam nova luminosidade às estrelas, -->
<!-- 	nova beleza ao mundo e maior amor ao coração dos homens." -->
<!-- 	<caption>Fernando Pessoa, in "O Eu Profundo"</caption> -->
<!--       </aphorism> -->

      <p><verb>PyTables</verb> implements several classes to represent
	the different nodes in the object tree. They are named
	<verb>File</verb>, <verb>Group</verb>, <verb>Leaf</verb>,
	<verb>Table</verb>, <verb>Array</verb>, <verb>EArray</verb>,
	<verb>VLArray</verb> and <verb>UnImplemented</verb>. Another
	one allows the user to complement the information on these
	different objects; its name is
	<verb>AttributeSet</verb>. Finally, another important class
	called <verb>IsDescription</verb> allows to build a
	<verb>Table</verb> record description by declaring a subclass
	of it. Many other classes are defined in
	<verb>PyTables</verb>, but they can be regarded as helpers
	whose goal is mainly to declare the <em>data type
	properties</em> of the different first class objects and will
	be described at the end of this chapter as well.
      </p>
      <p>An important function, called <verb>openFile</verb> is
	responsible to create, open or append to files. In addition, a
	few utility functions are defined to guess if the user
	supplied file is a <em>PyTables</em> or <em>HDF5</em>
	file. These are called <verb>isPyTablesFile</verb> and
	<verb>isHDF5</verb>, respectively. Finally, there exists a
	function called <verb>whichLibVersion</verb> that informs
	about the versions of the underlying C libraries (for example,
	the <verb>HDF5</verb> or the <verb>Zlib</verb>).
      </p>

      <p>Let's start discussing the first-level variables and
	functions available to the user, then the different classes
	defined in <verb>PyTables</verb>.
      </p>

      <section>
	<heading><visual markup="tt">tables</visual> variables and
	  functions</heading>

	<subsection>
	  <heading>Global variables</heading>

	  <description>

	    <term>__version__</term> <item>The <verb>PyTables</verb>
	    version number.</item>

	    <term>ExtVersion</term> <item>The version of the Pyrex
	      extension module. This might be useful when reporting
	      bugs.</item>

	    <term>HDF5Version</term>
	    <item>The underlying HDF5 library version number.</item>

	  </description>
	  
	</subsection>

	<subsection id="GlobalFunctDescr">
	  <heading>Global functions</heading>

	  <description>

	    <term>copyFile(srcFilename=None, dstFilename=None, title=None,
	      filters=None, copyuserattrs=1, overwrite=0)
	    </term>

	    <item>Copy a closed <verb>PyTables</verb> (or generic
	      <verb>HDF5</verb>) file specified by
	      <em>srcFilename</em> to <em>dstFilename</em>. Returns a
	      tuple in the form <verb>(ngroups, nleaves,
	      nbytes)</verb> specifiying the number of groups, leaves
	      and bytes copied.
	    
	      <description id="copyFileDescr">

		<term>title</term> <item>The title for the new
		  file. If not specified, the source file title will
		  be copied.
		</item>

		<term>filters</term> <item>A Filters instance (see
		    <ref refid="FiltersClassDescr"></ref>). If
		    specified, it will override the original filter
		    properties in <visual markup="bf">all</visual>
		    source nodes.
		</item>

		<term>copyuserattrs</term> <item>You can prevent the
		  user attributes from being copied by setting this
		  parameter to 0. The default is to copy them.
		</item>

		<term>overwrite</term><item>If
		  <verb>dstFilename</verb> file already exists and
		  overwrite is 1, it will be silently overwritten. The
		  default is not overwriting.
		</item>

	      </description>

	    </item>

	    <term>isHDF5(filename)</term> <item>Determines whether
	      filename is in the HDF5 format or not. When successful,
	      returns a positive value, for TRUE, or 0 (zero), for
	      FALSE. Otherwise returns a negative value. To this
	      function to work, it needs a closed file.
	    </item>

	    <term>isPyTablesFile(filename)</term> <item>Determines
	      whether a file is in the <verb>PyTables</verb> format.
	      When successful, returns the format version string, for
	      TRUE, or 0 (zero), for FALSE. Otherwise returns a
	      negative value. To this function to work, it needs a
	      closed file.
	    </item>

	    <term>openFile(filename, mode='r', title='', trMap={},
	      rootUEP="/", filters=None)
	    </term>

	    <item>Open a <verb>PyTables</verb> (or generic
	    <verb>HDF5</verb>) file and returns a <verb>File</verb>
	    object.
	    
	      <description id="openFileDescr">

		<term>filename</term> <item>The name of the file
		  (supports environment variable expansion). It is
		  suggested that it should have any of
		  <verb>".h5"</verb>, <verb>".hdf"</verb> or
		  <verb>".hdf5"</verb> extensions, although this is
		  not mandatory.
		</item>

		<term>mode</term> <item>The mode to open the file. It
		  can be one of the following:

		  <description>

		    <term>'r'</term> <item>read-only; no data can be
		      modified.</item>

		    <term>'w'</term> <item>write; a new file is
		      created (an existing file with the same name
		      would be deleted).</item>

		    <term>'a'</term> <item>append; an existing file is
		      opened for reading and writing, and if the file
		      does not exist it is created.</item>

		    <term>'r+'</term> <item>is similar to 'a', but the
		      file must already exist.</item>

		  </description>
		</item>

		<term>title</term> <item>If filename is new, this will
		  set a title for the root group in this file. If
		  filename is not new, the title will be read from
		  disk, and this will not have any effect.
		</item>

		<term>trMap</term> <item>A dictionary to map names in
		  the object tree Python namespace into different HDF5
		  names in file namespace. The keys are the Python
		  names, while the values are the HDF5 names. This is
		  useful when you need to use HDF5 node names with
		  invalid or reserved words in Python.
		</item>

		<term>rootUEP</term> <item>The root User Entry
		  Point. This is a group in the HDF5 hierarchy which
		  will be taken as the starting point to create the
		  object tree. The group has to be named after its
		  HDF5 name and can be a path. If it does not exist, a
		  <verb>RuntimeError</verb> exception is issued. Use
		  this if you do not want to build the <visual
		  markup="bf">entire</visual> object tree, but rather
		  only a <visual markup="bf">subtree</visual> of it.
		</item>

		<term>filters</term><item>An instance of the
		  <verb>Filters</verb> class (see section<ref
		  refid="FiltersClassDescr"></ref>) that provides
		  information about the desired I/O filters applicable
		  to the leaves that hangs directly from <em>root</em>
		  (unless other filters properties are specified for
		  these leaves). Besides, if you do not specify filter
		  properties for its child groups, they will inherit
		  these ones. So, if you open a new file with this
		  parameter set, all the leaves that would be created
		  in the file will recursively inherit this filtering
		  properties (again, if you don't prevent that from
		  happening by specifying other filters on the child
		  groups or leaves).
		</item>

	      </description>

	    </item>

	    <term>whichLibVersion(libname)</term> <item>Returns info
	      about versions of the underlying C libraries. <visual
	      markup="bf">libname</visual> can be whether
	      <verb>"hdf5"</verb>, <verb>"zlib"</verb>,
	      <verb>"lzo"</verb> or <verb>"ucl"</verb>. It always
	      returns a tuple of 3 elements. When successful, the
	      first element of this tuple has a positive value, and is
	      0 (zero) when library is not available (for example LZO
	      or UCL). In case the library is available, the second
	      element of tuple contains the library version and the
	      third element the date (if available) of that version.
	    </item>


	  </description>
	</subsection>
      </section>

      <section id="FileClassDescr">
	<heading>The <visual markup="tt">File</visual> class</heading>

	<p>This class is returned when a <verb>PyTables</verb> file is
	  opened with the <verb>openFile</verb> function. It has
	  methods to flush and close files. Also, the
	  <verb>File</verb> class offers methods to create, rename and
	  delete nodes, as well as to traverse the object tree. One of
	  its attributes (<verb>rootUEP</verb>) represents the
	  <em>user entry point</em> to the object tree attached to the
	  file.
	</p>

	<p>Next, we will discuss the attributes and methods for File
	  class<footnote>On the following, the term <verb>Leaf</verb>
	  will refer to either a <verb>Table</verb>,
	  <verb>Array</verb>, <verb>EArray</verb>,
	  <verb>VLArray</verb> or <verb>UnImplemented</verb> node
	  object.</footnote>.
	</p>

	<subsection id="FileInstanceVariablesDescr">
	  <heading><visual markup="tt">File</visual> instance
	    variables</heading>
	  <description>

	    <term>filename</term> <item>Filename opened.</item>

	    <term>format_version</term> <item>The
	    <verb>PyTables</verb> version number of this file.</item>

	    <term>isopen</term> <item>It takes the value 1 if the
	      underlying file is open. 0 otherwise.</item>

	    <term>mode</term> <item>Mode in which the filename was
	      opened.</item>

	    <term>root</term> <item>The <em>root</em> of the object
	       tree hierarchy. It is a <verb>Group</verb> instance.
	    </item>

	    <term>rootUEP</term> <item>The UEP (User Entry Point)
	      group in file (see <ref
	      refid="openFileDescr"></ref>).</item>

	    <term>title</term> <item>The title of the root group in
	      file.</item>

	    <term>trMap</term> <item>This is a dictionary that maps
	      node names between python and HDF5 domain names. Its
	      initial values are set from the <em>trMap</em> parameter
	      passed to the <verb>openFile</verb> function. You can
	      change its contents <em>after</em> a file is opened and
	      the new map will take effect over any new object added
	      to the tree.
	    </item>

	    <term>filters</term> <item>Container for filter properties
	      associated to this file.  See <ref
	      refid="FiltersClassDescr">section</ref> for more
	      information on this object.
	    </item>

	    <term>objects</term> <item>Dictionary with all objects
	      (groups or leaves) on tree.</item>

	    <term>groups</term> <item>Dictionary with all object
	      groups on tree.</item>

	    <term>leaves</term> <item>Dictionary with all object
	      leaves on tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">File</visual> methods</heading>

	  <subsubsection id="FilecopyChildrenDescr">

	    <heading>copyChildren(whereSrc, whereDst, recursive=0,
                   filters=None, copyuserattrs=1, start=0, stop=None,
                   step=1, overwrite = 0)
	    </heading>

	    <p>Copy (recursively) the children of a group into another
	      location. Returns a tuple in the form <verb>(ngroups,
	      nleaves, nbytes)</verb> specifiying the number of
	      groups, leaves and bytes copied.
	    </p>

	    <description>
	      <term>whereSrc</term> <item>The parent group where the
		children to be copied are hanging on. This parameter
		can be a path string (for example
		<verb>"/level1/group5"</verb>), or another
		<verb>Group</verb> instance.
	      </item>

	      <term>whereDst</term> <item>The parent group where the
		source children will be copied to. This group must exist
		or a <verb>LookupError</verb> will be issued. This
		parameter can be a path string (for example
		<verb>"/level1/group6"</verb>), or another
		<verb>Group</verb> instance.
	      </item>

	      <term>recursive</term> <item>Specifies whether the copy
		should recurse into subgroups or not. The default is
		not recurse.
	      </item>
	      
	      <term>filters</term> <item>Whether or not override the
		original filter properties present in source nodes.
		This parameter must be an instance of the
		<verb>Filters</verb> class (see section<ref
		refid="FiltersClassDescr"></ref>). The default is to
		copy the filter attributes from source children.
	      </item>

	      <term>copyuserattrs</term> <item>You can prevent the
		user attributes from being copied by setting this
		parameter to 0. The default is to copy them.
	      </item>

	      <term>start, stop, step</term><item>Specifies the range
		of rows in child leaves to be copied; the default is
		to copy all the rows.
	      </item>

	      <term>overwrite</term><item>Whether the possible
		existing children hanging from <verb>whereDst</verb>
		and having the same names than <verb>whereSrc</verb>
		children should overwrite the destination nodes or
		not.
	      </item>
	    </description>
	  </subsubsection> <!-- copyChildren -->

	  <subsubsection id="FilecopyFileDescr">
	    <heading>copyFile(dstFilename=None, title=None,
                 filters=None, copyuserattrs=1, overwrite=0)
	    </heading>

	    <p>Copy the contents of this file to <em>dstFilename</em>.
	      If the filename already exists it won't be overwritten
	      unless <em>overwrite</em> is set to true (see later).
	      Returns a tuple in the form <verb>(ngroups, nleaves,
	      nbytes)</verb> specifiying the number of groups, leaves
	      and bytes copied.
	    </p>

	    <description>
	      <term>title</term> <item>The title for the new file. If
		not specified, the source file title will be copied.
	      </item>

	      <term>filters</term> <item>Whether or not override the
		original filter properties present in source nodes.
		This parameter must be an instance of the
		<verb>Filters</verb> class (see section<ref
		refid="FiltersClassDescr"></ref>). The default is to
		copy the filter attributes from source children.
	      </item>

	      <term>copyuserattrs</term> <item>You can prevent the
		user attributes from being copied by setting this
		parameter to 0. The default is to copy them.
	      </item>

	      <term>copyuserattrs</term> <item>You can prevent the
		user attributes from being copied by setting this
		parameter to 0. The default is to copy them.
	      </item>

	      <term>overwrite</term><item>Whether overwrite or not the
		possibly existing <em>dstFilename</em> file. The
		default is not overwrite it.
	      </item>
	    </description>
	  </subsubsection> <!-- copyFile -->

	  <subsubsection id="createGroupDescr">
	    <heading>createGroup(where, name, title='', filters=None)
	    </heading>

	    <p>Create a new Group instance with name <em>name</em> in
	      <em>where</em> location.
	    </p>

	    <description>
	      <term>where</term> <item>The parent group where the new
		group will hang from. <em>where</em> parameter can be
		a path string (for example
		<verb>"/level1/group5"</verb>), or another Group
		instance. </item>

	      <term>name</term>
	      <item>The name of the new group.</item>
	      
	      <term>title</term> <item>A description for this
		group.</item>

	      <term>filters</term><item>An instance of the
		<verb>Filters</verb> class (see section<ref
		refid="FiltersClassDescr"></ref>) that provides
		information about the desired I/O filters applicable
		to the leaves that hangs directly from this new group
		(unless other filters properties are specified for
		these leaves). Besides, if you do not specify filter
		properties for its child groups, they will inherit
		these ones.
	      </item>

	    </description>

	  </subsubsection>

	  <subsubsection>
	    <heading id="createTableDescr">createTable(where, name,
	      description, title='', filters=None,
	      expectedrows=10000)
	    </heading>
	    <p>Create a new <verb>Table</verb> instance with name
	      <em>name</em> in <em>where</em> location.
	    </p>
	    <description>
	      <term>where</term> <item>The parent group where the new
		table will hang from. <em>where</em> parameter can be
		a path string (for example
		<verb>"/level1/leaf5"</verb>), or Group instance.
               </item>
	      <term>name</term> <item>The name of the new table.
              </item>
	      <term>description</term> <item>An instance of a
		user-defined class (derived from the
		<verb>IsDescription</verb> class) where table fields
		are defined. However, in certain situations, it is
		more handy to allow this description to be supplied as
		a dictionary (for example, when you do not know
		beforehand which structure will have your table). In
		such a cases, you can pass the description as a
		dictionary as well. See <ref
		refid="secondExample">section</ref> for an example of
		use. Finally, a <verb>RecArray</verb> object from the
		<verb>numarray</verb> package is also accepted, and
		all the information about columns and other metadata
		is used as a basis to create the <verb>Table</verb>
		object. Moreover, if the <verb>RecArray</verb> has
		actual data this is also injected on the newly created
		<verb>Table</verb> object.
	      </item>
	      <term>title</term> <item>A description for this object.
	      </item>
	      <term>filters</term> <item>An instance of the
		<verb>Filters</verb> class (see <ref
		refid="FiltersClassDescr">section</ref>) that provides
		information about the desired I/O filters to be
		applied during the life of this object.
	      </item>
	      <term>expectedrows</term> <item>An user estimate of the
		number of records that will be on table. If not
		provided, the default value is appropriate for tables
		until 1 MB in size (more or less, depending on the
		record size). If you plan to save bigger tables you
		should provide a guess; this will optimize the HDF5
		B-Tree creation and management process time and memory
		used. See <ref refid="expectedRowsOptim">section</ref>
		for a discussion on that issue.
	      </item>
	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="createArrayDescr">createArray(where, name,
	      object, title='')</heading>

	    <p>Create a new <verb>Array</verb> instance with name
	      <em>name</em> in <em>where</em> location.
	    </p>
	    <description>
	      <term>object</term> <item>The regular array to be
		saved. Currently accepted values are: lists, tuples,
		scalars (int and float), strings and
		(multidimensional) <verb>Numeric</verb> and
		<verb>NumArray</verb> arrays (including
		<verb>CharArrays</verb> string arrays). However, these
		objects must be regular (i.e. they cannot be like, for
		example, <verb>[[1,2],2]</verb>). Also, objects that
		have some of their dimensions equal to zero are not
		supported (use an <verb>EArray</verb> object if you
		want to create an array with one of its dimensions
		equal to 0).
	      </item>
	    </description>
	    <p>See <ref
	      refid="createTableDescr"><verb>createTable</verb>
	      description</ref> for more information on the
	      <em>where</em>, <em>name</em> and <em>title</em>,
	      parameters.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading id="createEArrayDescr">createEArray(where, name,
	      atom, title='', filters=None, expectedrows=1000)
	    </heading>

	    <p>Create a new <verb>EArray</verb> instance with name
	      <em>name</em> in <em>where</em> location.
	    </p>

	    <description>

	      <term>atom</term> <item>An <verb>Atom</verb> instance
		representing the <em>shape</em>, <em>type</em> and
		<em>flavor</em> of the atomic objects to be saved.
		One (and only one) of the shape dimensions <visual
		markup="bf">must</visual> be 0. The dimension being 0
		means that the resulting <verb>EArray</verb> object
		can be extended along it. Multiple enlargeable
		dimensions are not supported right now.  See <ref
		refid="AtomClassDescr">section</ref> for the supported
		set of <verb>Atom</verb> class descendants.
              </item>
	      <term>expectedrows</term> <item>In the case of
                enlargeable arrays this represents an user estimate
                about the number of row elements that will be added to
                the growable dimension in the EArray object. If not
                provided, the default value is 1000 rows. If you plan
                to create both much smaller or much bigger EArrays try
                providing a guess; this will optimize the HDF5 B-Tree
                creation and management process time and the amount of
                memory used.
	      </item>
	    </description>
	    <p>See <ref
	      refid="createTableDescr"><verb>createTable</verb>
	      description</ref> for more information on the
	      <em>where</em>, <em>name</em>, <em>title</em>,
	      and <em>filters</em> parameters.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading id="createVLArrayDescr">createVLArray(where,
	      name, atom=None, title='', filters=None,
	      expectedsizeinMB=1.0)
	    </heading>

	    <p>Create a new <verb>VLArray</verb> instance with name
	      <em>name</em> in <em>where</em> location. See the <ref
		refid="VLArrayClassDescr">section</ref> for a
	      description of the <verb>VLArray</verb> class.
	    </p>

	    <description>
	      <term>atom</term> <item>An <verb>Atom</verb> instance
                representing the shape, type and flavor of the atomic
                object to be saved. See <ref
                refid="AtomClassDescr">section</ref> for the supported set
                of <verb>Atom</verb> class descendants.
              </item>
              <term>expectedsizeinMB</term> <item>An user estimate
                about the size (in MB) in the final
                <verb>VLArray</verb> object. If not provided, the
                default value is 1 MB.  If you plan to create both
                much smaller or much bigger VLA's try providing a
                guess; this will optimize the HDF5 B-Tree creation and
                management process time and the amount of memory used.
              </item>
	    </description>
	    <p>See <ref
	      refid="createTableDescr"><verb>createTable</verb>
	      description</ref> for more information on the
	      <em>where</em>, <em>name</em>, <em>title</em>, and
	      <em>filters</em> parameters.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading id="getNodeDescr">getNode(where, name='',
	      classname='')</heading>

	    <p>Returns the object node <em>name</em> under
	      <em>where</em> location.
	    </p>

	      <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exist or has already a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>name</term> <item>The object name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

		<term>classname</term> <item>If supplied, returns only
		  an instance of this class name. Possible values are:
		  <verb>'Group'</verb>, <verb>'Leaf'</verb>,
		  <verb>'Table'</verb>, <verb>'Array'</verb>,
		  <verb>'EArray'</verb>, <verb>'VLArray'</verb> and
		  <verb>'UnImplemented'</verb>. Note that these values
		  are strings.
		</item>

	      </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="getAttrNodeDescr">getAttrNode(where,
	      attrname, name='' )</heading>

	    <p>Returns the attribute <em>attrname</em> under
	      <em>where.name</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exist or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>attrname</term> <item>The name of the attribute
		  to get.
		</item>

		<term>name</term> <item>The node name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="setAttrNodeDescr">setAttrNode(where,
	      attrname, attrvalue, name='')</heading>

	    <p>Sets the attribute <em>attrname</em> with value
	      <em>attrvalue</em> under <em>where.name</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exist or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>attrname</term> <item>The name of the attribute
		  to set on disk.
		</item>

		<term>attrvalue</term> <item>The value of the
		  attribute to set. Only strings attributes are
		  supported natively right now. However, you can
		  always use <verb>(c)Pickle</verb> so as to serialize
		  any object you want save therein.
		</item>

		<term>name</term> <item>The node name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="listNodesDescr">listNodes(where,
	      classname='')</heading>

	    <p>Returns a list with all the object nodes (Group or
	      Leaf) hanging from <em>where</em>. The list is
	      alpha-numerically sorted by node name.
	    </p>
	    <description>

		<term>where</term> <item>The parent group. Can be a
		  path string or <verb>Group</verb> instance.
		</item>

		<term>classname</term> <item>If a <em>classname</em>
		  parameter is supplied, the iterator will return only
		  instances of this class (or subclasses of it). The
		  only supported classes in <em>classname</em> are
		  <verb>'Group'</verb>, <verb>'Leaf'</verb>,
		  <verb>'Table'</verb>, <verb>'Array'</verb>,
		  <verb>'EArray'</verb>, <verb>'VLArray'</verb> and
		  <verb>'UnImplemented'</verb>. Note that these values
		  are strings.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="removeNodeDescr">removeNode(where, name = "",
	      recursive=0)</heading>

	    <p>Removes the object node
	      <em>name</em> under <em>where</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance.  If <em>where</em>
		  doesn't exist or has not a child called
		  <em>name</em>, a <verb>LookupError</verb> error is
		  raised.</item>

		<term>name</term> <item>The name of the node to be
		  removed. If not provided, the <em>where</em> node is
		  changed.</item>

		<term>recursive</term> <item>If not supplied, the
		  object will be removed only if it has no
		  children. If supplied with a true value, the object
		  and all its descendants will be completely
		  removed.</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="renameNodeDescr">renameNode(where, newname,
	      name)</heading>

	    <p>Rename the object node <em>name</em> under
	      <em>where</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance.  If <em>where</em>
		  doesn't exist or has not a child called
		  <em>name</em>, a <verb>LookupError</verb> error is
		  raised.</item>

		<term>newname</term> <item>Is the new name to be
		  assigned to the node.</item>

		<term>name</term> <item>The name of the node to be
		  changed. If not provided, the <em>where</em> node is
		  changed.</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="walkGroupsDescr">walkGroups(where='/')</heading>

	    <p><em>Iterator</em> that returns the list of Groups (not
	      Leaves) hanging from <em>where</em>. If <em>where</em>
	      is not supplied, the root object is taken as origin. The
	      returned Group list is in a top-bottom order, and
	      alpha-numerically sorted when they are at the same level.
	    </p>
	    <description>

		<term>where</term> <item>The origin group. Can be a
		  path string or <verb>Group</verb> instance.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading>flush()</heading>

	    <p>Flush all the leaves in the object tree.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading>close()</heading>

	    <p>Flush all the leaves in object tree and close the file.
	    </p>
	  </subsubsection>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">File</visual> special
	      methods</heading>

	  <p>Following are described the methods that automatically
	    trigger actions when a <verb>File</verb> instance is
	    accessed in a special way (e.g.,
	    <verb>fileh("/detector")</verb> will cause a call to
	    <verb>group.__call__("/detector")</verb>).
	  </p>

	  <subsubsection>
	    <heading id="__callFileDescr">__call__(where="/",
	      classname="")</heading>

	    <p>Recursively iterate over the children in the
	      <verb>File</verb> instance. It takes two parameters:</p>

	    <description>

	      <term>where</term> <item>If supplied, the iteration
	      starts from this group.</item>

	      <term>classname</term> <item><em>(String)</em> If
	      supplied, only instances of this class are
	      returned.</item>

	    </description>

	    <p>Example of use:</p>

	    <verbatim>
	      # Recursively print all the nodes hanging from '/detector'
	      print "Nodes hanging from group '/detector':"
	      for node in h5file("/detector"):
	          print node
	    </verbatim>

	  </subsubsection>

	  <subsubsection>
	    <heading id="__iterFileDescr">__iter__()</heading>

	    <p>Iterate over the children on the <verb>File</verb>
	      instance. However, this does not accept parameters. This
	      iterator <em>is recursive</em>.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      # Recursively list all the nodes in the object tree
	      h5file = tables.openFile("vlarray1.h5")
	      print "All nodes in the object tree:"
	      for node in h5file:
	          print node
	    </verbatim>

	  </subsubsection>

	</subsection>

      </section>

      <section id="GroupClassDescr">
	<heading>The <visual markup="tt">Group</visual> class</heading>

	<p>Instances of this class are a grouping structure containing
	  instances of zero or more groups or leaves, together with
	  supporting metadata.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files, respectively, in a Unix
	  filesystem. As with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. This full path can be specified either
	  as a string (like in <verb>'/group1/group2'</verb>) or as a
	  complete object path written in <em>natural name</em> schema
	  (like in <newline/><verb>file.root.group1.group2</verb>) as
	  discussed in the <ref
	  refid='ObjectTreeSection'>section</ref>.
	</p>

	<p>A collateral effect of the <em>natural naming</em> schema
	  is that you must be aware when assigning a new attribute
	  variable to a Group object to not collide with existing
	  children node names. For this reason and to not pollute the
	  children namespace, it is explicitly forbidden to assign
	  "normal" attributes to Group instances, and the only ones
	  allowed must start with some reserved prefixes, like
	  "<verb>_f_</verb>" (for methods) or "<verb>_v_</verb>" (for
	  instance variables) prefixes. Any attempt to assign a new
	  attribute that does not starts with these prefixes, will
	  raise a <verb>NameError</verb> exception.
	</p>

	<p>Other effect is that you cannot use reserved Python names
	  or other non-allowed python names (like for example "$a" or
	  "44") as node names. You can, however, make use of the
	  <verb>trMap</verb> (translation map dictionary) parameter in
	  the <verb>openFile</verb> function (see section <ref
	  refid="openFileDescr"></ref>) in order to use non-valid
	  Python names as node names in the file.
	</p>

	<subsection>

	  <heading><visual markup="tt">Group</visual> instance
	    variables</heading>
	  <description>

	    <term>_v_title</term>
	    <item>A description for this group.</item>

	    <term>_v_name</term>
	    <item>The name of this group.</item>

	    <term>_v_hdf5name</term> <item>The name of this group in
	      HDF5 file namespace.</item>

	    <term>_v_pathname</term>
	    <item>A string representation of the group location
	      in tree.</item>

	    <term>_v_parent</term>
	    <item>The parent Group instance.</item>

	    <term>_v_rootgroup</term>
	    <item>Pointer to the root group object.</item>

	    <term>_v_file</term>
	    <item>Pointer to the associated File object.</item>

	    <term>_v_depth</term> <item>The depth level in tree for
	      this group.</item>

	    <term>_v_nchildren</term> <item>The number of children
	      (groups or leaves) hanging from this instance.</item>

	    <term>_v_children</term> <item>Dictionary with all nodes
	      (groups or leaves) hanging from this instance.</item>

	    <term>_v_groups</term> <item>Dictionary with all node
	      groups hanging from this instance.</item>

	    <term>_v_leaves</term> <item>Dictionary with all node
	      leaves hanging from this instance.</item>

	    <term>_v_attrs</term> <item>The associated
	    <verb>AttributeSet</verb> instance (see <ref
	    refid="AttributeSetClassDescr"></ref>).</item>

	    <term>_v_filters</term> <item>Container for filter
	      properties.  See <ref
	      refid="FiltersClassDescr">section</ref> for more
	      information on this object.
	    </item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> methods</heading>

	  <p>This class define the <verb>__setattr__</verb>,
	    <verb>__getattr__</verb> and <verb>__delattr__</verb> and
	    they work as normally intended. So, you can access, assign
	    or delete children to a group by just using the next
	    constructs:

	    <verbatim>
	      # Add a Table child instance under group with name "tablename"
	      group.tablename = Table(recordDict, "Record instance")
	      table = group.tablename     # Get the table child instance
	      del group.tablename         # Delete the table child instance
	    </verbatim>             

	  </p>

	  <p><visual markup="bf">Caveat: </visual>The following
	    methods are documented for completeness, and they can be
	    used without any problem. However, you should use the
	    high-level counterpart methods in the <verb>File</verb>
	    class, because these are most used in documentation and
	    examples, and are a bit more powerful than those exposed
	    here.
	  </p>

	  <subsubsection id="Group_f_join">
	    <heading>_f_join(name)
	    </heading>
	    <p>Helper method to correctly concatenate a name child object
	      with the pathname of this group.
	    </p>
	  </subsubsection>
	  <subsubsection id="Group_f_rename">
	    <heading>_f_rename(newname)
	    </heading>
	    <p>Change the name of this group to <em>newname</em>.
	    </p>
	  </subsubsection>
	  <subsubsection id="Group_f_remove">
	    <heading>_f_remove(recursive=0)
	    </heading>
	    <p>Remove this object. If <em>recursive</em> is true,
	      force the removal even if this group has children.
	    </p>
	  </subsubsection>
	  <subsubsection id="Group_f_getAttr">
	    <heading>_f_getAttr(attrname)
	    </heading>
	    <p>Gets the HDF5 attribute <em>attrname</em> of this
	      group.
	    </p>
	  </subsubsection>

	  <subsubsection id="Group_f_setAttr">
	    <heading>_f_setAttr(attrname, attrvalue)
	    </heading>
	    <p>Sets the attribute <em>attrname</em> of this group to
	      the value <em>attrvalue</em>. Only string values are
	      allowed.
	    </p>
	  </subsubsection>

	  <subsubsection id="Group_f_listNodes">
	    <heading>_f_listNodes(classname='')
	    </heading>
	    <p>Returns a <em>list</em> with all the object nodes
	      hanging from this instance. The list is
	      alpha-numerically sorted by node name. If a
	      <em>classname</em> parameter is supplied, it will only
	      return instances of this class (or subclasses of
	      it). The supported classes in <em>classname</em> are
	      <verb>'Group'</verb>, <verb>'Leaf'</verb>,
	      <verb>'Table'</verb> and <verb>'Array'</verb>,
	      <verb>'EArray'</verb>, <verb>'VLArray'</verb> and
	      <verb>'UnImplemented'</verb>.
	    </p>
	  </subsubsection>
	  <subsubsection id="Group_f_walkGroups">
	    <heading>_f_walkGroups()
	    </heading>
	    <p>Iterator that returns the list of Groups (not Leaves)
	      hanging from <em>self</em>. The returned Group list is
	      in a top-bottom order, and alpha-numerically sorted when
	      they are at the same level.
	    </p>
	  </subsubsection>

	  <subsubsection id="Group_f_close">
	    <heading>_f_close()
	    </heading>
	    <p>Close this group, making it and its children
	      unaccessible in the object tree.
	    </p>
	  </subsubsection>

	  <subsubsection id="Group_f_copyChildrenDescr">

	    <heading>_f_copyChildren(where, recursive=0, filters=None,
	      copyuserattrs=1, start=0, stop=None, step=1,
	      overwrite=0)
	    </heading>

	    <p>Copy (recursively) the children of this group into
	      another location specified by <em>where</em> (it can be
	      a path string or a <verb>Group</verb> object). Returns a
	      tuple in the form <verb>(ngroups, nleaves,
	      nbytes)</verb> specifiying the number of groups, leaves
	      and bytes copied.
	    </p>

	    <description>
	      <term>recursive</term> <item>Specifies whether the copy
		should recurse into subgroups or not. The default is
		not recurse.
	      </item>
	      
	      <term>filters</term> <item>Whether or not override the
		original filter properties present in source nodes.
		This parameter must be an instance of the
		<verb>Filters</verb> class (see section<ref
		refid="FiltersClassDescr"></ref>). The default is to
		copy the filter attributes from source children.
	      </item>

	      <term>copyuserattrs</term> <item>You can prevent the
		user attributes from being copied by setting this
		parameter to 0. The default is to copy them.
	      </item>

	      <term>start, stop, step</term><item>Specifies the range
		of rows in child leaves to be copied; the default is
		to copy all the rows.
	      </item>

	      <term>overwrite</term><item>Whether the possible
		existing children hanging from this group and having
		the same names than <verb>where</verb> children should
		overwrite the destination nodes or not.
	      </item>
	    </description>
	  </subsubsection> <!-- _f_copyChildren -->

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> special
	      methods</heading>

	  <p>Following are described the methods that automatically
	    trigger actions when a <verb>Group</verb> instance is
	    accessed in a special way (e.g.,
	    <verb>group("Table")</verb> will be equivalent to a call
	    to <verb>group.__call__("Table")</verb>).
	  </p>

	  <subsubsection>
	    <heading id="__callGroupDescr">__call__(classname="",
	      recursive=0)</heading>

	    <p>Iterate over the children in the <verb>Group</verb>
	      instance. It takes two parameters:</p>

	    <description>

	      <term>classname</term> <item><em>(String)</em> If
	      supplied, only instances of this class are
	      returned.</item>

	      <term>recursive</term> <item><em>(Integer)</em> If
	      false, only children hanging immediately after the group
	      are returned. If true, a recursion over all the groups
	      hanging from it is performed. </item>

	    </description>

	    <p>Example of use:</p>

	    <verbatim>
	      # Recursively print all the arrays hanging from '/'
	      print "Arrays the object tree '/':"
	      for array in h5file.root(classname="Array", recursive=1):
	          print array
	    </verbatim>

	  </subsubsection>

	  <subsubsection>
	    <heading id="__iterGroupDescr">__iter__()</heading>

	    <p>Iterate over the children on the group instance. However,
	      this does not accept parameters. This iterator is
	      <visual markup="bf">not</visual> recursive.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      # Non-recursively list all the nodes hanging from '/detector'
	      print "Nodes in '/detector' group:"
	      for node in h5file.root.detector:
	          print node
	    </verbatim>

	  </subsubsection>

	</subsection>

      </section>

      <section id="LeafClassDescr">
	<heading>The <visual markup="tt">Leaf</visual> class</heading>

	<p>The goal of this class is to provide a place to put common
	  functionality of all its descendants as well as provide a
	  way to help classifying objects on the tree. A
	  <verb>Leaf</verb> object is an end-node, that is, a node
	  that can hang directly from a group object, but that is not
	  a group itself and, thus, it cannot have descendents. Right
	  now, the set of end-nodes is composed by <verb>Table</verb>,
	  <verb>Array</verb>, <verb>EArray</verb>,
	  <verb>VLArray</verb> and <verb>UnImplemented</verb> class
	  instances. In fact, all the previous classes inherit from
	  the <verb>Leaf</verb> class.
	</p>

	<subsection>
	  <heading><visual markup="tt">Leaf</visual> instance
	    variables</heading>

	  <p>The public variables and methods that class descendants
	    inherits from <verb>Leaf</verb> are listed below.
	  </p>

	  <description>

	    <term>name</term> <item>The Leaf node name in Python
	      namespace.
	    </item>
	    <term>hdf5name</term> <item>The Leaf node name in HDF5
	      namespace.
	    </item>
	    <term>objectID</term> <item>The HDF5 object ID of the Leaf
	      node.
	    </item>
	    <term>title</term> <item>The Leaf title (actually a
	      property rather than a plain attribute).
	    </item>
	    <term>shape</term> <item>The shape of the associated data
	      in the Leaf.
	    </item>
	    <term>byteorder</term> <item>The byteorder of
	      the associated data of the Leaf.
	    </item>
	    <term>attrs</term><item>The associated
	      <verb>AttributeSet</verb> instance (see <ref
	      refid="AttributeSetClassDescr"></ref>).
	    </item>
	    <term>filters</term> <item>Container for filter
	      properties.  See <ref
	      refid="FiltersClassDescr">section</ref> for more
	      information on this object.
	    </item>

	  </description>

	  <p>Besides, the next instance variables are also defined and
	    have similar meaning as its counterparts in the
	    <verb>Group</verb> class:
	  </p>

	  <description>
	    <term>_v_hdf5name</term> <item>The name of this leaf in
	      HDF5 file namespace.</item>

	    <term>_v_pathname</term>
	    <item>A string representation of the leaf location
	      in tree.</item>

	    <term>_v_parent</term>
	    <item>The parent <verb>Group</verb> instance.</item>

	    <term>_v_rootgroup</term> <item>Pointer to the root
	    <verb>Group</verb> object.</item>

	    <term>_v_file</term> <item>Pointer to the associated
	    <verb>File</verb> object.</item>

	    <term>_v_depth</term> <item>The depth level in tree for
	      this leaf.</item>

	  </description>
	</subsection>

	<subsection>
	  <heading><visual markup="tt">Leaf</visual> methods</heading>

	  <subsubsection>

	    <heading id="copyLeafDescr">copy(where, name, title=None,
	      filters=None, copyuserattrs=1, start=0, stop=None,
	      step=1, overwrite=0)
	    </heading>

	    <p>Copy this leaf into another location. It returns a
	      tuple <verb>(object, nbytes)</verb> where
	      <verb>object</verb> is the newly created object and
	      <verb>nbytes</verb> is the number of bytes copied. The
	      meaning of the parameters is explained below:
	      <description>
		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance.  If <em>where</em>
		  doesn't exist or has not a child called
		  <em>name</em>, a <verb>LookupError</verb> error is
		  raised.
		</item>
		<term>name</term> <item>The name of the destination
		  node.
		</item>
		<term>title</term><item>The new title for
		  destination. If None, the original title is copied.
		</item>
		<term>filters</term><item>An instance of the
		  <verb>Filters</verb> (see <ref
		  refid="FiltersClassDescr">section</ref>) class. A
		  None value means that the source properties are
		  copied <em>as is</em>.
		</item>
		<term>copyuserattrs</term><item>Whether copy the user
		  attributes of the source leaf to the destination or
		  not. The default is to copy them.
		</item>
		<term>start, stop, step</term><item>Specifies the
		  range of rows to be copied; the default is to copy
		  all the rows.
		</item>
		<term>overwrite</term><item>If the destination node
		  <em>name</em> already exists this specifies whether
		  it should be overwritten or not. The default is not
		  overwrite it.
		</item>
	      </description>
	    </p>

	  </subsubsection>

	  <subsubsection>
	    <heading id="removeLeafDescr">remove()</heading>
	    <p>Remove this leaf.</p>
	  </subsubsection>
	  <subsubsection>
	    <heading id="renameLeafDescr">rename(newname)</heading>
	    <p>Change the name of this leaf to <em>newname</em>.</p>
	  </subsubsection>
	  <subsubsection>
	    <heading id="getAttrLeafDescr">getAttr(attrname)</heading>
	    <p>Gets the HDF5 attribute <em>attrname</em> of this leaf.
	    </p>
	  </subsubsection>
	  <subsubsection>
	    <heading id="setAttrLeafDescr">setAttr(attrname,
	      attrvalue)
	    </heading>
	    <p>Sets the attribute <em>attrname</em> of this leaf to
	      the value <em>attrvalue</em>.
	    </p>
	  </subsubsection>
	  <subsubsection>
	    <heading id="flushLeafDescr">flush()</heading>
	    <p>Flush the leaf buffers (if any).</p>
	  </subsubsection>
	  <subsubsection>
	    <heading id="closeLeafDescr">close()</heading> <p>Flush
	    the leaf buffers (if any) and close the dataset.</p>
	  </subsubsection>
	</subsection>

      </section>

      <section id="TableClassDescr">
	<heading>The <visual markup="tt">Table</visual> class</heading>

	<p>Instances of this class represents table objects in the
	  object tree. It provides methods to read/write data and
	  from/to table objects in the file.
	</p>
	<p>Data can be read from or written to tables by accessing to
	  an special object that hangs from <verb>Table</verb>. This
	  object is an instance of the <verb>Row</verb> class (see
	  <ref refid="RowClassDescr"></ref>). See the tutorial
	  sections <ref refid="usage">chapter</ref> on how to use the
	  <verb>Row</verb> interface. The columns of the tables can
	  also be easily accessed (and more specifically, they can be
	  read but not written) by making use of the
	  <verb>Column</verb> class, through the use of an
	  <em>extension</em> of the natural naming schema applied
	  inside the tables. See the <ref
	  refid="ColumnClassDescr">section</ref> for some examples of
	  use of this capability.
	</p>
	<p>Note that this object inherits all the public attributes
	  and methods that <verb>Leaf</verb> already has.
	</p>

	<subsection>
	  <heading><visual markup="tt">Table</visual> instance
	    variables</heading>
	  <description>
	    <term>description</term> <item>The metaobject describing
	      this table.
	    </item>
	    <term>row</term> <item>The <verb>Row</verb> instance for
	      this table (see <ref refid="RowClassDescr"></ref>).
	    </item>
	    <term>nrows</term> <item>The number of rows in this table.
	    </item>
	    <term>rowsize</term> <item>The size, in bytes, of each
	      row.
	    </item>

	    <term>cols</term> <item>A <verb>Cols</verb> (see <ref
		refid="ColsClassDescr">section</ref>) instance that
		serves as accessor to <verb>Column</verb> (see <ref
		refid="ColumnClassDescr">section</ref>) objects.
	    </item>
	    <term>colnames</term> <item>The field names for the table
	      (list).
	    </item>
	    <term>coltypes</term> <item>The data types for the table
	      fields (dictionary).
	    </item>
	    <term>colshapes</term> <item>The shapes for the table
	      fields (dictionary).
	    </item>
	  </description>
	</subsection>

	<subsection>
	  <heading><visual markup="tt">Table</visual> methods
	  </heading>
	  <subsubsection>
	    <heading id="appendTableDescr">append(rows=None)
	    </heading>
	    <p>Append a series of rows to this <verb>Table</verb>
	      instance. <em>rows</em> is an object that can keep the
	      rows to be append in several formats, like a
	      <verb>RecArray</verb>, a list of tuples, list of
	      <verb>Numeric</verb>/<verb>NumArray</verb>/<verb>CharArray</verb>
	      objects, string, Python buffer or None (no append will
	      result). Of course, this <em>rows</em> object has to be
	      compliant with the underlying format of the
	      <verb>Table</verb> instance or a <verb>ValueError</verb>
	      will be issued.
	    </p>

	    <p>Example of use:
	      <verbatim>
from tables import *
class Particle(IsDescription):
    name        = StringCol(16, pos=1)   # 16-character String
    lati        = IntCol(pos=2)        # integer
    longi       = IntCol(pos=3)        # integer
    pressure    = Float32Col(pos=4)    # float  (single-precision)
    temperature = FloatCol(pos=5)      # double (double-precision)

fileh = openFile("test4.h5", mode = "w")
table = fileh.createTable(fileh.root, 'table', Particle, "A table")
# Append several rows in only one call
table.append([("Particle:     10", 10, 0, 10*10, 10**2),
              ("Particle:     11", 11, -1, 11*11, 11**2),
              ("Particle:     12", 12, -2, 12*12, 12**2)])
fileh.close()
	      </verbatim>
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading id="iterrowsTableDescr">iterrows(start=None,
	      stop=None, step=1)</heading>

	    <p>Returns an iterator yielding <verb>Row</verb> (see <ref
	      refid="RowClassDescr">section</ref>) instances built
	      from rows in table. If a range is supplied (i.e. some of
	      the <em>start</em>, <em>stop</em> or <em>step</em>
	      parameters are passed), only the appropriate rows are
	      returned. Else, all the rows are returned. See also the
	      <verb>__call__()</verb> and <verb>__iter__()</verb>
	      special methods in <ref
	      refid="TableSpecialMethods">section</ref> for shorter
	      ways to call this iterator.
	    </p>
	    <p>The meaning of the <em>start</em>, <em>stop</em> and
	      <em>step</em> parameters is the same as in the
	      <verb>range()</verb> python function, except that
	      negative values of <verb>step</verb> are not
	      allowed. Moreover, if only <verb>start</verb> is
	      specified, then <verb>stop</verb> will be set to
	      <verb>start+1</verb>. If you do not specify neither
	      <em>start</em> nor <em>stop</em>, then <visual
	      markup="bf">all the rows</visual> in the object are
	      selected.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading id="readTableDescr">read(start=None, stop=None,
	      step=1, field=None, flavor="numarray")</heading>

	    <p>Returns the actual data in <verb>Table</verb>. If
	      <em>field</em> is not supplied, it returns the data as a
	      <verb>RecArray</verb> object table.
	    </p>

	    <p>The meaning of the <em>start</em>, <em>stop</em> and
	      <em>step</em> parameters is the same as in the
	      <verb>range()</verb> python function, except that
	      negative values of <verb>step</verb> are not
	      allowed. Moreover, if only <verb>start</verb> is
	      specified, then <verb>stop</verb> will be set to
	      <verb>start+1</verb>. If you do not specify neither
	      <em>start</em> nor <em>stop</em>, then all the rows in
	      the object are selected.
	    </p>
	    <p>The rest of the parameters are described next:</p>

	    <description>
	      <term>field</term> <item>If specified, only the column
		<em>field</em> is returned as a <verb>NumArray</verb>
		object. If this is not supplied, all the fields are
		selected and a <verb>RecArray</verb> is returned.
	      </item>
	      <term>flavor</term> <item>When a field in table is
		selected, passing a <em>flavor</em> parameter make an
		additional conversion to happen in the default
		<verb>"numarray"</verb> returned
		object. <em>flavor</em> must have any of the next
		values: <verb>"numarray"</verb> (i.e. no conversion is
		made), <verb>"Numeric"</verb>, <verb>"Tuple"</verb> or
		<verb>"List"</verb>.
	      </item>
	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="removeRowsDescr">removeRows(start=None,
	      stop=None)</heading>

	    <p>Removes a range of rows in the table.  If only
	      <em>start</em> is supplied, this row is to be
	      deleted. If a range is supplied, i.e. both the
	      <em>start</em> and <em>stop</em> parameters are passed,
	      all the rows in the range are removed. A <em>step</em>
	      parameter is not supported, and it is not foreseen to
	      implement it anytime soon.
	    </p>
	    <description>
		<term>start</term> <item>Sets the starting row to
		  be removed. It accepts negative values meaning that
		  the count starts from the end. A value of 0 means
		  the first row.</item>

		<term>stop</term> <item>Sets the last row to be
		  removed to <em>stop</em> - 1, i.e. the end point is
		  omitted (in the Python <verb>range</verb>
		  tradition). It accepts, likewise <em>start</em>,
		  negative values. A special value of
		  <verb>None</verb> (the default) means removing just
		  the row supplied in start.
		</item>

	      </description>
	  </subsubsection>

	</subsection>
	<subsection id="TableSpecialMethods">
	  <heading><visual markup="tt">Table</visual> special
	      methods</heading>

	  <p>Following are described the methods that automatically
	    trigger actions when a <verb>Table</verb> instance is
	    accessed in a special way (e.g.,
	    <verb>table["var2"]</verb> will be equivalent to a call to
	    <verb>table.__getitem__("var2")</verb>).
	  </p>

	  <subsubsection>
	    <heading id="__callTableDescr">__call__(start=None,
	    stop=None, step=1)</heading>

	    <p>It returns the same iterator than
	      <verb>Table.iterrows(start, stop, step)</verb>. It is,
	      therefore, a shorter way to call it.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      result = [ row['var2'] for row in table(step=4)
                          	      if row['var1'] &lt;= 20 ]
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      result = [ row['var2'] for row in table.iterrows(step=4) 
                          	      if row['var1'] &lt;= 20 ]
	    </verbatim>

	  </subsubsection>
	  <subsubsection>
	    <heading id="__iterTableDescr">__iter__()</heading>

	    <p>It returns the same iterator than
	      <verb>Table.iterrows(0,0,1)</verb>. However, this does not
	      accept parameters.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      result = [ row['var2'] for row in table 
                                     if row['var1'] &lt;= 20 ]
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      result = [ row['var2'] for row in table.iterrows() 
                                     if row['var1'] &lt;= 20 ]
	    </verbatim>

	  </subsubsection>

	  <subsubsection>
	    <heading id="__getitemTableDescr">__getitem__(key)</heading>

	    <p>It takes different actions depending on the
	      type of the <verb>key</verb> parameter:</p>

	    <description>
	      <term><visual markup="tt">key</visual> is an
		<verb>Integer</verb></term> <item>The corresponding
		table row is returned as a
		<verb>RecArray.Record</verb> object.</item>

	      <term><visual markup="tt">key</visual> is a
		<verb>Slice</verb></term><item>The row slice
		determined by <verb>key</verb> is returned as a
		<verb>RecArray</verb> object.</item>

	      <term><visual markup="tt">key</visual> is a
		<verb>String</verb></term> <item>The <verb>key</verb>
		is interpreted as a <em>column</em> name of the table,
		and, if it exists, it is read and returned as a
		<verb>NumArray</verb> or <verb>CharArray</verb> object
		(whatever is appropriate).</item>
	    </description>

	    <p>Example of use:</p>

	    <verbatim>
	      record = table[4]
	      recarray = table[4:1000:2]
	      narray = table["var2"]
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      record = table.read(start=4)[0]
	      recarray = table.read(start=4, stop=1000, step=2)
	      narray = table.read(field="var2")
	    </verbatim>

	  </subsubsection>
	</subsection>

	<subsection id="RowClassDescr">
	  <heading>The <visual markup="tt">Row</visual> class</heading>

	  <p>This class is used to fetch and set values on the table
	    fields. It works very much like a dictionary, where the keys
	    are the field names of the associated table and the values
	    are the values of those fields in a specific row.
	  </p>
	  <p>This object turns out to actually be an extension type,
	    so you won't be able to access its documentation
	    interactively. Neither you won't be able to access its
	    internal attributes (they are not directly accessible from
	    Python), although <em>accessors</em> (i.e. methods that
	    return an internal attribute) have been defined for the most
	    important variables.
	  </p>

	  <subsubsection>
	    <heading><visual markup="tt">Row</visual>
	      methods</heading>

	    <description>

	      <term id="appendRowDescr">append()</term> <item>Once you
		have filled the proper fields for the current row,
		calling this method actually commits these data to the
		disk (actually data are written to the output
		buffer).</item>

	      <term>nrow()</term> <item>Accessor that returns the
		current row number in the table. It is useful to know
		which row is being dealt with in the middle of a
		loop.</item>
	    </description>
	  </subsubsection>
	</subsection> <!-- Row -->

	<subsection id="ColsClassDescr">
	  <heading>The <visual markup="tt">Cols</visual> class</heading>

	  <p>This class is used as an <em>accessor</em> to the table
	    columns following the natural name convention, so that you
	    can access the different columns because there exist one
	    attribute with the name of the columns for each associated
	    <verb>Column</verb> instances. Besides, and like the
	    <verb>Row</verb> class, it works similar to a dictionary,
	    where the keys are the column names of the associated
	    table and the values are <verb>Column</verb>
	    instances. See <ref refid="ColumnClassDescr">section</ref>
	    for examples of use.
	  </p>
	</subsection> <!-- Cols -->

	<subsection id="ColumnClassDescr">
	  <heading>The <visual markup="tt">Column</visual> class</heading>

	  <p>Each instance of this class is associated with one column
	    of every table. These instances are used to fetch (but not
	    set) actual data from the table columns. The access
	    interface is like a regular list, and you can select
	    individual values or slices.
	  </p>

	  <subsubsection>
	    <heading><visual markup="tt">Column</visual> instance
	      variables
	    </heading>
	    <description>
	      <term>table</term> <item>The parent <verb>Table</verb>
		instance.
	      </item>
	      <term>name</term> <item>The name of the associated
		column.
	      </item>
	    </description>
	  </subsubsection>
	  <subsubsection>
	    <heading><visual markup="tt">Column</visual>
	      methods</heading>

	    <description>
	      <term>__getitem__(key)</term> <item>Returns a column
		element or slice. It takes different actions depending
		on the type of the <em>key</em> parameter:

		If <em>key</em> is an integer, the corresponding
		element in the column is returned as a scalar object
		or as a <verb>NumArray</verb>/<verb>CharArray</verb>
		object, depending on its shape. If <em>key</em> is a
		slice, the row range determined by this slice is
		returned as a <verb>NumArray</verb> or
		<verb>CharArray</verb> object (whichever is
		appropriate).
	      </item>
	    </description>

	    <p>Example of use:
	      <verbatim>
print "Column handlers:"
for name in table.colnames:
    print table.cols[name]
print
print "Some selections:"
print "Select table.cols.name[1]-->", table.cols.name[1]
print "Select table.cols.name[1:2]-->", table.cols.name[1:2]
print "Select table.cols.lati[1:3]-->", table.cols.lati[1:3]
print "Select table.cols.pressure[:]-->", table.cols.pressure[:]
print "Select table.cols['temperature'][:]-->", table.cols['temperature'][:]
	      </verbatim>
	      and the output of this for a certain arbitrary table is:
	      <verbatim>
Column handlers:
/table.cols.name (Column(1,), CharType)
/table.cols.lati (Column(2,), Int32)
/table.cols.longi (Column(1,), Int32)
/table.cols.pressure (Column(1,), Float32)
/table.cols.temperature (Column(1,), Float64)

Some selections:
Select table.cols.name[1]--> Particle:     11
Select table.cols.name[1:2]--> ['Particle:     11']
Select table.cols.lati[1:3]--> [[11 12]
 [12 13]]
Select table.cols.pressure[:]--> [  90.  110.  132.]
Select table.cols['temperature'][:]--> [ 100.  121.  144.]
	      </verbatim>
	      See the <verb>examples/table2.py</verb> for a more
	      complete example.
	    </p>
	  </subsubsection> <!-- Column methods -->
	</subsection> <!-- Column -->
      </section> <!-- Table -->

      <section id="ArrayClassDescr">
	<heading>The <visual markup="tt">Array</visual>
	class</heading>

	<p>Represents an array on file. It provides methods to
	  write/read data to/from array objects in the file. This
	  class does not allow you to enlarge the datasets on disk;
	  see the <verb>EArray</verb> descendant in <ref
	  refid="EArrayClassDescr">section</ref> if you want
	  enlargeable dataset support and/or compression features.
	</p>

        <!-- arrays now support complex data types -->
	<p>The array data types supported are the same as the set
	  provided by <verb>Numeric</verb> and <verb>numarray</verb>.
	  For details of these data types see <ref
	  refid="datatypesSupported">appendix</ref>, or the
	  <verb>numarray</verb> reference manual (<cite
	  refid="Numarray"></cite>).
	</p>

	<p>Note that this object inherits all the public attributes
	  and methods that <verb>Leaf</verb> already provides.
	</p>

	<subsection id="ArrayClassInstanceVariables">
	  <heading><visual markup="tt">Array</visual> instance
	    variables</heading>
	  <description>
	    <term>flavor</term> <item>The object representation for
	      this array. It can be any of <em>"NumArray"</em>,
	      <em>"CharArray"</em> <em>"Numeric"</em>,
	      <em>"List"</em>, <em>"Tuple"</em>, <em>"String"</em>,
	      <em>"Int"</em> or <em>"Float"</em> values.
	    </item>
	    <term>nrows</term> <item>The length of the first dimension
	      of Array.
	    </item>
	    <term>nrow</term> <item>On iterators, this is the index of
	      the current row.
	    </item>

	    <term>type</term> <item>The type class of the represented
	      array.
	    </item>

	    <term>itemsize</term> <item>The size of the base
              items. Specially useful for <verb>CharArray</verb>
              objects.
	    </item>
	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Array</visual>
	    methods</heading>

	  <p>Note that, as this object has no internal I/O buffers, it
	    is not necessary to use the flush() method inherited from
	    <verb>Leaf</verb> in order to save its internal state to
	    disk. When a writing method call returns, all the data is
	    already on disk.
	  </p>

	  <subsubsection>
	    <heading id="iterrowsArrayDescr">iterrows(start=None,
	      stop=None, step=1)</heading>

	    <p>Returns an iterator yielding <verb>numarray</verb>
	      instances built from rows in array. The return rows are
	      taken from the first dimension in case of an
	      <verb>Array</verb> instance and the enlargeable
	      dimension in case of an <verb>EArray</verb> instance. If
	      a range is supplied (i.e. some of the <em>start</em>,
	      <em>stop</em> or <em>step</em> parameters are passed),
	      only the appropriate rows are returned. Else, all the
	      rows are returned. See also the <verb>__call__()</verb>
	      and <verb>__iter__()</verb> special methods in <ref
	      refid="ArraySpecialMethods">section</ref> for shorter
	      ways to call this iterator.
	    </p>

	    <p>The meaning of the <em>start</em>, <em>stop</em> and
	      <em>step</em> parameters is the same as in the
	      <verb>range()</verb> python function, except that
	      negative values of <verb>step</verb> are not
	      allowed. Moreover, if only <verb>start</verb> is
	      specified, then <verb>stop</verb> will be set to
	      <verb>start+1</verb>. If you do not specify neither
	      <em>start</em> nor <em>stop</em>, then all the rows in
	      the object are selected.
	    </p>
	  </subsubsection>

	  <subsubsection id="readArrayDescr">
	    <heading>read(start=None, stop=None, step=1)</heading>

	    <p>Read the array from disk and return it as a
	      <verb>numarray</verb> (default) object, or an object
	      with the same original <em>flavor</em> that it was
	      saved. It accepts start, stop and step parameters to
	      select rows (the first dimension in the case of an
	      <verb>Array</verb> instance and the <em>enlargeable</em>
	      dimension in case of an <verb>EArray</verb>) for
	      reading.
	    </p>
	    <p>The meaning of the <em>start</em>, <em>stop</em> and
	      <em>step</em> parameters is the same as in the
	      <verb>range()</verb> python function, except that
	      negative values of <verb>step</verb> are not
	      allowed. Moreover, if only <verb>start</verb> is
	      specified, then <verb>stop</verb> will be set to
	      <verb>start+1</verb>. If you do not specify neither
	      <em>start</em> nor <em>stop</em>, then all the rows in
	      the object are selected.
	    </p>
	  </subsubsection> <!-- read() -->
	</subsection> <!-- Array methods -->

	<subsection id="ArraySpecialMethods">
	  <heading><visual markup="tt">Array</visual> special
	      methods</heading>

	  <p>Following are described the methods that automatically
	    trigger actions when an <verb>Array</verb> instance is
	    accessed in a special way (e.g.,
	    <verb>array[2:3,...,::2]</verb> will be equivalent to a
	    call to <newline/><verb>array.__getitem__(slice(2,3, None),
	    Ellipsis, slice(None, None, 2))</verb>).
	  </p>

	  <subsubsection>
	    <heading id="__callArrayDescr">__call__(start=None,
	      stop=None, step=1)</heading>

	    <p>It returns the same iterator than
	      <verb>Array.iterrows(start, stop, step)</verb>. It is,
	      therefore, a shorter way to call it.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      result = [ row for row in arrayInstance(step=4) ]
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      result = [ row for row in arrayInstance.iterrows(step=4) ]
	    </verbatim>

	  </subsubsection>
	  <subsubsection>
	    <heading id="__iterArrayDescr">__iter__()</heading>

	    <p>It returns the same iterator than
	      <verb>Array.iterrows(0,0,1)</verb>. However, this does not
	      accept parameters.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      result = [ row[2] for row in array ]

	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      result = [ row[2] for row in array.iterrows(0, 0, 1) ]
	    </verbatim>

	  </subsubsection>

	  <subsubsection>
	    <heading id="__getitemArrayDescr">__getitem__(key)</heading>

	    <p>It returns a <verb>numarray</verb> (default) object (or
	      an object with the same original <em>flavor</em> that it
	      was saved) containing the slice of rows stated in the
	      <verb>key</verb> parameter. The set of allowed tokens in
	      <verb>key</verb> is the same as extended slicing in
	      python (the <verb>Ellipsis</verb> token included).
	    </p>

	    <p>Example of use:</p>

	    <verbatim>
	      array1 = array[4]   # array1.shape == array.shape[1:]
	      array2 = array[4:1000:2]  # len(array2.shape) == len(array.shape)
	      array3 = array[::2, 1:4, :]
	      array4 = array[1, ..., ::2, 1:4, 4:] # General slice selection
	    </verbatim>

	  </subsubsection> <!-- __getitem__() -->
	</subsection> <!-- Special methods -->
      </section> <!-- Array class -->

      <section id="EArrayClassDescr">
	<heading>The <visual markup="tt">EArray</visual> class</heading>

	<p>This is a child of the <verb>Array</verb> class (see <ref
	  refid="ArrayClassDescr"></ref>) and as such,
	  <verb>EArray</verb> represents an array on the file. The
	  difference is that <verb>EArray</verb> allows to enlarge
	  datasets along any single dimension<footnote>In the future,
	  multiple enlargeable dimensions might be implemented as
	  well.</footnote> you select. Another important difference is
	  that it also supports compression.
	 </p>

	<p>So, in addition to the attributes and methods that
	  <verb>EArray</verb> inherits from <verb>Array</verb>, it
	  supports a few more that provide a way to enlarge the
	  arrays on disk. Following are described the new variables
	  and methods as well as some that already exist in
	  <verb>Array</verb> but that differ somewhat on the meaning
	  and/or functionality in the <verb>EArray</verb> context.
	</p>

	<subsection id="EArrayClassInstanceVariables">
	  <heading><visual markup="tt">EArray</visual> instance
	    variables</heading>
	  <description>
	    <term>atom</term> <item>The class instance chosen for the
	      atom object (see <ref refid="AtomClassDescr">section</ref>).
	    </item>
	    <term>extdim</term> <item>The enlargeable dimension.
	    </item>
	    <term>nrows</term> <item>The length of the enlargeable
	      dimension.
	    </item>
	  </description>
	</subsection>

	<subsection id="EArrayMethodsDescr">
	  <heading><visual markup="tt">EArray</visual>
	    methods</heading>

	  <subsubsection id="EArrayAppendDescr">
	    <heading>append(object)</heading>

	    <p>Appends an <verb>object</verb> to the underlying
	      dataset. Obviously, this object has to have the same
	      type as the <verb>EArray</verb> instance; otherwise a
	      <verb>TypeError</verb> is issued. In the same way, the
	      dimensions of the <verb>object</verb> have to conform to
	      those of <verb>EArray</verb>, that is, all the
	      dimensions have to be the same except, of course, that of
	      the enlargeable dimension which can be of any length
	      (even 0!).
	    </p>
	    <p>Example of use (code available in
	      <verb>examples/earray1.py</verb>):
	    </p>
	    <verbatim>
import tables
from numarray import strings

fileh = tables.openFile("earray1.h5", mode = "w")
a = tables.StringAtom(shape=(0,), length=8)
# Use 'a' as the object type for the enlargeable array
array_c = fileh.createEArray(fileh.root, 'array_c', a, "Chars")
array_c.append(strings.array(['a'*2, 'b'*4], itemsize=8))
array_c.append(strings.array(['a'*6, 'b'*8, 'c'*10], itemsize=8))

# Read the string EArray we have created on disk
for s in array_c:
    print "array_c[%s] => '%s'" % (array_c.nrow, s)
# Close the file
fileh.close()
	    </verbatim>

	    <p>and the output is:
	    </p>

	    <verbatim>
	      array_c[0] => 'aa'
	      array_c[1] => 'bbbb'
	      array_c[2] => 'aaaaaa'
	      array_c[3] => 'bbbbbbbb'
	      array_c[4] => 'cccccccc'
	    </verbatim>

	  </subsubsection> <!-- EArray.append -->
	</subsection> <!-- EArray methods -->
      </section> <!-- EArray class -->

      <section id="VLArrayClassDescr">
	<heading>The <visual markup="tt">VLArray</visual> class</heading>

	<p>Instances of this class represents array objects in the
	  object tree with the property that their rows can have a
	  <visual markup="bf">variable</visual> number of
	  (homogeneous) elements (called <em>atomic</em> objects, or
	  just <em>atoms</em>). Variable length arrays (or
	  <em>VLA's</em> for short), similarly to <verb>Table</verb>
	  instances, can have only one dimension, and likewise
	  <verb>Table</verb>, the compound elements (the
	  <em>atoms</em>) of the rows of <verb>VLArrays</verb> can be
	  fully multidimensional objects.
	</p>
	<p><verb>VLArray</verb> provides methods to read/write data
	  from/to variable length array objects residents on disk.
	  Also, note that this object inherits all the public
	  attributes and methods that <verb>Leaf</verb> already has.
	</p>

	<subsection>
	  <heading><visual markup="tt">VLArray</visual> instance
	    variables</heading>
	  <description>
	    <term>atom</term> <item>The class instance chosen for the
	      atom object (see <ref refid="AtomClassDescr">section</ref>).
	    </item>
	    <term>nrow</term> <item>On iterators, this is the index of
	      the current row.
	    </item>
	    <term>nrows</term> <item>The total number of rows.
	    </item>
	  </description>
	</subsection>

	<subsection>
	  <heading><visual markup="tt">VLArray</visual> methods</heading>

	  <subsubsection>
	    <heading
	      id="appendVLArrayDescr">append(object1, object2, ...)</heading>

	    <p>Append the <verb>objects</verb> passed as parameters to
	      a single row in the <verb>VLArray</verb> instance. The
	      type of the objects has to be compliant with the
	      <verb>VLArray.atom</verb> instance type.
	    </p>

	    <p>Example of use (code available in
	      <verb>examples/vlarray1.py</verb>):
	    </p>

	    <verbatim>
	      import tables
	      from Numeric import *   # or, from numarray import *

	      # Create a VLArray:
	      fileh = tables.openFile("vlarray1.h5", mode = "w")
	      vlarray = fileh.createVLArray(fileh.root, 'vlarray1',
	      tables.Int32Atom(flavor="Numeric"),
	                       "ragged array of ints", Filters(complevel=1))
	      # Append some (variable length) rows
	      # All these different parameter specification are accepted:
	      vlarray.append(array([5, 6]))
	      vlarray.append(array([5, 6, 7]))
	      vlarray.append([5, 6, 9, 8])
	      vlarray.append(5, 6, 9, 10, 12)

	      # Now, read it through an iterator
	      for x in vlarray:
	          print vlarray.name+"["+str(vlarray.nrow)+"]-->", x

	      # Close the file
	      fileh.close()
	    </verbatim>

	    <p>And the output for this looks like:</p>

	    <verbatim>
	      vlarray1[0]--> [5 6]
	      vlarray1[1]--> [5 6 7]
	      vlarray1[2]--> [5 6 9 8]
	      vlarray1[3]--> [ 5  6  9 10 12]
	    </verbatim>

	  </subsubsection> <!-- VLArray.append() -->

	  <subsubsection>
	    <heading id="iterrowsVLArrayDescr">iterrows(start=None,
	      stop=None, step=1)</heading>

	    <p>Returns an iterator yielding one row per iteration. If
	      a range is supplied (i.e. some of the <em>start</em>,
	      <em>stop</em> or <em>step</em> parameters are passed),
	      only the appropriate rows are returned. Else, all the
	      rows are returned. See also the <verb>__call__()</verb>
	      and <verb>__iter__()</verb> special methods in <ref
	      refid="VLArraySpecialMethods">section</ref> for shorter
	      ways to call this iterator.
	    </p>
	    <p>The meaning of the <em>start</em>, <em>stop</em> and
	      <em>step</em> parameters is the same as in the
	      <verb>range()</verb> python function, except that
	      negative values of <verb>step</verb> are not
	      allowed. Moreover, if only <verb>start</verb> is
	      specified, then <verb>stop</verb> will be set to
	      <verb>start+1</verb>. If you do not specify neither
	      <em>start</em> nor <em>stop</em>, then all the rows in
	      the object are selected.
	    </p>

	  </subsubsection> <!-- VLArray.iterrows -->

	  <subsubsection>
	    <heading id="readVLArrayDescr">read(start=None, stop=None,
	      step=1)</heading>

	    <p>Returns the actual data in <verb>VLArray</verb>. As the
	      lengths of the different rows are variable, the returned
	      value is a python list, with as many entries as
	      specified rows in the range parameters.
	    </p>
	    <p>The meaning of the <em>start</em>, <em>stop</em> and
	      <em>step</em> parameters is the same as in the
	      <verb>range()</verb> python function, except that
	      negative values of <verb>step</verb> are not
	      allowed. Moreover, if only <verb>start</verb> is
	      specified, then <verb>stop</verb> will be set to
	      <verb>start+1</verb>. If you do not specify neither
	      <em>start</em> nor <em>stop</em>, then all the rows in
	      the object are selected.
	    </p>
	  </subsubsection>

	</subsection> <!-- VLArray methods -->

	<subsection id="VLArraySpecialMethods">
	  <heading><visual markup="tt">VLArray</visual> special
	      methods</heading>

	  <p>Following are described the methods that automatically
	    trigger actions when a <verb>VLArray</verb> instance is
	    accessed in a special way (e.g., <verb>vlarray[2:5]</verb>
	    will be equivalent to a call to
	    <verb>vlarray.__getitem__(slice(2,5,None)</verb>).
	  </p>

	  <subsubsection>
	    <heading id="__callVLArrayDescr">__call__(start=None,
	      stop=None, step=1)</heading>

	    <p>It returns the same iterator than
	      <verb>VLArray.iterrows(start, stop, step)</verb>. It is,
	      therefore, a shorter way to call it.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      for row in vlarray(step=4):
	          print vlarray.name+"["+str(vlarray.nrow)+"]-->", row
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      for row in vlarray.iterrows(step=4):
	          print vlarray.name+"["+str(vlarray.nrow)+"]-->", row
	    </verbatim>

	  </subsubsection>
	  <subsubsection>
	    <heading id="__iterVLArrayDescr">__iter__()</heading>

	    <p>It returns the same iterator than
	      <verb>VLArray.iterrows(0,0,1)</verb>. However, this does
	      not accept parameters.</p>

	    <p>Example of use:</p>

	    <verbatim>
	      result = [ row for row in vlarray ]
	    </verbatim>

	    <p>Which is equivalent to:</p>

	    <verbatim>
	      result = [ row for row in vlarray.iterrows() ]
	    </verbatim>

	  </subsubsection>

	  <subsubsection>
	    <heading id="__getitemVLArrayDescr">__getitem__(key)</heading>

	    <p>It returns the slice of rows determined by
	      <verb>key</verb>, which can be an integer index or an
	      extended slice. The returned value is a list of objects
	      of type <verb>array.atom.type</verb>.
	    </p>

	    <p>Example of use:</p>

	    <verbatim>
	      list1 = vlarray[4]
	      list2 = vlarray[4:1000:2]
	    </verbatim>

	  </subsubsection> <!-- VLArray __getitem__ -->
	</subsection> <!-- VLArray special methods --> 
      </section> <!-- VLArray class -->

      <section id="UnImplementedClassDescr">
	<heading>The <visual markup="tt">UnImplemented</visual> class</heading>

	<p>Instances of this class represents an unimplemented dataset
	  in a generic HDF5 file. When reading such a file (i.e. one
	  that has not been created with <verb>PyTables</verb>, but
	  with some other HDF5 library based tool), chances are that
	  the specific combination of <em>datatypes</em> and/or
	  <em>dataspaces</em> in some dataset might not be supported
	  by <verb>PyTables</verb> yet. In such a case, this dataset
	  will be mapped into the <verb>UnImplemented</verb> class and
	  hence, the user will still be able to build the complete
	  object tree of this generic HDF5 file, as well as enabling
	  the access (both read and <em>write</em>) of the attributes
	  of this dataset and some metadata. Of course, the user won't
	  be able to read the actual data on it.
	</p>

	<p>This is an elegant way to allow users to work with generic
	  HDF5 files despite the fact that some of its datasets would
	  not be supported by <verb>PyTables</verb>. However, if you
	  are really interested in having access to an unimplemented
	  dataset, please, get in contact with the developer team.
	</p>
	<p>This class does not have any public instance variables,
	  except those inherited from the <verb>Leaf</verb> class
	  (<ref refid="LeafClassDescr">see</ref>).
	</p>
      </section> <!-- UnImplemented class -->

      <section id="AttributeSetClassDescr">
	<heading>The <visual markup="tt">AttributeSet</visual>
	class</heading>

	<p>Represents the set of attributes of a node (Leaf or
	  Group). It provides methods to create new attributes, open,
	  rename or delete existing ones.
	</p>

	<p>Like in <verb>Group</verb> instances,
           <verb>AttributeSet</verb> instances make use of the
           <em>natural naming</em> convention, i.e. you can access the
           attributes on disk like if they were <em>normal</em>
           <verb>AttributeSet</verb> attributes. This offers the user
           a very convenient way to access (but also to set and
           delete) node attributes by simply specifying them like a
           <em>normal</em> attribute class.
        </p>

	<p><visual markup="bf">Caveat:</visual> All Python data types
	  are supported. The scalar ones (i.e. String, Int and Float)
	  are mapped directly to the HDF5 counterparts, so you can
	  correctly visualize them with any HDF5 tool. However, the
	  rest of the data types and more general objects are
	  serialized using <verb>cPickle</verb>, so you will be able
	  to correctly retrieve them only from a Python-aware HDF5
	  library. Hopefully, the list of supported native attributes
	  will be extended to fully multidimensional arrays sometime
	  in the future.
	</p>

	<subsection id="AttributeSetClassInstanceVariables">
	  <heading><visual markup="tt">AttributeSet</visual> instance
	    variables</heading>
	  <description>

	    <term>_v_node</term> <item>The parent node instance.</item>

	    <term>_v_attrnames</term> <item>List with all attribute
	      names.</item>

	    <term>_v_attrnamessys</term> <item>List with system attribute
	      names.</item>

	    <term>_v_attrnamesuser</term> <item>List with user attribute
	      names.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">AttributeSet</visual>
	    methods</heading>

	  <p>Note that this class define the <verb>__setattr__</verb>,
	    <verb>__getattr__</verb> and <verb>__delattr__</verb> and
	    they work as normally intended. So, you can access, assign
	    or delete attributes on disk by just using the next
	    constructs:

	    <verbatim>
	      leaf.attrs.myattr = "string attr"  # Set the attribute myattr
	      attrib = leaf.attrs.myattr  # Get the attribute myattr
	      del leaf.attrs.myattr       # Delete the attribute myattr
	    </verbatim>             

	  </p>

	  <description>
	    <term id="copyAttrDescr">_f_copy(where)</term><item>Copy
	      the user attributes to <em>where</em>
	      object. <em>where</em> has to be a <verb>Group</verb> or
	      <verb>Leaf</verb> instance.
	    </item>
	    <term id="listAttrDescr">_f_list(attrset = "user")</term>
	    <item>Return the list of attributes of the parent
	    node. <em>attrset</em> selects the attribute set to be
	    returned. An <verb>"user"</verb> value returns only the
	    user attributes and this is the
	    default. <verb>"sys"</verb> returns only the system (some
	    of which are read-only)
	    attributes. <verb>"readonly"</verb> returns the system
	    read-only attributes. <verb>"all"</verb> returns both the
	    system and user attributes.
	    </item>

	    <term id="renameAttrDescr">_f_rename(oldattrname,
	      newattrname)</term><item>Rename an attribute.</item>
	  </description>
	  
	</subsection>

      </section> <!-- AttributeSet class -->

      <section id="declarativeClasses">
	<heading>Declarative classes
	</heading>
	<p>In this section a series of classes that are meant to
	  <em>declare</em> datatypes that are required for primary
	  <verb>PyTables</verb> (like <verb>Table</verb> or
	  <verb>VLArray</verb> ) objects are described.
	</p>

	<subsection id="IsDescriptionClassDescr">
	  <heading>The <visual markup="tt">IsDescription</visual>
	    class</heading>

	  <p>This class is in fact a so-called <em>metaclass</em>
	    object. There is nothing special on this fact, except that
	    their subclasses attributes are transformed during its
	    instantiation phase, and new methods for instances are
	    defined based on the values of the class attributes.
	  </p>
	  <p>It is designed to be used as an easy, yet meaningful way
	    to describe the properties of <verb>Table</verb> objects
	    through the use of classes that inherit properties from
	    it. In order to define such a special class, you have to
	    declare it as descendant of <em>IsDescription</em>, with
	    many attributes as columns you want in your table. The
	    name of these attributes will become the name of the
	    columns, while its values are the properties of the
	    columns that are obtained through the use of the
	    <verb>Col</verb> class constructor. See the <ref
	    refid="ColClassDescr">section</ref> for instructions on
	    how define the properties of the table columns.
	  </p>
	  <p>Then, you can pass an instance of this object to the
	    <verb>Table</verb> constructor, where all the information it
	    contains will be used to define the table structure. See
	    the <ref refid="secondExample">section</ref> for an example
	    on how that works.
	  </p>

	</subsection> <!-- isDescription -->

	<subsection id="ColClassDescr">
	  <heading>The <visual markup="tt">Col</visual> class and its descendants</heading>

	  <p>The <verb>Col</verb> class is used as a mean to declare
	    the different properties of a table column. In addition, a
	    series of descendant classes are offered in order to make
	    these column descriptions easier to the user. In general,
	    it is recommended to use these descendant classes, as they
	    are more meaningful when found in the middle of the code.
	    Caveat: tables do not yet support complex datatypes.
	  </p>
	  <p>Note that the only public method accessible in these
	    classes is the constructor itself.
	  </p>

	  <description>

	    <term>Col(dtype="Float64", shape=1, dflt=None, pos=None)
	    </term>
	    <item>Declare the properties of a <verb>Table</verb>
	      column.

	      <description>

		<term>dtype</term> <item>The data type for the
		  column. 
		  It is an error to specify a complex datatype in the Col
		  constructor or in a <visual
		  markup="tt">IsDescription</visual> class declaration.
		  However, all
		  other types listed in <ref refid="datatypesSupported">
		  appendix</ref> are valid data types for columns.
		  The type description is accepted both in
		  string format and as a numarray data type.</item>

		<term>shape</term> <item>An integer or a tuple, that
		  specifies the number of <em>dtype</em> items for
		  each element (or shape, for multidimensional
		  elements) of this column. For <verb>CharType</verb>
		  columns, the last dimension is used as the length
		  of the character strings. However, for this kind of
		  objects, the use of <verb>StringCol</verb> subclass
		  is strongly recommended.</item>

		<term>dflt</term> <item>The default value for elements
		  of this column. If the user does not supply a value
		  for an element while filling a table, this default
		  value will be written to disk. If the user supplies an
		  scalar value for a multidimensional column, this value
		  is automatically <em>broadcasted</em> to all the
		  elements in the column cell. If <em>dflt</em> is not
		  supplied, an appropriate zero value (or <em>null</em>
		  string) will be chosen by default.</item>

		<term>pos</term> <item>By default, columns are arranged
		  in memory following an alpha-numerical order of the
		  column names. In some situations, however, it is
		  convenient to impose a user defined
		  ordering. <em>pos</em> parameter allows the user to
		  force the desired ordering.</item>

	      </description>
	    </item>

	    <term>StringCol(length=None, dflt=None, shape=1, pos=None)
	    </term>
	    <item>Declare a column to be of type
	      <verb>CharType</verb>. The <em>length</em> parameter
	      sets the length of the strings. The meaning of the other
	      parameters are like in the <verb>Col</verb> class.
	    </item>

	    <term>BoolCol(dflt=0, shape=1, pos=None) </term>
	      <item>Define a column to be of type <verb>Bool</verb>.
	      The meaning of the parameters are the same of those in
	      the <verb>Col</verb> class.
	    </item>

	    <term>IntCol(dflt=0, shape=1, itemsize=4, sign=1, pos=None)
	    </term>
	    <item>Declare a column to be of type <verb>IntXX</verb>,
	      depending on the value of <em>itemsize</em> parameter,
	      that sets the number of bytes of the integers in the
	      column. <em>sign</em> determines whether the integers
	      are signed or not. The meaning of the other parameters
	      are the same of those in the <verb>Col</verb> class.

	      <p>This class has several descendants:
	      </p>

	      <description>
		<term>Int8Col(dflt=0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>Int8</verb>.</item>

		<term>UInt8Col(dflt=0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>UInt8</verb>.</item>

		<term>Int16Col(dflt=0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>Int16</verb>.</item>

		<term>UInt16Col(dflt=0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>UInt16</verb>.</item>

		<term>Int32Col(dflt=0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>Int32</verb>.</item>

		<term>UInt32Col(dflt=0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>UInt32</verb>.</item>

		<term>Int64Col(dflt=0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>Int64</verb>.</item>

		<term>UInt64Col(dflt=0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>UInt64</verb>.</item>

	      </description>

	    </item>

	    <term>FloatCol(dflt=0, shape=1, itemsize=8, pos=None)
	    </term>
	    <item>Define a column to be of type <verb>FloatXX</verb>,
	      depending on the value of <verb>itemsize</verb>. The
	      <verb>itemsize</verb> parameter sets the number of bytes
	      of the floats in the column and the default is 8 bytes
	      (double precision). The meaning of the other parameters
	      are the same as those in the <verb>Col</verb> class.

	      <p>This class has two descendants:
	      </p>

	      <description>
		<term>Float32Col(dflt=0.0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>Float32</verb>.</item>

		<term>Float64Col(dflt=0.0, shape=1, pos=None)</term>
		<item>Define a column of type <verb>Float64</verb>.</item>

	      </description>
	    </item>
	  </description>

	</subsection> <!-- Col classes -->

	<subsection id="AtomClassDescr">
	  <heading>The <visual markup="tt">Atom</visual> class and its
	    descendants.
	  </heading>
	  <p>The <verb>Atom</verb> class is meant to declare the
	    different properties of the <em>base element</em> (also
	    known as <em>atom</em>) of <verb>EArray</verb> and
	    <verb>VLArray</verb> objects. The <verb>Atom</verb>
	    instances have the property that their length is always the
	    same. However, you can grow objects along the extendable
	    dimension in the case of <verb>EArray</verb> or put a
	    variable number of them on a <verb>VLArray</verb>
	    row. Moreover, the atoms are not restricted to scalar
	    values, and they can be fully multidimensional objects.
	  </p>
	  <p>A series of descendant classes are offered in order to
	    make the use of these element descriptions easier. In
	    general, it is recommended to use these descendant
	    classes, as they are more meaningful when found in the
	    middle of the code. Note that the only public methods
	    accessible in these classes are the
	    <verb>atomsize()</verb> method and the constructor
	    itself. The <verb>atomsize()</verb> method returns the
	    total length, in bytes, of the element base atom.
	  </p>
	  <p>A description of the different constructors with their
	    parameters follows:
	  </p>

	  <description>
	    <term>Atom(dtype="Float64", shape=1, flavor="NumArray")
	    </term>
	    <item>Define properties for the base elements of
	      <verb>EArray</verb> and <verb>VLArray</verb> objects.
	      <description>
		<term>dtype</term> <item>The data type for the base
		  element. See the <ref
		  refid="datatypesSupported">appendix</ref> for a
		  relation of data types supported. The type
		  description is accepted both in string format and as
		  numarray data type.
		</item>

		<term>shape</term> <item>In a <verb>EArray</verb>
		  context, it is a <visual markup="bf">tuple</visual>
		  specifing the shape of the object, and one (and only
		  one) of its dimensions <visual
		  markup="bf">must</visual> be 0, meaning that the
		  <verb>EArray</verb> object will be enlarged along
		  this axis. In the case of a <verb>VLArray</verb>, it
		  can be an integer with a value of 1 (one) or a
		  tuple, that specifies whether the atom is an scalar
		  (in the case of a 1) or has multiple dimensions (in
		  the case of a tuple). For <!-- <verb>CharType</verb>
		  elements, the first dimension -->
		  <verb>CharType</verb> elements, the last dimension
		  is used as the length of the character
		  strings. However, for this kind of objects, the use
		  of <verb>StringAtom</verb> subclass is strongly
		  recommended.
		</item>

		<term>flavor</term>
		  <item>The object representation for this atom. It
		  can be any of <em>"CharArray"</em> or
		  <em>"String"</em> for the <verb>CharType</verb> type
		  and <em>"NumArray"</em>, <em>"Numeric"</em>,
		  <em>"List"</em> or <em>"Tuple"</em> for the rest of
		  the types. If the specified values differs from
		  <em>CharArray</em> or <em>NumArray</em> values, the
		  read atoms will be converted to that specific
		  flavor. If not specified, the atoms will remain in
		  their native format (i.e. <verb>CharArray</verb> or
		  <verb>NumArray</verb>).
		</item>
	      </description>

	    </item> <!-- Atom class -->

	    <term>StringAtom(shape=1, length=None,
	      flavor="CharArray")</term> <item>Define an atom to be of
	      <verb>CharType</verb> type. The meaning of the
	      <em>shape</em> parameter is the same as in the
	      <verb>Atom</verb> class. <em>length</em> sets the length
	      of the strings atoms. <em>flavor</em> can be whether
	      <verb>"CharArray"</verb> or
	      <verb>"String"</verb>. Unicode strings are not supported
	      by this type; see the <verb>VLStringAtom</verb> class if
	      you want Unicode support (only available for
	      <verb>VLAtom</verb> objects).
	    </item>

	    <term>BoolAtom(shape=1, flavor="NumArray") </term>
	      <item>Define an atom to be of type <verb>Bool</verb>.
	      The meaning of the parameters are the same of those in
	      the <verb>Atom</verb> class.
	    </item>

	    <term>IntAtom(shape=1, itemsize=4, sign=1,
	      flavor="NumArray") </term> <item>Define an atom to be of
	      type <verb>IntXX</verb>, depending on the value of
	      <em>itemsize</em> parameter, that sets the number of
	      bytes of the integers that conform the
	      atom. <em>sign</em> determines whether the integers are
	      signed or not. The meaning of the other parameters are
	      the same of those in the <verb>Atom</verb> class.

	      <p>This class has several descendants:
	      </p>

	      <description>
		<term>Int8Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>Int8</verb>.</item>

		<term>UInt8Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>UInt8</verb>.</item>

		<term>Int16Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>Int16</verb>.</item>

		<term>UInt16Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>UInt16</verb>.</item>

		<term>Int32Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>Int32</verb>.</item>

		<term>UInt32Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>UInt32</verb>.</item>

		<term>Int64Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>Int64</verb>.</item>

		<term>UInt64Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>UInt64</verb>.</item>

	      </description>

	    </item>

	    <term>FloatAtom(shape=1, itemsize=8, flavor="NumArray")
	    </term>
	    <item>Define an atom to be of <verb>FloatXX</verb>
	      type, depending on the value of <verb>itemsize</verb>. The
	      <verb>itemsize</verb> parameter sets the number of bytes
	      of the floats in the atom and the default is 8 bytes
	      (double precision). The meaning of the other parameters
	      are the same as those in the <verb>Atom</verb> class.

	      <p>This class has two descendants:
	      </p>

	      <description>
		<term>Float32Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>Float32</verb>.</item>

		<term>Float64Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>Float64</verb>.</item>

	      </description>
	    </item>

	    <term>ComplexAtom(shape=1, itemsize=16, flavor="NumArray")
	    </term>
	    <item>Define an atom to be of <verb>ComplexXX</verb>
	      type, depending on the value of <verb>itemsize</verb>. The
	      <verb>itemsize</verb> parameter sets the number of bytes
	      of the floats in the atom and the default is 16 bytes
	      (double precision complex). The meaning of the other parameters
	      are the same as those in the <verb>Atom</verb> class.

	      <p>This class has two descendants:
	      </p>

	      <description>
		<term>Complex32Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>Complex32</verb>.</item>

		<term>Complex64Atom(shape=1, flavor="NumArray")</term>
		<item>Define an atom of type <verb>Complex64</verb>.</item>

	      </description>
	    </item>
	  </description>

	  <p>Now, there come two special classes,
	    <verb>ObjectAtom</verb> and <verb>VLString</verb>, that
	    actually do not descend from <verb>Atom</verb>, but which
	    goal is so similar that they should be described here. The
	    difference between them and the <verb>Atom</verb> and
	    descendents classes is that these special classes does not
	    allow multidimensional atoms, nor multiple values per
	    row. A <em>flavor</em> can't be specified neither as it is
	    immutable (see below).
	  </p>
	  <p><visual markup="bf">Caveat emptor:</visual> You are only
	    allowed to use these classes to create
	    <verb>VLArray</verb> objects, not <verb>EArray</verb>
	    objects.
	  </p>

	  <description>
	    <term>ObjectAtom()</term> <item>This class is meant to fit
	      <em>any</em> kind of object in a row of an
	      <verb>VLArray</verb> instance by using
	      <verb>cPickle</verb> behind the scenes. Due to the fact
	      that you cannot foresee how long will be the output of
	      the <verb>cPickle</verb> serialization (i.e. the atom
	      already has a <em>variable</em> length), you can only
	      fit a representant of it per row. However, you can still
	      pass several parameters to the
	      <verb>VLArray.append()</verb> method as they will be
	      regarded as a <em>tuple</em> of compound objects (the
	      parameters), so that we still have only one object to be
	      saved in a single row. It does not accept parameters and
	      its flavor is automatically set to
	      <verb>"Object"</verb>, so the reads of rows always
	      returns an arbitrary python object.
	      
	      You can regard <verb>ObjectAtom</verb> types as an easy
	      way to save an arbitrary number of generic python
	      objects in a <verb>VLArray</verb> object.
	    </item>

	    <term>VLStringAtom()</term> <item>This class describes a
	      <em>row</em> of the <verb>VLArray</verb> class, rather
	      than an <em>atom</em>. It differs from the
	      <verb>StringAtom</verb> class in that you can only add
	      one instance of it to one specific row, i.e. the
	      <verb>VLArray.append()</verb> method only accepts one
	      object when the base atom is of this type. Besides, it
	      supports Unicode strings (contrarily to
	      <verb>StringAtom</verb>) because it uses the UTF-8
	      codification (this is why its <verb>atomsize()</verb>
	      method returns always 1) when serializing to disk. It
	      does not accept any parameter and because its
	      <em>flavor</em> is automatically set to
	      <verb>"VLString"</verb>, the reads of rows always
	      returns a python string. See the <ref
	      refid="VLArrayFormatDescr">appendix</ref> if you are
	      curious on how this is implemented at the low-level.

	      You can regard <verb>VLStringAtom</verb> types as an
	      easy way to save generic variable length strings.
	    </item>
	  </description>

<!-- 	  <p>See in this example how to use the different atom types: -->
<!-- 	  </p> -->
	  
<!-- 	  <verbatim> -->
<!-- # -*- coding: latin-1 -*- -->
<!-- from numarray import * -->
<!-- from tables import * -->

<!-- # Open a new empty HDF5 file -->
<!-- fileh = openFile("vlarray2.h5", mode = "w") -->
<!-- # Get the root group -->
<!-- root = fileh.root -->
<!-- # Boolean arrays -->
<!-- vlarray = fileh.createVLArray(root, 'vlarray1', BoolAtom(2), "Boolean atoms") -->
<!-- vlarray.append([[1,0]]) -->
<!-- vlarray.append([1,0], [3,0], [0, 20])  # This will be converted to booleans -->
<!-- # Unicode variable length strings (with Unicode support) -->
<!-- vlarray = fileh.createVLArray(root, 'vlarray2', VLStringAtom(), -->
<!--                               "Variable Length String") -->
<!-- vlarray.append(u"asd") -->
<!-- vlarray.append(u"")   # The empty string -->
<!-- vlarray.append(u"aaañá") -->
<!-- # Create an VLArray made of objects -->
<!-- vlarray = fileh.createVLArray(root, 'vlarray3', ObjectAtom(), -->
<!--                               "pickled object") -->
<!-- vlarray.append({"passwd": "abracadabra"}) # A dictionary -->
<!-- vlarray.append()  # An empty row -->
<!-- vlarray.append(["123", "456"], "3") # Different objects (tuple) on a single row -->
<!-- # Close the file -->
<!-- fileh.close() -->
<!-- # Open the file for reading -->
<!-- fileh = openFile("vlarray2.h5", mode = "r") -->
<!-- for vlarray in fileh.listNodes(fileh.root, "VLArray"): -->
<!--     print repr(vlarray) -->
<!--     for i in range(vlarray.nrows): -->
<!--         print "%s[%s] -\-> &lt;%s>" % (vlarray.name, i, vlarray[i]) -->
<!-- 	  </verbatim> -->

<!-- 	  <p>The output:</p> -->

<!-- 	  <verbatim> -->
<!-- /vlarray1 (VLArray(2,)) 'Boolean atoms' -->
<!--   atom = Atom(type=Bool, shape=1, flavor='NumArray') -->
<!--   nrows = 2 -->
<!--   flavor = 'NumArray' -->
<!--   byteorder = 'little' -->
<!-- vlarray1[0] -\-> &lt;[1]> -->
<!-- vlarray1[1] -\-> &lt;[1 0 1]> -->
<!-- /vlarray2 (VLArray(3,)) 'Variable Length String' -->
<!--   atom = VLString() -->
<!--   nrows = 3 -->
<!--   flavor = 'VLString' -->
<!--   byteorder = 'little' -->
<!-- vlarray2[0] -\-> &lt;asd> -->
<!-- vlarray2[1] -\-> &lt;> -->
<!-- vlarray2[2] -\-> &lt;aaañá> -->
<!-- /vlarray3 (VLArray(3,)) 'pickled object' -->
<!--   atom = Object() -->
<!--   nrows = 3 -->
<!--   flavor = 'Object' -->
<!--   byteorder = 'little' -->
<!-- vlarray3[0] -\-> &lt;{'passwd': 'abracadabra'}> -->
<!-- vlarray3[1] -\-> &lt;None> -->
<!-- vlarray3[2] -\-> &lt;(['123', '456'], '3')> -->
<!-- 	  </verbatim> -->

	  <p>See <verb>examples/vlarray1.py</verb> and
	    <verb>examples/vlarray2.py</verb> for further examples on
	    <verb>VLArray</verb>s, including object serialization and
	    Unicode string management.
	  </p>

	</subsection> <!-- Atom and its descendants -->
      </section> <!-- Declarative classes -->

      <section id="helperClasses">
	<heading>Helper classes</heading>

	<p>In this section are listed classes that does not fit in any
	  other section and that mainly serves for ancillary
	  purposes.</p>

	<subsection id="FiltersClassDescr">
	  <heading>The <visual markup="tt">Filters</visual> class
	  </heading>

	  <p>This class is meant to serve as a container that keeps
	    information about the filter properties associated with
	    the enlargeable leaves, that is <verb>Table</verb>,
	    <verb>EArray</verb> and <verb>VLArray</verb>.
	  </p>

	  <p>The public variables of <verb>Filters</verb> are listed
	    below:
	  </p>

	  <description>
	    <term>complevel</term> <item>The compression level (0
	      means no compression).
	    </item>
	    <term>complib</term> <item>The compression filter used (in
	      case of compressed dataset).
	    </item>
	    <term>shuffle</term> <item>Whether the shuffle filter is
	      active or not.
	    </item>
	    <term>fletcher32</term> <item>Whether the fletcher32
	      filter is active or not.
	    </item>
	  </description>

	  <p>There are no <verb>Filters</verb> public methods with the
	    exception of the constructor itself that is described
	    next.
	  </p>

	  <subsubsection id="FiltersInitDescr">
	    <heading><visual markup="tt">Filters(complevel=0,
		complib="zlib", shuffle=1, fletcher32=0)</visual>
	    </heading>

	    <p>The parameters that can be passed to the
	      <verb>Filters</verb> class constructor are:
	    </p>

	    <description>
	      <term>complevel</term> <item>Specifies a compress level
		for data. The allowed range is 0-9. A value of 0
		disables compression. The default is that compression
		is disabled, that balances between compression effort
		and CPU consumption.
	      </item>
	      <term>complib</term> <item> Specifies the compression
		library to be used. Right now, <verb>"zlib"</verb>
		(default), <verb>"lzo"</verb> and <verb>"ucl"</verb>
		values are supported. See <ref
		  refid="compressionIssues">section</ref> for some advice
		on which library is better suited to your needs.
	      </item>
	      <term>shuffle</term><item>Whether or not to use the
		<em>shuffle</em> filter present in the
		<verb>HDF5</verb> library. This is normally used to
		improve the compression ratio (at the cost of
		consuming a little bit more CPU time). A value of 0
		disables shuffling and 1 makes it active. The default
		value depends on whether compression is enabled or
		not; if compression is enabled, shuffling defaults to
		be active, else shuffling is disabled.
	      </item>
	      <term>fletcher32</term> <item>Whether or not to use the
		<em>fletcher32</em> filter in the HDF5 library. This
		is used to add a checksum on each data chunk. A value
		of 0 disables the checksum and it is the default.
	      </item>
	    </description>
	    
	    <p>Of course, you can also create an instance and then
	      assign the ones you want to change. For example:
	      <verbatim>
import numarray as na
from tables import *

fileh = openFile("test5.h5", mode = "w")
atom = Float32Atom(shape=(0,2))
filters = Filters(complevel=1, complib = "lzo")
filters.fletcher32 = 1
arr = fileh.createEArray(fileh.root, 'earray', atom, "A growable array",
                         filters = filters)
# Append several rows in only one call
arr.append(na.array([[1., 2.],
                     [2., 3.],
                     [3., 4.]], type=na.Float32))

# Print information on that enlargeable array
print "Result Array:"
print repr(arr)

fileh.close()
	      </verbatim>
	      This enforces the use of the <verb>LZO</verb> library, a
	      compression level of 1 and a fletcher32 checksum filter
	      as well. See the output of this example:
	      <verbatim>
Result Array:
/earray (EArray(3L, 2), fletcher32, shuffle, lzo(1)) 'A growable array'
  type = Float32
  shape = (3L, 2)
  itemsize = 4
  nrows = 3
  extdim = 0
  flavor = 'NumArray'
  byteorder = 'little'
	      </verbatim>
	    </p>
	  </subsubsection> <!-- Filters constructor method -->
	</subsection> <!-- Filters class -->
      </section> <!-- Helper classes -->
    </chapter>

    <chapter id="optimizationTips">
      <heading>Optimization tips</heading>

<!--       <aphorism>... durch planmässiges Tattonieren.  <caption>Johann -->
<!-- 	Karl Friedrich Gauss <newline/>[asked how he came upon his -->
<!-- 	theorems]</caption> -->
<!--       </aphorism> -->

      <p>On this chapter, you will get deeper knowledge of
	<verb>PyTables</verb> internals. <verb>PyTables</verb> has
	several places where the user can improve the performance of
	his application. If you are planning to deal with really large
	data, you should read carefully this section in order to learn
	how to get an important boost for your code. But if your
	dataset is small or medium size (say, up to 1 MB), you should
	not worry about that as the default parameters in
	<verb>PyTables</verb> are already tuned to handle that
	perfectly.
      </p>

      <section>
	<heading>Taking advantage of Psyco</heading>

	<p>Psyco (see <cite refid="psycoRef"></cite>) is a kind of
	  specialized compiler for Python that typically accelerates
	  Python applications with no change in source code. You can
	  think of Psyco as a kind of just-in-time (JIT) compiler, a
	  little bit like Java's, that emits machine code on the fly
	  instead of interpreting your Python program step by
	  step. The result is that your unmodified Python programs run
	  faster.
	</p>

	<p>Psyco is very easy to install and use, so in most scenarios
	  it is worth to give it a try. However, it only runs on Intel
	  386 architectures, so if you are using other architectures,
	  you are out of luck (at least until Psyco will support
	  yours).
	</p>

	<p>As an example, imagine that you have a small script that
	  reads and selects data over a series of datasets, like this:
	</p>

	<verbatim>
def readFile(filename):
    "Select data from all the tables in filename"

    fileh = openFile(filename, mode = "r")
    result = []
    for table in fileh("/", 'Table'):
        result = [ p['var3'] for p in table if p['var2'] &lt;= 20 ]

    fileh.close()
    return e

if __name__=="__main__":
    print readFile("myfile.h5")
	</verbatim>

	<p>In order to accelerate this piece of code, you can rewrite
	  your main program to look like:
	</p>

	<verbatim>
if __name__=="__main__":
    import pysco
    psyco.bind(readFile)
    print readFile("myfile.h5")
	</verbatim>

	<p>That's all!. From now on, each time that you execute your
	  Python script, Psyco will deploy its sophisticated
	  algorithms so as to accelerate your calculations.
	</p>

	<p>You can see in the graphs <ref
	  refid="psycoWriteComparison"></ref> and <ref
	  refid="psycoReadComparison"></ref> how much I/O speed
	  improvement you can get by using Psyco. By looking at this
	  figures you can get an idea if these improvements are of
	  your interest or not. In general, if you are not going to
	  use compression you will take advantage of Psyco if your
	  tables are medium sized (from a thousand to a million rows),
	  and this advantage will disappear progressively when the
	  number of rows grows well over one million. However if you
	  use compression, you will probably see improvements even
	  beyond this limit (see <ref
	  refid="compressionIssues">section</ref>). As always, there
	  is no substitute for experimentation with your own dataset.
	</p>

	<figure id="psycoWriteComparison">
	  <graphics file="write-medium-psyco-nopsyco-comparison" scale="0.75" kind="vector">
	  </graphics>
	  <caption>Writing tables with/without Psyco.
	  </caption>
	</figure>

	<figure id="psycoReadComparison">
	  <graphics file="read-medium-psyco-nopsyco-comparison" scale="0.75" kind="vector">
	  </graphics>
	  <caption>Reading tables with/without Psyco.
	  </caption>
	</figure>

      </section> 

      <section id="compressionIssues">
	<heading>Compression issues</heading>

	<p>One of the beauties of <verb>PyTables</verb> is that it
	  supports compression on tables (but not on arrays!, that may
	  come later), although it is disabled by default. Compression
	  of big amounts of data might be a bit controversial feature,
	  because compression has a legend of being a very big CPU
	  time resources consumer. However, if you are willing to
	  check if compression can help not only reducing your dataset
	  file size but <visual markup="bf">also</visual> improving
	  your I/O efficiency, keep reading.
	</p>

	<p>There is an usual scenario where users need to save
	  duplicated data in some record fields, while the others
	  have varying values. In a relational database approach
	  such redundant data can normally be moved to other
	  tables and a relationship between the rows on the separate
	  tables can be created. But that takes analysis and
	  implementation time, and makes the underlying libraries
	  more complex and slower.
	</p>

	<p><verb>PyTables</verb> transparent compression allows the
	  users to not worry about finding which is their optimum data
	  tables strategy, but rather use less, not directly related,
	  tables with a larger number of columns while still not
	  cluttering the database too much with duplicated data
	  (compression is responsible to avoid that). As a side
	  effect, data selections can be made more easily because you
	  have more fields available in a single table, and they can
	  be referred in the same loop. This process may normally end
	  in a simpler, yet powerful manner to process your data
	  (although you should still be careful about in which kind of
	  scenarios compression use is convenient or not).
	</p>

	<p>The compression library used by default is the <visual
	    markup="bf">Zlib</visual> (see <cite
	    refid="zlibRef"></cite>), and as HDF5 <em>requires</em>
	  it, you can safely use it and expect that your HDF5 files
	  will be readable on any other platform that has HDF5 libraries
	  installed. Zlib provides good compression ratio, although
	  somewhat slow, and reasonably fast decompression. Because
	  of that, it is a good candidate to be used for compressing
	  you data.
	</p>

	<p>However, in many situations (i.e. write <em>once</em>, read
	  <em>multiple</em>), it is critical to have <em>very
	  good</em> decompression speed (at expense of whether less
	  compression or more CPU wasted on compression, as we will
	  see soon). This is why support for two additional
	  compressors has been added to PyTables: LZO and UCL (see
	  <cite refid="lzouclRef"></cite>). Following his author (and
	  checked by the author of this manual), LZO offers pretty
	  fast compression (although small compression ratio) and
	  extremely fast decompression while UCL achieves an excellent
	  compression ratio (at the price of spending much more CPU
	  time) while allowing very fast decompression (and <em>very
	  close</em> to the LZO one). In fact, LZO and UCL are so fast
	  when decompressing that, in general (that depends on your
	  data, of course), writing and reading a compressed table is
	  actually faster (and sometimes <visual markup="bf">much
	  faster</visual>) than if it is uncompressed. This fact is
	  very important, specially if you have to deal with very
	  large amounts of data.
	</p>

	<p>Be aware that the LZO and UCL support in PyTables is not
	  standard on HDF5, so if you are going to use your PyTables
	  files in other contexts different from PyTables you will not
	  be able to read them. Still, see the <ref
	  refid="ptrepackDescr">appendix</ref> where the
	  <verb>ptrepack</verb> utility is described to find a way to
	  free your files from LZO or UCL dependencies, so that you
	  can use these compressors locally with the warranty that you
	  can replace them with ZLIB (or even remove compression
	  completely) if you want to export the files to other HDF5
	  tools afterwards.
	</p>

	<p>In order to give you a raw idea of what ratios would be
	  achieved, and what resources would be consumed, look at the
	  <ref refid="comprTblComparison">table</ref>. This table has
	  been obtained from synthetic data and with a somewhat
	  outdated PyTables version (0.5), so take this just as a
	  guide because your mileage will probably vary. Have also a
	  look at the graphs <ref
	  refid="lzozlibuclWriteComparison"></ref> and <ref
	  refid="lzozlibuclReadComparison"></ref> (these graphs have
	  been obtained with tables with different row sizes and
	  PyTables version than the previous example, so do not try
	  to directly compare the figures). They show how the speed of
	  writing/reading rows evolves as the size (the row number)
	  of tables grows. Even though in these graphs the size of one
	  single row is 56 bytes, you can most probably extrapolate
	  this figures to other row sizes. If you are curious about how well
	  compression can perform together with Psyco, look at the
	  graphs <ref refid="psycolzozlibuclWriteComparison"></ref>
	  and <ref refid="psycolzozlibuclReadComparison"></ref>. As
	  you can see, the results are pretty interesting.
	</p>

	<table id="comprTblComparison">
	  <!-- 	    <tabular preamble="lrrrrr"> -->
	  <tabular preamble="lccccc">
	    <tabhead>
	      <srow>Compr. Lib | File size (MB) | Time writing (s) |
		Time reading (s) | Speed writing (Krow/s) | 
		Speed reading (Krow/s) </srow>
	    </tabhead>
	    <tabbody>
	      <srow>NO COMPR     | 244.0 | 24.4 | 16.0  | 18.0 |  27.8</srow>
	      <srow>Zlib (lvl 1) |   8.5 | 17.0 |  3.11 | 26.5 | 144.4</srow>
	      <srow>Zlib (lvl 6) |   7.1 | 20.1 |  3.10 | 22.4 | 144.9</srow>
	      <srow>Zlib (lvl 9) |   7.2 | 42.5 |  3.10 | 10.6 | 145.1</srow>
	      <srow>LZO (lvl 1)  |   9.7 | 14.6 |  1.95 | 30.6 | 230.5</srow>
	      <srow>UCL (lvl 1)  |   6.9 | 38.3 |  2.58 | 11.7 | 185.4</srow>
	    </tabbody>
	  </tabular>
	  <caption>Comparison between different compression
	    libraries. The tests have been conducted on a Pentium 4 at 2
	    GHz and a hard disk at 4200 RPM.</caption>
	</table>

	<figure id="lzozlibuclWriteComparison">
	  <graphics file="write-medium-lzo-zlib-ucl-comparison" scale="0.75" kind="vector">
	  
	  </graphics>
	  <caption>Writing tables with several compressors.
	  </caption>
	</figure>

	<figure id="lzozlibuclReadComparison">
	  <graphics file="read-medium-lzo-zlib-ucl-comparison" scale="0.75" kind="vector">
	  
	  </graphics>
	  <caption>Reading tables with several compressors.
	  </caption>
	</figure>

	<figure id="psycolzozlibuclWriteComparison">
	  <graphics file="write-medium-psyco-lzo-zlib-ucl-comparison" scale="0.75" kind="vector">
	  
	  </graphics>
	  <caption>Writing tables with several compressors and Psyco.
	  </caption>
	</figure>

	<figure id="psycolzozlibuclReadComparison">
	  <graphics file="read-medium-psyco-lzo-zlib-ucl-comparison" scale="0.75" kind="vector">
	  
	  </graphics>
	  <caption>Reading tables with several compressors and Psyco.
	  </caption>
	</figure>

	<p>
	  By looking at graphs, you can expect that, generally
	  speaking, LZO would be the fastest both compressing and
	  uncompressing, but the one that achieves the worse
	  compression ratio (although that may be just ok for many
	  situations). UCL is the slowest when compressing, but is
	  faster than Zlib when decompressing, and, besides, it
	  achieves very good compression ratios (generally better than
	  Zlib). Zlib represents a balance between them: it's somewhat
	  slow compressing, the slowest during decompression, but it
	  normally achieves fairly good compression ratios.
	</p>

	<p>So, if your ultimate goal is reading as fast as possible,
	  choose LZO. If you want to reduce as much as possible your
	  data, while retaining good read speed, choose UCL. If you
	  don't mind too much about the above parameters and/or
	  portability is important for you, Zlib is your best bet.
	</p>

	<p>The compression level that I recommend to use for all
	  compression libraries is 1. This is the lowest level of
	  compression, but if you take the approach suggested above,
	  normally the redundant data is to be found in the same
	  row, so the redundant data locality is very high and such
	  a small level of compression should be enough to achieve a
	  good compression ratio on your data tables, saving CPU
	  cycles for doing other things. Nonetheless, in some
	  situations you may want to check how compression level
	  affects your application.
	</p>

	<p> You can select the compression library and level by
	  setting the <verb>complib</verb> and <verb>compress</verb>
	  keywords in the <verb>Filters</verb> class (see <ref
	  refid="FiltersClassDescr"></ref>). A compression level of 0
	  will completely disable compression (the default), 1 is the
	  less CPU time demanding level, while 9 is the maximum level
	  and most CPU intensive. Finally, have in mind that LZO is
	  not accepting a compression level right now, so, when using
	  LZO, 0 means that compression is not active, and any other
	  value means that LZO is active.
	</p>

      </section>

      <section>
	<heading>Shuffling (or how to make the compression process
	  more effective)</heading>

	<p>The <verb>HDF5</verb> library provides an interesting
	  filter that can leverage the results of your favorite
	  compressor. Its name is <em>shuffle</em>, and because it can
	  greatly benefit compression and it doesn't take many CPU
	  resources, it is active by <em>default</em> in
	  <verb>PyTables</verb> whenever compression is activated
	  (independently of the chosen compressor). It is of course
	  deactivated when compression is off (which is the default,
	  as you already should know).
	</p>

	<p>From the HDF5 reference manual:</p>

	<quote>The <em>shuffle</em> filter de-interlaces a block of data
	  by reordering the bytes. All the bytes from one consistent
	  byte position of each data element are placed together in
	  one block; all bytes from a second consistent byte position
	  of each data element are placed together a second block;
	  etc. For example, given three data elements of a 4-byte
	  datatype stored as 012301230123, shuffling will re-order
	  data as 000111222333. This can be a valuable step in an
	  effective compression algorithm because the bytes in each
	  byte position are often closely related to each other and
	  putting them together can increase the compression
	  ratio.
	</quote>

	<p>In <ref refid="comprShuffleComparison">table</ref> you can
	  see a benchmark that shows how the <em>shuffle</em> filter
	  can help to the different libraries to compress data in
	  three table datasets. Generally speaking, <em>shuffle</em>
	  makes the writing process (shuffling+compressing) faster
	  (between 7% and 22%), which is an interesting result in
	  itself. However, the reading process
	  (unshuffling+decompressing) is slower, but by a lesser
	  extent (between 3% and 18%).
	</p>
	<p>But the most remarkable fact is the level of compression
	  that compressor filters can achieve after <em>shuffle</em>
	  has passed over the data: the total file size can be up to
	  40 times smaller than the uncompressed file, and up to 5
	  times smaller than the already compressed files (!). Of
	  course, the data for doing this test is synthetic, and
	  <em>shuffle</em> seems to do a great work with it, so in
	  general, the results will vary in your case. However, due to
	  the small drawbacks (reads are slowed down by a small extent)
	  and its potential gains (faster writing, but specially much
	  better compression level), I do believe that it is a good
	  thing to have such a filter enabled by default in the battle
	  for discovering redundancy in your data.
	</p>

	<table id="comprShuffleComparison">
	  <!-- 	    <tabular preamble="lrrrrr"> -->
	  <tabular preamble="lrcccc">
	    <tabhead>
	      <srow>Compr. Lib | File size (MB) | Time writing (s) |
		Time reading (s) | Speed writing (MB/s) | 
		Speed reading (MB/s) </srow>
	    </tabhead>
	    <tabbody>
	      <srow>NO COMPR     | 165.4 | 24.5 | 17.13 |  6.6 |   9.6</srow>
	      <srow>Zlib (lvl 1) |  26.4 | 22.2 |  5.77 |  7.3 |  28.4</srow>
	      <srow>Zlib+shuffle |   4.0 | 19.0 |  5.94 |  8.6 |  27.6</srow>
	      <srow>LZO (lvl 1)  |  44.9 | 17.8 |  4.13 |  9.2 |  39.7</srow>
	      <srow>LZO+shuffle  |   4.3 | 16.4 |  5.03 |  9.9 |  32.6</srow>
	      <srow>UCL (lvl 1)  |  27.4 | 48.8 |  5.02 |  3.3 |  32.7</srow>
	      <srow>UCL+shuffle  |   3.5 | 38.1 |  5.31 |  4.3 |  30.9</srow>
	    </tabbody>
	  </tabular>
	  <caption>Comparison between different compression
	    libraries, with and without shuffling.
	    The tests have been conducted on a Pentium 4 at 2
	    GHz and a hard disk at 4200 RPM.</caption>
	</table>



      </section> <!-- Shuffle -->

      <section id="expectedRowsOptim">
	<heading>Informing <visual markup="tt">PyTables</visual>
	  about expected number of rows in tables</heading>

	<p>The underlying HDF5 library that is used by
	  <verb>PyTables</verb> takes the data in bunches of a
	  certain length, so-called <em>chunks</em>, to write them
	  on disk as a whole, i.e. the HDF5 library treats chunks as
	  atomic objects and disk I/O is always made in terms of
	  complete chunks. This allows data filters to be defined by
	  the application to perform tasks such as compression,
	  encryption, checksumming, etc. on entire chunks.
	</p>

	<p>An in-memory B-tree is used to map chunk structures on
	  disk. The more chunks that are allocated for a dataset the
	  larger the B-tree. Large B-trees take memory and cause
	  file storage overhead as well as more disk I/O and higher
	  contention for the metadata cache. Consequently, it's
	  important to balance between memory and I/O overhead
	  (small B-trees) and time to access data (big B-trees).
	</p>

	<p><verb>PyTables</verb> can determine an optimum chunk size
	  to make B-trees adequate to your dataset size if you help
	  it by providing an estimation of the number of rows for a
	  table. This must be made in table creation time by passing
	  this value in the <verb>expectedrows</verb> keyword of
	  <verb>createTable</verb> method (see <ref
	    refid="createTableDescr"></ref>).
	</p>

	<p>When your table size is bigger than 1 MB (take this figure
	  only as a reference, not strictly), by providing this guess
	  of the number of rows you will be optimizing the access to
	  your data. When the table size is larger than, say 100MB,
	  you are <visual markup="bf">strongly</visual> suggested to
	  provide such a guess; failing to do that may cause your
	  application doing very slow I/O operations and demanding
	  <visual markup="bf">huge</visual> amounts of memory. You
	  have been warned!.
	</p>

      </section>

      <section>
	<heading>Selecting an User Entry Point (UEP) in your
	  tree</heading>

	<p>If you have a <visual markup="bf">huge</visual> tree in
	  your data file with many nodes on it, creating the object
	  tree would take long time. Many times, however, you are
	  interested only in access to a part of the complete tree, so
	  you won't strictly need PyTables to build the entire object
	  tree in-memory, but only the <em>interesting</em> part.
	</p>

	<p>This is where the <verb>rootUEP</verb> parameter of
	  <verb>openFile</verb> function (see <ref
	  refid="openFileDescr"></ref>) can be helpful. Imagine that
	  you have a file called <verb>"test.h5"</verb> with the
	  associated tree that you can see in figure <ref
	  refid="rootUEPfig1"></ref>, and you are interested only in
	  the section marked in red.  You can avoid the build of all
	  the object tree by saying to <verb>openFile</verb> that your
	  root will be the <verb>/Group2/Group3</verb> group. That is:
	</p>
	<verbatim>
	  fileh = openFile("test.h5", rootUEP="/Group2/Group3")
	</verbatim>

	<p>As a result, the actual object tree built will be like the
	  one that can be seen in <ref
	  refid="rootUEPfig2">figure</ref>.
	</p>

	<p>Of course this has been a simple example and the use
	  of the <verb>rootUEP</verb> parameter was not very
	  necessary. But when you have <em>thousands</em> of nodes on
	  a tree, you will certainly appreciate the
	  <verb>rootUEP</verb> parameter.
	</p>

	<figure id="rootUEPfig1">
	  <graphics file="rootUEP1" scale="0.6" kind="vector">
	  </graphics>
	  <caption>Complete tree in file <visual
	    markup="tt">test.h5</visual>, and subtree of interest for
	    the user.
	  </caption>
	</figure>

	<figure id="rootUEPfig2">
	  <graphics file="rootUEP2" scale="0.75" kind="vector">
	  </graphics>
	  <caption>Resulting object tree derived from the use of the
	    <visual markup="tt">rootUEP</visual> parameter.
	  </caption>
	</figure>
	
      </section>

      <section>
	<heading>Compacting your <visual markup="tt">PyTables</visual>
	  files
	</heading>

	<p>Let's suppose that you have a file on which you have made a
	  lot of row deletions on one or more tables, or deleted many
	  leaves or even entire subtrees. These operations migth leave
	  <em>holes</em> (i.e. space that is not used anymore) in your
	  files, that may potentially affect not only the size of the
	  files but, more importantly, the performance of I/O. This is
	  because when you delete a lot of rows on a table, the space
	  is not automatically recovered on-the-flight. In addition,
	  if you add many more rows to a table than specified in the
	  <verb>expectedrows</verb> keyword in creation time this may
	  affect performace as well, as explained in <ref
	  refid="expectedRowsOptim">section</ref>.
	</p>

	<p>In order to cope with these issues, you should be aware
	  that a handy <verb>PyTables</verb> utility called
	  <verb>ptrepack</verb> can be very useful, not only to
	  compact your already existing <em>leaky</em> files, but also
	  to adjust some internal parameters (both in memory and in
	  file) in order to create adequate buffer sizes and chunk
	  sizes for optimum I/O speed. Please, check the <ref
	  refid="ptrepackDescr">appendix</ref> for a brief tutorial on
	  its use.
	</p>

	<p>Another thing that you might want to use
	  <verb>ptrepack</verb> for is changing the compression
	  filters or compression levels on your existing data for
	  different goals, like checking how this can affect both
	  final size and I/O performance, or getting rid of the
	  optional compressors like <verb>LZO</verb> or
	  <verb>UCL</verb> in your existing files in case you want to
	  use them with generic HDF5 tools that do not have support
	  for these filters.
	</p>

      </section>

    </chapter>

    <appendix>
      <chapter id="datatypesSupported">
	<heading>Supported data types in <visual
	markup="tt">PyTables</visual></heading>

	<p>The Array, VLArray and EArray classes can all 
	  handle all the data types supported by the <visual
	  markup="tt">numarray</visual> package (see <cite
	  refid="Numarray"></cite>) in Python.
	  The data types for array elements can be set through
	  the use of the <verb>Atom</verb> class and its descendants
	  (<ref refid="AtomClassDescr">see</ref>).
	</p>
	<p>In the case of tables, a subset of the numarray data types 
	  can be used to define the fields.
	  Such a set is the same as for arrays, with the exception of
	  the complex datatypes that are not supported yet.
	  The table fields can be set via the constructor for the <verb>
	  Col</verb> class and its decendants
	  (<ref refid="ColClassDescr">see</ref>),
	  or in a <verb>IsDescription</verb> class declaration
	  (<ref refid="IsDescriptionClassDescr">see</ref>).
	</p>
	<p>A quick reference to the complete set of data types supported by
	  PyTables is given in <ref refid="datatypesSupported">table</ref>.
	</p>

	<table id="datatypesSupportedTable">
	  <tabular preamble="lllclc">
	  <tabhead>
	    <srow>Type Code | Description | C Type | Size (in bytes) |
	      Python Counterpart | Supported in tables</srow>
	  </tabhead>
	  <tabbody>
	    <srow>Bool | boolean | unsigned char | 1 | Boolean | yes </srow>
	    <srow>Int8 | 8-bit integer | signed char | 1 | Integer | yes </srow>
	    <srow>UInt8 | 8-bit unsigned integer | unsigned char | 1 | Integer | yes </srow>
	    <srow>Int16 | 16-bit integer | short | 2 | Integer | yes </srow>
	    <srow>UInt16 | 16-bit unsigned integer | unsigned short | 2 | Integer | yes </srow>
	    <srow>Int32 | integer | int | 4  | Integer | yes </srow>
	    <srow>UInt32 | unsigned integer | unsigned int | 4 | Long | yes </srow>
	    <srow>Int64 | 64-bit integer | long long | 8 | Long | yes </srow>
	    <srow>UInt64 | unsigned 64-bit integer | unsigned long long | 8 | Long | yes </srow>
	    <srow>Float32 | single-precision float | float | 4 | Float | yes </srow>
	    <srow>Float64 | double-precision float | double | 8 | Float | yes </srow>
	    <srow>Complex32 | single-precision complex | struct {float r, i;} | 8 | Complex | no </srow>
	    <srow>Complex64 | double-precision complex | struct {double r, i;} | 16 | Complex | no </srow>
	    <srow>CharType | arbitrary length string | char[] | * | String | yes </srow>
	  </tabbody>
	</tabular>
	  <caption>Data types supported for array elements and
	      tables columns in PyTables.
	  </caption>
	</table>

      </chapter>  <!-- Data types supported -->

      <chapter id="PyTablesInternalFormat">
	<heading><visual markup="tt">PyTables</visual> File
	  Format</heading>

	<p><verb>PyTables</verb> has a powerful capability to deal
	  with native HDF5 files created with another tools. However,
	  there are situations were you may want to create truly
	  native <verb>PyTables</verb> files with those tools while
	  retaining fully compatibility with <verb>PyTables</verb>
	  format. That is perfectly possible, and in this appendix is
	  presented the format that you should endow to your
	  own-generated files in order to get a fully
	  <verb>PyTables</verb> compatible file.
	</p>

	<p>We are going to describe the <visual markup="bf">1.2
	  version of <verb>PyTables</verb> file format</visual>
	  (introduced in <verb>PyTables</verb> version 0.8). At this
	  stage, this file format is considered stable enough to do
	  not introduce significant changes during a reasonable
	  amount of time. As times goes by, some changes will be
	  introduced (and documented here) in order to cope with new
	  necessities. However, the changes will be carefully analyzed
	  so as to ensure backward compatibility whenever is possible.
	</p>

	<p>A <verb>PyTables</verb> file is composed with arbitrarily
	  large amounts of HDF5 groups (<verb>Groups</verb> in
	  <verb>PyTables</verb> naming scheme) and datasets
	  (<verb>Leaves</verb> in <verb>PyTables</verb> naming
	  scheme). For groups, the only requirements are that they
	  must have some <em>system attributes</em> available. By
	  convention, system attributes in <verb>PyTables</verb> are
	  written in upper case, and user attributes in lower case but
	  this is not enforced by the software. In the case of
	  datasets, besides the mandatory system attributes, some
	  conditions are further needed in their storage layout, as
	  well as in the datatypes used in there, as we will see
	  shortly.
	</p>

	<p>As a final remark, you can use any filter as you want to
	  create a <verb>PyTables</verb> file, provided that the
	  filter is a standard one in HDF5, like <em>zlib</em>,
	  <em>shuffle</em> or <em>szip</em> (although the last one
	  cannot be used from within <verb>PyTables</verb> to create a
	  new file, datasets compressed with szip can be read, because
	  it is the HDF5 library which do the decompression
	  transparently).
	</p>

	<section>
	  <heading>Mandatory attributes for a <visual
	      markup="tt">File</visual></heading>

	  <p>The <verb>File</verb> object is, in fact, an special HDF5
	    <em>group</em> structure that is <em>root</em> for the
	    rest of the objects on the object tree. The next
	    attributes are mandatory for the HDF5 <em>root group</em>
	    structure in <verb>PyTables</verb> files:
	  </p>

	  <description>
	    <term>CLASS</term> <item>This attribute should always be
	    set to <verb>'GROUP'</verb> for group structures.</item>
	    <term>PYTABLES_FORMAT_VERSION</term> <item>It represents
	    the internal format version, and currently should be set
	    to the <verb>'1.2'</verb> string.</item>
	    <term>TITLE</term> <item>A string where the user can put
	    some description on what is this group used for. </item>
	    <term>VERSION</term> <item>Should contains the string
	    <verb>'1.0'</verb>.</item>
	  </description>

	</section>
	<section>
	  <heading>Mandatory attributes for a <visual
	      markup="tt">Group</visual></heading>

	  <p>The next attributes are mandatory for <em>group</em>
	    structures:
	  </p>

	  <description>
	    <term>CLASS</term> <item>This attribute should always be
	    set to <verb>'GROUP'</verb> for group structures.</item>
	    <term>TITLE</term> <item>A string where the user can put
	    some description on what is this group used for. </item>
	    <term>VERSION</term> <item>Should contains the string
	    <verb>'1.0'</verb>.</item>
	  </description>

	  <p>There exist a special <verb>Group</verb>, called the
	    <em>root</em>, that, in addition to the attributes listed
	    above, it requires the next one:
	  </p>

	  <description>
	    <term>PYTABLES_FORMAT_VERSION</term> <item>It represents
	    the internal format version, and currently should be set
	    to the <verb>'1.2'</verb> string.</item>
	  </description>

	</section>

	<section>
	  <heading>Mandatory attributes, storage layout and supported
	      datatypes for <visual markup="tt">Leaves</visual>
	      </heading>

	  <p>This depends on the kind of <verb>Leaf</verb>. The
	    format for each type follows.
	  </p>

	  <subsection id="TableFormatDescr">
	    <heading><visual markup="tt">Table</visual>
	    format</heading>

	    <subsubsection>
	      <heading>Mandatory attributes</heading>

	      <p>The next attributes are mandatory for <em>table</em>
		structures:
	      </p>

	      <description>
		<term>CLASS</term> <item>Must be set to
		  <verb>'TABLE'</verb>.</item>

		<term>TITLE</term> <item>A string where the user can
		  put some description on what is this dataset used
		  for. </item>

		<term>VERSION</term> <item>Should contain the string
		  <verb>'2.1'</verb>.</item>

		<term>FIELD_X_NAME</term> <item>It contains the names
		  of the different fields. The <verb>X</verb> means
		  the number of the field (beware, order do
		  matter). You should add as many attributes of this
		  kind as fields you have in your records.
		</item>

		<term>NROWS</term> <item>This should contain the
		  number of <em>compound</em> datatype entries in the
		  dataset. It must be an <em>int</em> datatype.</item>
	      </description>

	    </subsubsection>

	    <subsubsection>
	      <heading>Storage Layout</heading>

	      <p>A <verb>Table</verb> has a <em>dataspace</em> with a
		<em>1-dimensional chunked</em> layout.
	      </p>
	    </subsubsection>

	    <subsubsection>
	      <heading>Datatypes supported</heading>

	      <p>The datatype of the elements (rows) of
		<verb>Table</verb> must be the H5T_COMPOUND
		<em>compound</em> datatype, and each of these compound
		components must be built with only the next HDF5
		datatypes <em>classes</em>:
	      </p>

	      <description>
		<term>H5T_BITFIELD</term> <item>This class is used to
		  represent the <verb>Bool</verb> type. Such a type
		  must be build using a H5T_NATIVE_B8 datatype,
		  followed by a HDF5 <verb>H5Tset_precision</verb>
		  call to set its precision to be just 1 bit.
		</item>
		<term>H5T_INTEGER</term> <item>This includes the next
		  datatypes:
		  <description>
		    <term>H5T_NATIVE_SCHAR</term> <item>This
		      represents a <em>signed char</em> C type, but it
		      is effectively used to represent an
		      <verb>Int8</verb> type.
		    </item>
		    <term>H5T_NATIVE_UCHAR</term> <item>This
		      represents an <em>unsigned char</em> C type, but
		      it is effectively used to represent an
		      <verb>UInt8</verb> type.
		    </item>
		    <term>H5T_NATIVE_SHORT</term> <item>This
		      represents a <em>short</em> C type, and
		      it is effectively used to represent an
		      <verb>Int16</verb> type.
		    </item>
		    <term>H5T_NATIVE_USHORT</term> <item>This
		      represents an <em>unsigned short</em> C type, and
		      it is effectively used to represent an
		      <verb>UInt16</verb> type.
		    </item>
		    <term>H5T_NATIVE_INT</term> <item>This represents
		      an <em>int</em> C type, and it is effectively
		      used to represent an <verb>Int32</verb> type.
		    </item>
		    <term>H5T_NATIVE_UINT</term> <item>This
		      represents an <em>unsigned int</em> C type, and
		      it is effectively used to represent an
		      <verb>UInt32</verb> type.
		    </item>
		    <term>H5T_NATIVE_LONG</term> <item>This represents
		      a <em>long</em> C type, and it is effectively
		      used to represent an <verb>Int32</verb> or an
		      <verb>Int64</verb>, depending on whether you are
		      running a 32-bit or 64-bit architecture.
		    </item>
		    <term>H5T_NATIVE_ULONG</term> <item>This
		      represents an <em>unsigned long</em> C type, and
		      it is effectively used to represent an
		      <verb>UInt32</verb> or an <verb>UInt64</verb>,
		      depending on whether you are running a 32-bit or
		      64-bit architecture.
		    </item>
		    <term>H5T_NATIVE_LLONG</term> <item>This
		      represents a <em>long long</em> C type
		      (<verb>__int64</verb>, if you are using a
		      Windows system) and it is effectively
		      used to represent an <verb>Int64</verb> type.
		    </item>
		    <term>H5T_NATIVE_ULLONG</term> <item>This
		      represents an <em>unsigned long long</em> C type
		      (beware: this type does not have a
		      correspondence on Windows systems) and it is
		      effectively used to represent an
		      <verb>UInt64</verb> type.
		    </item>
		  </description>
		</item>	<!-- H5T_INTEGER -->
		<term>H5T_FLOAT</term> <item>This includes the next
		  datatypes:
		  <description>
		    <term>H5T_NATIVE_FLOAT</term> <item>This
		      represents a <em>float</em> C type and it is
		      effectively used to represent an
		      <verb>Float32</verb> type.
		    </item>
		    <term>H5T_NATIVE_DOUBLE</term> <item>This
		      represents a <em>double</em> C type and it is
		      effectively used to represent an
		      <verb>Float64</verb> type.
		    </item>
		  </description>
		</item>
		<term>H5T_STRING</term> <item>The datatype used to
		  describe strings in PyTables is H5T_C_S1 (i.e. a
		  <em>string</em> C type) followed with a call to the
		  HDF5 <verb>H5Tset_size()</verb> function to set
		  their length.
		</item>
		<term>H5T_ARRAY</term> <item>This allows the
		  construction of homogeneous, multi-dimensional
		  arrays, so that you can include such objects in
		  compound records. The types supported as elements of
		  H5T_ARRAY datatypes are the ones described
		  above. Currently, PyTables<verb></verb> does not
		  support nested H5T_ARRAY types.
		</item>
	      </description>
	      
	      <p>You should note that <em>nested compound</em>
		datatypes are not allowed in <verb>Table</verb>
		objects.
	      </p>

	    </subsubsection>

	  </subsection>	<!-- Table -->

	  <subsection id="ArrayFormatDescr">
	    <heading><visual markup="tt">Array</visual>
	      format</heading>

	    <subsubsection>
	      <heading>Mandatory attributes</heading>

	      <p>The next attributes are mandatory for <em>array</em>
		structures:
	      </p>

	      <description>
		<term>CLASS</term> <item>Must be set to
		  <verb>'ARRAY'</verb>.
		</item>

		<term>FLAVOR</term> <item>This is meant to provide the
		  information about the kind of object kept in the
		  <verb>Array</verb>, i.e. when the dataset is read,
		  it will be converted to the indicated flavor. It can
		  take one the next string values:

		  <description>
		    <term>"NumArray"</term> <item>The dataset will be
		      returned as a <verb>NumArray</verb> object (from
		      the <verb>numarray</verb> package).
		    </item>
		    <term>"CharArray"</term> <item>The dataset will be
		      returned as a <verb>CharArray</verb> object
		      (from the <verb>numarray</verb> package).
		    </item>
		    <term>"Numeric"</term> <item>The dataset will be
		      returned as an <verb>array</verb> object
		      (from the <verb>Numeric</verb> package).
		    </item>
		    <term>"List"</term> <item>The dataset will be
		      returned as a Python <verb>List</verb> object.
		    </item>
		    <term>"Tuple"</term> <item>The dataset will be
		      returned as a Python <verb>Tuple</verb> object.
		    </item>
		    <term>"Int"</term> <item>The dataset will be
		      returned as a Python <verb>Int</verb>
		      object. This is meant mainly for scalar
		      (i.e. without dimensions) integer values.
		    </item>
		    <term>"Float"</term> <item>The dataset will be
		      returned as a Python <verb>Float</verb>
		      object. This is meant mainly for scalar
		      (i.e. without dimensions) floating point values.
		    </item>
		    <term>"String"</term> <item>The dataset will be
		      returned as a Python <verb>String</verb>
		      object. This is meant mainly for scalar
		      (i.e. without dimensions) string values.
		    </item>
		  </description>
		</item>

		<term>TITLE</term> <item>A string where the user can
		  put some description on what is this dataset used
		  for.
		</item>

		<term>VERSION</term> <item>Should contain the string
		  <verb>'2.0'</verb>.
		</item>
	      </description>
	    </subsubsection>

	    <subsubsection>
	      <heading>Storage Layout</heading>

	      <p>An <verb>Array</verb> has a <em>dataspace</em> with a
		<em>N-dimensional contiguous</em> layout (if you
		prefer a <em>chunked</em> layout see
		<verb>EArray</verb> below).
	      </p>
	    </subsubsection>

	    <subsubsection>
	      <heading>Datatypes supported</heading>

	      <p>The elements of <verb>Array</verb> must have HDF5 either
		<em>atomic</em> datatypes or a <em>compound</em> datatype 
		representing a complex number.
		The atomic datatypes and can currently be one of
		the next HDF5 datatype <em>classes</em>:
		H5T_BITFIELD, H5T_INTEGER, H5T_FLOAT and
		H5T_STRING. See the <verb>Table</verb> format
		description in <ref
		refid="TableFormatDescr">section</ref> for more info
		about these types.
	      </p>

	      <p>In addition to the HDF5 atomic datatypes, the Array
		format supports complex numbers with the H5T_COMPOUND
		datatype class. The H5T_COMPOUND type class contains two
		members. Both members must have the H5T_FLOAT atomic
		datatype class. The name of the first member should 
		be "r" and represents the real
		part. The name of the second member should be "i" and
		represents the imaginary part.
		The <em>precision</em> property of both of the H5T_FLOAT members
		must be either 32 significant bits (e.g. H5T_NATIVE_FLOAT) or 
		64 significant bits (e.g. H5T_NATIVE_DOUBLE). 
		They represent Complex32 and Complex64 types respectively.
	      </p>

	      <p>You should note that H5T_ARRAY class datatypes are
		not allowed in <verb>Array</verb> objects.
	      </p>
	    </subsubsection>
	  </subsection>	<!-- Array -->

	  <subsection id="EArrayFormatDescr">
	    <heading><visual markup="tt">EArray</visual>
	      format</heading>

	    <subsubsection>
	      <heading>Mandatory attributes</heading>

	      <p>The next attributes are mandatory for <em>earray</em>
		structures:
	      </p>

	      <description>
		<term>CLASS</term> <item>Must be set to
		  <verb>'EARRAY'</verb>.
		</item>

		<term>EXTDIM</term> <item>(<em>Integer</em>) Must be
		  set to the extensible dimension. Only one extensible
		  dimension is supported right now.
		</item>

		<term>FLAVOR</term> <item>This is meant to provide the
		  information about the kind of objects kept in the
		  <verb>EArray</verb>, i.e. when the dataset is read,
		  it will be converted to the indicated flavor. It can
		  take the same values as the <verb>Array</verb>
		  object (see <ref refid="ArrayFormatDescr"></ref>),
		  except <verb>"Int"</verb> and <verb>"Float"</verb>.

		</item>
		<term>TITLE</term> <item>A string where the user can
		  put some description on what is this dataset used
		  for.
		</item>

		<term>VERSION</term> <item>Should contain the string
		  <verb>'1.0'</verb>.
		</item>

	      </description>
	    </subsubsection>

	    <subsubsection>
	      <heading>Storage Layout</heading>

	      <p>An <verb>EArray</verb> has a <em>dataspace</em> with
		a <em>N-dimensional chunked</em> layout.
	      </p>
	    </subsubsection>

	    <subsubsection>
	      <heading>Datatypes supported</heading>

	      <p>The elements of <verb>EArray</verb> are allowed to have
		the same
		datatypes as for the elements in the Array format.
		They can be one of the HDF5 <em>atomic</em> datatype 
		<em>classes</em>:
		H5T_BITFIELD, H5T_INTEGER, H5T_FLOAT or
		H5T_STRING, see the <verb>Table</verb> format
		description in <ref
		refid="TableFormatDescr">section</ref> for more info
		about these types. 
		They can also be a HDF5 <em>compound</em> 
		datatype representing a complex number, 
		see the <verb>Array</verb> format
		description in <ref
		refid="ArrayFormatDescr">section</ref>.
	      </p>
	      
	      <p>You should note that H5T_ARRAY class datatypes are
		not allowed in <verb>EArray</verb> objects.
	      </p>
	    </subsubsection>
	  </subsection>	<!-- EArray -->

	  <subsection id="VLArrayFormatDescr">
	    <heading><visual markup="tt">VLArray</visual>
	      format</heading>

	    <subsubsection>
	      <heading>Mandatory attributes</heading>

	      <p>The next attributes are mandatory for
		<em>vlarray</em> structures:
	      </p>

	      <description>
		<term>CLASS</term> <item>Must be set to
		  <verb>'VLARRAY'</verb>.
		</item>

		<term>FLAVOR</term> <item>This is meant to provide the
		  information about the kind of objects kept in the
		  <verb>VLArray</verb>, i.e. when the dataset is read,
		  it will be converted to the indicated flavor. It can
		  take one of the next values:

		  <description>
		    <term>"NumArray"</term> <item>The elements in
		      dataset will be returned as
		      <verb>NumArray</verb> objects (from the
		      <verb>numarray</verb> package).
		    </item>
		    <term>"CharArray"</term> <item>The elements in
		      dataset will be returned as
		      <verb>CharArray</verb> objects (from the
		      <verb>numarray</verb> package).
		    </item>
		    <term>"String"</term> <item>The elements in the
		      dataset will be returned as Python
		      <verb>String</verb> objects of <em>fixed</em>
		      length (and not as <verb>CharArrays</verb>).
		    </item>
		    <term>"Numeric"</term> <item>The elements in the
		      dataset will be returned as
		      <verb>array</verb> objects (from the
		      <verb>Numeric</verb> package).
		    </item>
		    <term>"List"</term> <item>The elements in the
		      dataset will be returned as Python
		      <verb>List</verb> objects.
		    </item>
		    <term>"Tuple"</term> <item>The elements in the
		      dataset will be returned as Python
		      <verb>Tuple</verb> objects.
		    </item>
		    <term>"Object"</term> <item>The elements in the
		      dataset will be interpreted as pickled
		      (i.e. serialized objects through the use of the
		      <verb>Pickle</verb> Python module) objects and
		      returned as Python <em>generic</em>
		      objects. Only one of such objects will be
		      supported per entry. As the <verb>Pickle</verb>
		      module is not normally available in other
		      languages, this flavor won't be useful in
		      general.
		    </item>
		    <term>"VLString"</term> <item>The elements in the
		      dataset will be returned as Python
		      <verb>String</verb> objects of <em>any</em>
		      length, with the twist that <visual
		      markup="bf">Unicode</visual> strings are
		      supported as well (provided you use the <visual
		      markup="bf">UTF-8</visual> codification, see
		      below). However, only one of such objects will
		      be supported per entry.
		    </item>
		  </description>
		</item>

		<term>TITLE</term> <item>A string where the user can
		  put some description on what is this dataset used
		  for.
		</item>

		<term>VERSION</term> <item>Should contain the string
		  <verb>'1.0'</verb>.
		</item>

	      </description>
	    </subsubsection>

	    <subsubsection>
	      <heading>Storage Layout</heading>

	      <p>An <verb>VLArray</verb> has a <em>dataspace</em> with
		a <em>1-dimensional chunked</em> layout. 
	      </p>
	    </subsubsection>

	    <subsubsection>
	      <heading>Datatypes supported</heading>

	      <p>The datatype of the elements (rows) of
		<verb>VLArray</verb> objects must be the H5T_VLEN
		<em>variable-length</em> (or VL for short) datatype,
		and the base datatype specified for the VL datatype
		can be of any <em>atomic</em> HDF5 datatype that is
		listed in the <verb>Table</verb> format <ref
		refid="TableFormatDescr">description
		section</ref>. That includes the classes:
	      </p>
	      <itemize>
		<item>H5T_BITFIELD</item>
		<item>H5T_INTEGER</item>
		<item>H5T_FLOAT</item>
		<item>H5T_STRING</item>
		<item>H5T_ARRAY</item>
	      </itemize>
	      <p>They can also be a HDF5 <em>compound</em> 
		datatype representing a complex number, 
		see the <verb>Array</verb> format
		description in <ref
		refid="ArrayFormatDescr">section</ref> for a 
		detailed description.
	      </p>
	      <p>You should note that this does not include another VL
		datatype, or a compound datatype that does not fit
		the description of a complex number. Note as well that, for
		<verb>Object</verb> and <verb>VLString</verb>
		special flavors, the base for the VL datatype is
		always a H5T_NATIVE_UCHAR. That means that the
		complete row entry in the dataset has to be used in
		order to fully serialize the object or the variable
		length string.
	      </p>
	      <p>In addition, if you plan to use a
		<verb>VLString</verb> flavor for your text data and
		you are using ascii-7 (7 bits ASCII) codification for
		your strings, but you don't know (or just don't want)
		to convert it to the required UTF-8 codification, you
		should not worry too much about that because the ASCII
		characters with values in the range [0x00, 0x7f] are
		directly mapped to Unicode characters in the range
		[U+0000, U+007F] and the UTF-8 encoding has the useful
		property that an UTF-8 encoded ascii-7 string is
		indistinguishable from a traditional ascii-7 string.
		So, you will not need any further conversion in order
		to save your ascii-7 strings and have an
		<verb>VLString</verb> flavor.
	      </p>

	    </subsubsection>
	  </subsection>	<!-- VLArray -->

	</section> <!-- Leaf -->

      </chapter> <!-- PyTables Internal Format -->

      <chapter id="PTutilities">
	<heading>Utilities</heading>

	<p><verb>PyTables</verb> comes with a couple of utilities that
	  make the life easier to the user. One is called
	  <verb>ptdump</verb> and lets you see the contents of a
	  <verb>PyTables</verb> file (or generic <verb>HDF5</verb>
	  file, if supported). The other one is named
	  <verb>ptrepack</verb> that allows to (recursively) copy
	  sub-hierarchies of objects present in a file into another
	  one, changing, if desired, some of the filters applied to
	  the leaves during the copy process.
	</p>

	<p>Normally, these utilities will be installed somewhere in
	  your PATH during the process of installation of the
	  <verb>PyTables</verb> package, so that you can invoke them
	  from any place in your filesystem after the installation has
	  successfully finished.
	</p>

	<section id="ptdumpDescr">
	  <heading>ptdump</heading>

	  <p>As has been said before, <verb>ptdump</verb> utility
	    allows you look into the contents of your
	    <verb>PyTables</verb> files. It lets you see not only the
	    data but also the metadata (that is, the
	    <em>structure</em> and additional information in the form
	    of <em>attributes</em>).
	  </p>

	  <subsection>
	    <heading>Usage</heading>

	    <p>For instructions on how to use it, just pass the
	      <verb>-h</verb> flag to the command:

	      <verbatim>
$ ptdump -h
	      </verbatim>

	      to see the message usage:

	      <verbatim>
usage: ptdump [-R start,stop,step] [-a] [-h] [-d] [-v] file[:nodepath]
  -R RANGE -- Select a RANGE of rows in the form "start,stop,step"
  -a -- Show attributes in nodes (only useful when -v or -d are active)
  -c -- Show info of columns in tables (only useful when -v or -d are active)
  -i -- Show info of indexed columns (only useful when -v or -d are active)
  -d -- Dump data information on leaves
  -h -- Print help on usage
  -v -- Dump more metainformation on nodes
	      </verbatim>
	    </p>

	  </subsection>
	  <subsection>
	    <heading>A small tutorial on <visual
		markup="tt">ptdump</visual>
	    </heading>

	    <p>Let's suppose that we want to know only the
	      <em>structure</em> of a file. In order to do that, just
	      don't pass any flag, just the file as parameter:

	      <verbatim>
$ ptdump vlarray1.h5
Filename: 'vlarray1.h5' Title: '' , Last modif.: 'Fri Feb  6 19:33:28 2004' ,
 rootUEP='/', filters=Filters(), Format version: 1.2
/ (Group) ''
/vlarray1 (VLArray(4,), shuffle, zlib(1)) 'ragged array of ints'

	      </verbatim>

	      we can see that the file contains a just a leaf object
	      called <verb>vlarray1</verb>, that is an instance of
	      <verb>VLArray</verb>, has 4 rows, and two filters has
	      been used in order to create it: <verb>shuffle</verb>
	      and <verb>zlib</verb> (with a compression level of 1).
	    </p>

	    <p>Let's say we want more metainformation. Just add the
	      <verb>-v</verb> (verbose) flag:

	      <verbatim>
$ ptdump -v vlarray1.h5
/ (Group) ''
  children := ['vlarray1' (VLArray)]
/vlarray1 (VLArray(4,), shuffle, zlib(1)) 'ragged array of ints'
  atom = Atom(type=Int32, shape=1, flavor='Numeric')
  nrows = 4
  flavor = 'Numeric'
  byteorder = 'little'
	      </verbatim>
	      so we can see more info about the atoms that are the
	      components of the <verb>vlarray1</verb> dataset,
	      i.e. they are scalars of type <verb>Int32</verb> and
	      with <verb>Numeric</verb> <em>flavor</em>.
	    </p>

	    <p>If we want information about the attributes on the
	      nodes, we must add the <verb>-a</verb> flag:

	      <verbatim>
$ ptdump -va vlarray1.h5
/ (Group) ''
  children := ['vlarray1' (VLArray)]
  /._v_attrs (AttributeSet), 5 attributes:
   [CLASS := 'GROUP',
    FILTERS := None,
    PYTABLES_FORMAT_VERSION := '1.2',
    TITLE := '',
    VERSION := '1.0']
/vlarray1 (VLArray(4,), shuffle, zlib(1)) 'ragged array of ints'
  atom = Atom(type=Int32, shape=1, flavor='Numeric')
  nrows = 4
  flavor = 'Numeric'
  byteorder = 'little'
  /vlarray1.attrs (AttributeSet), 4 attributes:
   [CLASS := 'VLARRAY',
    FLAVOR := 'Numeric',
    TITLE := 'ragged array of ints',
    VERSION := '1.0']
	      </verbatim>
	    </p>

	    <p>Let's have a look at the real data:

	      <verbatim>
$ ptdump -d vlarray1.h5
/ (Group) ''
/vlarray1 (VLArray(4,), shuffle, zlib(1)) 'ragged array of ints'
  Data dump:
[array([5, 6]), array([5, 6, 7]), array([5, 6, 9, 8]), array([ 5,  6,  9, 10, 12])]
	      </verbatim>
	      we see here a data dump of the 4 rows in
	      <verb>vlarray1</verb> object, in the form of a
	      list. Because the object is a VLA, we see a different
	      number of integers on each row.
	    </p>

	    <p>Say that we are interested only on a specific <em>row
		range</em> of the <verb>/vlarray1</verb> object:
	      <verbatim>
ptdump -R2,4 -d vlarray1.h5:/vlarray1
/vlarray1 (VLArray(4,), shuffle, zlib(1)) 'ragged array of ints'
  Data dump:
[array([5, 6, 9, 8]), array([ 5,  6,  9, 10, 12])]
	      </verbatim>
	      Here, we have specified the range of rows between 2 and
	      4 (the upper limit excluded, as usual in Python). See
	      how we have selected only the <verb>/vlarray1</verb>
	      object for doing the dump
	      (<verb>vlarray1.h5:/vlarray1</verb>).
	    </p>

	    <p>Finally, you can mix several information at once:
	      <verbatim>
$ ptdump -R2,4 -vad vlarray1.h5:/vlarray1
/vlarray1 (VLArray(4,), shuffle, zlib(1)) 'ragged array of ints'
  atom = Atom(type=Int32, shape=1, flavor='Numeric')
  nrows = 4
  flavor = 'Numeric'
  byteorder = 'little'
  /vlarray1.attrs (AttributeSet), 4 attributes:
   [CLASS := 'VLARRAY',
    FLAVOR := 'Numeric',
    TITLE := 'ragged array of ints',
    VERSION := '1.0']
  Data dump:
[array([5, 6, 9, 8]), array([ 5,  6,  9, 10, 12])]
	      </verbatim>
	    </p>
	  </subsection>
	</section> <!-- ptdump -->

	<section id="ptrepackDescr">
	  <heading>ptrepack</heading>

	  <p>This utility is a very powerful one and let's you to copy
	    any leaf, group or complete subtree into another
	    file. During the copy process you are allowed to change
	    the filter properties if you want so. Also, in the case of
	    duplicated pathnames, you can decide if you want to
	    overwrite already existing nodes on the destination
	    file. Generally speaking, <verb>ptrepack</verb> can be
	    useful in may situations, like replicating a subtree in
	    another file, change the filters in objects and see how
	    affect this to the compression degree or I/O performance,
	    consolidating specific data in repositoris or even
	    <em>importing</em> generic <verb>HDF5</verb> files and
	    create true <verb>PyTables</verb> counterparts.
	  </p>

	  <subsection>
	    <heading>Usage</heading>

	    <p>For instructions on how to use it, just pass the
	      <verb>-h</verb> flag to the command:

	      <verbatim>
$ ptrepack -h
	      </verbatim>

	      to see the message usage:

	      <verbatim>
usage: ptrepack [-h] [-v] [-o] [-R start,stop,step] [--non-recursive]
  [--dest-title=title] [--dont-copyuser-attrs] [--overwrite-nodes]
  [--complevel=(0-9)] [--complib=lib] [--shuffle=(0|1)]
  [--fletcher32=(0|1)] [--keep-source-filters] 
  sourcefile:sourcegroup destfile:destgroup
 -h -- Print usage message.
 -v -- Show more information.
 -o -- Overwite destination file.
 -R RANGE -- Select a RANGE of rows (in the form "start,stop,step")
     during the copy of *all* the leaves.
 --non-recursive -- Do not do a recursive copy. Default is to do it.
 --dest-title=title -- Title for the new file (if not specified,
     the source is copied).
 --dont-copy-userattrs -- Do not copy the user attrs (default is to do it)
 --overwrite-nodes -- Overwrite destination nodes if they exist. Default is
     to not overwrite them.
 --complevel=(0-9) -- Set a compression level (0 for no compression, which
     is the default).
 --complib=lib -- Set the compression library to be used during the copy.
     lib can be set to "zlib", "lzo" or "ucl". Defaults to "zlib".
 --shuffle=(0|1) -- Activate or not the shuffling filter (default is active
     if complevel>0).
 --fletcher32=(0|1) -- Whether to activate or not the fletcher32 filter (not
     active by default).
 --keep-source-filters -- Use the original filters in source files. The
     default is not doing that if any of --complevel, --complib, --shuffle
     or --fletcher32 option is specified.
	      </verbatim>
	    </p>
	  </subsection>
	  <subsection>
	    <heading>A small tutorial on <visual
		markup="tt">ptrepack</visual>
	    </heading>

	    <p>Imagine that we have ended the tutorial 1 (see the
	      output of <verb>examples/tutorial1-1.py</verb>), and we
	      want to copy our reduced data (i.e. those datasets that
	      hangs from the <verb>/column</verb> group) to another
	      file. First, let's remember the content of the
	      <verb>examples/tutorial1.h5</verb>:

	      <verbatim>
$ ptdump tutorial1.h5
Filename: 'tutorial1.h5' Title: 'Test file' , Last modif.: 'Fri Feb  6 
  19:33:28 2004' , rootUEP='/', filters=Filters(), Format version: 1.2
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout (Table(10L,)) 'Readout example'
	      </verbatim>

	      Now, copy the <verb>/columns</verb> to other
	      non-existing file. That's easy:

	      <verbatim>
$ ptrepack tutorial1.h5:/columns reduced.h5
	      </verbatim>
	      That's all. Let's see the contents of the newly created
	      <verb>reduced.h5</verb> file:

	      <verbatim>
$ ptdump reduced.h5
Filename: 'reduced.h5' Title: '' , Last modif.: 'Fri Feb 20 15:26:47 2004' ,
 rootUEP='/', filters=Filters(), Format version: 1.2
/ (Group) ''
/name (Array(3,)) 'Name column selection'
/pressure (Array(3,)) 'Pressure column selection'
	      </verbatim>
	      so, you have copied the childs of <verb>/columns</verb>
	      group into the <em>root</em> of the
	      <verb>reduced.h5</verb> file.
	    </p>

	    <p>Now, you suddenly realized that what you intended to do
	      was to copy all the hierarchy, the group
	      <verb>/columns</verb> itself included. You can do that
	      by just specificing the destination group:

	      <verbatim>
$ ptrepack tutorial1.h5:/columns reduced.h5:/columns
ptdump reduced.h5
Filename: 'reduced.h5' Title: '' , Last modif.: 'Fri Feb 20 15:39:15 2004' ,
 rootUEP='/', filters=Filters(), Format version: 1.2
/ (Group) ''
/name (Array(3,)) 'Name column selection'
/pressure (Array(3,)) 'Pressure column selection'
/columns (Group) ''
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
	      </verbatim>
	      Ok. Much better. But you want to get rid of the existing
	      nodes on the new file. You can achieve this by adding
	      the -o flag:

	      <verbatim>
$ ptrepack -o tutorial1.h5:/columns reduced.h5:/columns
$ ptdump reduced.h5
Filename: 'reduced.h5' Title: '' , Last modif.: 'Fri Feb 20 15:41:57 2004' ,
 rootUEP='/', filters=Filters(), Format version: 1.2
/ (Group) ''
/columns (Group) ''
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
	      </verbatim>
	      where you can see how the old contents of the
	      <verb>reduced.h5</verb> file has been overwritten.
	    </p>

	    <p>You can copy just one single node in the repacking
	      operation and change its name in destination:

	      <verbatim>
$ ptrepack tutorial1.h5:/detector/readout reduced.h5:/rawdata
$ ptdump reduced.h5
Filename: 'reduced.h5' Title: '' , Last modif.: 'Fri Feb 20 15:52:22 2004',
 rootUEP='/', filters=Filters(), Format version: 1.2
/ (Group) ''
/rawdata (Table(10L,)) 'Readout example'
/columns (Group) ''
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
	      </verbatim>
	      where the <verb>/detector/readout</verb> has been copied
	      to <verb>/rawdata</verb> in destination.
	    </p>

	    <p>We can change the filter properties as well:
	      <verbatim>
$ ptrepack --complevel=1 tutorial1.h5:/detector/readout reduced.h5:/rawdata
Problems doing the copy from 'tutorial1.h5:/detector/readout' to 
'reduced.h5:/rawdata'
The error was --> exceptions.ValueError: The destination
 (/rawdata (Table(10L,)) 'Readout example') already exists.
 Assert the overwrite parameter if you really want to overwrite it.
The destination file looks like:
Filename: 'reduced.h5' Title: ''; Last modif.: 'Fri Feb 20 15:52:22 2004';
 rootUEP='/'; filters=Filters(), Format version: 1.2
/ (Group) ''
/rawdata (Table(10L,)) 'Readout example'
/columns (Group) ''
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'

Traceback (most recent call last):
  File "../utils/ptrepack", line 358, in ?
    start=start, stop=stop, step=step)
  File "../utils/ptrepack", line 111, in copyLeaf
    raise RuntimeError, "Please, check that the node names are not
  duplicated in destination, and if so, add the --overwrite-nodes flag 
  if desired."
RuntimeError: Please, check that the node names are not duplicated in
 destination, and if so, add the --overwrite-nodes flag if desired.
	    </verbatim>
	      ooops!. We ran into problems: we forgot that
	      <verb>/rawdata</verb> pathname already existed
	      in destination file. Let's add the
	      <verb>--overwrite-nodes</verb>, as the verbose
	      error suggested:
	      <verbatim>
$ ptrepack --overwrite-nodes --complevel=1 tutorial1.h5:/detector/readout 
reduced.h5:/rawdata
$ ptdump reduced.h5
Filename: 'reduced.h5' Title: ''; Last modif.: 'Fri Feb 20 16:02:20 2004';
 rootUEP='/'; filters=Filters(), Format version: 1.2
/ (Group) ''
/rawdata (Table(10L,), shuffle, zlib(1)) 'Readout example'
/columns (Group) ''
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
	      </verbatim>
	      you can check how the filter properties has been changed
	      for the <verb>/rawdata</verb> table. Check as the other
	      nodes still exists.
	    </p>

	    <p>Finally, let's copy a <em>slice</em> of the
	      <verb>readout</verb> table in origin to destination,
	      under a new group called <verb>/slices</verb> and with
	      the name, for example, <verb>aslice</verb>:
	      <verbatim>
$ ptrepack -R1,8,3 tutorial1.h5:/detector/readout reduced.h5:/slices/aslice
$ ptdump reduced.h5
Filename: 'reduced.h5' Title: ''; Last modif.: 'Fri Feb 20 16:17:13 2004';
 rootUEP='/'; filters=Filters(); Format version: 1.2
/ (Group) ''
/rawdata (Table(10L,), shuffle, zlib(1)) 'Readout example'
/columns (Group) ''
/columns/name (Array(3,)) 'Name column selection'
/columns/pressure (Array(3,)) 'Pressure column selection'
/slices (Group) ''
/slices/aslice (Table(3L,)) 'Readout example'
	      </verbatim>
	      note how only 3 rows of the original
	      <verb>readout</verb> table has been copied to the new
	      <verb>aslice</verb> destination. Note as well how the
	      previously inexistent <verb>slices</verb> group has been
	      created in the same operation.
	    </p>
	  </subsection>
	</section> <!-- ptrepack -->
      </chapter>
    </appendix>	

  </mainmatter>

  <backmatter>

    <!-- latex code="\renewcommand{\refname}{References}"/> -->


    <references bibfile="usersguide"/>

  </backmatter>
</book>

<!-- Keep this comment at the end of the file
Local variables:
mode: xml
sgml-omittag:nil
sgml-shorttag:nil
sgml-namecase-general:nil
sgml-general-insert-case:lower
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:2
sgml-indent-data:t
sgml-parent-document:nil
sgml-exposed-tags:nil
sgml-local-catalogs:nil
sgml-local-ecat-files:nil
End:
-->

