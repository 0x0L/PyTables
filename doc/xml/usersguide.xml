<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE book PUBLIC "-//Torsten Bronger//DTD tbook 1.3//EN"
                      "/usr/local/share/xml/tbook/tbook.dtd">
<book>
  <frontmatter>
    <title><visual markup="tt">PyTables</visual> User's Guide</title>
    <author>Francesc Alted</author>
    <subtitle>Release 0.6</subtitle>
    <date>June, 12th</date>
    <year>2003</year>
    <legalnotice>


<!--	   Copyright (c) 2002, 2003 Francesc Alted -->

      <p>Permission is hereby granted, free of charge, to any person
	obtaining a copy of this software and associated documentation
	files (the "Software"), to deal in the Software without
	restriction, including without limitation the rights to use,
	copy, modify, merge, publish, distribute, sublicense, and/or
	sell copies of the Software, and to permit persons to whom the
	Software is furnished to do so, subject to the following
	conditions:
      </p>
      <p>The above copyright notice and this permission notice shall
	be included in all copies or substantial portions of the
	Software.
      </p>
      <p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
	KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
	WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR
	PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
	COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
	LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
	OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
	SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
	<newline vspace="1cm"/>
      </p>

<!-- NCSA license -->

      <p><visual markup="bf">Copyright Notice and Statement for NCSA
	  Hierarchical Data Format (HDF) Software Library and
	  Utilities</visual>
      </p>


      <p>NCSA HDF5 (Hierarchical Data Format 5) Software Library and
	Utilities Copyright 1998, 1999, 2000, 2001, 2002, 2003 by the
	Board of Trustees of the University of Illinois.  All rights
	reserved.
      </p>

      <p>Contributors: National Center for Supercomputing Applications
	(NCSA) at the University of Illinois at Urbana-Champaign
	(UIUC), Lawrence Livermore National Laboratory (LLNL), Sandia
	National Laboratories (SNL), Los Alamos National Laboratory
	(LANL), Jean-loup Gailly and Mark Adler (gzip library).
      </p>
      <p>Redistribution and use in source and binary forms, with or
	without modification, are permitted for any purpose (including
	commercial purposes) provided that the following conditions
	are met:
      </p>

      <enumerate>
        <item>
	  Redistributions of source code must retain the above
	  copyright notice, this list of conditions, and the following
	  disclaimer.
	</item>
	<item>Redistributions in binary form must reproduce the above
	  copyright notice, this list of conditions, and the following
	  disclaimer in the documentation and/or materials provided
	  with the distribution.
	</item>
	<item>In addition, redistributions of modified forms of the
	  source or binary code must carry prominent notices stating
	  that the original code was changed and the date of the
	  change.
	</item>
	<item>All publications or advertising materials mentioning
	  features or use of this software are asked, but not
	  required, to acknowledge that it was developed by the
	  National Center for Supercomputing Applications at the
	  University of Illinois at Urbana-Champaign and to credit the
	  contributors.
	</item>
	<item>Neither the name of the University nor the names of the
	  Contributors may be used to endorse or promote products
	  derived from this software without specific prior written
	  permission from the University or the Contributors, as
	  appropriate for the name(s) to be used.
	</item>
	<item>THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY AND THE
	  CONTRIBUTORS "AS IS" WITH NO WARRANTY OF ANY KIND, EITHER
	  EXPRESSED OR IMPLIED.  In no event shall the University or
	  the Contributors be liable for any damages suffered by the
	  users arising out of the use of this software, even if
	  advised of the possibility of such damage.
	</item>
      </enumerate>
      <p>Portions of HDF5 were developed with support from the
	University of California, Lawrence Livermore National
	Laboratory (UC LLNL).  The following statement applies to
	those portions of the product and must be retained in any
	redistribution of source code, binaries, documentation, and/or
	accompanying materials:
      </p>
      <p> This work was partially produced at the University of
	California, Lawrence Livermore National Laboratory (UC LLNL)
	under contract no.  W-7405-ENG-48 (Contract 48) between the
	U.S. Department of Energy (DOE) and The Regents of the
	University of California (University) for the operation of UC
	LLNL.
      </p>

<!-- This paragraph does not fit well. Skip it!

      <visual markup="bf">DISCLAIMER:</visual>
      <p> This work was prepared as an account of work sponsored by an
	agency of the United States Government.  Neither the United
	States Government nor the University of California nor any of
	their employees, makes any warranty, express or implied, or
	assumes any liability or responsibility for the accuracy,
	completeness, or usefulness of any information, apparatus,
	product, or process disclosed, or represents that its use
	would not infringe privately- owned rights.  Reference herein
	to any specific commercial products, process, or service by
	trade name, trademark, manufacturer, or otherwise, does not
	necessarily constitute or imply its endorsement,
	recommendation, or favoring by the United States Government or
	the University of California.  The views and opinions of
	authors expressed herein do not necessarily state or reflect
	those of the United States Government or the University of
	California, and shall not be used for advertising or product
	endorsement purposes.
      </p>
 -->
    </legalnotice>
  </frontmatter>

  <!--  This is only for article
  <abstract>

  <p><visual markup="tt">PyTables</visual> is a Python package whose
    goal is to allow dealing easily, but in a powerful way, with
    scientific data tables and Numerical Python objects organized in a
    hierarchical structure. Such a tables are defined as a collection
    of records whose values are stored in fixed-length fields. As a
    foundation for the underlying hierarchical data organization the
    excellent HDF5 library (http://hdf.ncsa.uiuc.edu/HDF5) has been
    chosen.
  </p>

  <p><visual markup="tt">PyTables</visual> is intended to be
    easy-to-use, and tries to be a high-performance interface to
    HDF5. To achieve this, the newest improvements introduced in
    Python 2.2 (like generators or slots and metaclasses in new-brand
    classes) has been used. Pyrex creation extension tool has been
    chosen to access the HDF5 library.
  </p>

  </abstract> -->

  <mainmatter>

<!--    <chapter kind='preface'> -->
<!--       <heading></heading> -->

<!--       <aphorism>La sabiduría no vale la pena si no es posible servirse -->
<!-- 	de ella para inventar una nueva manera de preparar los -->
<!-- 	garbanzos.  <caption>in "Cien años de soledad". Gabriel García -->
<!-- 	Márquez</caption> -->
<!--       </aphorism> -->

<!--     </chapter> -->

    <chapter>
      <heading>Introduction</heading>

      <aphorism>La sabiduría no vale la pena si no es posible servirse
	de ella para inventar una nueva manera de preparar los
	garbanzos.<caption>Un sabio catalán<newline/> in "Cien años de
	soledad"<newline/> Gabriel García Márquez</caption>
      </aphorism>

      <p>The goal of <verb>PyTables</verb> is to enable the end user
	to manipulate easily scientific data <visual
	markup="bf">tables</visual> and array objects objects in a
	hierarchical structure. The foundation of the underlying
	hierarchical data organization is the excellent
	<verb>HDF5</verb> library
	(see <cite refid="HDFWhatIs"></cite>). Right now,
	<verb>PyTables</verb> provides limited support of all the HDF5
	functions, but I hope to add the more interesting ones (for
	<verb>PyTables</verb> needs) in the near future.
      </p>
      <p>
	Nonetheless, this package is not intended to serve as a
	complete wrapper for the entire HDF5 API, but to provide a
	flexible, <em>very Pythonic</em> tool to deal with (arbitrary)
	large amounts of data (typically bigger than available memory)
	in tables and arrays organized in a hierarchical, persistent
	disk storage.
      </p>

      <p>A table is defined as a collection of records whose values
	are stored in <em>fixed-length</em> fields. All records have
	the same structure and all values in each field have the same
	<em>data type</em>. The terms <em>fixed-length</em> and
	strict <em>data types</em> seems to be quite a strange
	requirement for an interpreted language like Python, but they
	serve a useful function if the goal is to save very large
	quantities of data (such as is generated by many scientific
	applications, for example) in an efficient manner that reduces
	demand on CPU time and I/O.
      </p>

      <p>In order to emulate records (that will be mapped to C structs
	in HDF5) in Python <verb>PyTables</verb> implements a special
	<em>metaclass</em> object in order to easily define all its
	fields and other properties.  <verb>PyTables</verb> also
	provides a powerful interface to mine data in table. Records
	in tables are also known, in the <verb>HDF5</verb> naming
	scheme, as <em>compound</em> data types.
      </p>

      <p>For example, you can define arbitrary tables in Python
	simply by declaring a class with the name field and types
	information, like in:
      </p>

<verbatim>
class Particle(IsDescription):
    name      = Col("CharType", 16)  # 16-character String
    idnumber  = Col("Int64", 1)      # Signed 64-bit integer
    ADCcount  = Col("UInt16", 1)     # Unsigned short integer
    TDCcount  = Col("UInt8", 1)      # unsigned byte
    grid_i    = Col("Int32", 1)      # integer
    grid_j    = Col("Int32", 1)      # integer
    pressure  = Col("Float32", 1)    # float  (single-precision)
    energy    = Col("Float64", 1)    # double (double-precision)
</verbatim>

      <p>then, you have to pass this class to the table constructor,
	fill its rows with your values, and save (arbitrary large)
	collections of them in a file for persistent storage. After
	that, this data can be retrieved and post-processed quite
	easily with <visual markup="tt">PyTables</visual> or even with
	another <verb>HDF5</verb> application (in C, Fortran, Java or
	whatever language that provides an interface to HDF5).
      </p>

      <p>Next section describes the most interesting capabilities of
	<verb>PyTables</verb>.
      </p>

      <section>
	<heading>Main Features</heading>
	<p>
	  <verb>PyTables</verb> take advantage of the powerful object
	  orientation and introspection capabilities offered by Python
	  to bring the next features to the user:
	</p>

	<itemize>
	  <item><em>Support of table entities:</em> Allows working
	    with a large number of records, i.e. that don't fit in
	    memory.
	  </item>
	  <item><em>Appendable tables:</em> It supports adding records
	    to already created tables. This can be done without
	    copying the dataset or redefining its structure, even
	    between different Python sessions.
	  </item>
	  <item><em>Support of arrays:</em> <verb>Numeric</verb> (see
	    <cite refid="Numeric"></cite>) or <verb>numarray</verb>
	    (see <cite refid="Numarray"></cite>) arrays are a very
	    useful complement of tables to keep homogeneous table
	    slices (like selections of table columns).
	  </item>
	  <item><em>Supports a hierarchical data model:</em> That way,
	    you can structure very clearly all your
	    data. <verb>PyTables</verb> builds up an <em>object
	    tree</em> in memory that replicates the underlying file
	    data structure. Access to the file objects is achieved by
	    walking throughout this object tree, and manipulating it.
	  </item>
	  <item><em>Automatically check for correct field name, and
	    data type:</em> That reduces programmer mistakes and if
	    <visual markup="tt">PyTables</visual> does not report an
	    error, you can be more confident that your data is
	    probably ok.
	  </item>
	  <item><em>Support of files bigger than 2 GB:</em> The
	    underlying HDF5 library already can do that (if your
	    platform supports the C long long integer, or, on Windows,
	    __int64), and <verb>PyTables</verb> automatically inherits
	    this capability.
	  </item>
	  <item><em>Can read generic HDF5 files:</em>
	    <verb>PyTables</verb> can access to objects in generic
	    HDF5 files provided they contain any combination of
	    groups, compound type datasets (that will be mapped to
	    <verb>Table</verb> objects) or homogeneous datasets (that
	    will be mapped to <verb>Array</verb> objects). However, as
	    these kind of data is the most common to be saved HDF5
	    format, <verb>PyTables</verb> can probably most of the
	    HDF5 files out there.
	  </item>
	  <item><em>Data compression:</em> It supports data
	    compression (through the use of the <visual
	    markup="tt"><visual markup="bf">Zlib</visual></visual>,
	    <visual markup="tt"><visual
	    markup="bf">LZO</visual></visual> and <visual
	    markup="tt"><visual markup="bf">UCL</visual></visual>
	    libraries) out of the box. This become important when you
	    have repetitive data patterns and don't want to loose your
	    time searching for an optimized way to save them (i.e. it
	    saves you data organization analysis time).
	  </item>
	  <item><em>High performance I/O:</em> On modern systems, and
	    for large amounts of data, tables and array objects can be
	    read and written at a speed only limited by the
	    performance of the underlying I/O subsystem. Moreover, if
	    your data is compressible, even faster than that!.
	  </item>
	  <item><em>Architecture-independent:</em> <visual
	    markup="tt">PyTables</visual> has been carefully coded (as
	    HDF5 itself) with little-endian/big-endian byte orderings
	    issues in mind . So, in principle, you can write a file in
	    a big-endian machine (like a Sparc or MIPS) and read it in
	    other little-endian (like Intel or Alpha) without
	    problems.
	  </item>

	</itemize>

      </section>

      <section id="ObjectTreeSection">
	<heading>The Object Tree</heading>

	<p>The hierarchical model of the underlying HDF5 library
	  allows <verb>PyTables</verb> to manage tables and arrays in
	  a tree-like structure. In order to achieve this, an
	  <em>object tree</em> entity is <em>dynamically</em> created
	  imitating the HDF5 structure on disk. That way, the access
	  to the HDF5 objects is made by walking throughout this
	  object tree, and, by looking at their <em>metadata</em>
	  nodes, you can get a nice picture of what kind data is kept
	  there.
	</p>

	<p>The different nodes in the object tree are instances of
	  <verb>PyTables</verb> classes. There are several types of
	  those classes, but the most important ones are the
	  <verb>Group</verb> and the
	  <verb>Leaf</verb>. <verb>Group</verb> instances (that we
	  will be calling <em>groups</em> from now on) are a grouping
	  structure containing instances of zero or more groups or
	  leaves, together with supplementary metadata.
	  <verb>Leaf</verb> instances (that will be called
	  <em>leaves</em>) are containers for actual data and cannot
	  contain further groups or leaves. The <verb>Table</verb> and
	  <verb>Array</verb> classes are descendants of
	  <verb>Leaf</verb>, and inherits all its properties.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files, respectively, in a Unix
	  filesystem. As with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. In <verb>PyTables</verb> this full
	  path can be specified either as string (like in
	  <verb>'/subgroup2/table3'</verb>) or as a complete object
	  path written in a certain way known as <em>natural name</em>
	  schema (like in <verb>file.root.subgroup2.table3</verb>).
	</p>

	<p>The support for <em>natural naming</em> is a key aspect of
	  <verb>PyTables</verb> and means that the names of instance
	  variables of the node objects are the same as the names of
	  the element's children<footnote>I have got this simple but
	  powerful idea from the excellent <visual
	  markup="tt">Objectify</visual> module by David Mertz (see
	  <cite refid="Objectify"></cite>)</footnote>. This is very
	  <em>Pythonic</em> and comfortable in many cases, as you can
	  check in the tutorial <ref
	  refid="readingAndSelectingUsage">section</ref>.
	</p>
	<p>You should also note that not all the data present on file
	  is loaded in the object tree, but only the <em>metadata</em>
	  (i.e. special data that describes the structure of the
	  actual data). The actual data is not read until you ask for
	  it (by calling a method on a particular node). By making use
	  of the object tree (the metadata) you can get information on
	  the objects on disk such as table names, title, name
	  columns, data types in columns, the number of rows, or, in
	  the case of arrays, the shape, the typecode, and so on. You
	  can also traverse the tree in order to search for something
	  and when you find the data you are interested in you can
	  read it and process it. In some sense, you can think of
	  <verb>PyTables</verb> as a tool that provide the same
	  introspection capabilities of Python objects, but applied to
	  the persistent storage of large amounts of data.
	</p>
	<p>To better understand the dynamic nature of this object tree
	  entity, let's start by a first example and try to realize
	  what kind of object tree the next script (you can find it in
	  <verb>examples/objecttree.py</verb>) would create:
	</p>

	<verbatim>
from tables import *

class Particle(IsDescription):
    identity = Col("CharType", 16, " ", pos = 0)  # character String
    idnumber = Col("Int16", 1, pos = 1)  # short integer
    speed = Col("Float32", 1, pos = 1)  # single-precision

# Open a file in "w"rite mode
fileh = openFile("objecttree.h5", mode = "w")
# Get the HDF5 root group
root = fileh.root

# Create the groups:
group1 = fileh.createGroup(root, "group1")
group2 = fileh.createGroup(root, "group2")

# Now, create a table in "group0" group
array1 = fileh.createArray(root, "array1", ["string", "array"], "String array")
# Create 2 new tables in group1
table1 = fileh.createTable(group1, "table1", Particle)
table2 = fileh.createTable("/group2", "table2", Particle)
# Create the last table in group2
array2 = fileh.createArray("/group1", "array2", [1,2,3,4])

# Now, fill the tables:
for table in (table1, table2):
    # Get the record object associated with the table:
    row = table.row
    # Fill the table with 10 records
    for i in xrange(10):
        # First, assign the values to the Particle record
        row['identity']  = 'This is particle: %2d' % (i)
        row['idnumber'] = i
        row['speed']  = i * 2.
        # This injects the Record values
        row.append()

    # Flush the table buffers
    table.flush()

# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
	</verbatim>

	<p>This small program creates a simple HDF5 file, called
	  <verb>objecttree.h5</verb>, with the structure that appears
	  in <ref refid="objecttree-h5">figure</ref>. During creation
	  time, metadata in the object tree is updated in memory while
	  the actual data is being saved on disk and when you close
	  the file the object tree becomes unavailable. But, when you
	  will open again this file the object tree with will be
	  re-constructed in memory from the metadata existent on disk,
	  so that you can work with it exactly in the same way than
	  during the original creation process.
	</p>

	<figure id="objecttree-h5">
	  <graphics file="objecttree-h5" scale="0.6" kind="bitmap">
	  </graphics>
	  <caption>An HDF5 example with 2 subgroups, 2 tables and 1
	    array.</caption>
	</figure>

	<p>In <ref refid="objecttree">figure</ref> you can see an
	  example of the object tree created by reading the above
	  <verb>objecttree.h5</verb> file (in fact, such an object is
	  always created when reading any supported generic HDF5
	  file). If you are going to become a <visual
	  markup="tt">PyTables</visual> user, take your time to
	  understand it<footnote>Bear in mind, however, that this
	  diagram is <visual markup="bf">not</visual> a standard UML
	  class diagram; it is rather meant to show the connections
	  between the <verb>PyTables</verb> objects and some of its
	  most important attributes and methods.</footnote>. That will
	  also make you more proactive by avoiding programming
	  mistakes.
	</p>

	<figure id="objecttree">
	  <graphics file="objecttree" scale="0.35" kind="vector">
	  
	  <!-- If you want to convert the eps to jpeg use command:
pstoimg -scale 0.75 -aaliastext -type png -crop a -interlace objecttree.eps
	  and then, convert again to jpg with:
	  convert objecttree.png objecttree.jpg
	  Use this tag to include the jpeg file:
	  <graphics file="objecttree" scale="0.5" kind="bitmap">
	  -->
	  </graphics>
	  <caption>An object tree example in <visual
	      markup="tt">PyTables</visual>.
	  </caption>
	</figure>

      </section>

    </chapter>

    <chapter>
      <heading>Installation</heading>

      <aphorism>El meu país es tan petit <newline/> que quan el sol
	se'n va a dormir <newline/> no està mai prou segur d'haver-lo
	vist <caption>Lluís Llach in the song "Petit País"</caption>
      </aphorism>

<!--       <aphorism>Make things as simple as possible, but not any -->
<!-- 	simpler.  <caption>Einstein</caption> </aphorism> -->

      <p>The Python <verb>Distutils</verb> are used to build and
	install <verb>PyTables</verb>, so it is fairly simple to get
	things ready to go.
      </p>

      <section>
	<heading>Binary installation (Windows)</heading>

	<p>This section is only intended for Windows platforms. If you
	  have Unix, or want to compile PyTables for Windows, jump to
	  the next section.
	</p>
	<p>First, make sure that you have HDF5 1.4.x and numarray
	  installed (I'm using HDF5 1.4.5 and numarray 0.5
	  currently). If don't, you can find them at
	  <verb>http://hdf.ncsa.uiuc.edu/HDF5</verb> and <newline/>
	  <verb>http://sourceforge.net/projects/numpy/</verb>. Download
	  the binary packages and install them. For the HDF5 it should
	  be enough by manually copying the <verb>hdf5dll.dll</verb>
	  file to a directory in your <verb>PATH</verb> environment
	  variable.
	</p>
	<p>Download the
	  <verb>tables-&lt;version>.win32-py&lt;version>.exe</verb>
	  file and execute it.
	</p>
	<p>You can (<em>you should</em>) test your installation by
	  unpacking the source tarball. Go to the <verb>test/</verb>
	  directory and execute the <verb>test_all.py</verb>
	  script. If all the tests passes (maybe with a couple of
	  warnings, related with the possibly missing LZO and UCL
	  libs, but that's ok for the binary version) you already have
	  a working, well tested, copy of PyTables installed!. If not,
	  please, execute the <verb>test_all.py -v</verb> and return
	  the output to me.
	</p>
	<p>If you want support for LZO and UCL libraries (see <ref
	  refid="compressionIssues">section</ref> for hints about what
	  they are useful for), fetch
	  <verb>tables-&lt;version>-LU.win32-py&lt;version>.exe</verb>
	  instead, and remember to install the LZO and UCL DLL
	  libraries (see next section).
	</p>

	<p>That's it!. Now, proceed with the next chapter to see how to
	  use <verb>PyTables</verb>.
	</p>

      </section>

      <section>
	<heading>Installation from sources</heading>

	<p>
	  These instructions are both for Unix/Linux and Windows
	  systems. If you are using Windows, it is assumed that you
	  are using a recent version of <verb>MS Visual C++</verb> (>=
	  6.0) compiler. A <verb>GCC</verb> compiler is asumed for
	  Unix, but other compilers should work as well.
	</p>

	<p>Extensions in <visual markup="tt">PyTables</visual> has been
	  made using Pyrex (see <cite refid="Pyrex"></cite>) and C
	  language. You can rebuild everything from scratch if you got
	  Pyrex installed, but this is not necessary, as the Pyrex
	  compiled source is included in the distribution. In order to
	  do that, merely replace <visual markup="tt">setup.py</visual>
	  script in these instructions by <visual
	    markup="tt">setup-pyrex.py</visual>.
	</p>

	<p>To compile <verb>PyTables</verb> you will need a recent
	  version of <verb>HDF5</verb> (C flavor) library and
	  <verb>numarray</verb> (see <cite refid="Numarray"></cite>)
	  package. Although you won't need <verb>Numerical Python</verb>
	  (see <cite refid="Numeric"></cite>) in order to compile
	  PyTables, it is supported; you only will need a reasonably
	  recent version of it (>= 21.x). PyTables has been successfully
	  tested with Numeric 21.3, 22.0 and 23.0. If you have
	  <verb>Numeric</verb> installed, the test driver module will
	  detect it and will run the tests for <verb>Numeric</verb>
	  automatically.
	</p>

	<enumerate>

	  <item>
	    <p>First, make sure that you have <verb>HDF5 1.4.x</verb>
	      and <verb>numarray</verb> installed (I'm using
	      <verb>HDF5 1.4.5</verb> and <verb>numarray 0.5</verb>
	      currently). If don't, you can find them at
	      <verb>http://hdf.ncsa.uiuc.edu/HDF5</verb> and
	      <verb>http://www.pfdubois.com/numpy</verb>. Compile/install
	      them.
	    </p>
	    <p>Optionally, consider to install the excellent LZO and
	      UCL compression libraries (see <cite
	      refid="lzouclRef"></cite> and section <ref
	      refid="compressionIssues"></ref>).
	    </p>
	    <description>
	      <term>Windows</term>
	      <item>
		<p>If you are using Windows, and don't want to
		  compile the libraries by hand, there are available
		  binary packages for them. You can fetch the HDF5 and
		  numarray binaries from their homes.
		</p>

		<p>Besides, you can (should) fetch the LZO and UCL
		  binaries from:
		  <verb>http://gnuwin32.sourceforge.net/</verb>. Normally,
		  you will only need to fetch and install the
		  <verb>&lt;package>-&lt;version>-bin.zip</verb> file,
		  although in some cases the headers are in
		  <verb>&lt;package>-&lt;version>-lib.zip</verb> file.
		</p>
		<p>Note that you need to copy manually the
		  <verb>hdf5dll.dll</verb> (and <verb>lzo.dll</verb>
		  or <verb>ucl.dll</verb> if you want them) to a
		  directory in the <verb>PATH</verb>, so that they can
		  be find by PyTables extensions.</p>
	      </item>

	      <term>Unix</term>
	      <item>

		<p><verb>setup.py</verb> will detect
		  <verb>HDF5</verb>, <verb>LZO</verb> or
		  <verb>UCL</verb> libraries and include files under
		  <verb>/usr</verb> or <verb>/usr/local</verb>; this
		  will catch installations from RPMs, DEBs and most
		  hand installations under Unix. If
		  <verb>setup.py</verb> can't find your
		  <verb>libhdf5</verb> (or any other library you may
		  wish) or if you have several versions installed and
		  want to select one of them, then you can give it a
		  hint either in the environment (using the
		  <verb>HDF5_DIR</verb> environment variable or
		  <verb>LZO_DIR</verb> and <verb>UCL_DIR</verb> for
		  the optional libraries) or on the command line by
		  specifying the directory containing the include and
		  lib directory. For example:
		</p>

		<verbatim>
		  --hdf5=/stuff/hdf5-1.4.5
		  --ucl=/stuff/ucl-1.0.1
		</verbatim>

		<p>If your <verb>HDF5</verb> library was built as
		  shared library, and if this shared library is not in
		  the runtime load path, then you can specify the
		  additional linker flags needed to find the shared
		  library on the command line as well. For example:
		</p>
		<verbatim>
		  --lflags="-Xlinker -rpath -Xlinker /stuff/hdf5-1.4.5/lib"
		</verbatim>
		<p>or perhaps just
		</p>
		<verbatim>
		  --lflags="-R /stuff/hdf5-1.4.5/lib"
		</verbatim>

		<p>Check your compiler and linker documentation for correct
		  syntax.
		</p>

		<p>It is also possible to specify linking against different
		  libraries with the <verb>--libs</verb> switch:
		</p>
		<verbatim>
		  --libs="-lhdf5-1.4.6"
		  --libs="-lhdf5-1.4.6 -lnsl"
		</verbatim>
	      </item>
	      <term>Windows</term>
	      <item>

		<p><verb>setup.py</verb> will need that you inform it
		  about where the library <em>stubs</em>
		  (<verb>.lib</verb>) are installed as well as the
		  <em>header</em> files (<verb>.h</verb>). To tell
		  setup.py<verb></verb> where the stubs and headers
		  are, set the next environment variables:
		</p>

		<description>
		  <term>HDF5_DIR</term><item>Points to the HDF5 main
		    directory (where the include/ and dll/ directories
		    hangs). <em>Mandatory</em>.</item>
		    
		  <term>LZO_DIR</term> <item>Points to the LZO main
		    directory (where the include/ and lib/ directories
		    hangs). <em>Optional</em>.</item>

		  <term>UCL_DIR</term> <item>Points to the UCL main
		    directory (where the include/ and lib/ directories
		    hangs). <em>Optional</em>.</item>

		</description> 

		<p>For example:
		</p>
		<verbatim>
		  set HDF5_DIR=c:\stuff\5-145-winVS\c\release
		  set LZO_DIR=c:\stuff\lzo-1.07
		  set UCL_DIR=c:\stuff\ucl-1.01
		</verbatim>

		<p>Or you can pass this info to <verb>setup.py</verb>
		  within the command line by specifying the directory
		  containing the include and lib directory. For
		  example:
		</p>

		<verbatim>
		  --hdf5=c:\stuff\5-146-winVS\c\release --lzo=c:\stuff\lzo-1.07
		  --ucl=c:\stuff\ucl-1.01
		</verbatim>	
	      </item>

	    </description>

	  </item>

	  <item>
 	    <p>From the main <verb>PyTables</verb> distribution
	      directory run this command, (plus any extra flags needed
	      as discussed above):
	    </p>
	    <verbatim>
	      python setup.py build_ext --inplace
	    </verbatim>
	    <p>depending on the compiler flags used when compiling your
	      Python executable, there may appear lots of warnings. Don't
	      worry, almost all of them are caused by variables declared
	      but never used. That's normal in Pyrex extensions.
	    </p>
	  </item>
	  <item>
	    <p>To run the test suite change into the test directory
	      and run this command:
	    </p>
	    <description>
	      <term>Unix</term> <item>In the shell <verb>sh</verb> and
	      its variants:
		<verbatim>
		  PYTHONPATH=..  
		  export PYTHONPATH
		  python test_all.py
		</verbatim>
	      </item>
	      <term>Windows</term>
	      <item>Open a DOS terminal and write:
		<verbatim>
		  set PYTHONPATH=..  
		  python test_all.py
		</verbatim>
	      </item>
	    </description>

	    <p>If you would like to see some verbose output from the
	      tests simply add the flag <verb>-v</verb> and/or the word
	      <verb>verbose</verb> to the command line. You can also
	      run just the tests in a particular test module. For
	      example:
	    </p>
	    <verbatim>
	      python test_types.py -v
	    </verbatim>

	    <p>If there is some test that do not pass, please, run the
	      failing test module with all verbosity enabled (flags
	      <verb>-v verbose</verb>), and send back the output to
	      developers.
	    </p>

	    <p> If you run into problems because Python can't load the
	      HDF5, or any other shared library:
	    </p>
	    <description>
	      <term>Unix</term>
	      <item>
		Try to set the LD_LIBRARY_PATH environment variable to
		point to the directory where the libraries are.
	      </item>
	      <term>Windows</term> <item>Put the DLL libraries
	      (<verb>hdf5dll.dll</verb> and, optionally,
	      <verb>lzo.dll</verb> and <verb>ucl.dll</verb>) on a
	      directory listed on your <verb>PATH</verb> environment
	      variable.  The <verb>setup.py</verb> should already
	      warned you about that.
	      </item>
	    </description>
	  </item>
	  <item>
	    <p>To install the entire <visual
		markup="tt">PyTables</visual> Python package, change back
	      to the root distribution directory and run this command as
	      the root user (remember to add any extra flags needed):
	    </p>
	    <verbatim>
	      python setup.py install
	    </verbatim>

	  </item>
	</enumerate>

	<p>That's it!. Now, proceed with the next chapter to see how to
	  use <verb>PyTables</verb>.
	</p>

      </section>

    </chapter>

    <chapter id="usage">
      <heading>Some tutorials</heading>

      <p>This chapter begins with a series of simple, yet
	comprehensive sections written in a tutorial style that will
	let you understand the main features that
	<verb>PyTables</verb> provide. If during the trip you want
	more information on some specific instance variable, global
	function or method, look at the doc strings or go to the
	library reference in <ref
	refid="libraryReference">chapter</ref>. However, if you are
	reading this in PDF or HTML formats, there should be an
	hyperlink to its reference near each newly introduced
	entity.
      </p>

      <p>Please, note that throughout this document the terms
	<em>column</em> and <em>field</em> will be used
	interchangeably with the same meaning, and the same goes for
	the terms <em>row</em> and <em>record</em>.
      </p>

      <section>
	<heading>Getting started</heading>

	<p>In this section, we will see how to define our own records
	  from Python and save collections of them (i.e. a <visual
	  markup="bf">table</visual>) on a file. Then, we will select
	  some data in the table using Python cuts, creating Numerical
	  arrays to keep this selection as separate objects in the
	  tree.
	</p>
	<p>
	  In <em>examples/tutorial1-1.py</em> you will find the
	  working version of all the code in this
	  section. Nonetheless, this tutorial series has been written
	  to allow you reproduce it in a Python interactive
	  console. You are encouraged to take advantage of that by
	  doing parallel testing and inspecting the created objects
	  (variables, docs, children objects, etc.) during the
	  voyage!.
	</p>

	<subsection>
	  <heading>Importing <visual markup="tt">tables</visual>
	    objects</heading>
	  
	  <p>Before doing anything you need to import the
	    public objects in the <verb>tables</verb> package. You
	    normally do that by issuing:
	  </p>
	  <verbatim>
>>> import tables
>>>
	  </verbatim>
	  <p>This is the recommended way to import <verb>tables</verb>
	    if you don't want to pollute too much your
	    namespace. However, <verb>PyTables</verb> has a very
	    reduced set of first-level primitives, so you may consider
	    to use this alternative:
	  </p>
	  <verbatim>
>>> from tables import *
>>>
	  </verbatim>
	  <p>that will export in your caller application namespace the
	    next objects: <verb>openFile</verb>, <verb>isHDF5</verb>,
	    <verb>isPyTablesFile</verb> and
	    <verb>IsDescription</verb>. These are a rather small number
	    of objects, and for convenience, we will use this last way
	    to access them.
	  </p>
	  <p>If you are going to deal with <verb>Numeric</verb> or
	    <verb>numarray</verb> arrays (and normally, you will) you
	    also need to import some objects from it. You can do that
	    in the normal way. So, to access to <verb>PyTables</verb>
	    functionality normally you should start you programs with:
	  </p>
	  <verbatim>
>>> import tables        # but in this tutorial we use "from tables import *"
>>> from Numeric import *  # or "from numarray import *"
>>>
	  </verbatim>
	</subsection>

	<subsection>
	  <heading>Declaring a Column Descriptor</heading>

	  <p>Now, imagine that we have a particle detector and we want
	    to create a table object in order to save data that comes
	    from it. You need first to define that table, how many
	    columns it have, which kind of object is each element on
	    the columns, and so on.
	  </p>
	  <p>Our detector has a TDC (Time to Digital Converter)
	    counter with a dynamic range of 8 bits and an ADC
	    (Analogic to Digital Converter) with a range of 16
	    bits. For these values, we will define 2 fields in our
	    record object called <verb>TDCcount</verb> and
	    <verb>ADCcount</verb>. We also want to save the grid
	    position in which the particle has been detected and we
	    will add two new fields called <verb>grid_i</verb> and
	    <verb>grid_j</verb>. Our instrumentation also can obtain
	    the pressure and energy of this particle that we want to
	    add in the same way. The resolution of pressure-gauge
	    allows us to use simple-precision float which will be
	    enough to save <verb>pressure</verb> information, while
	    <verb>energy</verb> would need a double-precision
	    float. Finally, to track this particle we want to assign
	    it a name to inform about the kind of the particle and a
	    number identifier unique for each particle. So we will add
	    a couple of fields: <verb>name</verb> will be the a string
	    of up-to 16 characters and because we want to deal with a
	    really huge number of particles, <verb>idnumber</verb>
	    will be an integer of 64 bits.
	  </p>
	  <p>With all of that, we can declare a new
	    <verb>Particle</verb> class that will keep all this info:
	  </p>

	  <verbatim>
>>> class Particle(IsDescription):
...     name      = Col("CharType", 16)  # 16-character String
...     idnumber  = Col("Int64", 1)      # Signed 64-bit integer
...     ADCcount  = Col("UInt16", 1)     # Unsigned short integer
...     TDCcount  = Col("UInt8", 1)      # unsigned byte
...     grid_i    = Col("Int32", 1)      # integer
...     grid_j    = Col("Int32", 1)      # integer
...     pressure  = Col("Float32", 1)    # float  (single-precision)
...     energy    = Col("Float64", 1)    # double (double-precision)
...
>>>
	  </verbatim>
	  <p>This definition class is quite
	    auto-explanatory. Basically, you have to declare a class
	    variable for each field you need, and as its value we
	    assign a <verb>Col</verb> instance, that takes as
	    arguments the data type and the number of items on each
	    column element (in fact, the <verb>Col()</verb>
	    constructor accepts a few more arguments, see <ref
	    refid="ColClassDescr">section</ref> for a detailed
	    descrition). See <ref
	    refid="datatypesSupported">appendix</ref> for a list of
	    data types supported in <verb>Col</verb> constructors.
	  </p>
	  <p>From now on, we can use <verb>Particle</verb> instances
	    as a descriptor for our detector data table. We will see
	    how to pass this object to the <verb>Table</verb>
	    constructor. But first, we must create a file where all
	    the actual data pushed into <verb>Table</verb> will be
	    saved.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating a <visual markup="tt">PyTables</visual> file from scratch</heading>

	  <p>To create a <verb>PyTables</verb> file use the
	    first-level <verb>openFile</verb> (see <ref
	    refid="openFileDescr"></ref>) function:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial1.h5", mode = "w", title = "Test file")
	  </verbatim>
	  <p>This <verb>openFile</verb> is one of the objects imported
	    by the "<verb>from tables import *</verb>", do you
	    remember?. Here, we are telling that we want to create a
	    new file called "<verb>tutorial1.h5</verb>" in
	    "<verb>w</verb>"rite mode and with an descriptive title
	    string ("<verb>Test file</verb>"). This function tries to
	    open the file, and if successful, returns a
	    <verb>File</verb> (see <ref refid="FileClassDescr"></ref>)
	    instance which hosts the root of the object tree on its
	    <verb>root</verb> attribute.
	  </p>
	</subsection>

	<subsection>
	  <heading>Creating a new group</heading>

	  <p>Now, to better organize our data, we will create a group
	    hanging from the root called <em>detector</em>. We will
	    use this group to save our particle data there.
	  </p>
	  <verbatim>
>>> group = h5file.createGroup("/", 'detector', 'Detector information')
>>>
	  </verbatim>

	  <p>Here, we have taken the <verb>File</verb> instance
	    <verb>h5file</verb> and invoked its
	    <verb>createGroup</verb> method (see<ref
	    refid="createGroupDescr"></ref>), telling that we want to
	    create a new group called <em>detector</em> hanging from
	    "<em>/</em>", which is other way to refer to the
	    <verb>h5file.root</verb> object we mentioned before. This
	    will create a new <verb>Group</verb> (see<ref
	    refid="GroupClassDescr"></ref>) instance that will be
	    assigned to the <verb>group</verb> variable.
	  </p>

	</subsection>
	<subsection>
	  <heading>Creating a new table</heading>

	  <p>Let's now create the <verb>Table</verb> (see <ref
	    refid="TableClassDescr"></ref>) object hanging from the new
	    created group. We do that by calling the
	    <verb>createTable</verb> (see <ref
	    refid="createTableDescr"></ref>) method from the
	    <verb>h5file</verb> object:
	  </p>
	  <verbatim>
>>> table = h5file.createTable(group, 'readout', Particle, "Readout example")
>>>
	  </verbatim>

	  <p>You can see how we asked to create the <verb>Table</verb>
	    instance hanging from <verb>group</verb>, with name
	    <em>'readout'</em>. We have passed <verb>Particle</verb>,
	    the class that we have declared before, as the
	    <em>description</em> parameter and finally we have used
	    "<em>Readout example</em>" as a <verb>Table</verb>
	    title. With all this information, a new <verb>Table</verb>
	    instance is created and assigned to <em>table</em>
	    variable.
	  </p>

	  <p>If you are getting curious how the object tree looks like
	    at this moment, simply print the name of the
	    <verb>File</verb> instance, <em>h5file</em>, and look at
	    their output:
	  </p>

	  <verbatim>
>>> print h5file
Filename: tutorial1.h5 'Test file'
/ (Group) 'Test file'
/detector (Group) 'Detector information'
/detector/readout Table(0,) 'Readout example'

>>>
	  </verbatim>

	  <p>As you can see, a dump of the object tree has been shown
	    and it's very easy to visualize the <verb>Group</verb> and
	    <verb>Table</verb> objects we have just created. If you
	    want more information, just type the name of the
	    <verb>File</verb> instance:
	  </p>

	  <verbatim>
>>> h5file
>>> h5file
Filename: tutorial1.h5 'Test file'
  mode = 'w'
  trMap = {}
/ (Group) 'Test file'
/detector (Group) 'Detector information'
/detector/readout Table(0,) 'Readout example'
  description = {
    'ADCcount': Col('UInt16', (1,)),
    'TDCcount': Col('UInt8', (1,)),
    'energy': Col('Float64', (1,)),
    'grid_i': Col('Int32', (1,)),
    'grid_j': Col('Int32', (1,)),
    'idnumber': Col('Int64', (1,)),
    'name': Col('CharType', (16,)),
    'pressure': Col('Float32', (1,)) }
  byteorder = little

>>>
	  </verbatim>

	  <p>where more detailed info is printed on each object on the
	    tree. Pay attention on how <verb>Particle</verb>, our
	    column descriptor class, is printed as part of the
	    <em>readout</em> table description information. In
	    general, you can obtain lot of information on the objects
	    and its children by just printing them. That introspection
	    capability is quite powerful, so I recommend you to use it
	    extensively.
	  </p>

	  <p>Now, time to fill this table with some values. But first,
	    we are going to get a pointer to the <verb>Row</verb>
	    instance of this <verb>table</verb> instance:
	  </p>
	  <verbatim>
>>> particle = table.row
>>>
	  </verbatim>

	  <p>The <verb>row</verb> attribute of <verb>table</verb>
	    points to the <verb>Row</verb> (see <ref
	    refid="RowClassDescr"></ref>) instance that will be used
	    to input data rows into the table. We achieve this by just
	    assigning it the values for each row as if it was a
	    dictionary (although it is actually an <em>extension
	    class</em>) and using the column names as keys.
	  </p>

	  <p>Look at how the filling process works like:
	  </p>

	  <verbatim>
>>> particle = table.row
>>> for i in xrange(10):
...     particle['name']  = 'Particle: %6d' % (i)
...     particle['TDCcount'] = i % 256
...     particle['ADCcount'] = (i * 256) % (1 &lt;&lt; 16)
...     particle['grid_i'] = i
...     particle['grid_j'] = 10 - i
...     particle['pressure'] = float(i*i)
...     particle['energy'] = float(particle['pressure'] ** 4)
...     particle['idnumber'] = i * (2 ** 34)
...     # Insert a new particle record
...     particle.append()
...
>>>
	  </verbatim>
	  
	  <p>This code is quite easy to understand. The lines inside
	    the loop just assign values to the different columns in
	    the <verb>particle</verb> row object and then a call to
	    its <verb>append()</verb> (see <ref
	    refid="RowClassDescr"></ref>) method is made to put this
	    information in the <verb>table</verb> I/O buffer.
	  </p>

	  <p>After we have pushed all our data, we should flush the
	    I/O buffer for the table if we want to consolidate all
	    this data on disk. We can achieve that by calling the
	    <verb>table.flush()</verb> method.
	  </p>
	  <verbatim>
>>> table.flush()
>>>
	  </verbatim>

	</subsection>

	<subsection id="readingAndSelectingUsage">
	  <heading>Reading (and selecting) data in table</heading>

	  <p>Ok. We have now our data on disk but to this data be
	    useful we need to access it and select some values we are
	    interested in and located at some specific columns. That's
	    is easy to do:
	  </p>
	  <verbatim>
>>> table = h5file.root.detector.readout
>>> pressure = [ x['pressure'] for x in table.iterrows()
...              if x['TDCcount'] > 3 and x['pressure'] &lt; 50 ]
>>> pressure
[16.0, 25.0, 36.0, 49.0]
>>>
	  </verbatim>

	  <p>The first line is only to declare a convenient shortcut
	    to the <em>readout</em> table which is a bit deeper on the
	    object tree. As you can see, we have used the <visual
	    markup="bf">natural naming</visual> schema to access
	    it. We could also have used the
	    <verb>h5file.getNode()</verb> method instead, and we
	    will certainly do that later on.
	  </p>

	  <p>The last two lines are a Python comprehensive list. It
	    loops over rows in <em>table</em> as they are provided by
	    <verb>table.iterrows()</verb> iterator (see <ref
	    refid="iterrowsDescr"></ref>) that returns values until
	    data in table is exhausted. This rows are filtered using
	    the expression <verb>x['TDCcount'] > 3 and x['pressure']
	    &lt; 50</verb>, and the <verb>pressure</verb> field for
	    satisfying records is selected to form the final list that
	    is assigned to <verb>pressure</verb> variable.
	  </p>

	  <p>We could indeed have used a normal <verb>for</verb> loop
	    to do that, but I find comprehension syntax to be more
	    compact and elegant.
	  </p>

	  <p>Let's select the names for the same set of particles:
	  </p>

	  <verbatim>
>>> names = [ x['name'] for x in table.iterrows()
...           if x['TDCcount'] > 3 and x['pressure'] &lt; 50 ]
>>> names
['Particle:      4', 'Particle:      5', 'Particle:      6', 'Particle:      7']
>>>
	  </verbatim>

	  <p>Ok. that's enough for selections. Next section will show
	    you how to save these selections on file.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating new array objects</heading>

	  <p>In order to separate the selected data from the detector
	    data, we will create a new group, called
	    <verb>columns</verb> hanging from the root group:
	  </p>

	  <verbatim>
>>> gcolumns = h5file.createGroup(h5file.root, "columns", "Pressure and Name")
>>>
	  </verbatim>

	  <p>Note that this time we have specified the first parameter
	    in a natural naming fashion (<verb>h5file.root</verb>)
	    instead of using an absolute path string ("/").
	  </p>

	  <p>Now, create one <verb>Array</verb> object:
	  </p>

	  <verbatim>
>>> h5file.createArray(gcolumns, 'pressure', array(pressure),
...                    "Pressure column selection")
/columns/pressure Array(4,) 'Pressure column selection'
  type = 'Float64'
  itemsize = 8
  flavor = 'Numeric'
  byteorder = 'little'
	  </verbatim>

	  <p>We already know the first two parameters of the
	    <verb>createArray</verb> (see <ref
	    refid="createArrayDescr"></ref>) methods (these are the
	    same as the firsts in <verb>createTable</verb>): they are
	    the parent group <em>where</em> <verb>Array</verb> will be
	    created and the <verb>Array</verb> instance
	    <em>name</em>. You can figure out that the fourth
	    parameter is the <em>title</em>. And in the third position
	    we have the <em>object</em> we want to save on disk. In
	    this case, it is a <verb>Numeric</verb> array that is
	    built from the selection lists we created before.
	  </p>

	  <p>Now, we are going to save the other selection. In this
	    case it's a list of strings, and we want to save this
	    object as is, with no further conversion. Look at how this
	    can be done:
	  </p>

	  <verbatim>
>>> h5file.createArray(gcolumns, 'name', names, "Name column selection")
/columns/name Array(4,) 'Name column selection'
  type = 'CharType'
  itemsize = 16
  flavor = 'List'
  byteorder = 'little'
>>>
	  </verbatim>

	  <p>You see, <verb>createArray()</verb> accepts
	    <em>names</em> (which is a regular Python list) as
	    <em>object</em> parameter. Actually, it accepts a variety
	    of other regular objects (see <ref
	    refid="createArrayDescr"></ref>). We will check that we can
	    retrieve exactly this same object from disk later on.
	  </p>
	  <p>Note that in this examples, <verb>createArray</verb>
	    method returns an <verb>Array</verb> instance that is not
	    assigned to any variable. Don't worry, this was
	    intentional, because I wanted to show you the kind of
	    object we have created by showing its
	    representation. Indeed, the <verb>Array</verb> objects has
	    been attached to the object tree and saved on disk, as you
	    can see if you print the complete object tree:
	  </p>
	  <verbatim>
>>> print h5file
Filename: tutorial1.h5 'Test file'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name Array(4, 16) 'Name column selection'
/columns/pressure Array(4,) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout Table(10,) 'Readout example'

>>>
	  </verbatim>
	</subsection>

	<subsection>
	  <heading>Closing the file and looking at its content</heading>

	  <p>To finish this first tutorial, we use the
	    <verb>close</verb> method of the h5file <verb>File</verb>
	    instance to close the file before exiting Python:
	  </p>
	  <verbatim>
>>> h5file.close()
>>> ^D
	  </verbatim>

	  <p>With all that, you have created your first
	    <verb>PyTables</verb> file with a table and two
	    arrays. That was easy, admit it. Now, you can have a look
	    at it with some generic HDF5 tool, like
	    <verb>h5dump</verb> or <verb>h5ls</verb>. Here is the
	    result of passing to <verb>h5ls</verb> the
	    <verb>tutorial1.h5</verb> file:
	  </p>
	  <verbatim>
$ h5ls -rd tutorial1.h5
/columns                 Group
/columns/name            Dataset {4}
    Data:
        (0) "Particle:      4", "Particle:      5", "Particle:      6",
        (3) "Particle:      7"
/columns/pressure        Dataset {4}
    Data:
        (0) 16, 25, 36, 49
/detector                Group
/detector/readout        Dataset {10/Inf}
    Data:
        (0) {0, 0, 0, 0, 10, 0, "Particle:      0", 0},
        (1) {256, 1, 1, 1, 9, 17179869184, "Particle:      1", 1},
        (2) {512, 2, 256, 2, 8, 34359738368, "Particle:      2", 4},
        (3) {768, 3, 6561, 3, 7, 51539607552, "Particle:      3", 9},
        (4) {1024, 4, 65536, 4, 6, 68719476736, "Particle:      4", 16},
        (5) {1280, 5, 390625, 5, 5, 85899345920, "Particle:      5", 25},
        (6) {1536, 6, 1679616, 6, 4, 103079215104, "Particle:      6", 36},
        (7) {1792, 7, 5764801, 7, 3, 120259084288, "Particle:      7", 49},
        (8) {2048, 8, 16777216, 8, 2, 137438953472, "Particle:      8", 64},
        (9) {2304, 9, 43046721, 9, 1, 154618822656, "Particle:      9", 81}
	  </verbatim>

	  <p>or, using the "dumpFile.py" <verb>PyTables</verb> utility
	    (located in <verb>examples/</verb> directory):
	  </p>

	  <verbatim>
$ python dumpFile.py tutorial1.h5
Filename: tutorial1.h5
All objects:
Filename: tutorial1.h5 'Test file'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name Array(4, 16) 'Name column selection'
/columns/pressure Array(4,) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout Table(10,) 'Readout example'

	  </verbatim>

	  <p>You can pass the <verb>-v</verb> or <verb>-d</verb>
	    options to <verb>dumpFile.py</verb> if you want more
	    verbosity. Try it!.
	  </p>
	</subsection>
      </section>

      <section>
	<heading>Browsing the <visual markup="it">object tree</visual>
	  and more</heading>

	<p>In this section, we will learn how to browse the tree while
	  retrieving metainformation about the actual data, and will
	  finish by appending some rows to the existing table to show
	  how table objects can be enlarged.
	</p>
	<p>
	  In <em>examples/tutorial1-2.py</em> you will find the
	  working version of all the code in this section. As before,
	  you are encouraged to use a python shell and inspect the
	  object tree during the voyage.
	</p>

	<subsection>
	  <heading>Traversing the object tree</heading>

	  <p>First of all, let's open the file we have recently
	    created in last tutorial section, as we will take it as a
	    basis for this section:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial1.h5", "a")
	  </verbatim>

	  <p>This time, we have opened the file in "a"ppend mode. We
	    are using this mode because we want to add more
	    information to the file.
	  </p>
	  <p><verb>PyTables</verb>, following the Python tradition,
	    offers powerful instropection capabilities, i.e. you can
	    easily ask information about any component of the object
	    tree as well as traverse the tree searching for something.
	  </p>
	  <p>To start with, you can get a first glance image of the
	    object tree, by simply printing the existing
	    <verb>File</verb> instance:
	  </p>

	  <verbatim>
>>> print h5file
Filename: tutorial1.h5 'Test file'
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/columns/name Array(4,) 'Name column selection'
/columns/pressure Array(4,) 'Pressure column selection'
/detector (Group) 'Detector information'
/detector/readout Table(10,) 'Readout example'

>>>
	  </verbatim>

	  <p>That's right, it seems that all our objects are there. We
	    can use the <verb>walkGroups</verb> method (see <ref
	    refid="walkGroupsDescr"></ref>) of <verb>File</verb> class
	    to list all the groups on tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...   print group
...
/ (Group) 'Test file'
/columns (Group) 'Pressure and Name'
/detector (Group) 'Detector information'
>>>
	  </verbatim>

	  <p>Note that <verb>walkGroups()</verb> actually returns an
	    <em>iterator</em>, not a list of objects. Combining this
	    iterator with the <verb>listNodes()</verb> method, we can
	    do very powerful things. Let's see an example listing all
	    the arrays in the tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...     for array in h5file.listNodes(group, classname = 'Array'):
...         print array
...
/columns/name Array(4,) 'Name column selection'
/columns/pressure Array(4,) 'Pressure column selection'
	  </verbatim>

	  <p><verb>listNodes()</verb> (see <ref
	    refid="listNodesDescr"></ref>) lists all the nodes hanging
	    from a <em>group</em>, and if <em>classname</em>
	    keyword is specified, the method will filter all instances
	    which are not descendants of it. We have specified it so
	    as to return only the <verb>Array</verb> instances.
	  </p>
	  <p>
	    <visual markup="bf">Caveat emptor</visual>:
	    <verb>listNodes</verb> (conversely to
	    <verb>walkGroups</verb>) returns an actual list, not an
	    iterator!.
	  </p>

	  <p>As a final example, we will list all the
	    <verb>Leaf</verb> (i.e. <verb>Table</verb> and
	    <verb>Array</verb> instances, see <ref
	    refid="LeafClassDescr"></ref> for detailed information on
	    <verb>Leaf</verb> class) objects in <em>/detector</em>
	    group. Check that only one instance of <verb>Table</verb>
	    class (i.e. <em>readout</em>), will be selected in this
	    group (as it should be):
	  </p>

	  <verbatim>
>> for table in h5file.listNodes("/detector", 'Leaf'):
...   print table
...
/detector/readout Table(10,) 'Readout example'
>>> 
	  </verbatim>

	  <p>Of course you can do more sophisticated node selections
	    using this two powerful functions, but first, we need to
	    learn a bit about some important instance variables of
	    <verb>PyTables</verb> objects.
	  </p>

	</subsection>

	<subsection>
	  <heading>Setting and getting user attributes</heading>

	  <p>PyTables provides an easy and concise way to complement
	    the meaning of your node objects on the tree by using the
	    <verb>AttributeSet</verb> class (see <ref
	    refid="AttributeSetClassDescr">section</ref>). You can
	    access to this object through the standard attribute
	    <verb>attrs</verb> in <verb>Leaf</verb> nodes and
	    <verb>_v_attrs</verb> in <verb>Group</verb> nodes.
	  </p>

	  <p>For example, let's imagine that we want to save the date
	    indicating when the data in <verb>/detector/readout</verb>
	    table has been acquired, as well as the temperature during
	    the gathering process. That is easy:
	  </p>

	  <verbatim>
>>> table = h5file.root.detector.readout
>>> table.attrs.gath_date = "Wed, 06/12/2003 18:33"
>>> table.attrs.temperature = 18.4
>>> table.attrs.temp_scale = "Celsius"
>>>
	  </verbatim>

	  <p>Now, set a somewhat more complex attribute in the
	    <verb>/detector</verb> group:
	  </p>

	  <verbatim>
>>> detector = h5file.root.detector
>>> detector._v_attrs.stuff = [5, (2.3, 4.5), "Integer and tuple"]
>>>
	  </verbatim>

	  <p>Note how the AttributeSet instance is accessed with
	    <verb>_v_attrs</verb> because detector is a
	    <verb>Group</verb> node. In general, you can save any
	    standard Python data structure as an attribute node, but
	    see <ref refid="AttributeSetClassDescr">section</ref> for
	    a more detailed explanation of how this are serialized on
	    disk.
	  </p>

	  <p>Now, getting the attributes is equally easy:
	  </p>

	  <verbatim>
>>> table.attrs.gath_date
'Wed, 06/12/2003 18:33'
>>> table.attrs.temperature
18.399999999999999
>>> table.attrs.temp_scale
'Celsius'
>>> detector._v_attrs.stuff
[5, (2.2999999999999998, 4.5), 'Integer and tuple']
>>>
	  </verbatim>

	  <p>You can probably guess how to delete attributes:
	  </p>

	  <verbatim>
>>> del table.attrs.gath_date
	  </verbatim>

	  <p>If you want to have a look at the current attribute set
	  of <verb>/detector/table</verb>, you can print its
	  representation (try also hitting the TAB key twice if you
	  are in a python shell):
	  </p>

	  <verbatim>
>>> table.attrs
/detector/readout (AttributeSet): 13 attributes
   [CLASS := 'TABLE',
    FIELD_0_NAME := 'ADCcount',
    FIELD_1_NAME := 'TDCcount',
    FIELD_2_NAME := 'energy',
    FIELD_3_NAME := 'grid_i',
    FIELD_4_NAME := 'grid_j',
    FIELD_5_NAME := 'idnumber',
    FIELD_6_NAME := 'name',
    FIELD_7_NAME := 'pressure',
    TITLE := 'Readout example',
    VERSION := '1.0',
    temp_scale := 'Celsius',
    temperature := 18.399999999999999]
>>>
	  </verbatim>

	  <p>You can get a list only the user or system (read-only)
	    attributes with the <verb>_v_list()</verb> method.
	  </p>

	  <verbatim>
>>> print table.attrs._f_list("user")
['temp_scale', 'temperature']
>>> print table.attrs._f_list("sys")
['CLASS', 'FIELD_0_NAME', 'FIELD_1_NAME', 'FIELD_2_NAME',
 'FIELD_3_NAME', 'FIELD_4_NAME', 'FIELD_5_NAME', 'FIELD_6_NAME', 
 'FIELD_7_NAME', 'TITLE', 'VERSION']
>>>
	  </verbatim>

	  <p>And rename attributes:
	  </p>

	  <verbatim>
>>> table.attrs._f_rename("temp_scale","tempScale")
>>> print table.attrs._f_list()
['tempScale', 'temperature']
>>>
	  </verbatim>

	  <p>However, you can't set, delete or rename system attributes:
	  </p>

	  <verbatim>
>>> table.attrs._f_rename("VERSION", "version")
Traceback (most recent call last):
  File "&gt;stdin>", line 1, in ?
  File "/home/falted/PyTables/pytables-0.6/tables/AttributeSet.py", line 249, in _f_rename
    raise RuntimeError, \
RuntimeError: System attribute ('VERSION') cannot be overwritten or renamed
>>>
	  </verbatim>

	  <p>As you can see, the use of attributes can be a good
	    mechanism to add (meta) information to your actual data.
	  </p>

	</subsection>

	<subsection>
	  <heading>Getting object metadata</heading>

	  <p>Each object in <verb>PyTables</verb> has metadata about
	    the actual data on the file. Normally this metainformation
	    is accessible through the node instance variables. Let's
	    have a look at some examples:
	  </p>

	  <verbatim>
>>> print "Object:", table
Object: /detector/readout Table(10,) 'Readout example'
>>> print "Table name:", table.name
Table name: readout
>>> print "Table title:", table.title
Table title: Readout example
>>> print "Number of rows in table:", table.nrows
Number of rows in table: 10
>>> print "Table variable names with their type and shape:"
Table variable names with their type and shape:
>>> for name in table.colnames:
...     print "  ", name, ':=', table.coltypes[name], table.colshapes[name]
...
   ADCcount := UInt16 (1,)
   TDCcount := UInt8 (1,)
   energy := Float64 (1,)
   grid_i := Int32 (1,)
   grid_j := Int32 (1,)
   idnumber := Int64 (1,)
   name := CharType (16,)
   pressure := Float32 (1,)
>>>
	  </verbatim>

	  <p>
	    Here, the <verb>name</verb>, <verb>title</verb>,
	    <verb>nrows</verb>, <verb>colnames</verb>,
	    <verb>coltypes</verb> and <verb>colshapes</verb>
	    attributes (see <ref
	    refid="FileInstanceVariablesDescr"></ref> for a complete
	    attribute list) of <verb>Table</verb> object give us quite
	    a lot of information about actual table data.
	  </p>

	  <p>In general, you can get up-to-the-minute information
	    about the public objects in PyTables in a interactive way
	    by printing its internal doc strings:
	  </p>

	  <verbatim>
>>> print table.__doc__
Represent a table in the object tree.

    It provides methods to create new tables or open existing ones, as
    well as to write/read data to/from table objects over the
    file. A method is also provided to iterate over the rows without
    loading the entire table or column in memory.

    Data can be written or read both as Row() instances or as numarray
    (NumArray or RecArray) objects.

    Methods:

      Common to all leaves:
        close()
        flush()
        getAttr(attrname)
        rename(newname)
        remove()
        setAttr(attrname, attrvalue)

      Specific of Table:
        iterrows()
        read([start] [, stop] [, step] [, field [, flavor]])

    Instance variables:

      Common to all leaves:
        name -- the leaf node name
        hdf5name -- the HDF5 leaf node name
        title -- the leaf title
        shape -- the leaf shape
        byteorder -- the byteorder of the leaf

      Specific of Table:
        description -- the metaobject describing this table
        row -- a reference to the Row object associated with this table
        nrows -- the number of rows in this table
        rowsize -- the size, in bytes, of each row
        colnames -- the field names for the table (list)
        coltypes -- the type class for the table fields (dictionary)
        colshapes -- the shapes for the table fields (dictionary)


>>>
	  </verbatim>

	  <p>This is very handy if you don't have this manual at
	    hand. Try yourself with other objects docs!.
	  </p>
	  <p>Now, print some metadata in <em>/columns/pressure</em>
	    <verb>Array</verb> object:
	  </p>

	  <verbatim>
>>> pressureObject = h5file.getNode("/columns", "pressure")
>>> print "Info on the object:", repr(pressureObject)
Info on the object: /columns/pressure Array(4,) 'Pressure column selection'
  type = 'Float64'
  itemsize = 8
  flavor = 'Numeric'
  byteorder = 'little'
>>> print "  shape: ==>", pressureObject.shape
  shape: ==> (4,)
>>> print "  title: ==>", pressureObject.title
  title: ==> Pressure column selection
>>> print "  type ==>", pressureObject.type
  type ==> Float64
>>>
	  </verbatim>

	  <p>Observe how we have used the <verb>getNode()</verb>
	    method of <verb>File</verb> class to access a node in the
	    tree, instead of the natural naming method. Both are
	    useful, and depending on the context you will prefer to
	    use one or another. <verb>getNode()</verb> has the
	    advantage that it can get a node from the pathname string
	    (like in this example), and, besides, you can force a
	    filter so that the node in that location has to be a
	    <em>classname</em> instance. However, natural naming is
	    more elegant and quicker to specify, specially if you are
	    using the name completion capability present in
	    interactive console. I suggest to give a try at this
	    powerful combination of natural naming and completion
	    capabilities present on most Python shell. You will see
	    that browsing the object tree in that way is a very
	    pleasant experience (well, as far as this activity can be
	    qualified in that way).
	  </p>
	  <p>If you look at the <verb>typecode</verb> attribute of the
	    <verb>pressureObject</verb>, you can certify that this is
	    a "<visual markup="bf">Float64</visual>" array, and that
	    by looking at their <verb>shape</verb> attribute, it can
	    deduced that the array on disk is unidimensional and has 4
	    elements. See <ref
	    refid="ArrayClassInstanceVariables"></ref> or the internal
	    string docs for the complete <verb>Array</verb> attribute
	    list.
	  </p>
	</subsection>

	<subsection>
	  <heading>Reading actual data from <visual
	  markup="tt">Array</visual> objects</heading>

	  <p>Once you have found the desired <verb>Array</verb> and
	    decided that you want to retrieve the actual data array
	    from it, you should use the <verb>read()</verb> method of
	    the <verb>Array</verb> object:</p>

	  <verbatim>
>>> pressureArray = pressureObject.read()
>>> nameArray = h5file.root.columns.name.read()
>>> print "pressureArray is an object of type:", type(pressureArray)
pressureArray is an object of type: &lt;type 'array'>
>>> pressureArray
array([ 16.,  25.,  36.,  49.])
>>> print "nameArray is an object of type:", type(nameArray)
nameArray is an object of type: &lt;type 'list'>
>>> nameArray
['Particle:      4', 'Particle:      5', 'Particle:      6', 'Particle:      7']
>>>
>>> print "Data on arrays nameArray and pressureArray:"
Data on arrays nameArray and pressureArray:
>>> for i in range(pressureObject.shape[0]):
...     print nameArray[i], "-->", pressureArray[i]
... 
Particle:      4 --> 16.0
Particle:      5 --> 25.0
Particle:      6 --> 36.0
Particle:      7 --> 49.0
>>> 
	  </verbatim>

	  <p>You can verify as the <verb>read()</verb> method (see
	    <ref refid="readArrayDescr"></ref>) returns an authentic
	    <verb>Numeric</verb> array looking at the output of the
	    <verb>type()</verb> call. This is because the type of the
	    object saved is kept as an HDF5 attribute (named
	    <verb>FLAVOR</verb>) for this object on disk. This
	    attribute is then read as part of the <verb>Array</verb>
	    metainformation and accessible through the
	    <verb>Array.flavor</verb> instance variable, enabling the
	    read array to be converted into the original object. This
	    provides a means to save a large variety of objects as
	    arrays, with the guarantee that you will be able to
	    recover them in its original form afterwards. See <ref
	    refid="createArrayDescr">section</ref> for a complete list
	    of supported objects.
	  </p>

	</subsection>

	<subsection>
	  <heading>Appending data to an existing table</heading>

	  <p>To finish this section, let's have a look at how we can
	    add records to an existing on-disk table. Let's use our
	    well-known <em>readout</em> <verb>Table</verb> instance
	    and let's append some new values to it:
	  </p>

	  <verbatim>
>>> table = h5file.root.detector.readout
>>> particle = table.row
>>> for i in xrange(10, 15):
...     particle['name']  = 'Particle: %6d' % (i)
...     particle['TDCcount'] = i % 256
...     particle['ADCcount'] = (i * 256) % (1 &lt;&lt; 16)
...     particle['grid_i'] = i
...     particle['grid_j'] = 10 - i
...     particle['pressure'] = float(i*i)
...     particle['energy'] = float(particle['pressure'] ** 4)
...     particle['idnumber'] = i * (2 ** 34)
...     particle.append()
...
>>> table.flush()
>>>
	  </verbatim>

	  <p>That works exactly in the same way than filling a new
	    table. <verb>PyTables</verb> knows that this table is on
	    disk, and when you add new records, they are appended to
	    the end of the table<footnote>Note that you can only
	    append values to tables, not array objects. However, I
	    plan to support unlimited dimension of arrays shortly, in
	    the tradition of the NetCDF module (see <cite
	    refid="NetCDF"></cite>) of the Scientific Python package
	    (<cite refid="NetCDFSP"></cite>).</footnote>.
	  </p>
	  <p>
	    If you look carefully at the code you will see that we
	    have used the <verb>table.row</verb> attribute so as to
	    access a table row and fill it up with the new values.
	    Each time that its <verb>append()</verb> method is called,
	    the actual row is committed to the output buffer and the
	    row pointer is incremented to point to the next table
	    record.
	  </p>
	  <p>Let's have a look at some columns of the resulting table:
	  </p>

	  <verbatim>
>>> for r in table.iterrows():
...     print "%-16s | %11.1f | %11.4g | %6d | %6d | %8d |" % \
...        (r['name'], r['pressure'], r['energy'], r['grid_i'], r['grid_j'],
...         r['TDCcount'])
...
...
Particle:      0 |         0.0 |           0 |      0 |     10 |        0 |
Particle:      1 |         1.0 |           1 |      1 |      9 |        1 |
Particle:      2 |         4.0 |         256 |      2 |      8 |        2 |
Particle:      3 |         9.0 |        6561 |      3 |      7 |        3 |
Particle:      4 |        16.0 |   6.554e+04 |      4 |      6 |        4 |
Particle:      5 |        25.0 |   3.906e+05 |      5 |      5 |        5 |
Particle:      6 |        36.0 |    1.68e+06 |      6 |      4 |        6 |
Particle:      7 |        49.0 |   5.765e+06 |      7 |      3 |        7 |
Particle:      8 |        64.0 |   1.678e+07 |      8 |      2 |        8 |
Particle:      9 |        81.0 |   4.305e+07 |      9 |      1 |        9 |
Particle:     10 |       100.0 |       1e+08 |     10 |      0 |       10 |
Particle:     11 |       121.0 |   2.144e+08 |     11 |     -1 |       11 |
Particle:     12 |       144.0 |     4.3e+08 |     12 |     -2 |       12 |
Particle:     13 |       169.0 |   8.157e+08 |     13 |     -3 |       13 |
Particle:     14 |       196.0 |   1.476e+09 |     14 |     -4 |       14 |
	  </verbatim>

	  <p>In <ref refid="tutorial-h5">figure</ref> you can see a
	    graphical view of the <verb>PyTables</verb> file we have
	    just created.
	  </p>

	  <figure id="tutorial-h5">
	    <graphics file="tutorial-h5" scale="0.55" kind="bitmap">
	    </graphics>
	    <caption>The data file after appending some rows.
	    </caption>
	  </figure>


	  <p>We are near the end of this first tutorial. But, ei!, do
	    not forget to close the file after you finish all the
	    work:
	  </p>

	  <verbatim>
>>> h5file.close()
>>> ^D
$ 

	  </verbatim>

	</subsection>

      </section>

      <section id="secondExample">
	<heading><visual markup="tt">PyTables</visual> automatic
	  sanity checks</heading>

	<p>Now, time for a more real life example (i.e. with errors in
	  code). Here, we will create a couple of groups hanging
	  directly from <verb>root</verb> called
	  <verb>Particles</verb> and <verb>Events</verb>. Then, we
	  will put 3 tables in each group; in <verb>Particles</verb>
	  we will put tables based on <verb>Particle</verb> descriptor
	  and in <verb>Events</verb>, tables based <verb>Event</verb>
	  descriptor.
	</p>
	<p>
	  After that, we will feed the tables with a number of
	  records. Finally, we will read the recently created table
	  <verb>/Events/TEvent3</verb> and select some values from it
	  using a comprehension list.
	</p>
	<p>Look at the next script (you can find it in
	  <verb>examples/tutorial2.py</verb>). It seems to do all of
	  that, but a couple of small bugs will be shown up. Note that
	  this <verb>Particle</verb> class is not directly related
	  with the one defined in last example; this one is
	  simpler. And we will introduce a new manner to describe a
	  <verb>Table</verb> as a dictionary, as you can see in the
	  <verb>Event</verb> description. See section <ref
	  refid="createTableDescr"></ref> about the different kinds of
	  descriptor objects that can be passed to the
	  <verb>createTable()</verb> method.
	</p>

	<verbatim>
"""This program shows the different protections that PyTables offer to
the user in order to insure a correct data injection in tables.

Example to be used in the second tutorial in the User's Guide.

"""

from tables import *

# Describe a particle record
class Particle(IsDescription):
    name      = Col("CharType", 16)  # 16-character String
    lati      = Col("Int32", 1)      # integer
    longi     = Col("Int32", 1)      # integer
    pressure  = Col("Float32", 1)    # float  (single-precision)
    temperature = Col("Float64", 1)    # double (double-precision)

# Another way to describe the columns of a table
Event = {
    "name"    : Col("CharType", 16),    # 16-character String
    "TDCcount": Col("UInt8", 1),        # unsigned byte
    "ADCcount": Col("UInt16", 1),       # Unsigned short integer
    "xcoord"  : Col("Float32", 1),      # integer
    "ycoord"  : Col("Float32", 1),      # integer
    }

# Open a file in "w"rite mode
fileh = openFile("tutorial2.h5", mode = "w")
# Get the HDF5 root group
root = fileh.root

# Create the groups:
for groupname in ("Particles", "Events"):
    group = fileh.createGroup(root, groupname)

# Now, create and fill the tables in Particles group
gparticles = root.Particles
# Create 3 new tables
for tablename in ("TParticle1", "TParticle2", "TParticle3"):
    # Create a table
    table = fileh.createTable("/Particles", tablename, Particle,
                           "Particles: "+tablename)
    # Get the record object associated with the table:
    particle = table.row
    # Fill the table with 257 particles
    for i in xrange(257):
        # First, assign the values to the Particle record
        particle['name'] = 'Particle: %6d' % (i)
        particle['lati'] = i 
        particle['longi'] = 10 - i
        particle['pressure'] = float(i*i)
        particle['temperature'] = float(i**2)
        # This injects the Record values
        particle.append()      

    # Flush the table buffers
    table.flush()

# Now, go for Events:
for tablename in ("TEvent1", "TEvent2", "TEvent3"):
    # Create a table in Events group
    table = fileh.createTable(root.Events, tablename, Event,
                           "Events: "+tablename)
    # Get the record object associated with the table:
    event = table.row
    # Fill the table with 257 events
    for i in xrange(257):
        # First, assign the values to the Event record
        event['name']  = 'Event: %6d' % (i)
        # Range checks no longer works on 0.4. Hope that
        # next version of numarray can support that!
        #event['TDCcount'] = i            # Wrong range.
        event['TDCcount'] = i % (1&lt;&lt;8)   # Correct range
        ########### Detectable errors start here. Play with them!
        #event['xcoord'] = float(i**2)   # Correct spelling
        event['xcoor'] = float(i**2)     # Wrong spelling. This works on 0.3
        event['ADCcount'] = i * 2        # Correct type
        #event['ADCcount'] = "s"          # Wrong type
        ########### End of errors
        event['ycoord'] = float(i)**4
        # This injects the Record values
        event.append()

    # Flush the buffers
    table.flush()

# Read the records from table "/Events/TEvent3" and select some
table = root.Events.TEvent3
e = [ p['TDCcount'] for p in table.iterrows()
      if p['ADCcount'] &lt; 20 and 4 &lt;= p['TDCcount'] &lt; 15 ]
print "Last record ==>", p
print "Selected values ==>", e
print "Total selected records ==> ", len(e)

# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
	</verbatim>

	<subsection>
	  <heading>Field name checking</heading>

	  <p>If you have read the code carefully it looks pretty good,
	    but it won't work. When you run this example, you will get
	    the next error:
	  </p>
	  <verbatim>
Traceback (most recent call last):
  File "tutorial2.py", line 69, in ?
    event['xcoor'] = float(i**2)     # Wrong spelling
  File "/home/falted/PyTables/pytables-0.4/src/hdf5Extension.pyx",
  line 1078, in __setitem__
    raise AttributeError, "Error accessing \"%s\" attr.\n %s" % \
AttributeError: Error accessing "xcoor" attr.
 Error was: "exceptions.KeyError: xcoor"
	  </verbatim>

	  <p>This error is telling us that we tried to assign a value to
	    a non-existent field in the <em>event</em> table
	    object. By looking carefully at the <verb>Event</verb>
	    class attributes, we see that we misspelled the
	    <verb>xcoord</verb> field (we wrote <verb>xcoor</verb>
	    instead). This is very unusual in Python because if you
	    try to assign a value to a non-existent instance variable,
	    a new one is created with that name. Such a feature is not
	    satisfactory when we are dealing with an object that has
	    fixed list of field names. So, a check is made inside
	    PyTables so that if you try to assign a value to a
	    non-existing field a <verb>KeyError</verb> is raised.
	  </p>

	</subsection>

	<subsection>
	  <heading>Data type checking</heading>

	  <p>Finally, in order to test the type checking, we will change
	    the next line:
	  </p>
	  <verbatim>
	    event.ADCcount = i * 2        # Correct type
	  </verbatim>

	  <p>to read:</p>

	  <verbatim>
	    event.ADCcount = "s"          # Wrong type
	  </verbatim>

	  <p>After this modification, the next exception will be
	    raised when the script is executed:
	  </p>

	  <verbatim>
Traceback (most recent call last):
  File "tutorial2.py", line 68, in ?
    event['ADCcount'] = "s"      # Wrong type
  File "/home/falted/PyTables/pytables-0.4/src/hdf5Extension.pyx",
  line 1078, in __setitem__
    raise AttributeError, "Error accessing \"%s\" attr.\n %s" % \
AttributeError: Error accessing "ADCcount" attr.
 Error was: "exceptions.TypeError: NA_setFromPythonScalar: bad value type."
	  </verbatim>

	  <p>that states the kind of error (<verb>TypeError</verb>).
	  </p>

	  <p>You can admire the structure we have created with this
	    (corrected) script in <ref refid="tutorial2">figure</ref>.
	  </p>

	  <figure id="tutorial2">
	    <graphics file="tutorial2-h5" scale="0.6" kind="bitmap">
	    </graphics>
	    <caption>Table hierarchy for second example.</caption>
	  </figure>

	  <p>Feel free to visit the rest of examples in directory
	    <verb>examples</verb>, and try to understand them. I've
	    tried to make several use cases to give you an idea of the
	    <visual markup="tt">PyTables</visual> capabilities and its
	    way of dealing with HDF5 objects.
	  </p>

	</subsection>
      </section>
    </chapter>

    <chapter id="optimizationTips">
      <heading>Optimization tips</heading>

      <p>On this chapter, you will get deeper knowledge of
	<verb>PyTables</verb> internals. <verb>PyTables</verb> has
	several places where the user can improve the performance of
	his application. If you are planning to deal with really large
	data, you should read carefully this section in order to learn
	how to get an important boost for your code. But if your
	dataset is small or medium size (say, up to 1 MB), you should
	not worry about that as the default parameters in
	<verb>PyTables</verb> are already tuned to handle that
	perfectly.
      </p>

      <section id="compressionIssues">
	<heading>Compression issues</heading>

	<p>One of the beauties of <verb>PyTables</verb> is that it
	  supports compression on tables (but not on arrays!, that
	  may come later), although it is disabled by
	  default. Compression of big amounts of data might be a bit
	  controversial feature, because compression has a legend of
	  being a very big CPU time resources consumer. However, if
	  you are willing to check if compression can help reducing
	  your dataset, keep reading.
	</p>

	<p>There is an usual scenario where users need to save
	  duplicated data in some record fields, while the others
	  have varying values. In a relational database approach
	  such a redundant data can normally be moved to other
	  tables and a relationship between the rows on the separate
	  tables can be created. But that takes analysis and
	  implementation time, and made the underlying libraries
	  more complex and slower.
	</p>

	<p><verb>PyTables</verb> transparent compression allows the
	  user to not worry about finding which is their optimum
	  data tables strategy, but rather use less, not directly
	  related, tables with a larger number of columns while
	  still not cluttering the database too much with duplicated
	  data (compression is responsible to avoid that). As a side
	  effect, data selections can be made more easily because
	  you have more fields available in a single table, and they
	  can be referred in the same loop. This process may
	  normally end in a simple, yet powerful manner to process
	  your data (although you should still be careful about what
	  kind of scenarios compression is convenient or not).
	</p>

	<p>The compression library used by default is the <visual
	    markup="bf">Zlib</visual> (see <cite
	    refid="zlibRef"></cite>), and as HDF5 <em>requires</em>
	  it, you can safely use it and expect that your HDF5 files
	  can be read on any other platform that has HDF5 libraries
	  installed. Zlib provides good compression ratio, although
	  somewhat slow, and reasonably fast decompression. Because
	  of that, it is a good candidate to be used for compress
	  you data.
	</p>

	<p>However, in many situations (i.e. write <em>once</em>,
	  read <em>multiple</em>), it is critical to have <em>very
	    good</em> decompression speed (at expense of whether less
	  compression or more CPU wasted on compression, as we will
	  see soon). This is why support for two new compressors has
	  been added to PyTables: LZO and UCL (see <cite
	    refid="lzouclRef"></cite>). Following his author (and
	  checked by the author of this manual), LZO offers pretty
	  fast compression (although small compression ratio) and
	  extremly fast decompression while UCL achieve an excellent
	  compression ratio (at the price of spending much more CPU
	  time) while allowing very fast decompression (and <em>very
	    close</em> to the LZO one). In fact, LZO and UCL are so
	  fast when decompressing that, in general (that depends on
	  your data, of course), writing and reading a compressed
	  table is actually faster (and sometimes <visual
	    markup="bf">much faster</visual>) than if it is
	  uncompressed. This fact is very important, specially if
	  you have to deal with very large amounts of data.
	</p>

	<p>Be aware that the LZO and UCL support in PyTables is not
	  standard on HDF5, so if you are going to use your PyTables
	  files in other contexts different from PyTables you will
	  not be able to read them. You have been warned.
	</p>

	<p>In order to give you a raw idea of what ratios would be
	  achieved, and what resources would be consumed, look at
	  the <ref refid="comprTblComparison">table</ref>. This
	  table has been obtained from synthetic data, so take this
	  just as a guide because your mileage will probably
	  vary.
	</p>
	<p>
	  However, you can expect that, in general, LZO would be the
	  fastest both compressing and uncompressing, but the one
	  that achieves the worse compression ratio (although that
	  may be just ok for many situations). UCL is the slowest
	  when compressing, but is faster than Zlib when
	  decompressing, and, besides, it achieves very good
	  compression ratios (generally better than Zlib). Zlib
	  represents a balance between them: it's somewhat slow
	  compressing, the slowest during decompressing, but it
	  normally achieves fairly good compression ratios.
	</p>

	<p>So, if your ultimate goal is reading as fast as possible,
	  choose LZO. If you want to reduce as much as possible your
	  data, while retaining good read speed, choose UCL. If you
	  don't mind too much about the above parameters and/or
	  portability is important for you, Zlib is your best bet.
	</p>

	<table id="comprTblComparison">
	  <!-- 	    <tabular preamble="lrrrrr"> -->
	  <tabular preamble="lccccc">
	    <tabhead>
	      <srow>Compr. Lib | File size (MB) | Time writing (s) |
		Time reading (s) | Speed writing (Krow/s) | 
		Speed reading (Krow/s) </srow>
	    </tabhead>
	    <tabbody>
	      <srow>NO COMPR     | 244.0 | 24.4 | 16.0  | 18.0 |  27.8</srow>
	      <srow>Zlib (lvl 1) |   8.5 | 17.0 |  3.11 | 26.5 | 144.4</srow>
	      <srow>Zlib (lvl 6) |   7.1 | 20.1 |  3.10 | 22.4 | 144.9</srow>
	      <srow>Zlib (lvl 9) |   7.2 | 42.5 |  3.10 | 10.6 | 145.1</srow>
	      <srow>LZO (lvl 1)  |   9.7 | 14.6 |  1.95 | 30.6 | 230.5</srow>
	      <srow>UCL (lvl 1)  |   6.9 | 38.3 |  2.58 | 11.7 | 185.4</srow>
	    </tabbody>
	  </tabular>
	  <caption>Comparison between different compression
	    libaries. The tests has been conducted on a Pentium 4 at 2
	    GHz and a hard disk at 4200 RPM.</caption>
	</table>

	<p>The compression level that I recommend to use for all
	  compression libraries is 1. This is the lowest level of
	  compression, but if you take the approach suggested above,
	  normally the redundant data is to be found in the same
	  row, so the redundant data locality is very high and such
	  a small level of compression should be enough to achieve a
	  good compression ratio on your data tables, saving CPU
	  cycles for doing other things. Nonetheless, in some
	  situations you may want to check how compression level
	  affects your application.
	</p>

	<p> You can select the compression library and level by
	  setting the <verb>complib</verb> and <verb>compress</verb>
	  keywords in the <verb>createTable</verb> method (see <ref
	    refid="createTableDescr"></ref>). A compression level of 0
	  will completely disable compression (the default), 1 is
	  the less CPU time demanding level, while 9 is the maximum
	  level and most CPU intensive. Finally, have in mind that
	  LZO is not accepting a compression level right now, so,
	  when using LZO, 0 means that compression is not active,
	  and any other value means that LZO is active.
	</p>


      </section>

      <section id="expectedRowsOptim">
	<heading>Informing <visual markup="tt">PyTables</visual>
	  about expected number of rows in tables</heading>

	<p>The underlying HDF5 library that is used by
	  <verb>PyTables</verb> takes the data in bunches of a
	  certain length, so-called <em>chunks</em>, to write them
	  on disk as a whole, i.e. the HDF5 library treats chunks as
	  atomic objects and disk I/O is always made in terms of
	  complete chunks. This allows data filters to be defined by
	  the application to perform tasks such as compression,
	  encryption, checksumming, etc. on entire chunks.
	</p>

	<p>An in-memory B-tree is used to map chunk structures on
	  disk. The more chunks that are allocated for a dataset the
	  larger the B-tree. Large B-trees take memory and causes
	  file storage overhead as well as more disk I/O and higher
	  contention for the meta data cache. Consequently, it's
	  important to balance between memory and I/O overhead
	  (small B-trees) and time to access to data (big B-trees).
	</p>

	<p><verb>PyTables</verb> can determine an optimum chunk size
	  to make B-trees adequate to your dataset size if you help
	  it by providing an estimation of the number of rows for a
	  table. This must be made in table creation time by passing
	  this value in the <verb>expectedrows</verb> keyword of
	  <verb>createTable</verb> method (see <ref
	    refid="createTableDescr"></ref>).
	</p>

	<p>When your dataset size is bigger than 1 MB (take this
	  figure only as a reference, not strictly), by providing
	  this guess of the number of rows, you will be optimizing
	  the access to your table data. When the dataset size is
	  larger than, say 100MB, you are <visual
	    markup="bf">strongly</visual> suggested to provide such a
	  guess; failing to do that may cause your application doing
	  very slow I/O operations and demanding huge amounts
	  of memory. You have been warned!.
	</p>

      </section>
    </chapter>

    <chapter id="libraryReference">
      <heading>Library Reference</heading>
      
      <p><verb>PyTables</verb> implements several classes to represent
	the different nodes in the object tree. They are named
	<verb>File</verb>, <verb>Group</verb>, <verb>Leaf</verb>,
	<verb>Table</verb> and <verb>Array</verb>. Another one is
	responsible to build record objects from a subclass user
	declaration, and performs field and type checks; its name is
	<verb>IsDescription</verb>. An important function, called
	<verb>openFile</verb> is responsible to create, open or append
	to files. In addition, a few utility functions are defined to
	guess if an user supplied file is a <verb>PyTables</verb> or
	<verb>HDF5</verb> file. These are called
	<verb>isPyTablesFile</verb> and <verb>isHDF5</verb>. Finally,
	several first-level variables are also available to the user
	that informs about <verb>PyTables</verb> version, file format
	version or underlying libraries (as for example
	<verb>HDF5</verb>) version number.
      </p>

      <p>Let's start discussing the first-level variables and
	functions available to the user, then the methods in the
	classes defined in <verb>PyTables</verb>.
      </p>

      <section>
	<heading><visual markup="tt">tables</visual> variables and
	  functions</heading>

	<subsection>
	  <heading>Global variables</heading>

	  <description>

	    <term>__version__</term> <item>The <verb>PyTables</verb>
	    version number.</item>

	    <term>HDF5Version</term>
	    <item>The underlying HDF5 library version number.</item>

	    <term>ExtVersion</term> <item>The Pyrex extension types
	      version. This might be useful when reporting
	      bugs.</item>

	  </description>
	  
	</subsection>

	<subsection id="GlobalFunctDescr">
	  <heading>Global functions</heading>

	  <description id="openFileDescr">
	    <term>openFile(filename, mode='r', title='', trMap={})</term>
	    <item>Open a <verb>PyTables</verb> file and returns a File
	    object.
	    
	      <description>

		<term>filename</term> <item>The name of the file
		  (supports environment variable expansion). It is
		  suggested that it should have any of
		  <verb>".h5"</verb>, <verb>".hdf"</verb> or
		  <verb>".hdf5"</verb> extensions, although this is
		  not mandatory.
		</item>

		<term>mode</term> <item>The mode to open the file. It
		  can be one of the following:

		  <description>

		    <term>'r'</term> <item>read-only; no data can be
		      modified.</item>

		    <term>'w'</term> <item>write; a new file is created
		      (an existing file with the same name is
		      deleted).</item>

		    <term>'a'</term> <item>append; an existing file is
		      opened for reading and writing, and if the file does
		      not exist it is created.</item>

		    <term>'r+'</term> <item>is similar to 'a', but the
		      file must already exist.</item>

		  </description>
		</item>

		<term>title</term> <item>If filename is new, this will
		  set a title for the root group in this file. If
		  filename is not new, the title will be read from
		  disk, and this will not have any effect.
		</item>

		<term>trMap</term> <item>A dictionary to map names in
		  the object tree Python namespace into different HDF5
		  names in file namespace. The keys are the Python
		  names, while the values are the HDF5 names. This is
		  useful when you need to name HDF5 nodes with invalid
		  or reserved words in Python.
		</item>

	      </description>

	    </item>

	    <term>isHDF5(filename)</term> <item>Determines whether
	      filename is in the HDF5 format. When successful, returns
	      a positive value, for TRUE, or 0 (zero), for
	      FALSE. Otherwise returns a negative value.  To this
	      function to work, it needs a closed file.
	    </item>

	    <term>isPyTablesFile(filename)</term> <item>Determines
	      whether a file is in the <verb>PyTables</verb> format.
	      When successful, returns the format version string, for
	      TRUE, or 0 (zero), for FALSE. Otherwise returns a
	      negative value.  To this function to work, it needs a
	      closed file.
	    </item>

	  </description>
	</subsection>
      </section>

      <section id="IsDescriptionClassDescr">
	<heading>The <visual markup="tt">IsDescription</visual> class</heading>

	<p>This class is in fact a so-called <em>metaclass</em>
	  object. There is nothing special on this fact, except that
	  their subclasses attributes are transformed during its
	  instantiation phase, and new methods for instances are
	  defined based on the values of the class attributes.
	</p>
	<p>It is designed to be used as an easy, yet meaningful way to
	  describe the properties of <verb>Table</verb> objects
	  through the use of classes that inherit properties from
	  it. In order to define such an special class, you have to
	  declare it as descendent from <em>IsDescription</em>, with
	  many attributes as columns you want in your table. The name
	  of these attributes will become the name of the columns,
	  while its values are the properties of the columns that are
	  obtained through the use of the <verb>Col</verb> class
	  constructor. See the <ref
	  refid="ColClassDescr">section</ref> for instructions on how
	  define the properties of the table columns.
	</p>
	<p>Then, you can pass an instance of this object to the
	  <verb>Table</verb> constructor, where all the information it
	  contains will be used to define the table structure. See
	  the <ref refid="secondExample">section</ref> for an example
	  on how that works.
	</p>

      </section>

      <section id="ColClassDescr">
	<heading>The <visual markup="tt">Col</visual> class</heading>

	<p>
	  This class is used as a mean to declare the different
	  properties of a column of a table. The only public method
	  accessible is the constructor itself.
	</p>

	<description>

	  <term>Col(dtype="Float64", shape=(1,), dflt=None, pos =
	    None)
	  </term>
	  <item>Define properties for a <verb>Table</verb> column.

	    <description>

	      <term>dtype</term> <item>The data type for the column. See
		the <ref refid="datatypesSupported">appendix</ref> for a
		relation of data types supported in a <visual
		  markup="tt">IsDescription</visual> class declaration.</item>

	      <term>shape</term> <item>An integer (or, for
		multidimensional cases, a tuple, although this is not yet
		supported as for the version 0.4) that specifies the
		number of <em>dtype</em> items for each element (or shape,
		for multidimensional elements) of this column.</item>

	      <term>dflt</term> <item>The default value for elements of
		this column. If the user does not supply a value for an
		element while filling a table, this default value will be
		written to disk. If <em>dflt</em> is not supplied, a
		appropriate zero value (or <em>null</em> string) will be
		chosen by default.</item>

	      <term>pos</term> <item>By default, columns are disposed in
		memory following an alphanumerical order of the column
		names. In some situations, however, it is convenient to
		impose a user defined ordering. <em>pos</em> parameter
		allows the user to force the wanted disposition.</item>

	    </description>
	  </item>
	</description>

      </section>

      <section id="FileClassDescr">
	<heading>The <visual markup="tt">File</visual> class</heading>

	<p>This class is returned when a <verb>PyTables</verb> file is
	  opened with the <verb>openFile()</verb> function. It has
	  methods to create, open, flush and close
	  <verb>PyTables</verb> files. Also, <verb>File</verb> class
	  offer methods to traverse the object tree, as well as to
	  create, rename and delete nodes. One of its attributes
	  (<verb>root</verb>) is quite important because represents
	  the entry point to the object tree attached to the file.
	</p>

	<p>Next, we will discuss the attributes and methods for File
	  class<footnote>On the following, the term <verb>Leaf</verb>
	  will whether refer to a <verb>Table</verb> or
	  <verb>Array</verb> node object.</footnote>.
	</p>

	<subsection id="FileInstanceVariablesDescr">
	  <heading><visual markup="tt">File</visual> instance
	    variables</heading>
	  <description>

	    <term>filename</term> <item>Filename opened.</item>

	    <term>isopen</term> <item>It has the value 1 if the
	      underlying file is open. 0 otherwise.</item>

	    <term>mode</term> <item>Mode in which the filename was
	      opened.</item>

	    <term>title</term> <item>The title of the root group in
	      file.</item>

	    <term>root</term> <item>The root group in file. This is
	      the entry point to the object tree.</item>

	    <term>trMap</term> <item>This is a dictionary that maps
	      node names between python and HDF5 domain names. Its
	      initial values are set from the <em>trMap</em> parameter
	      passed to the <verb>openFile()</verb> function. You can
	      change its contents <em>after</em> a file is opened and
	      the new map will take effect over any new object added
	      to the tree.</item>

	    <term>objects</term> <item>Dictionary with all objects
	      (groups or leaves) on tree.</item>

	    <term>groups</term> <item>Dictionary with all object
	      groups on tree.</item>

	    <term>leaves</term> <item>Dictionary with all object
	      leaves on tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">File</visual> methods</heading>

	  <subsubsection id="createGroupDescr">
	    <heading>createGroup(where, name, title='')</heading>

	    <p>Create a new Group instance with name <em>name</em> in
	      <em>where</em> location.
	    </p>

	    <description>
	      <term>where</term> <item>The parent group where the new
		group will hang. <em>where</em> parameter can be a path
		string (for example
		<verb>"/Particles/TParticle1"</verb>), or another Group
		instance. </item>

	      <term>name</term>
	      <item>The name of the new group.</item>
	      
	      <term>title</term> <item>A description for this
		group.</item>

	    </description>

	  </subsubsection>

	  <subsubsection>
	    <heading id="createTableDescr">createTable(where, name,
	      description, title='', compress=0, complib = 'zlib',
	      expectedrows=10000)</heading>

	    <p>Create a new <verb>Table</verb> instance with name
	      <em>name</em> in <em>where</em> location.
	    </p>

	    <description>
	      <term>where</term> <item>The parent group where the
		new table will hang. <em>where</em> parameter can be
		a path string (for example
		<verb>"/Particles/TParticle1"</verb>), or Group
		instance. </item>

	      <term>name</term>
	      <item>The name of the new table.</item>

	      <term>description</term> <item>An instance of a
		user-defined class (derived from the
		<verb>IsDescription</verb> class) where table fields
		are defined. However, in certain situations, it is
		more handy to allow this description to be supplied
		as a dictionary (for example, when you do not know
		beforehand which structure will have your table). In
		such a cases, you can pass the description as a
		dictionary as well. See <ref
		  refid="secondExample">section</ref> for an example
		of use. Finally, a <verb>RecArray</verb> object from
		the <verb>numarray</verb> package is also accepted,
		and all the information about columns and other
		metadata is used as a basis to create the
		<verb>Table</verb> object. Moreover, if the
		<verb>RecArray</verb> has actual data this is also
		injected on the newly created <verb>Table</verb>
		object.
	      </item>

	      <term>title</term> <item>A description for this object.
	      </item>

	      <term>compress</term> <item>Specifies a compress level
		for data. The allowed range is 0-9. A value of 0
		disables compression. The default is that
		compression is disabled, that balances between
		compression effort and CPU consumption.
	      </item>
	      <term>complib</term> <item> Specifies the compression
		library to be used. Right now, <verb>"zlib"</verb>
		(default), <verb>"lzo"</verb> and <verb>"ucl"</verb>
		values are supported. See <ref
		refid="compressionIssues">section</ref> for some advice
		on which library is better suited to your needs.
	      </item>
	      <term>expectedrows</term> <item>An user estimate of the
		number of records that will be on table. If not
		provided, the default value is appropriate for tables
		until 1 MB in size (more or less, depending on the
		record size). If you plan to save bigger tables you
		should provide a guess; this will optimize the HDF5
		B-Tree creation and management process time and memory
		used. See <ref refid="expectedRowsOptim">section</ref>
		for a detailed justification of that issue.
	      </item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="createArrayDescr">createArray(where, name,
	      object, title='')</heading>

	    <p>Create a new <verb>Array</verb> instance with name
	      <em>name</em> in <em>where</em> location.
	    </p>
	    <description>

		<term>where</term> <item>The parent group where the
		  new array will hang. <em>where</em> parameter can be
		  a path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or
		  <verb>Group</verb> instance. 
		</item>

		<term>name</term> <item>The name of the new
		  array.
		</item>

		<term>object</term> <item>The regular array to be
		  saved. Currently accepted values are: lists, tuples,
		  scalars (int and float), strings and
		  (multidimensional) <verb>Numeric</verb> and
		  <verb>NumArray</verb> arrays (including
		  <verb>CharArrays</verb> string arrays). However,
		  these objects must be regular (i.e. they cannot be
		  like, for example, <verb>[[1,2],2]</verb>). Also,
		  objects that has some of its dimension equal to zero
		  are not supported (this will be solved when
		  unlimited arrays will be implemented).
		</item>

		<term>title</term> <item>A description for this
		  object.
		</item>

	      </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="getNodeDescr">getNode(where, name='',
	      classname='')</heading>

	    <p>Returns the object node <em>name</em> under
	      <em>where</em> location.
	    </p>

	      <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>name</term> <item>The object name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

		<term>classname</term> <item>If supplied, returns only
		  an instance of this class name. Allowed names in
		  <em>classname</em> are: <verb>'Group'</verb>,
		  <verb>'Leaf'</verb>, <verb>'Table'</verb> and
		  <verb>'Array'</verb>. Note that these values are
		  strings.
		</item>

	      </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="getAttrNodeDescr">getAttrNode(where,
	      attrname, name='' )</heading>

	    <p>Returns the attribute <em>attrname</em> under
	      <em>where.name</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>attrname</term> <item>The name of the attribute
		  to get.
		</item>

		<term>name</term> <item>The node name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="setAttrNodeDescr">setAttrNode(where,
	      attrname, attrvalue, name='')</heading>

	    <p>Sets the attribute <em>attrname</em> with value
	      <em>attrvalue</em> under <em>where.name</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance. If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>ValueError</verb> error is
		  raised.
		</item>

		<term>attrname</term> <item>The name of the attribute
		  to set on disk.
		</item>

		<term>attrvalue</term> <item>The value of the
		  attribute to set. Only strings attributes are
		  supported natively right now. However, you can
		  always use <verb>(c)Pickle</verb> so as to serialize
		  any object you want save therein.
		</item>

		<term>name</term> <item>The node name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="listNodesDescr">listNodes(where,
	      classname='')</heading>

	    <p>Returns a list with all the object nodes (Group or
	      Leaf) hanging from <em>where</em>. The list is
	      alphanumerically sorted by node name.
	    </p>
	    <description>

		<term>where</term> <item>The parent group. Can be a
		  path string or <verb>Group</verb> instance.
		</item>

		<term>classname</term> <item>If a <em>classname</em>
		  parameter is supplied, the iterator will return only
		  instances of this class (or subclasses of it). The
		  only supported classes in <em>classname</em> are
		  <verb>'Group'</verb>, <verb>'Leaf'</verb>,
		  <verb>'Table'</verb> and <verb>'Array'</verb>. Note
		  that these values are strings.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="removeNodeDescr">removeNode(where, name = "",
	      recursive=0)</heading>

	    <p>Removes the object node
	      <em>name</em> under <em>where</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance.  If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>LookupError</verb> error is
		  raised.</item>

		<term>name</term> <item>The name of the node to be
		  removed. If not provided, the <em>where</em> node is
		  changed.</item>

		<term>recursive</term> <item>If not supplied, the
		  object will be removed only if it has no
		  children. If supplied with a true value, the object
		  and all its descendents will be completely
		  removed.</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="renameNodeDescr">renameNode(where, newname,
	      name)</heading>

	    <p>Rename the object node <em>name</em> under
	      <em>where</em> location.
	    </p>
	    <description>

		<term>where</term> <item>Can be a path string or
		  <verb>Group</verb> instance.  If <em>where</em>
		  doesn't exists or has not a child called
		  <em>name</em>, a <verb>LookupError</verb> error is
		  raised.</item>

		<term>newname</term> <item>Is the new name to be
		  assigned to the node.</item>

		<term>name</term> <item>The name of the node to be
		  changed. If not provided, the <em>where</em> node is
		  changed.</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="walkGroupsDescr">walkGroups(where='/')</heading>

	    <p><em>Iterator</em> that recursively obtains groups (not
	      leaves) hanging from <em>where</em>. If <em>where</em>
	      is not supplied, the root object is taken as origin. The
	      groups are returned from in a top to bottom order, and
	      alphanumerically sorted when they are at the same level.
	    </p>
	    <description>

		<term>where</term> <item>The origin group. Can be a
		  path string or <verb>Group</verb> instance.
		</item>

	    </description>
	  </subsubsection>

	  <subsubsection>
	    <heading>flush()</heading>

	    <p>Flush all the leaves in the object tree.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading>close()</heading>

	    <p>Flush all the leaves in object tree and close the file.
	    </p>
	  </subsubsection>

	</subsection>
      </section>

      <section id="GroupClassDescr">
	<heading>The <visual markup="tt">Group</visual> class</heading>

	<p>Instances of this class are a grouping structure containing
	  instances of zero or more groups or leaves, together with
	  supporting metadata.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files, respectively, in a Unix
	  filesystem. As with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. This full path can be specified either
	  as string (like in <verb>'/group1/group2'</verb>) or as a
	  complete object path written in the Pythonic fashion known
	  as <em>natural name</em> schema (like in
	  <verb>file.root.group1.group2</verb>) and discussed in the
	  <ref refid='ObjectTreeSection'>section</ref>.
	</p>

	<p>A collateral effect of the <em>natural naming</em> schema
	  is that you must be aware when assigning a new attribute
	  variable to a Group object to not collide with existing
	  children node names. For this reason and to not pollute the
	  children namespace, it is explicitly forbidden to assign
	  "normal" attributes to Group instances, and the only ones
	  allowed must start with some reserved prefixes, like
	  "<verb>_f_</verb>" (for methods) or "<verb>_v_</verb>" (for
	  instance variables) prefixes. Any attempt to assign a new
	  attribute that does not starts with these prefixes, will
	  raise a <verb>NameError</verb> exception.
	</p>

	<p>Other effect is that you cannot use reserved Python names
	  or other non-allowed python names (like for example "$a" or
	  "44") as node names. You can, however, make use of a
	  translation map dictionary in the
	  <verb>File.openfile()</verb> method (see section <ref
	  refid="openFileDescr"></ref>) so as to use non valid Python
	  names as node names in the file.
	</p>

	<subsection>

	  <heading><visual markup="tt">Group</visual> instance
	    variables</heading>
	  <description>

	    <term>_v_title</term>
	    <item>A description for this group.</item>

	    <term>_v_name</term>
	    <item>The name of this group.</item>

	    <term>_v_hdf5name</term> <item>The name of this group in
	      HDF5 file namespace.</item>

	    <term>_v_pathname</term>
	    <item>A string representation of the group location
	      in tree.</item>

	    <term>_v_parent</term>
	    <item>The parent Group instance.</item>

	    <term>_v_rootgroup</term>
	    <item>Pointer to the root group object.</item>

	    <term>_v_file</term>
	    <item>Pointer to the associated File object.</item>

	    <term>_v_childs</term> <item>Dictionary with all nodes
	      (groups or leaves) hanging from this instance.</item>

	    <term>_v_groups</term> <item>Dictionary with all node
	      groups hanging from this instance.</item>

	    <term>_v_leaves</term> <item>Dictionary with all node
	      leaves hanging from this instance.</item>

	    <term>_v_attrs</term> <item>The associated
	    <verb>AttributeSet</verb> instance (see <ref
	    refid="AttributeSetClassDescr"></ref>).</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> methods</heading>

	  <p><visual markup="bf">Caveat: </visual>These methods are
	    documented for completeness, and they can be used without
	    any problem. However, you should use the high-level
	    counterpart methods in the <verb>File</verb> class,
	    because these are most used in documentation and examples,
	    and are a bit more powerful than ones those exposed here.
	  </p>

	  <description>

	    <term>_f_join(name)</term>
	    <item>Helper method to correctly concatenate a name child object
	      with the pathname of this group.</item>

	    <term>_f_rename(newname)</term>
	    <item>Change the name of this group to <em>newname</em>.</item>

	    <term>_f_remove(recursive=0)</term> <item>Remove this
	      object. If <em>recursive</em> is true, force the removal
	      even if this group has children.</item>

	    <term>_f_getAttr(attrname)</term> <item>Gets the HDF5
	      attribute <em>attrname</em> of this group.</item>

	    <term>_f_setAttr(attrname, attrvalue)</term> <item>Sets
	      the attribute <em>attrname</em> of this group to the
	      value <em>attrvalue</em>. Only string values are
	      allowed.</item>

	    <term>_f_listNodes(classname='')</term> <item>Returns a
	      <em>list</em> with all the object nodes hanging from
	      this instance. The list is alphanumerically sorted by
	      node name. If a <em>classname</em> parameter is
	      supplied, it will only return instances of this class
	      (or subclasses of it). The supported classes in
	      <em>classname</em> are <verb>'Group'</verb>,
	      <verb>'Leaf'</verb>, <verb>'Table'</verb> and
	      <verb>'Array'</verb>.</item>

	    <term>_f_walkGroups()</term> <item><em>Iterator</em> that
	      recursively obtains Groups (not Leaves) hanging from
	      self. The groups are returned from top to bottom, and
	      are alphanumerically sorted when they are at the same
	      level.
	    </item>

	    <term>_f_close()</term> <item>Close this group, making it
	      and its children unaccessible in the object tree.</item>

	  </description>

	</subsection>
      </section>

      <section id="LeafClassDescr">
	<heading>The <visual markup="tt">Leaf</visual> class</heading>

	<p>This is a helper class useful to place common functionality
	  of all Leaf objects. It is also useful for classifying
	  purposes. A Leaf object is an end-node, that is, a node that
	  can hang directly from a group object, but that is not a
	  group itself. Right now this set is composed by
	  <verb>Table</verb> and <verb>Array</verb> objects. In fact,
	  <verb>Table</verb> and <verb>Array</verb> classes inherit
	  functionality from this class using the <em>mix-in</em>
	  technique.
	</p>

	<p>The public variables and methods that <verb>Table</verb>
	  and <verb>Array</verb> inherits from <verb>Leaf</verb> are
	  listed below.</p>

	<subsection>
	  <heading><visual markup="tt">Leaf</visual> instance
	    variables</heading>
	  <description>

	    <term>name</term> <item>The Leaf node name in Python
	      namespace.</item>
	    
	    <term>hdf5name</term> <item>The Leaf node name in HDF5
	      namespace.</item>
	    
	    <term>title</term> <item>The Leaf title.</item>

	    <term>shape</term> <item>The shape of the associated data
	      in the Leaf.</item>

	    <term>byteorder</term> <item>The byteorder of
	      the associated data of the Leaf.</item>

	    <term>attrs</term> <item>The associated
	    <verb>AttributeSet</verb> instance (see <ref
	    refid="AttributeSetClassDescr"></ref>).</item>

	  </description>
	</subsection>

	<subsection>
	  <heading><visual markup="tt">Leaf</visual> methods</heading>
	  <description>

	    <term>rename(newname)</term>
	    <item>Change the name of this leaf to <em>newname</em>.</item>

	    <term>remove()</term> <item>Remove this
	      leaf.</item>

	    <term>getAttr(attrname)</term> <item>Gets the HDF5
	      attribute <em>attrname</em> of this leaf.</item>

	    <term>setAttr(attrname, attrvalue)</term> <item>Sets
	      the attribute <em>attrname</em> of this leaf to the
	      value <em>attrvalue</em>. Only string values are
	      allowed.</item>

	    <term>flush()</term> <item>Flush the leaf buffers.</item>

	    <term>close()</term> <item>Flush the leaf buffers and
	      close the HDF5 dataset.</item>

	  </description>
	</subsection>

      </section>

      <section id="TableClassDescr">
	<heading>The <visual markup="tt">Table</visual> class</heading>

	<p>Instances of this class represents table objects in the
	  object tree. It provides methods to create new tables or
	  open existing ones, as well as methods to read/write data
	  and metadata from/to table objects in the file.
	</p>
	<p>Data can be read from or written to tables by accessing to
	  an special object that hangs from <verb>Table</verb>. This
	  object is an instance of the <verb>Row</verb> class (see
	  <ref refid="RowClassDescr"></ref>). See the tutorial
	  sections <ref refid="usage">chapter</ref> on how to use the
	  <verb>Row</verb> interface.
	</p>
	<p>Please note that this object inherits all the public
	  attributes and methods from <verb>Leaf</verb>.
	</p>

	<subsection>
	  <heading><visual markup="tt">Table</visual> instance
	    variables</heading>
	  <description>

	    <term>description</term> <item>The metaobject describing
	      this table</item>

	    <term>row</term> <item>The <verb>Row</verb> instance for
	      this table.</item>

	    <term>nrows</term>
	    <item>The number of rows in this table.</item>

	    <term>colnames</term>
	    <item>The field names for the table (list).</item>

	    <term>coltypes</term>
	    <item>The data types for the table fields (dictionary).</item>

	    <term>colshapes</term>
	    <item>The shapes for the table fields (dictionary).</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Table</visual> methods</heading>

	  <subsubsection>
	    <heading id="iterrowsDescr">iterrows(start=None,
	      stop=None, step=None)</heading>


	    <p>Returns an iterator yielding Row instances built from
	      rows in table. This method is actually a
	      <em>generator</em>, i.e. it keeps track on the last
	      record returned so that next time it is invoked it
	      returns the next available row. If a range is supplied
	      (i.e. some of the <em>start</em>, <em>stop</em> or
	      <em>step</em> parameters are passed), only the
	      appropriate rows are returned. Else, all the rows are
	      returned.
	    </p>
	    <description>
		<term>start</term> <item>Sets the starting row to
		  return data. It accepts negative values meaning that
		  the count starts from the end.</item>

		<term>stop</term> <item>Sets the last row to be
		  returned to stop - 1, i.e. the end point is omitted
		  (in the Python <verb>range</verb> tradition). It
		  accepts, likewise start, negative values. A special
		  value of 0 means the last row.
		</item>

		<term>step</term> <item>When step is given, it
		  specifies the increment. Negative values are not
		  allowed right now.</item>

	      </description>
	  </subsubsection>

	  <subsubsection>
	    <heading id="readDescr">read(self, start=None, stop=None,
	      step=None, field=None, flavor=None)</heading>

	    <p>Returns
	      the actual data in <verb>Table</verb>. If <em>field</em>
	      is not supplied, it returns the data as a
	      <verb>RecArray</verb> object table.
	    </p>
	    <description>

		<term>start</term> <item>Sets the starting row to
		  return data. It accepts negative values meaning that
		  the count starts from the end.</item>

		<term>stop</term> <item>Sets the last row to be
		  returned to stop - 1, i.e. the end point is omitted
		  (in the Python <verb>range</verb> tradition). It
		  accepts, likewise start, negative values. A special
		  value of 0 means the last row.
		</item>

		<term>step</term> <item>When step is given, it
		  specifies the increment. Negative values are not
		  allowed right now.</item>

		<term>field</term> <item>If specified, only the column
		  <em>field</em> is returned as a
		  <verb>NumArray</verb> object. If this is not
		  supplied, all the fields are selected and a RecArray
		  is returned.</item>

		<term>flavor</term> <item>When a field in table is
		  selected, passing a <em>flavor</em> parameter make
		  an additional conversion to happen in the default
		  <verb>NumArray</verb> object. <em>flavor</em> must
		  have any of the next values: <verb>Numeric</verb>,
		  <verb>Tuple</verb> or <verb>List</verb>. </item>

	    </description>
	  </subsubsection>
	</subsection>
      </section>

      <section id="RowClassDescr">
	<heading>The <visual markup="tt">Row</visual>
	class</heading>

	<p>This class is used to fetch and set values on the table
	  fields. It works very much like a dictionary, where the keys
	  are the field names of the associated table and the values
	  are the values of those fields in a specific row.
	</p>
	<p>This object turns out to actually be an extension type, so
	  you won't be able to access their documentation
	  interactively. Neither you won't be able to access it's
	  internal attributes (they are not directly accessible from
	  Python), although that <em>accessors</em> (i.e. methods that
	  return an internal attribute) has been defined for the most
	  important variables.
	</p>

	<subsection>
	  <heading><visual markup="tt">Row</visual>
	    methods</heading>

	  <description>

	    <term id="appendRowDescr">append()</term> <item>Once you
	    have filled the proper fields for the current row, calling
	    this method actually commit this data to the disk
	    (actually data is written to the output buffer).</item>

	    <term>nrow()</term> <item>Accessor that returns the current
	      row in the table. It is useful to know which row is being
	      dealt with in the middle of a loop.</item>
	  </description>
	</subsection>
      </section>

      <section id="ArrayClassDescr">
	<heading>The <visual markup="tt">Array</visual>
	class</heading>

	<p>Represents an array on file. It provides methods to create
	  new arrays or open existing ones, as well as methods to
	  write/read data and metadata to/from array objects in the
	  file.
	</p>

	<p><visual markup="bf">Caveat:</visual> All
	  <verb>Numeric</verb> and <verb>numarray</verb> typecodes are
	  supported except those that corresponds to complex data
	  types<footnote>However, these might be included in the
	  future</footnote>. See <verb>numarray</verb> manual (<cite
	  refid="Numarray"></cite>) to know more about the
	  supported data types, or see <ref
	  refid="datatypesSupported">appendix</ref>.
	</p>

	<p>Please note that this object inherits all the public
	  attributes and methods from <verb>Leaf</verb>.
	</p>

	<subsection id="ArrayClassInstanceVariables">
	  <heading><visual markup="tt">Array</visual> instance
	    variables</heading>
	  <description>

	    <term>type</term> <item>The type class of the represented
	      array.</item>

	    <term>flavor</term> <item>The string object representation
	      for this array. It can be any of <em>"NumArray"</em>,
	      <em>"CharArray"</em>, <em>"Numeric"</em>,
	      <em>"List"</em>, <em>"Tuple"</em>, <em>"String"</em>,
	      <em>"Int"</em> or <em>"Float"</em> values.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Array</visual>
	    methods</heading>

	  <p>Note that, as this object has not internal I/O buffers,
	    there is no point in calling flush() method inherited from
	    <verb>Leaf</verb>.
	  </p>

	  <description>

	    <term id="readArrayDescr">read()</term> <item>Read the
	      array from disk and return it as a <verb>NumArray</verb>
	      (default) object, or if possible, with the original
	      <em>flavor</em> that it was saved. The supported flavors
	      are: <verb>NumArray</verb>, <verb>CharArray</verb>,
	      <verb>Numeric</verb>, <verb>List</verb>,
	      <verb>Tuple</verb>, <verb>String</verb>,
	      <verb>Int</verb> or <verb>Float</verb>. Note that as
	      long as this method is not called, the actual array data
	      is resident on disk, not in memory.</item>

	  </description>
	</subsection>
      </section>

      <section id="AttributeSetClassDescr">
	<heading>The <visual markup="tt">AttributeSet</visual>
	class</heading>

	<p>Represents the set of attributes of a node (Leaf or
	  Group). It provides methods to create new attributes, open,
	  rename or delete existing ones.
	</p>

	<p>Like in <verb>Group</verb> instances,
           <verb>AttributeSet</verb> instances use a special feature
           called <em>natural naming</em>, i.e. you can access the
           attributes on disk like if they were <em>normal</em>
           <verb>AttributeSet</verb> attributes. This offers the user
           a very convenient way to access (but also set and delete)
           node attributes by simply specifying them like a
           <em>normal</em> attribute class.
        </p>

	<p><visual markup="bf">Caveat:</visual> All Python datatypes
	  are supported. The scalar ones (i.e. String, Int and Float)
	  are mapped directly to the HDF5 counterparts, so you can
	  correctly visualize them with any HDF5 tool. However, the
	  rest of the datatypes and more general objects are
	  serialized using <verb>cPickle</verb>, so you will be able
	  to correctly retrieve them only from a Python-aware HDF5
	  library. Hopefully, the list of supported native attributes
	  will be extended to multidimensional arrays sometime in the
	  future.
	</p>

	<subsection id="AttributeSetClassInstanceVariables">
	  <heading><visual markup="tt">AttributeSet</visual> instance
	    variables</heading>
	  <description>

	    <term>_v_node</term> <item>The parent node instance.</item>

	    <term>_v_attrnames</term> <item>List with all attribute
	      names.</item>

	    <term>_v_attrnamessys</term> <item>List with system attribute
	      names.</item>

	    <term>_v_attrnamesuser</term> <item>List with user attribute
	      names.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">AttributeSet</visual>
	    methods</heading>

	  <p>Note that this class define the __setattr__, __getattr__
	    and __delattr__ and they work as normally intended. So,
	    you can access, assign or delete attributes on disk by
	    just using the intuitive way:

	    <verbatim>
	      leaf.attrs.myattr = "string attribute"  # Set the attribute
	      attrib = leaf.attrs.myattr  # Get the attribute
	      del leaf.attrs.myattr       # Delete the attribute
	    </verbatim>             

	  </p>

	  <description>
	    <term id="listAttrDescr">_f_list(attrset = "user")
	    </term>Return the list of attributes of the parent node.
	      <item>
		<description>
		  <term>attrset</term> <item>Selects the attribute set
		    to be returned. An <verb>"user"</verb> value
		    returns only the user attributes. This is the
		    default. <verb>"sys"</verb> returns only the
		    system (read-only) attributes. <verb>"all"</verb>
		    returns both the system and user
		    attributes.</item>
		</description>
	      </item>

	    <term id="renameAttrDescr">_f_rename(oldattrname,
	      newattrname)</term><item>Rename an attribute.</item>
	  </description>

	</subsection>

      </section>
    </chapter>

    <appendix>
      <chapter id="datatypesSupported">
	<heading>Supported data types in tables</heading>

	<p><verb>IsDescription</verb> subclasses supports a limited set
	  of data types to define the table fields. This is roughly
	  the same that the set supported by the <visual
	  markup="tt">numarray</visual> package (see <cite
	  refid="Numarray"></cite>) in Python, with the
	  exception of the complex datatypes that are not supported
	  yet. The supported set is listed on <ref
	  refid="datatypesSupported">table</ref>.
	</p>

	<table id="datatypesSupportedTable">
	  <tabular preamble="lllcl">
	  <tabhead>
	    <srow>Type Code | Description | C Type | Size (in bytes) |
	      Python Counterpart</srow>
	  </tabhead>
	  <tabbody>
	    <srow>'Int8' | 8-bit integer | signed char | 1 | Integer </srow>
	    <srow>'UInt8' | 8-bit unsigned integer | unsigned char | 1 | Integer </srow>
	    <srow>'Int16' | 16-bit integer | short | 2 | Integer </srow>
	    <srow>'UInt16' | 16-bit unsigned integer | unsigned short | 2 | Integer </srow>
	    <srow>'Int32' | integer | int | 4  | Integer </srow>
	    <srow>'UInt32' | unsigned integer | unsigned int | 4 | Long </srow>
	    <srow>'Int64' | long long integer | long long | 8 | Long </srow>
	    <srow>'UInt64' | unsigned long long integer | unsigned long long | 8 | Long </srow>
	    <srow>'Float32' | single-precision float | float | 4 | Float </srow>
	    <srow>'Float64' | double-precision float | double | 8 | Float </srow>
	    <srow>'CharType' | arbitrary length string | char[] | * | String </srow>
	  </tabbody>
	</tabular>
	  <caption>Data types supported by <visual
	      markup="tt">IsDescription</visual> subclasses.</caption>
	</table>

      </chapter>
    </appendix>
  </mainmatter>

<!--   <latex -->
<!--       code="\addto{\captionsenglish}{\renewcommand*{\refname}{References}}"/> -->

  <backmatter>

    <!-- latex code="\renewcommand{\refname}{References}"/> -->


    <references bibfile="usersguide"/>

<!--     <references> -->
<!--       <enumerate> -->

<!-- 	<item id="HDF5WhatIs"><em>What is HDF5?.</em> Concise -->
<!-- 	  description about HDF5 capabilities and its differences from -->
<!-- 	  earlier versions (HDF4). <url -->
<!-- 	  name="http://hdf.ncsa.uiuc.edu/whatishdf5.html"/> -->
<!-- 	</item> -->

<!-- 	<item id="HDF5Intr"><em>Introduction to HDF5.</em> -->
<!-- 	  Introduction to the HDF5 data model and programming -->
<!-- 	  model. <url -->
<!-- 	  name="http://hdf.ncsa.uiuc.edu/HDF5/doc/H5.intro.html"/> -->
<!-- 	</item> -->

<!-- 	<item id="HDF5_HL"><em>HDF5: High Level APIs.</em> A set of -->
<!-- 	  functions built on top of the basic HDF5 library. <url -->
<!-- 	  name="http://hdf.ncsa.uiuc.edu/HDF5/hdf5_hl/doc/"/> -->
<!-- 	</item> -->

<!-- 	<item id="HDF5TableExamples"><em>The HDF5 table programming -->
<!-- 	  model.</em> Examples on using HDF5 tables with the C -->
<!-- 	  API. <url -->
<!-- 	  name="http://hdf.ncsa.uiuc.edu/HDF5/hdf5_hl/doc/RM_hdf5tb_ex.html"/> -->
<!-- 	</item> -->

<!-- 	<item id="HL-HDF"><em>HL-HDF.</em> A High Level Interface to -->
<!-- 	  the HDF5 File Format. <url -->
<!-- 	  name="ftp://ftp.ncsa.uiuc.edu/HDF/HDF5/contrib/hl-hdf5/README.html"/> -->
<!-- 	</item> -->

<!-- 	<item id="zlibRef"><em>zlib.</em>A Massively Spiffy Yet -->
<!-- 	  Delicately Unobtrusive Compression Library.  -->
<!-- 	  <url name="http://www.gzip.org/zlib/"/> -->
<!-- 	</item> -->

<!-- 	<item id="Objectify"><em>On the 'Pythonic' treatment of XML -->
<!-- 	  documents as objects(II).</em> Article describing XML -->
<!-- 	  Objectify, a Python module that allows working with XML -->
<!-- 	  documents as Python objects. Some of the ideas presented -->
<!-- 	  here are used in <visual markup="tt">PyTables</visual>. <url -->
<!-- 	  name="http://www-106.ibm.com/developerworks/xml/library/xml-matters2/index.html"/> -->
<!-- 	</item> -->

<!-- 	<item id="GnosisUtils"><em>gnosis.xml.objectify.</em> This -->
<!-- 	  module is part of the Gnosis utilities, and allows to create -->
<!-- 	  a mapping between any XML element to "native" Python -->
<!-- 	  objects. <url -->
<!-- 	  name="http://gnosis.cx/download/Gnosis_Utils-current.tar.gz"/> -->
<!-- 	</item> -->

<!-- 	<item id="Pyrex"><em>Pyrex.</em> A Language for Writing Python -->
<!-- 	  Extension Modules. <url -->
<!-- 	  name="http://www.cosc.canterbury.ac.nz/~greg/python/Pyrex"/> -->
<!-- 	</item> -->

<!-- 	<item id="NetCDF"><em>NetCDF (network Common Data Form).</em> -->
<!-- 	  This is an interface for array-oriented data access and a -->
<!-- 	  library that provides an implementation of the -->
<!-- 	  interface. <url -->
<!-- 	  name="http://www.unidata.ucar.edu/packages/netcdf/"/> -->
<!-- 	</item> -->

<!-- 	<item id="NetCDFSP"><em>NetCDF module on Scientific -->
<!-- 	  Python.</em> ScientificPython is a collection of Python -->
<!-- 	  modules that are useful for scientific computing. Its NetCDF -->
<!-- 	  module is a powerful interface for NetCDF data format. <url -->
<!-- 	  name="http://starship.python.net/~hinsen/ScientificPython/ScientificPythonManual/"/> -->
<!-- 	</item> -->

<!-- 	<item id="Numerical"><em>Numerical Python.</em> Package to -->
<!-- 	  speed-up arithmetic operations on arrays of numbers. <url -->
<!-- 	  name="http://www.pfdubois.com/numpy/"/> -->
<!-- 	</item> -->

<!-- 	<item id="Numarray"><em>Numarray.</em> Reimplementation of -->
<!-- 	  Numeric which adds the ability to efficiently manipulate -->
<!-- 	  large numeric arrays in ways similar to Matlab and -->
<!-- 	  IDL. Among others, Numarray provides the record array -->
<!-- 	  extension. <url name="http://stsdas.stsci.edu/numarray/"/> -->
<!-- 	</item> -->

<!--       </enumerate> -->
<!--     </references> -->
  </backmatter>
</book>

