<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE book PUBLIC "-//Torsten Bronger//DTD tbook 1.3//EN"
                      "/usr/local/share/xml/tbook/tbook.dtd">
<book>
  <frontmatter>
    <title><visual markup="tt">PyTables</visual> User's Guide</title>
    <author>Francesc Alted</author>
    <date>November, 13th</date>
    <year>2002</year>
    <legalnotice>


<!--	   Copyright (c) 2002 Francesc Alted -->

      <p>Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:
</p>
      <p>The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.
</p>
      <p>THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</p>

<!-- NCSA license -->

      <p>Copyright Notice and Statement for NCSA HDF5 (Hierarchical Data Format
	5) Software Library and Utilities
      </p>

      <p>NCSA HDF5 (Hierarchical Data Format 5) Software Library and
	Utilities Copyright 1998, 1999, 2000, 2001, 2002 by the Board
	of Trustees of the University of Illinois All rights reserved.
      </p>
      <p>Contributors: National Center for Supercomputing Applications
	(NCSA) at the University of Illinois at Urbana-Champaign
	(UIUC), Lawrence Livermore National Laboratory (LLNL), Sandia
	National Laboratories (SNL), Los Alamos National Laboratory
	(LANL), Jean-loup Gailly and Mark Adler (gzip library).
      </p>
      <p>Redistribution and use in source and binary forms, with or
	without modification, are permitted for any purpose (including
	commercial purposes) provided that the following conditions
	are met:
      </p>

      <p>Put here the conditions....
      </p>

      <p>DISCLAIMER: This work was prepared as an account of work
	sponsored by an agency of the United States
	Government. Neither the United States Government nor the
	University of California nor any of their employees, makes any
	warranty, express or implied, or assumes any liability or
	responsibility for the accuracy, completeness, or usefulness
	of any information, apparatus, product, or process disclosed,
	or represents that its use would not infringe privately- owned
	rights. Reference herein to any specific commercial products,
	process, or service by trade name, trademark, manufacturer, or
	otherwise, does not necessarily constitute or imply its
	endorsement, recommendation, or favoring by the United States
	Government or the University of California. The views and
	opinions of authors expressed herein do not necessarily state
	or reflect those of the United States Government or the
	University of California, and shall not be used for
	advertising or product endorsement purposes.
      </p>
    </legalnotice>
  </frontmatter>

  <!-- <abstract>

  <p><visual markup="tt">PyTables</visual> is a Python package whose
    goal is to allow dealing easily, but in a powerful way, with
    scientific data tables and Numerical Python objects organized in a
    hierarchical structure. Such a tables are defined as a collection
    of records whose values are stored in fixed-length fields. As a
    foundation for the underlying hierachical data organization the
    excellent HDF5 library (http://hdf.ncsa.uiuc.edu/HDF5) has been
    choosed.
  </p>

  <p><visual markup="tt">PyTables</visual> is intended to be
    easy-to-use, and tries to be a high-performance interface to
    HDF5. To achieve this, the newest improvements introduced in
    Python 2.2 (like generators or slots and metaclasses in new-brand
    classes) has been used. Pyrex creation extension tool has been
    chosen to access the HDF5 library.
  </p>

  </abstract> -->

  <mainmatter>
    <chapter>
      <heading>Introduction</heading>

      <p>The goal of PyTables is to enable the end user to manipulate
	easily scientific data <visual markup="bf">tables</visual> and
	<em>Numerical Python</em> objects in a hierarchical structure. The
	foundation of the underlying hierachical data organization is
	the excellent <verb>HDF5</verb> library
	(<verb>http://hdf.ncsa.uiuc.edu/HDF5</verb>). Right now,
	PyTables provides limited support of all the HDF5 functions,
	but I hope to add the more interesting ones (for PyTables
	needs) in the near future. Nonetheless, this package is not
	intended to serve as a complete wrapper for the entire HDF5
	API.
      </p>

      <p>A table is defined as a collection of records whose values
	are stored in <em>fixed-length</em> fields. All records have
	the same structure and all values in each field have the same
	<em>data type</em>.  The terms <em>fixed-length</em> and
	strict <em>data types</em> seems to be quite a strange
	requirement for an interpreted language like Python, but they
	serve a useful function if the goal is to save very large
	quantities of data (such as is generated by many scientifc
	applications, for example) in an efficient manner that reduces
	demand on CPU time and I/O.
      </p>

      <p>In order to emulate records (C structs in HDF5) in Python
	PyTables implements a special metaclass object with the
	capability to detect errors in field assignments as well as
	range overflows. PyTables also provides a powerful interface
	to process table data. Records in tables are also known, in
	the <verb>HDF5</verb> naming scheme, as <em>compound</em> data
	types.
      </p>

      <p>For example, you can define arbitrary records in Python
	simply by declaring a class with the name field and types
	information, like in:
      </p>

<verbatim>
class Particle(IsRecord):
    name        = '16s'  # 16-character String
    idnumber    = 'Q'    # unsigned long long (i.e. 64-bit integer)
    TDCcount    = 'B'    # unsigned byte
    ADCcount    = 'H'    # unsigned short integer
    grid_i      = 'i'    # integer
    grid_j      = 'i'    # integer
    pressure    = 'f'    # float  (single-precision)
    energy      = 'd'    # double (double-precision)

</verbatim>

      <p>then, you will normally instantiate it, fill it with your
	values, and save (arbitrary large) collections of them in a
	file for persistent storage. After that, this data can be
	retrieved and post-processed quite easily with <visual
	markup="tt">PyTables</visual> or even with another
	<verb>HDF5</verb> application.
      </p>

      <section>
	<heading>Features</heading> <p><visual
	markup="tt">PyTables</visual> has the next capabilities:</p>

	<itemize>
	  <item><em>Support of table entities:</em> Allows
	    working with large number of records that don't fit in
	    memory.
	  </item>
	  <item><em>Support of <visual markup="tt">Numerical
	    Python</visual> arrays:</em> Numeric arrays are a very
	    useful complement of tables to keep homogeneus table
	    slices (like selections of table columns).
	  </item>
	  <item><em>Supports a hierarchical data model:</em> That way,
	    you can structure very clearly all your data. Pytables
	    builds up an object tree in memory that replicates the
	    underlying file structure and the access to the file
	    objects is made by walking throughout the <visual
	    markup="tt">PyTables</visual> object tree, and
	    manipulating them.
	  </item>
	  <item><em>Incremental I/O:</em> It supports adding records
	    to already created tables. So you won't need to book large
	    amounts of memory to fill the entire table and then save
	    it to disk but you can do that incrementally, even between
	    different Python sessions.
	  </item>
	  <item><em>Allows field name, data type and range
	    checking:</em> So you can be confident that if <visual
	    markup="tt">PyTables</visual> does not report an error,
	    you can be confident that your data is probably ok.
	  </item>
	  <item><em>Support of files bigger than 2 GB:</em> The
	    underlying HDF5 library already can do that (if your
	    platform supports the C long long integer, or, on Windows,
	    __int64), so PyTables automatically inherits get this
	    benefit.
	  </item>
	  <item><em>Data compression:</em> It supports data
	    compression (trough the use of the zlib library) out of
	    the box. This become important when you have repetitive
	    data patterns and don't want to loose your time searching
	    for an optimized way to save them (i.e. it saves you data
	    organization analysis time).
	  </item>
	  <item><em>Big-Endian/Low-Endian safety:</em> <visual
	    markup="tt">PyTables</visual> has been coded (as HDF5 is)
	    to care with little-endian/big-endian byte orderings. So,
	    in principle, you can write a file in a big-endian machine
	    and read it in other little-endian without
	    problems<footnote>Well, I didn't actually test that in
	    real world, but if you do, please, tell
	    me.</footnote>.</item>
	</itemize>

	<p>Finally, it should noted that <visual
	  markup="tt">PyTables</visual> is not intended to be merely a
	  wrapper of HDF5_HL library (don't confuse with HL-HDF5, the
	  Swedish Meteorological and Hydrological Institute effort to
	  provide another high Level interface to HDF5; see <ref
	  refid="HL-HDF">reference</ref>), but to provide a flexible
	  tool to deal with large amounts of data (i.e., typically
	  bigger than available memory) in tables (heterogeneus data
	  types) and arrays (homogeneus data types) organized in a
	  hierarchical, persistent disk storage. PyTables take
	  advantage of the powerful object orientation and
	  introspection capabilities offered by Python to present all
	  this power to the user in a friendly manner.
	</p>
      </section>

      <section id="NaturalTreeSection">
	<heading>The object tree</heading>

	<p>The hierarchical model of the underlying HDF5 library
	  allows PyTables to manage tables and arrays in a tree-like
	  structure. This is achieved by <em>dynamically</em> creating
	  an object tree imitating the HDF5 structure on disk. That
	  way, the access to the HDF5 objects is made by walking
	  throughout the <visual markup="tt">PyTables</visual> object
	  tree, and manipulating them. A key aspect of PyTables is
	  that for accessing to the different nodes on the object tree
	  a <visual markup="bf">natural naming</visual> schema is
	  used, i.e. the attributes of the objects that represent HDF5
	  elements are the same as the names of the element's
	  children<footnote>I've taken this simple but powerful idea
	  from the excellent <visual markup="tt">Objectify</visual>
	  module by David Mertz (see references <ref
	  refid="Objectify"></ref> and <ref
	  refid="GnosisUtils"></ref>)</footnote>. See the <ref
	  refid="usage">chapter</ref> for a more detailed explanation.
	</p>
	<p>You should note that not all the data present on file is
	  loaded in <visual markup="tt">PyTables</visual> tree, but
	  only the <em>metadata</em> (i.e. data that actually
	  describes the structure of the real data). The actual access
	  to the real data is provided through the methods of those
	  objects.
	</p>
	<p>To better understand the dynamic nature of this object
	  tree, imagine we have made a script (in fact, this script
	  exists; its name is <verb>objecttree.py</verb> and you can
	  find it in the <verb>examples/</verb> directory) that
	  creates a simple HDF5 file, with the structure that appears
	  in <ref refid="objecttree-h5">figure</ref> (we have used the
	  java program <verb>hdfview</verb> to obtain this
	  image). During creation time, the object tree is updated at
	  the same time that data is saved on file and when you close
	  the file, this object is destroyed. If you re-open again
	  this file (in read only mode, for example), the object tree
	  with will be re-constructed from the metadata existent on
	  file.
	</p>
	<p>
	  It is important to stress that actual data is not read until
	  you ask for it in a particular node, but by making use of
	  the object tree (the metadata) you can get information on
	  the objects on disk, for example, table names, title, name
	  fields, data types in fields, number of records, or, in the
	  case of arrays, shapes, typecode, and so on. You can
	  traverse the tree with the supplied methods, and when you
	  find the data you want you can read and process it. In some
	  sense, you can think of PyTables to provide the
	  introspection capabilities of Python objects, but applied to
	  the persistent storage of large amounts of data.
	</p>

	<figure id="objecttree-h5">
	  <graphics file="objecttree-h5" scale="0.6" kind="bitmap">
	  </graphics>
	  <caption>An HDF5 example with 2 subgroups and 3 tables.</caption>
	</figure>

	<p>In <ref refid="objecttree">figure</ref> you can see an
	  example of the object tree created by reading a PyTables
	  file. If you are going to be a <visual
	  markup="tt">PyTables</visual> user, take your time to
	  understand it<footnote>Bear in mind, however, that this
	  diagram is <visual markup="bf">not</visual> a standard UML
	  class diagram; I've used an UML tool to draw it, that's
	  all)</footnote>. That will also make you more proactive by
	  avoiding programming mistakes.
	</p>

	<figure id="objecttree">
	  <!-- Now, this works! -->
	  <graphics file="objecttree" scale="0.4" kind="vector">
	  
	  <!-- We have a processing error here. We solved this by
	  converting the eps to jpeg with command:
pstoimg -scale 0.75 -aaliastext -type png -crop a -interlace objecttree.eps
	  and then, applying a new conversion to jpg with
	  convert objecttree.png objecttree.jpg
	  -->
	  <!-- <graphics file="objecttree" scale="0.5" kind="bitmap"> -->
	  </graphics>
	  <caption>An object tree example in <visual
	      markup="tt">PyTables</visual>.
	  </caption>
	</figure>
      
	<p>
	</p>

      </section>

    </chapter>

    <chapter>
      <heading>Installation</heading>

      <p>This are instructions for Unix/Linux system. If you are using
	Windows, and you get the library to work, please tell me about.
      </p>

      <p>Extensions in <visual markup="tt">PyTables</visual> has been
	made using Pyrex (see <ref refid="Pyrex">reference</ref>) and
	C. You can rebuild everything from scratch if you got Pyrex
	installed, but this is not necessary, as the Pyrex compiled
	source is included in the distribution. In order to do that,
	merely replace <visual markup="tt">setup.py</visual> script in
	these instructions by <visual
	markup="tt">setup-pyrex.py</visual>.
      </p>

      <p>The Python Distutils are used to build and install PyTables,
	so it is fairly simple to get things ready to go.
      </p>

      <enumerate>

	<item>
	  <p>First, make sure that you have <verb>HDF5 1.4.x</verb>
	    and <verb>Numerical Python</verb> installed (I'm using
	    <verb>HDF5 1.4.4</verb> and <verb>Numeric 22.0</verb>
	    currently). If don't, you can find them at
	    <verb>http://hdf.ncsa.uiuc.edu/HDF5</verb> and
	    <verb>http://www.pfdubois.com/numpy</verb>. Compile/install
	    them.
	  </p>
	  
	  <p><verb>setup.py</verb> will detect <verb>HDF5</verb>
	    libraries and include files under <verb>/usr</verb> or
	    <verb>/usr/local</verb>; this will catch installations
	    from RPMs, DEBs and most hand installations under Unix. If
	    <verb>setup.py</verb> can't find your <verb>libhdf5</verb>
	    or if you have several versions installed and want to
	    select one of them, then you can give it a hint either in
	    the environment (using the <verb>HDF5_DIR</verb>
	    evironment variable) or on the command line by specifying
	    the directory containing the include and lib directory.
	    For example:
	  </p>
	  <verbatim>
	    --hdf5=/stuff/hdf5-1.4.4
	  </verbatim>

	  <p>If your <verb>HDF5</verb> library was built as shared
	    library, and if this shared library is not in the runtime
	    load path, then you can specify the additional linker
	    flags needed to find the shared library on the command
	    line as well. For example:
	  </p>
	  <verbatim>
	    --lflags="-Xlinker -rpath -Xlinker /stuff/hdf5-1.4.4/lib"
	  </verbatim>
	  <p>or perhaps just
	  </p>
	  <verbatim>
	    --lflags="-R /stuff/hdf5-1.4.4/lib"
	  </verbatim>

	  <p>Check your compiler and linker documentation for correct
	    syntax.
	  </p>

	  <p>It is also possible to specify linking against different
	    libraries with the <verb>--libs</verb> switch:
	  </p>
	  <verbatim>
	    --libs="-lhdf5-1.4.6"
	    --libs="-lhdf5-1.4.6 -lnsl"
	  </verbatim>
	</item>
	<item>
	  <p>From the main pytables distribution directory run this
	    command, (plus any extra flags needed as discussed above):
	  </p>
	  <verbatim>
	    python setup.py build_ext --inplace
	  </verbatim>
	  <p>depending on the compiler flags used when compiling your
	    Python executable, there may appear lots of warnings. Don't
	    worry, almost all of them are caused by variables declared
	    but never used. That's normal in Pyrex extensions.
	  </p>
	</item>
	<item>
	  <p>To run the test suite change into the test directory and run this
	    command, (assuming your shell is <verb>sh</verb> or compatible):
	  </p>
	  <verbatim>
	    PYTHONPATH=..
	    export PYTHONPATH
	    python test_all.py
	  </verbatim>
	  <p>If you would like to see some verbose output from the
	    tests simply add the flag <verb>-v</verb> and/or the word
	    <verb>verbose</verb> to the command line. You can also
	    run just the tests in a particular test module. For
	    example:
	  </p>
	  <p>If you would like to see some verbose output from the tests
	    simply add the word <verb>verbose</verb> to the command
	    line. You can also run only the tests in a particular test
	    module by themselves. For example:</p>
	  <verbatim>
	    python test_types.py -v
	  </verbatim>
	</item>
	<item>
	  <p>To install the entire <visual
	    markup="tt">PyTables</visual> Python package, change back
	    to the root distribution directory and run this command as
	    the root user:
	  </p>
	  python setup.py install
	</item>
      </enumerate>

      <p>That's it!. Now, read on the next section to see how to use
	PyTables.
      </p>

    </chapter>

    <chapter id="usage">
      <heading>Usage</heading>

      <section>
	<heading>Getting started</heading>

	<p>This section is written in a tutorial style. We will see
	  how to define our own records from Python and save
	  collections of them (i.e. a <visual
	  markup="bf">table</visual>) on a file. Then, we will open
	  this freshly created file and we will select some data in
	  the table using Python cuts, creating Numerical arrays to
	  keep this selection as separate objects in the tree. We will
	  see how to browse the tree while retrieving metainformation
	  about the actual data, and will finish by appending some
	  rows to the existing table to show how table objects can be
	  enlarged.
	</p>

	<p>After reading this section you will hopefully learn the
	  main features of PyTables. If you want more information on
	  some specific instance variable, global function or method,
	  go to the library reference in <ref
	  refid="libraryReference">chapter</ref>. You can get deeper
	  knowledge of PyTables by reading the other sections (XXX
	  which ones?) in this chapter.
	</p>

	<p>You will find in the directory <verb>examples</verb> the
	  working version of all the code in this section (source file
	  <verb>tutorial.py</verb>).
	</p>

	<subsection>
	  <heading>Importing <visual markup="tt">tables</visual>
	    objects</heading>
	  
	  <p>Before to do anything you need to import the
	    public objects in the <verb>tables</verb> package. You
	    normally do that by issuing:
	  </p>
	  <verbatim>
>>> import tables
>>>
	  </verbatim>
	  <p>That is the recommended way to import <verb>tables</verb>
	    if you don't want to pollute too much your
	    namespace. However, PyTables has a very reduced set of
	    first-level primitives, so you may consider to use this
	    alternative:
	  </p>
	  <verbatim>
>>> from tables import *
>>>
	  </verbatim>
	  <p>which will export in your caller aplication namespace the
	    next objects: <verb>openFile</verb>, <verb>isHDF5</verb>,
	    <verb>isPyTablesFile</verb> and
	    <verb>IsRecord</verb>. These are a rather small number of
	    objects, and for commodity we will use this last way to
	    access them.
	  </p>
	  <p>If you are going to deal with <verb>Numeric</verb> arrays
	    you will also need to import some objects from it. You can
	    do that in the normal way. So, to access to PyTables
	    functionality normally you should start you programs with:
	  </p>
	  <verbatim>
>>> from tables import *
>>> from Numeric import *
>>>
	  </verbatim>

	</subsection>

	<subsection>
	  <heading>Declaring a Record</heading>

	  <p>Now, we want to declare a record object in order to save
	    data that comes from our particle detector. Imagine that
	    it has a TDC (Time to Digital Converter) counter with a
	    dynamic range of 8 bits and an ADC (Analogic to Digital
	    Converter) with a range of 16 bits. For these values, we
	    will define 2 fields in our Record object called
	    <verb>TDCcount</verb> and <verb>ADCcount</verb>. We also
	    want to save the grid position in which the particle has
	    been detected. We will add two new fields called
	    <verb>grid_i</verb> and <verb>grid_j</verb>. Our
	    instrumentation also can obtain the pressure and energy of
	    this particle, and we will add them in the same way. A
	    simple-precision float will be enough to save
	    <verb>pressure</verb> information, while
	    <verb>energy</verb> would need a double-precision
	    float. Finally, to track this particle we want to assign
	    it a name to inform about the kind of the particle and a
	    number identifier unique for each particle. So we will add
	    a couple of fields: <verb>name</verb> will be the a string
	    of up-to 16 characters and because we want to deal with a
	    really huge number of particles, <verb>idnumber</verb>
	    will be an integer of 64-bits.
	  </p>
	  <p>With all of that, we declare a new Particle class that will
	    keep all this info:
	  </p>

	  <verbatim>
>>> class Particle(IsRecord):
...     name        = '16s'  # 16-character String
...     idnumber    = 'Q'    # unsigned long long (i.e. 64-bit integer)
...     TDCcount    = 'B'    # unsigned byte
...     ADCcount    = 'H'    # unsigned short integer
...     grid_i      = 'i'    # integer
...     grid_j      = 'i'    # integer
...     pressure    = 'f'    # float  (single-precision)
...     energy      = 'd'    # double (double-precision)
... 
>>> 
	  </verbatim>
	  <p>This definition class is quite
	    auto-explanatory. Basically, you have to declare a class
	    variable for each field you need, and as its value, the
	    typecode for this data field. See <ref
	    refid="datatypesSupported">appendix</ref> for a list of
	    typecodes supported in PyTables.
	  </p>
	  <p>From now on, you can use this class instances as a
	    container for your data, and as you will see shortly, you
	    will get some magic properties associated with instances
	    from <verb>Particle</verb>, and the class
	    <verb>IsRecord</verb><footnote><verb>IsRecord</verb> is
	    actually a <em>metaclass</em> in object slang, but we
	    don't need to explain nothing more about it now. Check the
	    sources if you are interested on how that
	    works.</footnote> from which it is derived is responsible
	    for that magic.
	  </p>

	  <p>In order to do something useful with this record, we need
	    to attach it to a <verb>Table</verb> object. But first, we
	    must create a file where all the actual data pushed into
	    <verb>Table</verb> will be saved.
	  </p>

	</subsection>

	<subsection>
	  <heading>Creating a PyTables file from scratch</heading>

	  <p>To create a PyTables file use the first-level
	    <verb>openFile</verb> funtion:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial.h5", mode = "w", title = "Test file")
	  </verbatim>
	  <p>This <verb>openFile</verb> is one of the objects imported
	    by the "<verb>from tables import *</verb>", do you
	    remember?. We are telling that we want to create a new
	    file called "<verb>tutorial.h5</verb>" in "<verb>w</verb>"rite
	    mode and with an informative title string ("<verb>Test
	    file</verb>"). This function tries to open this file, and
	    if successful, returns a <verb>File</verb> instance which
	    hosts the root of the object tree on its <verb>root</verb>
	    attribute.
	  </p>
	</subsection>

	<subsection>
	  <heading>Creating a new group</heading>

	  <p>Now, to better organize our data, we will create a group
	    hanging from the root called <em>detector</em>. We will
	    use this group to save our particle data there.
	  </p>
	  <verbatim>
group = h5file.createGroup("/", 'detector', 'Detector information')
	  </verbatim>

	  <p>Here, we have take the <verb>File</verb> instance
	    <verb>h5file</verb> and invoked its
	    <verb>createGroup</verb> method, telling that we want to
	    create a new group called <em>detector</em> hanging from
	    "<em>/</em>", which is other way to refer to the
	    <verb>h5file.root</verb> object we mentioned before. This
	    will create a new <verb>Group</verb> instance that will be
	    assigned to the <verb>group</verb> variable.
	  </p>

	</subsection>
	<subsection>
	  <heading>Creating a new table</heading>

	  <p>Let's now create the <verb>Table</verb> object
	    hanging from the new created group. We do that by calling
	    the <verb>createTable</verb> method from the
	    <verb>h5file</verb> object:
	  </p>
	  <verbatim>
>>> table = h5file.createTable(group, 'readout', Particle(), "Readout example")
	  </verbatim>

	  <p>You can see how we asked to create the <verb>Table</verb>
	    instance hanging from <verb>group</verb>, with name
	    <em>'readout'</em>. As the record object we have passed an
	    instance of Particle, the class that we have declared
	    before, and finally we attach it a "<em>Readout
	    example</em>" title. With all this information, a new
	    <verb>Table</verb> instance is created and assigned to
	    <verb>table</verb> variable.
	  </p>

	  <p>Now, time to fill this table with some values. But first,
	    we want to get a pointer to the record object in this
	    <verb>table</verb> instance:
	  </p>
	  <verbatim>
>>> particle = table.record
	  </verbatim>

	  <p>The <verb>record</verb> attribute of <verb>table</verb>
	    points to the <verb>Particle</verb> instance used to
	    create the table, and we assign it to the
	    <verb>particle</verb> variable that will be used as a
	    shortcut. This step is not really necessary, but helps to
	    code legibility (and allows me to introduce the
	    <verb>record</verb> attribute).
	  </p>

	  <p>We can proceed right now to the filling process:
	  </p>

	  <verbatim>
>>> for i in xrange(10):
...     # First, assign the values to the Particle record
...     particle.name  = 'Particle: %6d' % (i)
...     particle.TDCcount = i % 256    
...     particle.ADCcount = (i * 256) % (1 &lt;&lt; 16)
...     particle.grid_i = i 
...     particle.grid_j = 10 - i
...     particle.pressure = float(i*i)
...     particle.energy = float(particle.pressure ** 4)
...     particle.idnumber = i * (2 ** 34)  # This exceeds long integer range
...     # Insert a new particle record
...     table.appendAsRecord(particle)      
...
>>> 
	  </verbatim>
	  
	  <p>This code is quite easy to understand. The lines inside
	    the loop just assigned values to the <verb>particle</verb>
	    record object and then a call to the
	    <verb>appendAsRecord</verb> method of <verb>table</verb>
	    instance is made to put this information in the
	    <verb>table</verb> I/O buffer.
	  </p>

	  <p>After we have filled all our data, we must flush the I/O
	    buffer for the table if we want to consolidate all this
	    data on disk. We do that by calling the <verb>table</verb>
	    <verb>flush</verb> method.
	  </p>
	  <verbatim>
>>> table.flush()
	  </verbatim>

	  <p>And last, we close the h5file File instance to close the file:
	  </p>
	  <verbatim>
>>> h5file.close()
	  </verbatim>

	  <p>With all that, you have created your first PyTables file
	    with a table inside it. That was easy, admit it. Now, you
	    can have a look at it with some generic HDF5 tool, like
	    h5dump or h5ls. Here is the result of passing to h5ls the
	    <verb>tutorial.h5</verb> file:
	  </p>
	  <verbatim>
$ h5ls -rd tutorial.h5 
/tutorial.h5/detector    Group
/tutorial.h5/detector/readout Dataset {10/Inf}
    Data:
        (0) {0, 0, 0, 0, 10, 0, "Particle:      0", 0},
        (1) {256, 1, 1, 1, 9, 17179869184, "Particle:      1", 1},
        (2) {512, 2, 256, 2, 8, 34359738368, "Particle:      2", 4},
        (3) {768, 3, 6561, 3, 7, 51539607552, "Particle:      3", 9},
        (4) {1024, 4, 65536, 4, 6, 68719476736, "Particle:      4", 16},
        (5) {1280, 5, 390625, 5, 5, 85899345920, "Particle:      5", 25},
        (6) {1536, 6, 1679616, 6, 4, 103079215104, "Particle:      6", 36},
        (7) {1792, 7, 5764801, 7, 3, 120259084288, "Particle:      7", 49},
        (8) {2048, 8, 16777216, 8, 2, 137438953472, "Particle:      8", 64},
        (9) {2304, 9, 43046721, 9, 1, 154618822656, "Particle:      9", 81}
	  </verbatim>

	  <p>or, using the "dumpFile.py" PyTables utility (located in
	    examples/ directory):
	  </p>

	  <verbatim>
$ python2.2 dumpFile.py tutorial.h5 
Filename: tutorial.h5
All objects:
Filename: tutorial.h5 \\ Title: "Test file" \\ Format version: 1.0
/ (Group) "Test file"
/detector (Group) "Detector information"
/detector/readout Table(8, 10) "Readout example"

	  </verbatim>

	  <p>You can pass the <verb>-v</verb> option to
	    <verb>dumpFile.py</verb> if you want more verbosity.
	  </p>

	</subsection>
	<subsection>
	  <heading>Reading and selecting table data</heading>

	  <p>Ok. We have our data on disk. But we want to access it
	    and select some values we are interested it in some
	    specific columns. That's is easy to do. First, let's open
	    the file we have recently created:
	  </p>

	  <verbatim>
>>> h5file = openFile("tutorial.h5", "a")
	  </verbatim>

	  <p>This time, we have opened the file in "a"ppend mode. We
	    are using this mode because we want to add more
	    information to the file. But for the moment, our interest
	    is to read an select data from table on disk. The next
	    lines do exactly that:
	  </p>

	  <verbatim>
>>> table = h5file.root.detector.readout
>>> pressure = [ x.pressure for x in table.readAsRecords()
...                  if x.TDCcount > 3 and x.pressure &lt; 50 ]
	  </verbatim>

	  <p>The first line is only to define a shortcut to the
	    <em>readout</em> table which is a bit deeper on the object
	    tree. As you can see, we have used the <visual
	    markup="bf">natural naming</visual> schema to access
	    it. We could also have used the
	    <verb>h5file.getNode</verb> method instead, and we
	    certainly do that later on.
	  </p>

	  <p>The last two lines are a Python comprenhensive list. It
	    loops on records returned by
	    <verb>table.readAsRecords()</verb> iterator that returns
	    values until table data is exhausted. This records are
	    filtered using the <em>cut</em> expression
	    <verb>x.TDCcount > 3 and x.pressure &lt; 50</verb>, and
	    the <verb>pressure</verb> field for satisfying records is
	    selected to form the final list that is assigned to
	    <verb>pressure</verb> variable.
	  </p>

	  <p>We could have used a normal <verb>for</verb> loop to do
	    that, but I find comprehensions syntax more compact and
	    elegant.
	  </p>

	  <p>Let's select the names for the same set of particles:
	  </p>

	  <verbatim>
>>> names = [ x.name for x in table.readAsRecords()
...               if x.TDCcount > 3 and x.pressure &lt; 50 ]
	  </verbatim>

	  <p>Ok. that's enough for selections. Now, save these
	  selections on file.</p>

	</subsection>

	<subsection>
	  <heading>Creating new array objects</heading>

	  <p>In order to separate the selections from the detector
	    data, we will create a new group, called
	    <verb>columns</verb> hanging from the root group:
	  </p>

	  <verbatim>
>>> gcolumns = h5file.createGroup(h5file.root, "columns", "Pressure and Name")
	  </verbatim>

	  <p>Note that this time we have specified the first parameter
	    in a natural naming fashion (<verb>h5file.root</verb>)
	    instead of a path string ("/").
	  </p>

	  <p>Now, create the Array objects on file:
	  </p>

	  <verbatim>
>>> h5file.createArray(gcolumns, 'pressure', array(pressure),
...                    "Pressure column selection")
&lt;tables.Array.Array object at 0x8217cac>
>>> h5file.createArray('/columns', 'name', array(names), 
...                    "Name column selection")
&lt;tables.Array.Array object at 0x814c3dc>
	  </verbatim>

	  <p>We already know the first two parameters of the
	    <verb>createArray</verb> methods (are the same as in
	    <verb>createTable</verb>): they are the parent group where
	    <verb>Array</verb> will be created and the
	    <verb>Array</verb> instance name. You can figure out that
	    the fourth parameter is the title. And in the third
	    position we have the <verb>Numeric</verb> objects we want
	    to save on disk. They are built from the selection lists
	    we created before, and their typecodes are automatically
	    selected by the <verb>array()</verb> constructor to store
	    the list of values. In these case, they will become
	    double-precision arrays, as we will see in short.
	  </p>

	  <p>Note that createArray method returns an Array instance,
	    that we don't keep anywhere. Don't worry, it is attached
	    to the object tree, and can be easily retrieved later
	    on. In fact, you can browse the object tree very easily
	    and retrieve any data you may be interested in. Keep
	    reading.
	  </p>

	</subsection>

	<subsection>
	  <heading>Traversing the object tree</heading>

	  <p>PyTables, following the Python tradition, offers powerful
	    instropection capabilities, i.e. you can easily ask
	    information about any component of the object tree as well
	    as traverse the tree searching for something. To start
	    with, you can get a first glance image of the object tree,
	    by simply printing the existing <verb>File</verb>
	    instance:
	  </p>

	  <verbatim>
>>> print h5file
Filename: tutorial.h5 \\ Title: "Test file" \\ Format version: 1.0
/ (Group) "Test file"
/columns (Group) "Pressure and Name"
/columns/name Array(4, 16) "Name column selection"
/columns/pressure Array(4,) "Pressure column selection"
/detector (Group) "Detector information"
/detector/readout Table(8, 10) "Readout example"

>>>
	  </verbatim>

	  <p>Right, it seems that all our objects are there. We can
	    use the <verb>walkGroups</verb> method of
	    <verb>File</verb> class to list all the groups in tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...     print group
... 
/ (Group) "Test file"
/columns (Group) "Pressure and Name"
/detector (Group) "Detector information"
	  </verbatim>

	  <p>Note that <verb>walkGroups</verb> actually returns an
	    iterator, not a list of objects. And combining it with the
	    <verb>listNodes</verb> method, we can do very powerful
	    lists. Let's see an example listing all the arrays in the
	    tree:
	  </p>

	  <verbatim>
>>> for group in h5file.walkGroups("/"):
...     for array in h5file.listNodes(group, classname = 'Array'):
...         print array
... 
/columns/name Array(4, 16) "Name column selection"
/columns/pressure Array(4,) "Pressure column selection"
	  </verbatim>

	  <p><verb>listNodes</verb> lists all the nodes hanging from a
	    <verb>group</verb>, and if <em>classname</em> keyword is
	    specified, the method will filter all instances which are
	    not representants of it. We have specified so as to return
	    only the <verb>Array</verb> instances.
	  </p>
	  <p>
	    <visual markup="bf">Caveat emptor</visual>:
	    <verb>listNodes</verb> (conversely to
	    <verb>walkGroups</verb>) returns an actual list, and not
	    an iterator!.
	  </p>

	  <p>As a final example, we will list all the
	    <verb>Leaf</verb> (i.e. <verb>Table</verb> or
	    <verb>Array</verb>) objects in <em>/detector</em>
	    group. Check that we have only one representant of
	    <verb>Table</verb> class in this group:
	  </p>

	  <verbatim>
>>> for table in h5file.listNodes("/detector", 'Leaf'):
...     print table
... 
/detector/readout Table(8, 10) "Readout example"
>>> 
	  </verbatim>

	  <p>Of course you can do more sophisticated node selections
	    using this two powerful funtions, but first, we need to
	    learn a bit about important instance variable of PyTables
	    objects.
	  </p>

	</subsection>

	<subsection>
	  <heading>Getting object metadata</heading>

	  <p>Each object in PyTables has metadata about the actual
	    data on the file. Normally this metainformation is
	    accessible trough the node instance variables. Let's see
	    some examples:
	  </p>

	  <verbatim>
>>> # Get the "/detector/table"
... table = h5file.getNode("/detector/readout", classname = 'Table')
>>> # Get metadata from table
... print "Object:", table
Object: /detector/readout Table(8, 10) "Readout example"
>>> print "Table name:", table.name
Table name: readout
>>> print "Table title:", table.title
Table title: Readout example
>>> print "Number of rows in table: %d" % (table.nrows)
Number of rows in table: 10
>>> print "Table variable names (sorted alphanumerically) with their type:"
Table variable names (sorted alphanumerically) with their type:
>>> for i in range(len(table.varnames)):
...     print "  ", table.varnames[i], ':=', table.vartypes[i]
... 
   ADCcount := H
   TDCcount := B
   energy := d
   grid_i := i
   grid_j := i
   idnumber := Q
   name := 16s
   pressure := f

	  </verbatim>

	  <p>
	    Here, the <verb>name</verb>, <verb>title</verb>,
	    <verb>nrows</verb>, <verb>varnames</verb> and
	    <verb>vartypes</verb> attributes of <verb>table</verb>
	    object give us quite a lot of information about actual
	    table data.
	  </p>
	  <p>Observe how we have used the <verb>getNode</verb> method
	    of <verb>File</verb> class to access a node in the tree,
	    instead of using the natural naming method. Both are
	    useful, and depending on the context you will prefer to
	    use one or another. <verb>getNode</verb> has the advantage
	    that can get a node from the pathname string (like in this
	    example), and you can force that the node in that location
	    has to be a <em>classname</em> instance. However, natural
	    naming is more elegant and quicker to specify (specially
	    if you are using the name completion capability present in
	    interactive console).
	  </p>

	  <p>Now, print some metadata in <em>/columns/pressure</em>
	    Array object:
	  </p>

	  <verbatim>
>>> # Get the object in "/columns pressure"
... pressureObject = h5file.getNode("/columns", "pressure")
>>> 
>>> # Get some metadata on this object
... print "Info on the object:", pressureObject
Info on the object: /columns/pressure Array(4,) "Pressure column selection"
>>> print "  shape: ==>", pressureObject.shape
  shape: ==> (4,)
>>> print "  title: ==>", pressureObject.title
  title: ==> Pressure column selection
>>> print "  typecode ==>", pressureObject.typecode
  typecode ==> d
	  </verbatim>

	  <p>If you look at the <verb>typecode</verb> attribute of the
	    <verb>pressureObject</verb>, you can certify that this is
	    a "d"ouble <verb>Numeric</verb> array, and that by looking
	    at their <verb>shape</verb> attribute the array on disk is
	    unidimensional and has 4 elements.
	  </p>

	</subsection>

	<subsection>
	  <heading>Reading actual data from <visual
	  markup="tt">Array</visual> objects</heading>

	  <p>Once you have found the desired <verb>Array</verb> and
	    decided that you want to retrieve the actual
	    <verb>Numeric</verb> array from it, you should use the
	    <verb>read</verb> method of the <verb>Array</verb>
	    object:</p>

	  <verbatim>
>>> # Read the 'pressure' actual data
... pressureArray = pressureObject.read()
>>> 
>>> # Read the 'name' Array actual data
... nameArray = h5file.root.columns.name.read()
>>> 
>>> # Check what kind of object we have created (they should be Numeric arrays)
... print "pressureArray is object of type:", type(pressureArray)
pressureArray is object of type: &lt;type 'array'>
>>> print "nameArray is object of type:", type(nameArray)
nameArray is object of type: &lt;type 'array'>
>>> 
	  </verbatim>

	  <p>You can verify that<verb> read()</verb> returns an
	    authentic <verb>Numeric</verb> array looking at the output
	    of the <verb>type()</verb> call.
	  </p>

	</subsection>

	<subsection>
	  <heading>Appending data to an existing table</heading>

	  <p>To finish this tutorial, let's have a look at how we can
	    add records to an existing on-disk table. Let's use our
	    well-known <em>readout</em> <verb>Table</verb> instance
	    and let's append some new values to it:
	  </p>

	  <verbatim>
>>> # Create a shortcut to table object
... table = h5file.root.detector.readout
>>> 
>>> # Get the object record from table
... particle = table.record
>>> 
>>> # Append 5 new particles to table (yes, tables can be enlarged!)
... for i in xrange(10, 15):
...     particle.name  = 'Particle: %6d' % (i)
...     particle.TDCcount = i % 256
...     particle.ADCcount = (i * 256) % (1 &lt;&lt; 16)
...     particle.grid_i = i
...     particle.grid_j = 10 - i
...     particle.pressure = float(i*i)
...     particle.energy = float(particle.pressure ** 4)
...     particle.idnumber = i * (2 ** 34)  # This exceeds long integer range
...     table.appendAsRecord(particle)
... 
>>> # Flush this table
... table.flush()
	  </verbatim>

	  <p>That works exactly in the same way than filling a new
	    table. PyTables knows that this table is on disk, and when
	    you add new records, they are appended to the end of the
	    table<footnote>Note that you can only append values to
	    tables, not array objects. However, I plan to support
	    unlimited dimension arrays in short term. Keep
	    tuned.</footnote>.
	  </p>
	  <p>
	    If you look carefully at the code you will see that we
	    have used the <verb>table.record</verb> attribute to
	    access to a <verb>Particle</verb> instance and that way we
	    could use it to fill new values. However, it should be
	    stressed that it is not necessary to have the original
	    class definition (Particle) in our code to re-create it:
	    it will be created only from metadata existing on file,
	    and it behaves exactly as an original Particle
	    instance!. This is part of the magic that allow the use of
	    <em>metaclasses</em> in PyTables, and that will easy the
	    creation of portable aplications that can read any
	    PyTables file <visual markup="bf">regardless</visual> of
	    having access to the original Python record class
	    definition.
	  </p>

	  <p>Let's have a look at some columns of the resulting table:
	  </p>

	  <verbatim>
>>> for x in table.readAsRecords():
...     print "%-16s | %11.1f | %11.4g | %6d | %6d | %8d |" % \
...        (x.name, x.pressure, x.energy, x.grid_i, x.grid_j,
...         x.TDCcount)
... 
Particle:      0 |         0.0 |           0 |      0 |     10 |        0 |
Particle:      1 |         1.0 |           1 |      1 |      9 |        1 |
Particle:      2 |         4.0 |         256 |      2 |      8 |        2 |
Particle:      3 |         9.0 |        6561 |      3 |      7 |        3 |
Particle:      4 |        16.0 |   6.554e+04 |      4 |      6 |        4 |
Particle:      5 |        25.0 |   3.906e+05 |      5 |      5 |        5 |
Particle:      6 |        36.0 |    1.68e+06 |      6 |      4 |        6 |
Particle:      7 |        49.0 |   5.765e+06 |      7 |      3 |        7 |
Particle:      8 |        64.0 |   1.678e+07 |      8 |      2 |        8 |
Particle:      9 |        81.0 |   4.305e+07 |      9 |      1 |        9 |
Particle:     10 |       100.0 |       1e+08 |     10 |      0 |       10 |
Particle:     11 |       121.0 |   2.144e+08 |     11 |     -1 |       11 |
Particle:     12 |       144.0 |     4.3e+08 |     12 |     -2 |       12 |
Particle:     13 |       169.0 |   8.157e+08 |     13 |     -3 |       13 |
Particle:     14 |       196.0 |   1.476e+09 |     14 |     -4 |       14 |
>>> print

>>> print "Total numbers of entries after appending new rows:", table.nrows
Total numbers of entries after appending new rows: 15

	  </verbatim>

	  <p>In <ref refid="tutorial-h5">figure</ref> you can see an
	    view created with <verb>hdfview</verb> Java application of
	    the PyTables file we have created.
	  </p>

	  <figure id="tutorial-h5">
	    <graphics file="tutorial-h5" scale="0.6" kind="bitmap">
	    </graphics>
	    <caption>The PyTables file created in tutorial.</caption>
	  </figure>


	  <p>We are near the end of the tutorial. Ei!, do not forget to
	    close the file after you finish all the work:
	  </p>

	  <verbatim>
>>> h5file.close()
>>> ^D
$ 

	  </verbatim>

	</subsection>

      </section>

      <section id="secondExample">
	<heading>A somewhat more complex exercise</heading>

      <p>Now, time for a more sophisticated example. Here, we will
	create a couple of directories (groups, in HDF5 jargon)
	hanging directly from the root directory called
	<verb>Particles</verb> and <verb>Events</verb>. Then, we will
	put 3 tables in each group; in <verb>Particles</verb> we will
	put instances of <verb>Particle</verb> records and in
	<verb>Events</verb>, instances of <verb>Event</verb>. After
	that, we will feed the tables with 257 (you will see soon why
	I choose such an "esoteric" number) entries each. Finally, we
	will read the recently created table
	<verb>/Events/TEvent3</verb> and select some values from it
	using a comprehension list.
      </p>
      <p>Lets go,</p>

      <verbatim>
from tables import File, IsRecord

class Particle(IsRecord):
    name        = '16s'  # 16-character String
    lati        = 'i'    # integer
    longi       = 'i'    # integer
    pressure    = 'f'    # float  (single-precision)
    temperature = 'd'    # double (double-precision)

class Event(IsRecord):
    name        = '16s'  # 16-character String
    TDCcount    = 'B'    # unsigned char
    ADCcount    = 'H'    # unsigned short
    xcoord      = 'f'    # float  (single-precision)
    ycoord      = 'f'    # float  (single-precision)

# Open a file in "w"rite mode
fileh = File(name = "example2.h5", mode = "w")
# Get the HDF5 root group
root = fileh.getRootGroup()

# Create the groups:
for groupname in ("Particles", "Events"):
    group = fileh.newGroup(root, groupname)

# Now, create and fill the tables in Particles group
gparticles = fileh.getNode("/Particles")
# You can achieve the same result with the next notation
# (it can be convenient and more intuitive in some contexts)
#gparticles = root.Particles
# Create 3 new tables
for tablename in ("TParticle1", "TParticle2", "TParticle3"):
    # Create a table
    table = fileh.newTable("/Particles", tablename, Particle(),
                           "Particles: "+tablename)
    # Get the record object associated with the table:
    particle = fileh.getRecordObject(table)
    # Fill the table with 10 particles
    for i in xrange(257):
        # First, assign the values to the Particle record
        particle.name  = 'Particle: %6d' % (i)
        particle.lati = i 
        particle.longi = 10 - i
        particle.pressure = float(i*i)
        particle.temperature = float(i**2)
        # This injects the Record values
        fileh.appendRecord(table, particle)      

    # Flush the table buffers
    fileh.flushTable(table)

# Now, go for Events:
for tablename in ("TEvent1", "TEvent2", "TEvent3"):
    # Create a table. Look carefully at how we reference the Events group!.
    table = fileh.newTable(root.Events, tablename, Event(),
                           "Events: "+tablename)
    # Get the record object associated with the table:
    event = table.record
    # Fill the table with 10 events
    for i in xrange(257):
        # First, assign the values to the Event record
        event.name  = 'Event: %6d' % (i)
        #event.TDCcount = i
        event.ADCcount = i * 2
        event.xcoor = float(i**2)
        event.ycoord = float(i**4)
        # This injects the Record values
        fileh.appendRecord(table, event)      

    # Flush the buffers
    fileh.flushTable(table)

# Read the records from table "/Events/TEvent3" and select some
e = [ p.TDCcount for p in fileh.readRecords("/Events/TEvent3")
      if p.ADCcount &lt; 20 and 4&lt;= p.TDCcount &lt; 15 ]
print "Last record ==>", p
print "Selected values ==>", e
print "Total selected records ==> ", len(e)

# Finally, close the file (this also will flush all the remaining buffers!)
fileh.close()
      </verbatim>

      <p>Throughout the comments, you can see that <visual markup="tt">PyTables</visual> let's you
      do things in, generally, more than one way. I don't know if
      that's good or not, but I'm afraid it is not. This is in part
      due to the fact that <visual markup="tt">PyTables</visual> is in first stages of development,
      and probably as the API matures, there will be less choices.</p>

      <p>If you have read the code carefully it looks pretty good, but
      it won't work. If you run this example, you will get the next
      error:
      </p>
      <verbatim>
Traceback (most recent call last):
  File "example2.py", line 68, in ?
    event.xcoor  = float(i**2)
AttributeError: 'Event' object has no attribute 'xcoor'
      </verbatim>
      <p>This error is saying us that we tried to assign a value to a
	non-existent field in an <verb>Event</verb> object. By looking
	carefully at the <verb>Event</verb> attributes, we see that we
	misspelled the <verb>xcoord</verb> field (we wrote
	<verb>xcoor</verb> instead). So we correct this in the source,
	and run it again.</p>
      <p>And again, we find another problem:
      </p>
      <verbatim>
Traceback (most recent call last):
  File "example2.py", line 69, in ?
    table.appendRecord(event)      
  File "/usr/lib/python2.2/site-packages/tables/Table.py", line 210, in appendRecord
    self._v_packedtuples.append(recordObject._f_pack2())
  File "/usr/lib/python2.2/site-packages/tables/IsRecord.py", line 121, in _f_pack2
    self._f_raiseValueError()
  File "/usr/lib/python2.2/site-packages/tables/IsRecord.py", line 130, in 
_f_raiseValueError
    raise ValueError, \
ValueError: Error packing record object: 
 [('ADCcount', 'H', 256), ('TDCcount', 'B', 256), ('name', '16s', 'Event:    256'),
 ('xcoord', 'f', 65536.0), ('ycoord', 'f', 4294967296.0)]
 Error was: ubyte format requires 0&lt;=number&lt;=255
      </verbatim>
      <p>This other error is saying that one of the records is having
	trouble to be converted to the data types stated in the Event
	class definition. By looking carefully to the record object
	causing the problem, we see that we are trying to assign a
	value of 256 to the 'TDCcount' field which has a 'B' (C
	unsigned char) typecode and the allowed range for it is
	<verb>0&lt;=TDCcount&lt;=255</verb>. This is a very powerful
	capability to automatically check for ranges: the message
	error is explicit enough to figure out what is happening. In
	this case you can solve the problem by promoting the
	<verb>TDCcount</verb> to 'H' which is a unsigned 16-bit
	integer, or avoid the mistake you probably made in assigning a
	value greater than 255 to a 'B' typecode.
      </p>
      <p>If we change the line:
      </p>
      <verbatim>event.TDCcount = i
      </verbatim>
      <p>by the next one:
      </p>
      <verbatim>event.TDCcount = i % (1&lt;&lt;8)
      </verbatim>
      <p>you will see that our problem has disappeared, and the HDF5
	file has been created. As before, you will find in the
	directory <verb>examples</verb> the working version of the
	code (source file <verb>example2.py</verb>).
      </p>
      <p>Finally, admire the structure we have created in <ref
      refid="example2">figure</ref>.</p>

      <figure id="example2">
	<graphics file="example2" scale="0.6" kind="bitmap">
	</graphics>
	<caption>Tables structured in a hierarchical order.</caption>
      </figure>

      <p>Feel free to visit the rest of examples in directory
        <verb>examples</verb>, and try to understand them. I've tried
        to make several cases in different to give you an idea of the
        <visual markup="tt">PyTables</visual> capabilities and its way
        of dealing with HDF5 objects.</p>

      </section>
    </chapter>

    <chapter id='libraryReference'>
      <heading>Library Reference</heading>
      
      <p><verb>PyTables</verb> implements several classes to represent
	the different nodes in the object tree. They are called
	<verb>File</verb>, <verb>Group</verb>, <verb>Leaf</verb>,
	<verb>Table</verb> and <verb>Array</verb>. Another one is
	responsible to build record objects from a subclass user
	declaration, and performs field, type and range checks; it is
	called <verb>IsRecord</verb>. An important function, called
	<verb>openFile</verb> is responsible to create, open or append
	to <verb>PyTables</verb> files. In addition, a few utility
	funtions are defined to guess if an user supplied file is a
	<verb>PyTables</verb> file or not. These are called
	<verb>isPyTablesFile</verb> and <verb>isHDF5</verb>. Finally,
	several variables are also available to the user that informs
	about <verb>PyTables</verb> version, file format version or
	underlying libraries (as for example <verb>HDF5</verb>)
	version number.
      </p>

      <p>Let's start discussing the global variables and functions
	available to the user, then the methods in the classes defined
	in PyTables.
      </p>

      <section>
	<heading><visual markup="tt">tables</visual> Variables and
	  Functions</heading>

	<subsection>
	  <heading>Global Variables</heading>

	  <description>

	    <term>__version__</term>
	    <item>The PyTables version number.</item>

	    <term>HDF5Version</term>
	    <item>The underlying HDF5 library version number.</item>

	    <term>ExtVersion</term>
	    <item>The Pyrex extension types version. This may be
	      useful for reporting bugs.</item>

	</description>

<!--	  <subsubsection>
	    <heading>__version__</heading>

	    <p>The PyTables version number.
	    </p>
	  </subsubsection>

	  <subsubsection>
	    <heading>HDF5Version</heading>
	    
	    <p>The underlying HDF5 library version number.
	    </p>
	  </subsubsection>
-->
	</subsection>



	<subsection>
	  <heading>Global Functions</heading>

	  <description>
	    <term>openFile(filename, mode='r', title='')</term>
	    <item>Open a PyTables file an returns a File object.
	    
	      <description>

		<term>filename:</term>

		<item>The name of the file (supports environment variable
		  expansion). It must have any of <verb>".h5"</verb>,
		  <verb>".hdf"</verb> or <verb>".hdf5"</verb> extensions.
		</item>

		<term>mode:</term>

		<item>The mode to open the file. It can be one of the
		  following:
		  <description>

		    <term>'r':</term> <item>read-only; no data can be
		      modified.</item>

		    <term>'w':</term> <item>write; a new file is created
		      (an existing file with the same name is
		      deleted).</item>

		    <term>'a':</term> <item>append; an existing file is
		      opened for reading and writing, and if the file does
		      not exist it is created.</item>

		    <term>'r+':</term> <item>is similar to 'a', but the
		      file must already exist.</item>

		    <term>title</term> <item>If filename is new, this
		      will set a title for the root group in this
		      file. If filename is not new, the title will be
		      read from disk, and this will not have any
		      effect.</item>

		  </description>
		</item>
	      </description>
	    </item>

	    <term>isHDF5(filename)</term> <item>Determines whether
	      filename is in the HDF5 format. When successful, returns
	      a positive value, for TRUE, or 0 (zero), for
	      FALSE. Otherwise returns a negative value.  To this
	      function to work, it needs a closed file.
	    </item>

	    <term>isPyTablesFile(filename)</term> <item>Determines
	      whether a file is in the PyTables format.  When
	      successful, returns the format version string, for TRUE,
	      or 0 (zero), for FALSE. Otherwise returns a negative
	      value.  To this function to work, it needs a closed
	      file.
	    </item>

	  </description>
	</subsection>
      </section>

      <section id="IsRecordClass">
	<heading>The <visual markup="tt">IsRecord</visual> class</heading>

	<p>This class is in fact a so-called <em>metaclass</em>
	  object. There is nothing special on it, except that their
	  subclasses attributes are transformed during its
	  construction phase, and new methods for the are defined
	  based on the values of the attributes. In that way, we can
	  <em>force</em> the resulting instance to only accept
	  assignments on the declared attributes (in fact, it has a
	  few more, but they are hidden with prefixes like <visual
	  markup="tt">"__"</visual>, <visual
	  markup="tt">"_v_"</visual> or <visual
	  markup="tt">"_f_"</visual>, so please, don't use attributes
	  names starting with these prefixes). If you try to do an
	  assignment to a non-declared attribute, <visual markup="tt">PyTables</visual> will raise
	  an error.</p>

	<p>To use such a particular class, you have to declare a
	  descendent class from <em>IsRecord</em>, with many
	  attributes as fields you want in your record. To declare
	  their types, you simply assign to these attributes their
	  <em>typecode</em>. That's all, from now on, you can
	  instantiate objects from you new class and use them as a
	  very flexible record object with safe features like
	  automatic name field, data type and range checks (see the
	  <ref refid="secondExample">section</ref> for an example on
	  how it works).
	</p>
	<p>See the <ref refid="datatypesSupported">appendix</ref> for
	  a relation of data types supported in a <visual
	  markup="tt">IsRecord</visual> class declaration.
	</p>

      </section>

      <section id="FileClass">
	<heading>The <visual markup="tt">File</visual> class</heading>

	<p>This class is returned when a PyTables is opened with the
	  <verb>openFile</verb> function. It is in charge of create,
	  open, flush and close the PyTables files. Also, File class
	  offer methods to traverse the object tree, as well as to
	  create new nodes. One of its attributes (<verb>root</verb>)
	  represents the entry point to the object tree.
	</p>

	<p>Next, we will discuss the attributes and methods for File
	  class<footnote>On the following, the term <verb>Leaf</verb>
	  will refer to a <verb>Table</verb> instance. Right now, the
	  only supported <verb>Leaf</verb> objects are
	  <verb>Table</verb> and <verb>Array</verb>, but this list may
	  be increased in the future.</footnote>.
	</p>

	<subsection>
	  <heading><visual markup="tt">File</visual> instance variables</heading>
	  <description>

	    <term>filename</term> <item>Filename opened.</item>

	    <term>mode</term> <item>Mode in which the filename was
	      opened.</item>

	    <term>title</term> <item>The title of the root group in
	      file.</item>

	    <term>root</term>
	    <item>The root group in file. This is the entry point to
	      the object tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">File</visual> methods</heading>

	  <description>

	    <term>createGroup(where, name, title='') </term>
	    <item>Create a new Group instance with name <em>name</em>
	    in <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the new
		  group will hang. <em>where</em> parameter can be a
		  path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or another
		  Group instance. </item>

		<term>name</term>
		<item>The name of the new group.</item>

		<term>title</term>
		<item>A descrition for this group.</item>

	      </description>
	    </item>

	    <term>createTable(where, name, RecordObject, title='',
	      compress=3, expectedrows=10000)</term> <item>Create
	      a new Table instance with name <em>name</em> in
	      <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the
		  new table will hang. <em>where</em> parameter can be
		  a path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or Group
		  instance. </item>

		<term>name</term>
		<item>The name of the new table.</item>

		<term>RecordObject</term> <item>An instance of a
		  user-defined class (derived from the
		  <verb>IsRecord</verb> class) where table fields are
		  defined.</item>

		<term>title</term>
		<item>A descrition for this table.</item>

		<term>compress</term> <item>Specifies a compress level
		  for data. The allowed range is 0-9. A value of 0
		  disables compression. The default is compression
		  level 3, that balances between compression effort
		  and CPU consumption.
		</item>

		<term>expectedrows</term> <item>An user estimate about
		  the number of records that will be on table. If not
		  provided, the default value is appropiate for tables
		  until 1 MB in size (more or less, depending on the
		  record size). If you plan to save bigger tables try
		  providing a guess; this will optimize the HDF5
		  B-Tree creation and management process time and
		  memory used.</item>

	      </description>
	    </item>

	    <term>createArray(where, name, NumericObject,
	      title='')</term> <item>Create a new instance Array with
	      name <em>name</em> in <em>where</em> location.

	      <description>

		<term>where</term> <item>The parent group where the
		  new array will hang. <em>where</em> parameter can be
		  a path string (for example
		  <verb>"/Particles/TParticle1"</verb>), or Group
		  instance. </item>

		<term>name</term>
		<item>The name of the new array.</item>

		<term>NumericObject</term> <item>The Numeric array to
		  be saved.</item>

		<term>title</term>
		<item>A description for this table.</item>

	      </description>
	    </item>

	    <term>getNode(where, name='', classname='')</term>
	    <item>Returns the object node <em>name</em> under
	      <em>where</em> location

	      <description>

		<term>where</term> <item>Can be a path string or Group
		  instance. If <em>where</em> doesn't exists or has not a
		  child called <em>name</em>, a ValueError error is raised.
		</item>

		<term>name</term> <item>The object name desired. If
		  <em>name</em> is a null string (''), or not
		  supplied, this method assumes to find the object in
		  <em>where</em>.</item>

		<term>classname</term> <item>If supplied, returns only
		  an instance of this class name. Allowed names in
		  <em>classname</em> are: 'Group', 'Leaf', 'Table' and
		  'Array'.</item>

	      </description>
	    </item>

	    <term>listNodes(where, classname='')</term>
	    <item>Returns a list with all the object nodes (Group or
	    Leaf) hanging from <em>where</em>. The list is
	    alphanumerically sorted by node name.

	      <description>

		<term>where</term> <item>The parent group. Can be a
		  path string or Group instance.  </item>

		<term>classname</term> <item>If a <em>classname</em>
		  parameter is supplied, the iterator will return only
		  instances of this class (or subclasses of it). The
		  only supported classes in <em>classname</em> are
		  <verb>'Group'</verb>, <verb>'Leaf'</verb>,
		  <verb>'Table'</verb> and
		  <verb>'Array'</verb>.</item>

	      </description>
	    </item>

	    <term>walkGroups(where='/')</term> <item><em>Iterator</em>
	      that recursively obtains Groups (not Leaves) hanging
	      from <em>where</em>. If <em>where</em> is not supplied,
	      the root object is taken as origin. The groups are
	      returned from top to bottom, and they are
	      alphanumerically sorted when they are at the same level.

	      <description>

		<term>where</term> <item>The origin group. Can be a
		  path string or Group instance.
		</item>

	      </description>
	    </item>

	    <term>flush()</term> <item>Flush all the objects on all
	      the HDF5 objects tree.
	    </item>

	    <term>close()</term> <item>Flush all the objects in HDF5
	      file and close the file.
	    </item>

	  </description>

	</subsection>
      </section>

      <section id="GroupClass">
	<heading>The <visual markup="tt">Group</visual> class</heading>

	<p>Instances of this class are a grouping structure containing
	  instances of zero or more groups or leaves, together with
	  supporting metadata.
	</p>

	<p>Working with groups and leaves is similar in many ways to
	  working with directories and files, respectively, in a Unix
	  filesystem. As with Unix directories and files, objects in
	  the object tree are often described by giving their full (or
	  absolute) path names. This full path can be specified either
	  as string (like in <verb>'/group1/group2'</verb>) or as a
	  complete object path written in the Pythonic fashion known
	  as <em>natural name</em> schema (like in
	  <verb>file.root.group1.group2</verb>) and discussed in the
	  <ref refid='NaturalTreeSection'>section</ref>.
	</p>

	<p>A collateral effect of the <em>natural naming</em> schema
	  is that you must be aware when assigning a new attribute to
	  a Group object to no collide with existing children node
	  names. For this reason and to not pollute the children
	  namespace, it is explicitely forbidden to assign "normal"
	  attributes to Group instances, and the only ones allowed
	  must start with "<verb>_c_</verb>" (for class variables),
	  "<verb>_f_</verb>" (for methods) or "<verb>_v_</verb>" (for
	  instance variables) prefixes. Any attempt to assign a new
	  attribute that does not starts with these prefixes, will
	  raise a <verb>NameError</verb> exception.
	</p>

	<subsection>
	  <heading><visual markup="tt">Group</visual> class variables</heading>
	  <description>

	    <term>_c_objects</term> <item>Dictionary with all objects
	      (groups or leaves) on tree.</item>

	    <term>_c_objgroups</term> <item>Dictionary with all object
	      groups on tree.</item>

	    <term>_c_objleaves</term> <item>Dictionary with all object
	      leaves on tree.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> instance variables</heading>
	  <description>

	    <term>_v_title</term>
	    <item>A description for this group.</item>

	    <term>_v_name</term>
	    <item>The name of this group.</item>

	    <term>_v_pathname</term>
	    <item>A string representation of the group location
            in tree.</item>

	    <term>_v_parent</term>
	    <item>The parent Group instance.</item>

	    <term>_v_objchilds</term> <item>Dictionary with all objects
	      (groups or leaves) hanging from this instance.</item>

	    <term>_v_objgroups</term> <item>Dictionary with all object
	      groups hanging from this instance.</item>

	    <term>_v_objleaves</term> <item>Dictionaly with all object
	      leaves hanging from this instance.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Group</visual> methods</heading>

	  <p>This methods are documented for completeness, and they
	    can be used without any problem. However, you should use
	    the high-level counterpart methods in the
	    <verb>File</verb> class, because these are most used in
	    documentation and examples, and are a bit more powerful
	    than those exposed here. </p>

	  <description>

	    <term>_f_join(name)</term>
	    <item>Helper method to correctly concatenate a name child object
	      with the pathname of this group.</item>

	    <term>_f_listNodes(classname='')</term> <item>Return a
	      list with all the object nodes hanging from this
	      instance. The list is alphanumerically sorted by node
	      name. If a <em>classname</em> parameter is supplied, it
	      will only return instances of this class (or subclasses
	      of it). The supported classes in <em>classname</em> are
	      <verb>'Group'</verb>, <verb>'Leaf'</verb>,
	      <verb>'Table'</verb> and <verb>'Array'</verb>.</item>

	    <term>_f_walkGroups()</term> <item><em>Iterator</em> that
	      recursively obtains Groups (not Leaves) hanging from
	      self. The groups are returned from top to bottom, and
	      are alphanumerically sorted when they are at the same
	      level.
	    </item>

	  </description>

	</subsection>
      </section>

      <section id="LeafClass">
	<heading>The <visual markup="tt">Leaf</visual> class</heading>

	<p>This is a helper class useful to place common functionality
	  of all Leaf objects. A Leaf object is an end-node, that is,
	  a node that can hang directly from a group object, but that
	  is not a group itself. Right now this set is composed by
	  <verb>Table</verb> and <verb>Array</verb> objects. In fact,
	  <verb>Table</verb> and <verb>Array</verb> classes inherit
	  functionality from this class using the <em>mix-in</em>
	  technique.
	</p>
	<p>Normally the user will not need to call any method from
	  here, but it is useful to know that it exists because it can
	  be used as a filter in methods like
	  <verb>File.GetNode()</verb> or
	  <verb>File.listNodes()</verb>, against others.
	</p>
      </section>

      <section id="TableClass">
	<heading>The <visual markup="tt">Table</visual> class</heading>

	<p>Instances of this class represents table objects in the
	  object tree. It provides methods to create new tables or
	  open existing ones, as well as methods to write/read data
	  and metadata to/from table objects in the file.
	</p>
	<p>Data can be written or read both as records or as
	  tuples. Records are recommended because they are more
	  intuitive and less error prone although they are slow. Using
	  tuples (or value sequences) is faster, but the user must be
	  very careful because when passing the sequence of values,
	  they have to be in the correct order (alphanumerically
	  ordered by field names). If not, unexpected results can
	  appear (most probably <verb>ValueError</verb> exceptions
	  will be raised).
	</p>

	<subsection>
	  <heading><visual markup="tt">Table</visual> instance
	    variables</heading>
	  <description>

	    <term>name</term>
	    <item>The node name.</item>

	    <term>title</term>
	    <item>The title for this node.</item>

	    <term>record</term>
	    <item>The record object for this table.</item>

	    <term>nrows</term>
	    <item>The number of rows (records) in this table.</item>

	    <term>varnames</term>
	    <item>The field names for the table.</item>

	    <term>vartypes</term>
	    <item>The typecodes for the table fields.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Table</visual>
	    methods</heading>
	  <description>

	    <term>appendAsRecord(RecordObject)</term> <item>Append the
	      <verb>RecordObject</verb> to the output buffer of the
	      table instance.

	      <description>

		<term>RecordObject</term> <item>An instance of the
		  user-defined record class. It has to be a
		  <verb>IsRecord</verb> descendant instance and if
		  not, a ValueError exception is raised.</item>

	      </description>

	    </item>

	    <term>appendAsTuple(tupleValues)</term> <item>Append the
	      <em>tupleValues</em> tuple to the output buffer of the
	      table instance. This method is faster (but also unsafer,
	      because requires user to introduce the values in correct
	      order!) than <verb>appendAsRecord</verb> method.

	      <description>

		<term>tupleValues</term> <item> is a tuple that has
		  values for all the user record fields. The user has
		  to provide them in the order determined by
		  alphanumerically sorting the record name
		  fields.</item>

	      </description>
	    </item>

	    <term>appendAsValues(*values)</term> <item> Append the
	      <em>values</em> parameters to the table output
	      buffer. This method is faster (and unsafer, because
	      requires user to introduce the values in correct order)
	      than <verb>appendAsRecord</verb> method. It is similar
	      to the <verb>appendAsTuple</verb> method, but accepts
	      separate parameters as values instead of a monolithic
	      tuple.
        
	      <description>
		<term>values</term> <item>Is a serie of parameters
		that provides values for all the user record
		fields. The user has to provide them in the order
		determined by alphanumerically sorting the record
		fields.</item>
	      </description>
	    </item>

	    <term>readAsRecords()</term> <item>Return a record
	      instance from rows in table each time. This method is a
	      <em>generator</em>, i.e. it keeps track on the last
	      record returned so that next time it is invoked it
	      returns the next available record. It is slower than
	      <verb>readAsTuples</verb> but in exchange, it returns
	      full-fledged instance records.</item>

	    <term>readAsTuples()</term> <item>Return a tuple from rows
	      in table each time. This method is a <em>generator</em>,
	      i.e. it keeps track on the last record returned so that
	      next time it is invoked it returns the next available
	      record. This method is twice as faster than
	      readAsRecords, but it yields the rows as
	      (alphanumerically orderd) tuples, instead of
	      full-fledged instance records.</item>

	    <term>flush()</term> <item>Flush the table buffers.</item>

	    <term>close()</term> <item>Flush the table buffers and
	      close the HDF5 dataset.</item>

	  </description>

	</subsection>

      </section>

      <section id="ArrayClass">
	<heading>The <visual markup="tt">Array</visual> class</heading>

	<p> Represent a Numeric Array in HDF5 file. It provides
	  methods to create new arrays or open existing ones, as well
	  as methods to write/read data and metadata to/from array
	  objects in the file.
	</p>
	<p> All Numeric typecodes are supported except
	  "<verb>F</verb>" and "<verb>D</verb>" which corresponds to
	  complex datatypes. These might be included in short future.
	</p>

	<subsection>
	  <heading><visual markup="tt">Array</visual> instance
	    variables</heading>
	  <description>

	    <term>name</term>
	    <item>The node name.</item>

	    <term>title</term>
	    <item>The node title.</item>

	    <term>shape</term> <item>tuple with the array shape (in
	      the Numeric fashion).</item>

	    <term>typecode</term>
	    <item>The typecode of the represented array.</item>

	  </description>

	</subsection>

	<subsection>
	  <heading><visual markup="tt">Array</visual>
	    methods</heading>

	  <p>The methods for this class are very few. Please note that
	    this object has not internal I/O buffers, so there is no
	    need to call flush() method. However, it is included for
	    consistency with <verb>Leaf</verb> nodes.</p>

	  <description>

	    <term>read()</term> <item>Read the array from disk and
	      return it as a Numeric object. Note that while this
	      method is not called, the actual array data is resident
	      on disk.</item>

	    <term>flush()</term> <item>Flush the internal
	      buffers. Remember: this is a do-nothing method.</item>

	    <term>close()</term> <item>Close the array on file.</item>

	  </description>

	</subsection>

      </section>

    </chapter>

    <appendix>
      <chapter id="datatypesSupported">
	<heading><visual markup="tt">PyTables</visual> Supported Data Types</heading>
        <p>The supported data types are the same that are supported by
	  the <visual markup="tt">array</visual> module in Python,
	  with some additions, which will be briefly discussed
	  shortly. The typecodes for the supported data types are
	  listed on <ref refid="datatypesSupported">table</ref>.
	</p>

	<table id="datatypesSupportedTable">
	  <tabular preamble="lllcl">
	  <tabhead>
	    <srow>Type Code | Description | C Type | Size (in bytes) |
	      Python Counterpart</srow>
	  </tabhead>
	  <tabbody>
	    <srow>'c' | 8-bit character | char | 1 | String of lenght 1 </srow>
	    <srow>'b' | 8-bit integer | signed char | 1 | Integer </srow>
	    <srow>'B' | 8-bit unsigned integer | unsigned char | 1 | Integer </srow>
	    <srow>'h' | 16-bit integer | short | 2 | Integer </srow>
	    <srow>'H' | 16-bit unsigned integer | unsigned short | 2 | Integer </srow>
	    <srow>'i' | integer | int | 4 or 8 | Integer </srow>
	    <srow>'I' | unsigned integer | unsigned int | 4 or 8 | Long </srow>
	    <srow>'l' | long integer | long | 4 or 8 | Integer </srow>
	    <srow>'L' | unsigned long integer | unsigned long | 4 or 8 | Long </srow>
	    <srow>'q' | long long integer | long long | 8 | Long </srow>
	    <srow>'Q' | unsigned long long integer | unsigned long long | 8 | Long </srow>
	    <srow>'f' | single-precision float | float | 4 | Float </srow>
	    <srow>'d' | double-precision float | double | 8 | Float </srow>
	    <srow>'s' | arbitrary lenght string | char[] | * | String </srow>
	  </tabbody>
	</tabular>
	  <caption>Data types supported by <visual markup="tt">PyTables</visual></caption>
	</table>

	<p>The additions to the array module typecodes are the <visual
	  markup="tt">'q'</visual>, <visual markup="tt">'Q'</visual>
	  and <visual markup="tt">'s'</visual>.  The <visual
	  markup="tt">'q'</visual> and <visual
	  markup="tt">'Q'</visual> conversion codes are available in
	  native mode only if the platform C compiler supports C long
	  long, or, on Windows, __int64. They are always available in
	  standard modes. The <visual markup="tt">'s'</visual>
	  typecode can be preceded by an integer to indicate the
	  maximum length of the string, so <visual
	  markup="tt">'16s'</visual> represents a 16-byte string.</p>

	<p>Also note that when the <visual markup="tt">'I'</visual>
	  and <visual markup="tt">'L'</visual> codetypes are used in
	  records, Python uses internally <visual
	  markup="tt">Long</visual> integers to represent them, that
	  can (or cannot, depending on what you are trying to do) be
	  a source of inefficiency in your code.</p>
      </chapter>
    </appendix>
  </mainmatter>

  <backmatter>
    <references>
      <enumerate>

	<item id="HDF5WhatIs"><em>What is HDF5?.</em> Concise
	  description about HDF5 capabilities and its differences from
	  earlier versions (HDF4). <url
	  name="http://hdf.ncsa.uiuc.edu/whatishdf5.html"/>
	</item>

	<item id="HDF5Intr"><em>Introduction to HDF5.</em>
	  Introduction to the HDF5 data model and programming
	  model. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/doc/H5.intro.html"/>
	</item>

	<item id="HDF5_HL"><em>HDF5: High Level APIs.</em> A set of
	  functions built on top of the basic HDF5 library. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/hdf5_hl/doc/"/>
	</item>

	<item id="HDF5TableExamples"><em>The HDF5 table programming
	  model.</em> Examples on using HDF5 tables with the C
	  API. <url
	  name="http://hdf.ncsa.uiuc.edu/HDF5/hdf5_hl/doc/RM_hdf5tb_ex.html"/>
	</item>

	<item id="HL-HDF"><em>HL-HDF.</em> A High Level Interface to
	  the HDF5 File Format. <url
	  name="ftp://ftp.ncsa.uiuc.edu/HDF/HDF5/contrib/hl-hdf5/README.html"/>
	</item>

	<item id="Objectify"><em>On the 'Pythonic' treatment of XML
	  documents as objects(II).</em> Article describing XML
	  Objectify, a Python module that allows working with XML
	  documents as Python objects. Some of the ideas presented
	  here are used in <visual markup="tt">PyTables</visual>. <url
	  name="http://www-106.ibm.com/developerworks/xml/library/xml-matters2/index.html"/>
	</item>

	<item id="GnosisUtils"><em>gnosis.xml.objectify.</em> This
	  module is part of the Gnosis utilities, and allows to create
	  a mapping between any XML element to "native" Python
	  objects. <url
	  name="http://gnosis.cx/download/Gnosis_Utils-current.tar.gz"/>
	</item>

	<item id="Pyrex"><em>Pyrex.</em> A Language for Writing Python
	  Extension Modules. <url
	  name="http://www.cosc.canterbury.ac.nz/~greg/python/Pyrex"/>
	</item>

	<item id="NetCDF"><em>NetCDF (network Common Data Form).</em>
	  This is an interface for array-oriented data access and a
	  library that provides an implementation of the
	  interface. <url
	  name="http://www.unidata.ucar.edu/packages/netcdf/"/>
	</item>

	<item id="NetCDFSP"><em>NetCDF module on Scientific
	  Python.</em> ScientificPython is a collection of Python
	  modules that are useful for scientific computing. Its NetCDF
	  module is a powerful interface for NetCDF data format. <url
	  name="http://starship.python.net/~hinsen/ScientificPython/ScientificPythonManual/"/>
	</item>

	<item id="Numerical"><em>Numerical Python.</em> Package to
	  speed-up arithmetic operations on arrays of numbers. <url
	  name="http://www.pfdubois.com/numpy/"/>
	</item>

	<item id="Numarray"><em>Numarray.</em> Reimplementation of
	  Numeric which adds the ability to efficiently manipulate
	  large numeric arrays in ways similar to Matlab and
	  IDL. Among others, Numarray provides the record array
	  extension. <url name="http://stsdas.stsci.edu/numarray/"/>
	</item>

      </enumerate>
    </references>
  </backmatter>
</book>

