Announcing PyTables 0.8
-----------------------

PyTables is a hierarchical database package designed to efficently
manage very large amounts of data. PyTables is built on top of the
HDF5 library and the numarray package. It features an object-oriented
interface that, combined with natural naming and C-code generated from
Pyrex sources, makes it a fast, yet extremely easy to use tool for
interactively save and retrieve very large amounts of data. Besides,
it provides flexible indexed access on disk to anywhere in the data
you want to go.

PyTables is not designed to work as a relational database opponent,
but rather as a teammate. If you want to deal with large datasets of
multidimensional data (for example for multidimensional analysis), or
just provide a categorized structure for some portions of your
cluttered RDBS, then give PyTables a try. It works just great for
storing data coming from data acquisition systems (DAS), simulation
software, network data monitoring systems (for example for
monitorizing IP packets on routers), or as a centralized repository
for system logs, to name only a few.
 
On this release you will find:
       - Variable Length Arrays (VLA's) that allow save a collection
         of variable length of elements in each row of an array.
       - Extensible Arrays (EA's) that allow to extend homogeneous
         datasets on disk.
       - Powerful replication capabilities ranging from single leaves
         up to complete hierarchies.
       - Very much improved HDF5 native files importing capabilities
         with the introduction of the UnImplemented class.
       - Two new useful utilities: ptdump & ptrepack
       - Much improved documentation (with the help of Scott Prater).
       - Many others minor improvements.

More in detail:

What's new
-----------

	- New VLArray class allows to keep large lists of rows having
          each of these rows a variable number of elements. The
          elements can be scalars or fully multimensional objects, in
          the PyTables tradition. This class supports two special
          objects as rows, which are Unicode strings (UTF-8
          codification is used internally) and generic Python objects
          (though the use of cPickle).

	- New EArray class allow to enlarge already existing
          multidimensional objects of homogeneous data. This can be
          seen as an extension of the already existing Array class,
          but with more functionality, as for example, on-line
          compression or other filters can be applied to EArray
          instances.

	  Another nice feature of EA's is that they support fully
          multidimensional data selection with extended slices, i.e.,
          you can write: earray[1,2:3,...,4:200] and get the desired
          data from the disk. This is implemented using the powerful
          selection capabilities of the HDF5 library, so this is very
          efficient in terms of I/O operations. The same functionality
          has been added to Array objects as well.

	- New UnImplemented class. If a dataset contains unsupported
          datatypes, it will be associated with an UnImplemented
          instance and added to the object tree in the normal way. In
          that way, you can continue to work with other possible
          supported objects, while retaining access to attributes of
          unsupported datatypes. This behaviour has changed from
          previous versions, where a RuntimeError was issued in case
          of an unsupported object.

	  The new UnImplemented class together with the support for
          new datatypes will enable PyTables to greatly enlarge the
          range of native HDF5 that can be read/modified.

	- Boolean support has been added for all the Leaf objects.

	- Table has now an append() method that allows to save big
          buffers of data in one shot (i.e. bypassing the Row
          accessor). This can largely improve the speed of data
          gathering.

	- The standard shuffle compression enabler filter present in
          HDF5 is supported.

	- The standard fletcher32 checksum filter present in HDF5 is
          supported.

	- As the supported number of filters is getting large (and
          that may be further increased in the future), a Filters()
          class has been introduced to deal more easily with filter
          information. A consequence of that is a slightly backward
          incompatible change in the createTable() function, in the
          sense that "compress" and "complib" parameters are
          deprecated now and you should use the "filters"
          parameter. However, you will be able to continue using the
          old parameters (only a Deprecation warning will be issued)
          for a couple of versions, but you should migrate to the new
          version as soon as possible. In general, you can easily
          migrate old code by substituting code like:

                table = fileh.createTable(group, 'table', Test, '',
                                          complevel, complib, nrows)
	  by

                table = fileh.createTable(group, 'table', Test, '',
                                          Filters(complevel, complib), nrows)


	- A copy() method that supports slicing and change of
          filtering capabilities has been added for all the Leaf
          objects. See User's Manual for more info.

	- A _f_copyChilds() has been added to Group class, so that you
          can replicate sub-hierarchies very easily, even to other
          files. Similarly, File has received a new .copyFile()
          method to copy complete hierarchies.

	- Two new utilities has been added: ptdump and
          ptrepack. ptdump allows the user to have a look at the
          contents of PyTables files (both data and
          metadata). ptrepack is a powerful utility that lets you to
          selectively copy (parts of) hierarchies to specific
          locations in other files. It can be also useful as an
          importer for generic HDF5 files.

        - The meaning of the stop parameter in read() methods has
          changed. Now a value of 'None' means the last row, and a
          value of 0 (zero) means the first row. This is more
          consistent with the range() function in python and the
          __getitem__() special method in numarray.

	- The "numarray" value has been added to the flavor parameter
          in Table.read() method for completeness.

	- The attributes (.attr instance variable) are Python
          properties now, and the access to their values is no longer
          lazy, i.e. you will be able to see both system or user
          attributes from the command line using the tab-completion
          capability of your python console (if enabled).

	- Documentation has been largely improved to include all the
          new functionality. In particular, the internal format of
          PyTables has been fully described. So, you can build
          "native" PyTables files using any other generic HDF5
          software by just mimicking their format.

	- As always, some bugs has been solved (specially when
          deleting and/or overwriting attributes).

	- And last, but not least, a new donations section has been
          added to the PyTables web site
          (http://sourceforge.net/projects/pytables, then follow
          "Donations" tag). If you like PyTables and want this effort
          to continue, please, donate!.


What is a table?
----------------

A table is defined as a collection of records whose values are stored
in fixed-length fields. All records have the same structure and all
values in each field have the same data type.  The terms
"fixed-length" and "strict data types" seems to be quite a strange
requirement for an language like Python, that supports dynamic data
types, but they serve a useful function if the goal is to save very
large quantities of data (such as is generated by many scientific
applications, for example) in an efficient manner that reduces demand
on CPU time and I/O resources.

What is HDF5?
-------------

For those people who know nothing about HDF5, it is is a general
purpose library and file format for storing scientific data made at
NCSA. HDF5 can store two primary objects: datasets and groups. A
dataset is essentially a multidimensional array of data elements, and
a group is a structure for organizing objects in an HDF5 file. Using
these two basic constructs, one can create and store almost any kind of
scientific data structure, such as images, arrays of vectors, and
structured and unstructured grids. You can also mix and match them in
HDF5 files according to your needs.

Platforms
---------

I'm using Linux (32-bit) as the main development platform, but
PyTables should be easy to compile/install on many other UNIX
machines. This package has also passed all the tests on a UltraSparc
platform with Solaris 7 and Solaris 8. It also compiles and passes all
the tests on a SGI Origin2000 with MIPS R12000 processors, with the
MIPSPro compiler and running IRIX 6.5. It also runs fine on Linux
64-bit platforms, like an AMD Opteron running SuSe Linux Enterprise
Server (SLES). It has also been tested in MacOSX platforms (10.2 and
10.3).

Regarding Windows platforms, PyTables has been tested with Windows
2000 and Windows XP (using the Microsoft Visual C compiler), but it
should also work with other flavors as well.

An example?
-----------

For online code examples, have a look at

http://pytables.sourceforge.net/tut/tutorial1-1.html

and 

http://pytables.sourceforge.net/tut/tutorial1-2.html

Web site
--------

Go to the PyTables web site for more details:

http://pytables.sourceforge.net/

Share your experience
---------------------

Let me know of any bugs, suggestions, gripes, kudos, etc. you may
have.

Have fun!

-- Francesc Alted
falted@pytables.org

