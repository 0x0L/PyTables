Announcing PyTables Pro 1.0
---------------------------

Blurb, blurb, blurb...

What it is
----------

PyTables is a solid hierarchical database package designed to
efficiently manage extremely large amounts of data (with support for
full 64-bit file addressing). It features an object-oriented interface
that, combined with C extensions for the performance-critical parts of
the code, makes it a very easy-to-use tool for high performance data
storage and retrieval.

It is built on top of the HDF5 library and the numarray package, and
provides containers for both heterogeneous data (Tables) and
homogeneous data (Array, EArray) as well as containers for keeping
lists of objects of variable length (like Unicode strings or general
Python objects) in a very efficient way (VLArray). It also sports a
series of filters allowing you to compress your data on-the-fly by
using different compressors and compression enablers.

But perhaps the more interesting features are its powerful browsing
and searching capabilities that allow you to perform data selections
over heterogeneous datasets exceeding gigabytes of data in just tenths
of second. Besides, all the PyTables I/O is buffered, implemented in C
and carefully tuned so that you can reach much better performance with
PyTables than with your own home-grown wrappings to the HDF5 library.

Changes more in depth
---------------------

Improvements:

- New Undo/Redo feature (i.e. integrated support for undoing and/or
  redoing actions). This functionality lets you to put marks in
  specific places of your data operations, so that you can make your
  HDF5 file to pop back (undo) to a specific mark (for example for
  inspecting how your data looked at that point). You can also go
  forward to a more recent marker (redo). You can even do jumps to the
  marker you want using just one instruction as we will see shortly

- The opening and copying of files with large number of objects has
  been made faster by correcting a typo in Table._open. Thanks to
  Ashley Walsh for sending a patch for this.

- All potentially long I/O operations has been bracketed by
  BEGIN_ALLOW_THREADS and END_ALLOW_THREADS in order to release the
  GIL during this I/O operations. This will allow better performance
  on multiprocessor machines. Thanks to Andrew Straw for suggesting
  this.

- Now, one can modify rank-0 (scalar) EArrays. Thanks to Norbert Nemec
  for providing a patch for this.

- You are allowed from this version on to add non-valid natural naming
  names as node or attribute names. A warning is issued to warn (but
  not forbidding) you in such a case. Of course, you have to use the
  getattr() function so as to access such a non-valid natural names.

- The indexes of Tables and *Arrays can be of LongType besides of
  IntType. However, indexes in slices are still restricted to regular
  IntType.

- The concept of READ_ONLY system attributes has disappeared. You can
  change them now at your own risk!. However, you still cannot remove
  or rename system attributes.

- Table.iterrows() returns an empty iterator when no rows are selected.


Backward-incompatible changes:

- Running an action on the wrong type of node now (i.e. using
  File.listNodes() on a leaf) raises a TypeError instead of a
  NodeError.

- Now, the deletion and getting of a non-existing attribute raises an
  AttributeError, instead of a RuntimeError.

- Deleting a non-existing child now raises a NoSuchNodeError, instead
  of doing nothing.

- Removing a non-empty child group using 'del group.child' fails with
  a NodeError instead of recursively removing it. This is because of
  the potential damage it may cause when used inadvertently. If a
  recursive behavior is needed, use the _f_remove() method of the
  child node.

- When start>=stop an empty iterator is returned by Table.iterrows
  instead of an empty RecArray. Thanks to Ashley Walsh for noting
  this.

- Copy operations (Group._f_copyChildren, File.copyChildren,
  File.copyNode...) do no longer return a tuple with the new node and
  statistics. Instead, they only return the new node, and stats are
  collected via an optional keyword argument.

- Swapped last two arguments of File.copyAttrs to match the other
  methods.

- The default values for 'name' and 'classname' arguments in
  File.getNode() are now None, although the empty string is still
  allowed for backwards compatibility.  File hierarchy manipulation
  and attribute handling operations using those arguments have changed
  to reflect this.


Bug fixes:

- Added partial native HDF5 chunked dataset support. They can read
  now, and even extended, but only along the first extendeable
  dimension. This limitation maybe removed when multiple extendeable
  dimensions would be supported in PyTables.


Important note for Python 2.4 and Windows users
-----------------------------------------------

If you are willing to use PyTables with Python 2.4 in Windows
platforms, you will need to get the HDF5 library compiled for MSVC
7.1, aka .NET (and possible LZO and UCL as well, if you want support
for LZO and UCL at all). It can be found at:
ftp://ftp.ncsa.uiuc.edu/HDF/HDF5/current/bin/windows/5-163-winxp-net2003.zip


Where can PyTables be applied?
------------------------------

PyTables is not designed to work as a relational database competitor,
but rather as a teammate. If you want to work with large datasets of
multidimensional data (for example, for multidimensional analysis), or
just provide a categorized structure for some portions of your
cluttered RDBS, then give PyTables a try. It works well for storing
data from data acquisition systems (DAS), simulation software, network
data monitoring systems (for example, traffic measurements of IP
packets on routers), very large XML files, or for creating a
centralized repository for system logs, to name only a few possible
uses.

What is a table?
----------------

A table is defined as a collection of records whose values are stored in
fixed-length fields. All records have the same structure and all values
in each field have the same data type.  The terms "fixed-length" and
"strict data types" seem to be quite a strange requirement for a
language like Python that supports dynamic data types, but they serve a
useful function if the goal is to save very large quantities of data
(such as is generated by many scientific applications, for example) in
an efficient manner that reduces demand on CPU time and I/O resources.

What is HDF5?
-------------

For those people who know nothing about HDF5, it is a general purpose
library and file format for storing scientific data made at NCSA. HDF5
can store two primary objects: datasets and groups. A dataset is
essentially a multidimensional array of data elements, and a group is a
structure for organizing objects in an HDF5 file. Using these two basic
constructs, one can create and store almost any kind of scientific data
structure, such as images, arrays of vectors, and structured and
unstructured grids. You can also mix and match them in HDF5 files
according to your needs.

Platforms
---------

I'm using Linux (Intel 32-bit) as the main development platform, but
PyTables should be easy to compile/install on many other UNIX
machines. This package has also passed all the tests on a UltraSparc
platform with Solaris 7 and Solaris 8. It also compiles and passes all
the tests on a SGI Origin2000 with MIPS R12000 processors, with the
MIPSPro compiler and running IRIX 6.5. It also runs fine on Linux
64-bit platforms, like AMD Opteron running GNU/Linux 2.4.21 Server,
Intel Itanium (IA64) running GNU/Linux 2.4.21 or PowerPC G5 with Linux
2.6.x in 64bit mode. It has also been tested in MacOSX platforms (10.2
but should also work on newer versions).

Regarding Windows platforms, PyTables has been tested with Windows
2000 and Windows XP (using the Microsoft Visual C compiler), but it
should also work with other flavors as well.

Web site
--------

Go to the PyTables web site for more details:

http://pytables.sourceforge.net/

To know more about the company behind the PyTables development, see:

http://www.carabos.com/

Share your experience
---------------------

Let me know of any bugs, suggestions, gripes, kudos, etc. you may
have.

Enjoy data!

-- Francesc Altet
